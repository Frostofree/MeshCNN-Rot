tensorboard X not installed, visualizing wont be available
------------ Options -------------
arch: mconvnet
batch_size: 16
beta1: 0.9
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: datasets/M40_512_norm_PCA
dataset_mode: classification
epoch_count: 1
export_folder: 
fc_n: 100
flip_edges: 0.2
gpu_ids: []
init_gain: 0.02
init_type: normal
is_train: True
lr: 0.0002
lr_decay_iters: 50
lr_policy: lambda
max_dataset_size: inf
name: M40
ncf: [32, 64, 128]
ninput_edges: 2000
niter: 100
niter_decay: 100
no_vis: False
norm: group
num_aug: 20
num_groups: 16
num_threads: 3
phase: train
pool_res: [1900, 1700, 1500]
print_freq: 10
resblocks: 1
run_test_freq: 300
save_epoch_freq: 1
save_latest_freq: 250
scale_verts: False
seed: None
serial_batches: False
slide_verts: 0.2
verbose_plot: False
which_epoch: latest
-------------- End ----------------
loaded mean / std from cache
#training meshes = 10187
---------- Network initialized -------------
[Network] Total number of parameters : 0.177 M
-----------------------------------------------
saving the latest model (epoch 1, total_steps 16)
(epoch: 1, iters: 80, time: 0.161, data: 0.750) loss: 3.680 
(epoch: 1, iters: 160, time: 0.164, data: 0.004) loss: 3.710 
(epoch: 1, iters: 240, time: 0.162, data: 0.000) loss: 3.704 
(epoch: 1, iters: 320, time: 0.163, data: 0.005) loss: 3.685 
(epoch: 1, iters: 400, time: 0.163, data: 0.000) loss: 3.688 
(epoch: 1, iters: 480, time: 0.162, data: 0.027) loss: 3.676 
(epoch: 1, iters: 560, time: 0.163, data: 0.000) loss: 3.662 
(epoch: 1, iters: 640, time: 0.163, data: 0.000) loss: 3.662 
(epoch: 1, iters: 720, time: 0.164, data: 0.000) loss: 3.651 
(epoch: 1, iters: 800, time: 0.162, data: 0.005) loss: 3.618 
(epoch: 1, iters: 880, time: 0.162, data: 0.000) loss: 3.602 
(epoch: 1, iters: 960, time: 0.164, data: 0.000) loss: 3.601 
(epoch: 1, iters: 1040, time: 0.164, data: 0.030) loss: 3.614 
(epoch: 1, iters: 1120, time: 0.166, data: 0.000) loss: 3.577 
(epoch: 1, iters: 1200, time: 0.163, data: 0.000) loss: 3.507 
(epoch: 1, iters: 1280, time: 0.164, data: 0.000) loss: 3.489 
(epoch: 1, iters: 1360, time: 0.163, data: 0.010) loss: 3.599 
(epoch: 1, iters: 1440, time: 0.163, data: 0.000) loss: 3.480 
(epoch: 1, iters: 1520, time: 0.163, data: 0.000) loss: 3.392 
(epoch: 1, iters: 1600, time: 0.159, data: 0.021) loss: 3.306 
(epoch: 1, iters: 1680, time: 0.158, data: 0.012) loss: 3.380 
(epoch: 1, iters: 1760, time: 0.159, data: 0.000) loss: 3.380 
(epoch: 1, iters: 1840, time: 0.159, data: 0.005) loss: 3.464 
(epoch: 1, iters: 1920, time: 0.160, data: 0.005) loss: 3.274 
(epoch: 1, iters: 2000, time: 0.162, data: 0.000) loss: 3.145 
(epoch: 1, iters: 2080, time: 0.161, data: 0.000) loss: 3.409 
(epoch: 1, iters: 2160, time: 0.161, data: 0.005) loss: 3.333 
(epoch: 1, iters: 2240, time: 0.167, data: 0.008) loss: 3.278 
(epoch: 1, iters: 2320, time: 0.159, data: 0.030) loss: 3.263 
(epoch: 1, iters: 2400, time: 0.158, data: 0.000) loss: 3.189 
(epoch: 1, iters: 2480, time: 0.158, data: 0.000) loss: 3.487 
(epoch: 1, iters: 2560, time: 0.157, data: 0.004) loss: 3.243 
(epoch: 1, iters: 2640, time: 0.160, data: 0.000) loss: 3.262 
(epoch: 1, iters: 2720, time: 0.158, data: 0.013) loss: 3.335 
(epoch: 1, iters: 2800, time: 0.157, data: 0.008) loss: 3.106 
(epoch: 1, iters: 2880, time: 0.158, data: 0.000) loss: 3.063 
(epoch: 1, iters: 2960, time: 0.158, data: 0.023) loss: 3.393 
(epoch: 1, iters: 3040, time: 0.160, data: 0.000) loss: 3.168 
(epoch: 1, iters: 3120, time: 0.160, data: 0.000) loss: 2.957 
(epoch: 1, iters: 3200, time: 0.160, data: 0.018) loss: 3.396 
(epoch: 1, iters: 3280, time: 0.161, data: 0.011) loss: 3.287 
(epoch: 1, iters: 3360, time: 0.158, data: 0.000) loss: 3.354 
(epoch: 1, iters: 3440, time: 0.157, data: 0.000) loss: 3.094 
(epoch: 1, iters: 3520, time: 0.158, data: 0.025) loss: 3.263 
(epoch: 1, iters: 3600, time: 0.160, data: 0.016) loss: 3.012 
(epoch: 1, iters: 3680, time: 0.160, data: 0.005) loss: 3.142 
(epoch: 1, iters: 3760, time: 0.158, data: 0.000) loss: 3.026 
(epoch: 1, iters: 3840, time: 0.159, data: 0.000) loss: 2.837 
(epoch: 1, iters: 3920, time: 0.159, data: 0.025) loss: 2.958 
(epoch: 1, iters: 4000, time: 0.161, data: 0.028) loss: 3.173 
saving the latest model (epoch 1, total_steps 4016)
(epoch: 1, iters: 4080, time: 0.159, data: 0.000) loss: 3.558 
(epoch: 1, iters: 4160, time: 0.160, data: 0.021) loss: 2.988 
(epoch: 1, iters: 4240, time: 0.159, data: 0.000) loss: 3.126 
(epoch: 1, iters: 4320, time: 0.162, data: 0.000) loss: 3.409 
(epoch: 1, iters: 4400, time: 0.168, data: 0.000) loss: 2.942 
(epoch: 1, iters: 4480, time: 0.160, data: 0.021) loss: 2.988 
(epoch: 1, iters: 4560, time: 0.159, data: 0.000) loss: 3.313 
(epoch: 1, iters: 4640, time: 0.157, data: 0.000) loss: 3.318 
(epoch: 1, iters: 4720, time: 0.159, data: 0.005) loss: 2.778 
(epoch: 1, iters: 4800, time: 0.160, data: 0.000) loss: 3.337 
(epoch: 1, iters: 4880, time: 0.159, data: 0.014) loss: 2.962 
(epoch: 1, iters: 4960, time: 0.157, data: 0.011) loss: 2.984 
(epoch: 1, iters: 5040, time: 0.160, data: 0.000) loss: 3.416 
(epoch: 1, iters: 5120, time: 0.160, data: 0.000) loss: 3.481 
(epoch: 1, iters: 5200, time: 0.159, data: 0.024) loss: 2.917 
(epoch: 1, iters: 5280, time: 0.160, data: 0.000) loss: 2.973 
(epoch: 1, iters: 5360, time: 0.160, data: 0.000) loss: 3.207 
(epoch: 1, iters: 5440, time: 0.159, data: 0.027) loss: 3.282 
(epoch: 1, iters: 5520, time: 0.168, data: 0.000) loss: 3.376 
(epoch: 1, iters: 5600, time: 0.158, data: 0.000) loss: 3.285 
(epoch: 1, iters: 5680, time: 0.159, data: 0.000) loss: 3.303 
(epoch: 1, iters: 5760, time: 0.160, data: 0.000) loss: 3.039 
(epoch: 1, iters: 5840, time: 0.158, data: 0.005) loss: 3.243 
(epoch: 1, iters: 5920, time: 0.158, data: 0.011) loss: 3.063 
(epoch: 1, iters: 6000, time: 0.158, data: 0.000) loss: 2.976 
(epoch: 1, iters: 6080, time: 0.158, data: 0.030) loss: 3.006 
(epoch: 1, iters: 6160, time: 0.156, data: 0.000) loss: 2.987 
(epoch: 1, iters: 6240, time: 0.157, data: 0.000) loss: 3.291 
(epoch: 1, iters: 6320, time: 0.157, data: 0.025) loss: 3.011 
(epoch: 1, iters: 6400, time: 0.160, data: 0.000) loss: 3.185 
(epoch: 1, iters: 6480, time: 0.157, data: 0.000) loss: 2.947 
(epoch: 1, iters: 6560, time: 0.158, data: 0.000) loss: 2.896 
(epoch: 1, iters: 6640, time: 0.157, data: 0.016) loss: 3.140 
(epoch: 1, iters: 6720, time: 0.156, data: 0.029) loss: 3.029 
(epoch: 1, iters: 6800, time: 0.160, data: 0.000) loss: 3.061 
(epoch: 1, iters: 6880, time: 0.157, data: 0.011) loss: 3.212 
(epoch: 1, iters: 6960, time: 0.158, data: 0.026) loss: 3.319 
(epoch: 1, iters: 7040, time: 0.166, data: 0.000) loss: 3.210 
(epoch: 1, iters: 7120, time: 0.156, data: 0.000) loss: 2.776 
(epoch: 1, iters: 7200, time: 0.158, data: 0.000) loss: 3.227 
(epoch: 1, iters: 7280, time: 0.159, data: 0.000) loss: 3.032 
(epoch: 1, iters: 7360, time: 0.159, data: 0.025) loss: 3.054 
(epoch: 1, iters: 7440, time: 0.158, data: 0.000) loss: 2.975 
(epoch: 1, iters: 7520, time: 0.163, data: 0.000) loss: 2.699 
(epoch: 1, iters: 7600, time: 0.157, data: 0.020) loss: 3.149 
(epoch: 1, iters: 7680, time: 0.155, data: 0.000) loss: 3.338 
(epoch: 1, iters: 7760, time: 0.155, data: 0.027) loss: 3.166 
(epoch: 1, iters: 7840, time: 0.158, data: 0.004) loss: 2.995 
(epoch: 1, iters: 7920, time: 0.164, data: 0.010) loss: 3.162 
(epoch: 1, iters: 8000, time: 0.157, data: 0.000) loss: 3.069 
saving the latest model (epoch 1, total_steps 8016)
(epoch: 1, iters: 8080, time: 0.159, data: 0.030) loss: 2.734 
(epoch: 1, iters: 8160, time: 0.156, data: 0.000) loss: 3.191 
(epoch: 1, iters: 8240, time: 0.156, data: 0.000) loss: 2.789 
(epoch: 1, iters: 8320, time: 0.157, data: 0.028) loss: 3.403 
(epoch: 1, iters: 8400, time: 0.156, data: 0.000) loss: 2.883 
(epoch: 1, iters: 8480, time: 0.155, data: 0.000) loss: 3.206 
(epoch: 1, iters: 8560, time: 0.155, data: 0.000) loss: 2.992 
(epoch: 1, iters: 8640, time: 0.155, data: 0.025) loss: 3.173 
(epoch: 1, iters: 8720, time: 0.158, data: 0.000) loss: 2.688 
(epoch: 1, iters: 8800, time: 0.158, data: 0.013) loss: 2.815 
(epoch: 1, iters: 8880, time: 0.156, data: 0.005) loss: 2.968 
(epoch: 1, iters: 8960, time: 0.155, data: 0.000) loss: 2.576 
(epoch: 1, iters: 9040, time: 0.157, data: 0.022) loss: 2.337 
(epoch: 1, iters: 9120, time: 0.157, data: 0.000) loss: 3.373 
(epoch: 1, iters: 9200, time: 0.159, data: 0.000) loss: 3.073 
(epoch: 1, iters: 9280, time: 0.157, data: 0.005) loss: 3.021 
(epoch: 1, iters: 9360, time: 0.156, data: 0.005) loss: 3.146 
(epoch: 1, iters: 9440, time: 0.158, data: 0.000) loss: 2.961 
(epoch: 1, iters: 9520, time: 0.155, data: 0.000) loss: 3.151 
(epoch: 1, iters: 9600, time: 0.155, data: 0.017) loss: 2.655 
(epoch: 1, iters: 9680, time: 0.157, data: 0.011) loss: 2.839 
(epoch: 1, iters: 9760, time: 0.157, data: 0.000) loss: 3.143 
(epoch: 1, iters: 9840, time: 0.155, data: 0.000) loss: 3.103 
(epoch: 1, iters: 9920, time: 0.158, data: 0.017) loss: 2.771 
(epoch: 1, iters: 10000, time: 0.154, data: 0.000) loss: 2.722 
(epoch: 1, iters: 10080, time: 0.157, data: 0.000) loss: 3.145 
(epoch: 1, iters: 10160, time: 0.151, data: 0.046) loss: 2.979 
saving the model at the end of epoch 1, iters 10192
End of epoch 1 / 200 	 Time Taken: 1625 sec
learning rate = 0.0002000
saving the latest model (epoch 2, total_steps 10208)
(epoch: 2, iters: 48, time: 0.155, data: 0.000) loss: 2.837 
(epoch: 2, iters: 128, time: 0.156, data: 0.010) loss: 2.567 
(epoch: 2, iters: 208, time: 0.159, data: 0.009) loss: 2.809 
(epoch: 2, iters: 288, time: 0.156, data: 0.000) loss: 2.521 
(epoch: 2, iters: 368, time: 0.155, data: 0.025) loss: 2.698 
(epoch: 2, iters: 448, time: 0.158, data: 0.029) loss: 2.561 
(epoch: 2, iters: 528, time: 0.158, data: 0.000) loss: 3.182 
(epoch: 2, iters: 608, time: 0.166, data: 0.013) loss: 2.944 
(epoch: 2, iters: 688, time: 0.157, data: 0.000) loss: 3.028 
(epoch: 2, iters: 768, time: 0.159, data: 0.005) loss: 2.785 
(epoch: 2, iters: 848, time: 0.156, data: 0.010) loss: 2.478 
(epoch: 2, iters: 928, time: 0.159, data: 0.000) loss: 3.076 
(epoch: 2, iters: 1008, time: 0.159, data: 0.005) loss: 2.611 
(epoch: 2, iters: 1088, time: 0.159, data: 0.008) loss: 2.962 
(epoch: 2, iters: 1168, time: 0.159, data: 0.000) loss: 3.160 
(epoch: 2, iters: 1248, time: 0.159, data: 0.024) loss: 2.952 
(epoch: 2, iters: 1328, time: 0.162, data: 0.000) loss: 2.706 
(epoch: 2, iters: 1408, time: 0.156, data: 0.000) loss: 2.925 
(epoch: 2, iters: 1488, time: 0.157, data: 0.000) loss: 2.718 
(epoch: 2, iters: 1568, time: 0.157, data: 0.014) loss: 2.843 
(epoch: 2, iters: 1648, time: 0.158, data: 0.000) loss: 3.155 
(epoch: 2, iters: 1728, time: 0.158, data: 0.000) loss: 3.087 
(epoch: 2, iters: 1808, time: 0.159, data: 0.009) loss: 2.603 
(epoch: 2, iters: 1888, time: 0.155, data: 0.000) loss: 3.285 
(epoch: 2, iters: 1968, time: 0.156, data: 0.025) loss: 2.597 
(epoch: 2, iters: 2048, time: 0.158, data: 0.000) loss: 3.233 
(epoch: 2, iters: 2128, time: 0.157, data: 0.005) loss: 3.414 
(epoch: 2, iters: 2208, time: 0.159, data: 0.005) loss: 3.045 
(epoch: 2, iters: 2288, time: 0.159, data: 0.024) loss: 2.873 
(epoch: 2, iters: 2368, time: 0.157, data: 0.008) loss: 3.042 
(epoch: 2, iters: 2448, time: 0.156, data: 0.000) loss: 2.844 
(epoch: 2, iters: 2528, time: 0.158, data: 0.000) loss: 2.877 
(epoch: 2, iters: 2608, time: 0.156, data: 0.000) loss: 2.415 
(epoch: 2, iters: 2688, time: 0.157, data: 0.015) loss: 3.029 
(epoch: 2, iters: 2768, time: 0.158, data: 0.028) loss: 2.849 
(epoch: 2, iters: 2848, time: 0.158, data: 0.000) loss: 2.530 
(epoch: 2, iters: 2928, time: 0.158, data: 0.000) loss: 2.775 
(epoch: 2, iters: 3008, time: 0.158, data: 0.014) loss: 2.884 
(epoch: 2, iters: 3088, time: 0.164, data: 0.000) loss: 2.887 
(epoch: 2, iters: 3168, time: 0.158, data: 0.000) loss: 3.326 
(epoch: 2, iters: 3248, time: 0.155, data: 0.000) loss: 2.478 
(epoch: 2, iters: 3328, time: 0.156, data: 0.000) loss: 2.627 
(epoch: 2, iters: 3408, time: 0.155, data: 0.014) loss: 3.069 
(epoch: 2, iters: 3488, time: 0.158, data: 0.005) loss: 3.077 
(epoch: 2, iters: 3568, time: 0.160, data: 0.000) loss: 3.161 
(epoch: 2, iters: 3648, time: 0.159, data: 0.000) loss: 2.791 
(epoch: 2, iters: 3728, time: 0.158, data: 0.014) loss: 3.029 
(epoch: 2, iters: 3808, time: 0.156, data: 0.005) loss: 2.896 
(epoch: 2, iters: 3888, time: 0.159, data: 0.000) loss: 2.363 
(epoch: 2, iters: 3968, time: 0.160, data: 0.000) loss: 2.822 
saving the latest model (epoch 2, total_steps 14208)
(epoch: 2, iters: 4048, time: 0.157, data: 0.000) loss: 2.537 
(epoch: 2, iters: 4128, time: 0.159, data: 0.000) loss: 2.912 
(epoch: 2, iters: 4208, time: 0.158, data: 0.000) loss: 3.427 
(epoch: 2, iters: 4288, time: 0.155, data: 0.000) loss: 2.976 
(epoch: 2, iters: 4368, time: 0.158, data: 0.000) loss: 2.980 
(epoch: 2, iters: 4448, time: 0.157, data: 0.041) loss: 3.129 
(epoch: 2, iters: 4528, time: 0.158, data: 0.000) loss: 2.397 
(epoch: 2, iters: 4608, time: 0.158, data: 0.000) loss: 2.839 
(epoch: 2, iters: 4688, time: 0.165, data: 0.000) loss: 3.229 
(epoch: 2, iters: 4768, time: 0.157, data: 0.000) loss: 2.538 
(epoch: 2, iters: 4848, time: 0.159, data: 0.000) loss: 3.262 
(epoch: 2, iters: 4928, time: 0.159, data: 0.025) loss: 2.803 
(epoch: 2, iters: 5008, time: 0.159, data: 0.000) loss: 2.824 
(epoch: 2, iters: 5088, time: 0.160, data: 0.010) loss: 2.452 
(epoch: 2, iters: 5168, time: 0.159, data: 0.000) loss: 3.039 
(epoch: 2, iters: 5248, time: 0.158, data: 0.005) loss: 3.064 
(epoch: 2, iters: 5328, time: 0.159, data: 0.000) loss: 3.035 
(epoch: 2, iters: 5408, time: 0.158, data: 0.028) loss: 2.762 
(epoch: 2, iters: 5488, time: 0.157, data: 0.000) loss: 2.816 
(epoch: 2, iters: 5568, time: 0.158, data: 0.000) loss: 2.800 
(epoch: 2, iters: 5648, time: 0.159, data: 0.015) loss: 2.441 
(epoch: 2, iters: 5728, time: 0.156, data: 0.032) loss: 2.688 
(epoch: 2, iters: 5808, time: 0.158, data: 0.000) loss: 2.725 
(epoch: 2, iters: 5888, time: 0.157, data: 0.000) loss: 3.044 
(epoch: 2, iters: 5968, time: 0.155, data: 0.000) loss: 3.105 
(epoch: 2, iters: 6048, time: 0.154, data: 0.000) loss: 2.652 
(epoch: 2, iters: 6128, time: 0.157, data: 0.000) loss: 2.469 
(epoch: 2, iters: 6208, time: 0.158, data: 0.000) loss: 3.144 
(epoch: 2, iters: 6288, time: 0.157, data: 0.016) loss: 2.769 
(epoch: 2, iters: 6368, time: 0.159, data: 0.012) loss: 2.361 
(epoch: 2, iters: 6448, time: 0.158, data: 0.000) loss: 3.088 
(epoch: 2, iters: 6528, time: 0.156, data: 0.000) loss: 2.558 
(epoch: 2, iters: 6608, time: 0.165, data: 0.000) loss: 2.899 
(epoch: 2, iters: 6688, time: 0.157, data: 0.000) loss: 2.229 
(epoch: 2, iters: 6768, time: 0.158, data: 0.031) loss: 2.229 
(epoch: 2, iters: 6848, time: 0.158, data: 0.000) loss: 3.017 
(epoch: 2, iters: 6928, time: 0.157, data: 0.000) loss: 2.941 
(epoch: 2, iters: 7008, time: 0.158, data: 0.005) loss: 2.324 
(epoch: 2, iters: 7088, time: 0.160, data: 0.005) loss: 2.952 
(epoch: 2, iters: 7168, time: 0.159, data: 0.020) loss: 2.783 
(epoch: 2, iters: 7248, time: 0.158, data: 0.000) loss: 2.739 
(epoch: 2, iters: 7328, time: 0.155, data: 0.000) loss: 2.633 
(epoch: 2, iters: 7408, time: 0.155, data: 0.000) loss: 2.455 
(epoch: 2, iters: 7488, time: 0.155, data: 0.005) loss: 2.798 
(epoch: 2, iters: 7568, time: 0.157, data: 0.000) loss: 2.830 
(epoch: 2, iters: 7648, time: 0.156, data: 0.000) loss: 2.994 
(epoch: 2, iters: 7728, time: 0.157, data: 0.008) loss: 3.020 
(epoch: 2, iters: 7808, time: 0.156, data: 0.000) loss: 2.924 
(epoch: 2, iters: 7888, time: 0.157, data: 0.016) loss: 2.649 
(epoch: 2, iters: 7968, time: 0.157, data: 0.000) loss: 3.203 
saving the latest model (epoch 2, total_steps 18208)
(epoch: 2, iters: 8048, time: 0.158, data: 0.021) loss: 2.348 
(epoch: 2, iters: 8128, time: 0.155, data: 0.005) loss: 2.466 
(epoch: 2, iters: 8208, time: 0.156, data: 0.019) loss: 3.380 
(epoch: 2, iters: 8288, time: 0.161, data: 0.000) loss: 2.305 
(epoch: 2, iters: 8368, time: 0.160, data: 0.005) loss: 2.727 
(epoch: 2, iters: 8448, time: 0.157, data: 0.005) loss: 2.323 
(epoch: 2, iters: 8528, time: 0.161, data: 0.000) loss: 2.963 
(epoch: 2, iters: 8608, time: 0.158, data: 0.005) loss: 3.265 
(epoch: 2, iters: 8688, time: 0.158, data: 0.000) loss: 1.962 
(epoch: 2, iters: 8768, time: 0.157, data: 0.008) loss: 2.966 
(epoch: 2, iters: 8848, time: 0.156, data: 0.013) loss: 2.514 
(epoch: 2, iters: 8928, time: 0.160, data: 0.000) loss: 2.484 
(epoch: 2, iters: 9008, time: 0.159, data: 0.000) loss: 3.589 
(epoch: 2, iters: 9088, time: 0.157, data: 0.000) loss: 2.282 
(epoch: 2, iters: 9168, time: 0.156, data: 0.033) loss: 3.024 
(epoch: 2, iters: 9248, time: 0.161, data: 0.000) loss: 2.622 
(epoch: 2, iters: 9328, time: 0.156, data: 0.000) loss: 2.798 
(epoch: 2, iters: 9408, time: 0.157, data: 0.000) loss: 2.985 
(epoch: 2, iters: 9488, time: 0.159, data: 0.000) loss: 2.938 
(epoch: 2, iters: 9568, time: 0.158, data: 0.000) loss: 2.879 
(epoch: 2, iters: 9648, time: 0.159, data: 0.010) loss: 2.845 
(epoch: 2, iters: 9728, time: 0.157, data: 0.005) loss: 2.689 
(epoch: 2, iters: 9808, time: 0.155, data: 0.000) loss: 3.448 
(epoch: 2, iters: 9888, time: 0.159, data: 0.018) loss: 2.511 
(epoch: 2, iters: 9968, time: 0.158, data: 0.005) loss: 2.388 
(epoch: 2, iters: 10048, time: 0.156, data: 0.005) loss: 2.993 
(epoch: 2, iters: 10128, time: 0.150, data: 0.005) loss: 2.920 
saving the model at the end of epoch 2, iters 20384
End of epoch 2 / 200 	 Time Taken: 1612 sec
learning rate = 0.0002000
(epoch: 3, iters: 16, time: 0.188, data: 0.005) loss: 2.626 
saving the latest model (epoch 3, total_steps 20400)
(epoch: 3, iters: 96, time: 0.158, data: 0.023) loss: 2.604 
(epoch: 3, iters: 176, time: 0.157, data: 0.009) loss: 2.796 
(epoch: 3, iters: 256, time: 0.157, data: 0.017) loss: 2.308 
(epoch: 3, iters: 336, time: 0.158, data: 0.000) loss: 2.615 
(epoch: 3, iters: 416, time: 0.155, data: 0.000) loss: 2.759 
(epoch: 3, iters: 496, time: 0.157, data: 0.009) loss: 2.350 
(epoch: 3, iters: 576, time: 0.158, data: 0.005) loss: 2.891 
(epoch: 3, iters: 656, time: 0.163, data: 0.000) loss: 2.748 
(epoch: 3, iters: 736, time: 0.158, data: 0.019) loss: 3.481 
(epoch: 3, iters: 816, time: 0.159, data: 0.028) loss: 2.488 
(epoch: 3, iters: 896, time: 0.157, data: 0.000) loss: 1.964 
(epoch: 3, iters: 976, time: 0.158, data: 0.037) loss: 2.266 
(epoch: 3, iters: 1056, time: 0.159, data: 0.000) loss: 3.015 
(epoch: 3, iters: 1136, time: 0.157, data: 0.009) loss: 2.437 
(epoch: 3, iters: 1216, time: 0.157, data: 0.009) loss: 2.689 
(epoch: 3, iters: 1296, time: 0.157, data: 0.000) loss: 2.658 
(epoch: 3, iters: 1376, time: 0.157, data: 0.024) loss: 2.346 
(epoch: 3, iters: 1456, time: 0.156, data: 0.000) loss: 2.991 
(epoch: 3, iters: 1536, time: 0.155, data: 0.011) loss: 2.759 
(epoch: 3, iters: 1616, time: 0.156, data: 0.000) loss: 2.574 
(epoch: 3, iters: 1696, time: 0.156, data: 0.000) loss: 2.749 
(epoch: 3, iters: 1776, time: 0.157, data: 0.000) loss: 3.015 
(epoch: 3, iters: 1856, time: 0.157, data: 0.000) loss: 2.191 
(epoch: 3, iters: 1936, time: 0.156, data: 0.000) loss: 3.002 
(epoch: 3, iters: 2016, time: 0.155, data: 0.005) loss: 2.328 
(epoch: 3, iters: 2096, time: 0.157, data: 0.000) loss: 2.074 
(epoch: 3, iters: 2176, time: 0.156, data: 0.008) loss: 2.703 
(epoch: 3, iters: 2256, time: 0.155, data: 0.000) loss: 2.856 
(epoch: 3, iters: 2336, time: 0.157, data: 0.015) loss: 2.980 
(epoch: 3, iters: 2416, time: 0.157, data: 0.000) loss: 2.532 
(epoch: 3, iters: 2496, time: 0.156, data: 0.024) loss: 2.384 
(epoch: 3, iters: 2576, time: 0.157, data: 0.000) loss: 2.931 
(epoch: 3, iters: 2656, time: 0.163, data: 0.005) loss: 2.842 
(epoch: 3, iters: 2736, time: 0.154, data: 0.000) loss: 2.440 
(epoch: 3, iters: 2816, time: 0.156, data: 0.000) loss: 2.672 
(epoch: 3, iters: 2896, time: 0.155, data: 0.000) loss: 2.925 
(epoch: 3, iters: 2976, time: 0.158, data: 0.000) loss: 2.712 
(epoch: 3, iters: 3056, time: 0.157, data: 0.000) loss: 2.304 
(epoch: 3, iters: 3136, time: 0.155, data: 0.032) loss: 2.746 
(epoch: 3, iters: 3216, time: 0.156, data: 0.014) loss: 2.464 
(epoch: 3, iters: 3296, time: 0.158, data: 0.013) loss: 2.267 
(epoch: 3, iters: 3376, time: 0.155, data: 0.023) loss: 2.326 
(epoch: 3, iters: 3456, time: 0.159, data: 0.000) loss: 2.993 
(epoch: 3, iters: 3536, time: 0.158, data: 0.017) loss: 2.676 
(epoch: 3, iters: 3616, time: 0.159, data: 0.000) loss: 2.684 
(epoch: 3, iters: 3696, time: 0.160, data: 0.000) loss: 2.589 
(epoch: 3, iters: 3776, time: 0.159, data: 0.000) loss: 2.050 
(epoch: 3, iters: 3856, time: 0.159, data: 0.000) loss: 2.423 
(epoch: 3, iters: 3936, time: 0.159, data: 0.018) loss: 2.245 
(epoch: 3, iters: 4016, time: 0.161, data: 0.008) loss: 2.966 
saving the latest model (epoch 3, total_steps 24400)
(epoch: 3, iters: 4096, time: 0.157, data: 0.000) loss: 2.291 
(epoch: 3, iters: 4176, time: 0.168, data: 0.000) loss: 2.670 
(epoch: 3, iters: 4256, time: 0.157, data: 0.021) loss: 2.359 
(epoch: 3, iters: 4336, time: 0.164, data: 0.000) loss: 2.295 
(epoch: 3, iters: 4416, time: 0.155, data: 0.000) loss: 2.136 
(epoch: 3, iters: 4496, time: 0.156, data: 0.015) loss: 2.504 
(epoch: 3, iters: 4576, time: 0.156, data: 0.022) loss: 2.068 
(epoch: 3, iters: 4656, time: 0.154, data: 0.000) loss: 2.423 
(epoch: 3, iters: 4736, time: 0.154, data: 0.005) loss: 1.961 
(epoch: 3, iters: 4816, time: 0.156, data: 0.000) loss: 2.067 
(epoch: 3, iters: 4896, time: 0.156, data: 0.000) loss: 2.545 
(epoch: 3, iters: 4976, time: 0.156, data: 0.016) loss: 2.793 
(epoch: 3, iters: 5056, time: 0.156, data: 0.000) loss: 2.045 
(epoch: 3, iters: 5136, time: 0.155, data: 0.036) loss: 2.897 
(epoch: 3, iters: 5216, time: 0.157, data: 0.000) loss: 2.380 
(epoch: 3, iters: 5296, time: 0.156, data: 0.000) loss: 2.205 
(epoch: 3, iters: 5376, time: 0.159, data: 0.000) loss: 2.885 
(epoch: 3, iters: 5456, time: 0.158, data: 0.000) loss: 2.793 
(epoch: 3, iters: 5536, time: 0.155, data: 0.000) loss: 2.520 
(epoch: 3, iters: 5616, time: 0.156, data: 0.000) loss: 2.663 
(epoch: 3, iters: 5696, time: 0.156, data: 0.009) loss: 2.669 
(epoch: 3, iters: 5776, time: 0.157, data: 0.010) loss: 2.423 
(epoch: 3, iters: 5856, time: 0.159, data: 0.000) loss: 2.246 
(epoch: 3, iters: 5936, time: 0.158, data: 0.025) loss: 2.640 
(epoch: 3, iters: 6016, time: 0.157, data: 0.000) loss: 2.316 
(epoch: 3, iters: 6096, time: 0.155, data: 0.024) loss: 2.232 
(epoch: 3, iters: 6176, time: 0.156, data: 0.000) loss: 2.449 
(epoch: 3, iters: 6256, time: 0.156, data: 0.032) loss: 2.529 
(epoch: 3, iters: 6336, time: 0.157, data: 0.000) loss: 2.569 
(epoch: 3, iters: 6416, time: 0.155, data: 0.005) loss: 2.451 
(epoch: 3, iters: 6496, time: 0.155, data: 0.021) loss: 2.483 
(epoch: 3, iters: 6576, time: 0.158, data: 0.000) loss: 2.983 
(epoch: 3, iters: 6656, time: 0.155, data: 0.000) loss: 2.561 
(epoch: 3, iters: 6736, time: 0.155, data: 0.000) loss: 2.265 
(epoch: 3, iters: 6816, time: 0.157, data: 0.000) loss: 2.938 
(epoch: 3, iters: 6896, time: 0.154, data: 0.020) loss: 2.391 
(epoch: 3, iters: 6976, time: 0.157, data: 0.010) loss: 2.486 
(epoch: 3, iters: 7056, time: 0.157, data: 0.000) loss: 2.610 
(epoch: 3, iters: 7136, time: 0.153, data: 0.000) loss: 2.461 
(epoch: 3, iters: 7216, time: 0.157, data: 0.017) loss: 2.900 
(epoch: 3, iters: 7296, time: 0.167, data: 0.000) loss: 1.947 
(epoch: 3, iters: 7376, time: 0.158, data: 0.005) loss: 2.512 
(epoch: 3, iters: 7456, time: 0.158, data: 0.000) loss: 2.312 
(epoch: 3, iters: 7536, time: 0.163, data: 0.000) loss: 2.100 
(epoch: 3, iters: 7616, time: 0.156, data: 0.014) loss: 2.850 
(epoch: 3, iters: 7696, time: 0.155, data: 0.000) loss: 2.338 
(epoch: 3, iters: 7776, time: 0.157, data: 0.000) loss: 2.527 
(epoch: 3, iters: 7856, time: 0.155, data: 0.015) loss: 2.388 
(epoch: 3, iters: 7936, time: 0.160, data: 0.023) loss: 2.613 
(epoch: 3, iters: 8016, time: 0.159, data: 0.000) loss: 2.486 
saving the latest model (epoch 3, total_steps 28400)
(epoch: 3, iters: 8096, time: 0.159, data: 0.000) loss: 3.176 
(epoch: 3, iters: 8176, time: 0.157, data: 0.000) loss: 2.254 
(epoch: 3, iters: 8256, time: 0.160, data: 0.021) loss: 2.415 
(epoch: 3, iters: 8336, time: 0.157, data: 0.000) loss: 2.779 
(epoch: 3, iters: 8416, time: 0.158, data: 0.005) loss: 2.259 
(epoch: 3, iters: 8496, time: 0.160, data: 0.004) loss: 2.348 
(epoch: 3, iters: 8576, time: 0.157, data: 0.000) loss: 2.352 
(epoch: 3, iters: 8656, time: 0.158, data: 0.000) loss: 2.316 
(epoch: 3, iters: 8736, time: 0.157, data: 0.015) loss: 2.719 
(epoch: 3, iters: 8816, time: 0.157, data: 0.000) loss: 1.554 
(epoch: 3, iters: 8896, time: 0.158, data: 0.005) loss: 2.842 
(epoch: 3, iters: 8976, time: 0.155, data: 0.005) loss: 2.783 
(epoch: 3, iters: 9056, time: 0.157, data: 0.005) loss: 2.600 
(epoch: 3, iters: 9136, time: 0.157, data: 0.008) loss: 2.741 
(epoch: 3, iters: 9216, time: 0.157, data: 0.005) loss: 2.259 
(epoch: 3, iters: 9296, time: 0.157, data: 0.029) loss: 2.357 
(epoch: 3, iters: 9376, time: 0.156, data: 0.009) loss: 2.424 
(epoch: 3, iters: 9456, time: 0.158, data: 0.000) loss: 2.104 
(epoch: 3, iters: 9536, time: 0.158, data: 0.032) loss: 2.066 
(epoch: 3, iters: 9616, time: 0.157, data: 0.000) loss: 2.658 
(epoch: 3, iters: 9696, time: 0.157, data: 0.000) loss: 2.500 
(epoch: 3, iters: 9776, time: 0.157, data: 0.000) loss: 2.411 
(epoch: 3, iters: 9856, time: 0.162, data: 0.000) loss: 2.077 
(epoch: 3, iters: 9936, time: 0.159, data: 0.016) loss: 2.113 
(epoch: 3, iters: 10016, time: 0.157, data: 0.000) loss: 2.798 
(epoch: 3, iters: 10096, time: 0.159, data: 0.005) loss: 2.948 
(epoch: 3, iters: 10176, time: 0.152, data: 0.000) loss: 2.464 
saving the model at the end of epoch 3, iters 30576
End of epoch 3 / 200 	 Time Taken: 1605 sec
learning rate = 0.0002000
saving the latest model (epoch 4, total_steps 30592)
(epoch: 4, iters: 64, time: 0.155, data: 0.003) loss: 2.549 
(epoch: 4, iters: 144, time: 0.154, data: 0.014) loss: 2.608 
(epoch: 4, iters: 224, time: 0.153, data: 0.011) loss: 2.884 
(epoch: 4, iters: 304, time: 0.152, data: 0.000) loss: 2.284 
(epoch: 4, iters: 384, time: 0.155, data: 0.000) loss: 2.428 
(epoch: 4, iters: 464, time: 0.160, data: 0.000) loss: 2.123 
(epoch: 4, iters: 544, time: 0.154, data: 0.033) loss: 2.913 
(epoch: 4, iters: 624, time: 0.154, data: 0.000) loss: 2.305 
(epoch: 4, iters: 704, time: 0.155, data: 0.000) loss: 2.532 
(epoch: 4, iters: 784, time: 0.153, data: 0.025) loss: 2.059 
(epoch: 4, iters: 864, time: 0.154, data: 0.000) loss: 2.262 
(epoch: 4, iters: 944, time: 0.154, data: 0.006) loss: 2.465 
(epoch: 4, iters: 1024, time: 0.155, data: 0.005) loss: 2.341 
(epoch: 4, iters: 1104, time: 0.153, data: 0.000) loss: 2.615 
(epoch: 4, iters: 1184, time: 0.155, data: 0.000) loss: 2.422 
(epoch: 4, iters: 1264, time: 0.153, data: 0.031) loss: 2.665 
(epoch: 4, iters: 1344, time: 0.154, data: 0.000) loss: 2.598 
(epoch: 4, iters: 1424, time: 0.153, data: 0.005) loss: 2.809 
(epoch: 4, iters: 1504, time: 0.162, data: 0.005) loss: 2.772 
(epoch: 4, iters: 1584, time: 0.154, data: 0.005) loss: 2.537 
(epoch: 4, iters: 1664, time: 0.153, data: 0.000) loss: 2.061 
(epoch: 4, iters: 1744, time: 0.153, data: 0.014) loss: 2.291 
(epoch: 4, iters: 1824, time: 0.154, data: 0.000) loss: 2.331 
(epoch: 4, iters: 1904, time: 0.154, data: 0.008) loss: 2.311 
(epoch: 4, iters: 1984, time: 0.153, data: 0.000) loss: 1.877 
(epoch: 4, iters: 2064, time: 0.155, data: 0.034) loss: 2.246 
(epoch: 4, iters: 2144, time: 0.156, data: 0.000) loss: 2.721 
(epoch: 4, iters: 2224, time: 0.158, data: 0.000) loss: 2.712 
(epoch: 4, iters: 2304, time: 0.155, data: 0.000) loss: 2.228 
(epoch: 4, iters: 2384, time: 0.155, data: 0.027) loss: 2.278 
(epoch: 4, iters: 2464, time: 0.157, data: 0.000) loss: 2.730 
(epoch: 4, iters: 2544, time: 0.155, data: 0.024) loss: 2.264 
(epoch: 4, iters: 2624, time: 0.156, data: 0.000) loss: 2.309 
(epoch: 4, iters: 2704, time: 0.159, data: 0.000) loss: 3.094 
(epoch: 4, iters: 2784, time: 0.155, data: 0.000) loss: 2.421 
(epoch: 4, iters: 2864, time: 0.157, data: 0.016) loss: 2.294 
(epoch: 4, iters: 2944, time: 0.154, data: 0.005) loss: 1.882 
(epoch: 4, iters: 3024, time: 0.157, data: 0.005) loss: 2.351 
(epoch: 4, iters: 3104, time: 0.157, data: 0.000) loss: 3.081 
(epoch: 4, iters: 3184, time: 0.155, data: 0.000) loss: 2.098 
(epoch: 4, iters: 3264, time: 0.156, data: 0.000) loss: 2.023 
(epoch: 4, iters: 3344, time: 0.155, data: 0.000) loss: 2.727 
(epoch: 4, iters: 3424, time: 0.155, data: 0.000) loss: 2.336 
(epoch: 4, iters: 3504, time: 0.155, data: 0.019) loss: 2.647 
(epoch: 4, iters: 3584, time: 0.156, data: 0.000) loss: 2.922 
(epoch: 4, iters: 3664, time: 0.157, data: 0.000) loss: 2.353 
(epoch: 4, iters: 3744, time: 0.156, data: 0.000) loss: 2.271 
(epoch: 4, iters: 3824, time: 0.157, data: 0.008) loss: 2.460 
(epoch: 4, iters: 3904, time: 0.157, data: 0.024) loss: 2.554 
(epoch: 4, iters: 3984, time: 0.158, data: 0.000) loss: 2.103 
saving the latest model (epoch 4, total_steps 34592)
(epoch: 4, iters: 4064, time: 0.155, data: 0.000) loss: 2.024 
(epoch: 4, iters: 4144, time: 0.156, data: 0.000) loss: 2.220 
(epoch: 4, iters: 4224, time: 0.159, data: 0.018) loss: 2.792 
(epoch: 4, iters: 4304, time: 0.157, data: 0.000) loss: 2.393 
(epoch: 4, iters: 4384, time: 0.159, data: 0.005) loss: 2.593 
(epoch: 4, iters: 4464, time: 0.157, data: 0.005) loss: 2.438 
(epoch: 4, iters: 4544, time: 0.156, data: 0.000) loss: 2.909 
(epoch: 4, iters: 4624, time: 0.156, data: 0.000) loss: 2.436 
(epoch: 4, iters: 4704, time: 0.154, data: 0.010) loss: 2.318 
(epoch: 4, iters: 4784, time: 0.155, data: 0.008) loss: 2.483 
(epoch: 4, iters: 4864, time: 0.155, data: 0.008) loss: 2.537 
(epoch: 4, iters: 4944, time: 0.157, data: 0.005) loss: 2.304 
(epoch: 4, iters: 5024, time: 0.157, data: 0.000) loss: 2.724 
(epoch: 4, iters: 5104, time: 0.157, data: 0.022) loss: 2.636 
(epoch: 4, iters: 5184, time: 0.155, data: 0.000) loss: 2.504 
(epoch: 4, iters: 5264, time: 0.156, data: 0.005) loss: 2.119 
(epoch: 4, iters: 5344, time: 0.156, data: 0.009) loss: 2.958 
(epoch: 4, iters: 5424, time: 0.156, data: 0.000) loss: 2.641 
(epoch: 4, iters: 5504, time: 0.155, data: 0.005) loss: 2.785 
(epoch: 4, iters: 5584, time: 0.157, data: 0.021) loss: 2.371 
(epoch: 4, iters: 5664, time: 0.154, data: 0.005) loss: 2.386 
(epoch: 4, iters: 5744, time: 0.156, data: 0.000) loss: 2.098 
(epoch: 4, iters: 5824, time: 0.155, data: 0.000) loss: 2.191 
(epoch: 4, iters: 5904, time: 0.155, data: 0.000) loss: 2.813 
(epoch: 4, iters: 5984, time: 0.155, data: 0.021) loss: 2.287 
(epoch: 4, iters: 6064, time: 0.155, data: 0.000) loss: 2.719 
(epoch: 4, iters: 6144, time: 0.155, data: 0.014) loss: 2.408 
(epoch: 4, iters: 6224, time: 0.154, data: 0.005) loss: 2.537 
(epoch: 4, iters: 6304, time: 0.155, data: 0.005) loss: 2.911 
(epoch: 4, iters: 6384, time: 0.157, data: 0.000) loss: 2.392 
(epoch: 4, iters: 6464, time: 0.155, data: 0.015) loss: 2.669 
(epoch: 4, iters: 6544, time: 0.155, data: 0.005) loss: 2.618 
(epoch: 4, iters: 6624, time: 0.154, data: 0.000) loss: 2.568 
(epoch: 4, iters: 6704, time: 0.155, data: 0.032) loss: 2.478 
(epoch: 4, iters: 6784, time: 0.155, data: 0.000) loss: 2.557 
(epoch: 4, iters: 6864, time: 0.156, data: 0.010) loss: 2.502 
(epoch: 4, iters: 6944, time: 0.156, data: 0.000) loss: 2.178 
(epoch: 4, iters: 7024, time: 0.155, data: 0.016) loss: 2.560 
(epoch: 4, iters: 7104, time: 0.155, data: 0.000) loss: 2.246 
(epoch: 4, iters: 7184, time: 0.158, data: 0.005) loss: 2.246 
(epoch: 4, iters: 7264, time: 0.156, data: 0.015) loss: 2.584 
(epoch: 4, iters: 7344, time: 0.157, data: 0.000) loss: 2.064 
(epoch: 4, iters: 7424, time: 0.157, data: 0.005) loss: 2.387 
(epoch: 4, iters: 7504, time: 0.154, data: 0.000) loss: 2.073 
(epoch: 4, iters: 7584, time: 0.155, data: 0.023) loss: 2.591 
(epoch: 4, iters: 7664, time: 0.155, data: 0.000) loss: 2.118 
(epoch: 4, iters: 7744, time: 0.154, data: 0.022) loss: 2.501 
(epoch: 4, iters: 7824, time: 0.155, data: 0.020) loss: 2.342 
(epoch: 4, iters: 7904, time: 0.155, data: 0.005) loss: 2.305 
(epoch: 4, iters: 7984, time: 0.154, data: 0.009) loss: 2.615 
saving the latest model (epoch 4, total_steps 38592)
(epoch: 4, iters: 8064, time: 0.157, data: 0.008) loss: 2.667 
(epoch: 4, iters: 8144, time: 0.154, data: 0.008) loss: 2.761 
(epoch: 4, iters: 8224, time: 0.155, data: 0.005) loss: 2.003 
(epoch: 4, iters: 8304, time: 0.157, data: 0.000) loss: 2.361 
(epoch: 4, iters: 8384, time: 0.153, data: 0.000) loss: 2.880 
(epoch: 4, iters: 8464, time: 0.156, data: 0.013) loss: 2.480 
(epoch: 4, iters: 8544, time: 0.155, data: 0.000) loss: 2.045 
(epoch: 4, iters: 8624, time: 0.156, data: 0.023) loss: 1.817 
(epoch: 4, iters: 8704, time: 0.156, data: 0.000) loss: 2.963 
(epoch: 4, iters: 8784, time: 0.156, data: 0.008) loss: 2.307 
(epoch: 4, iters: 8864, time: 0.157, data: 0.000) loss: 2.661 
(epoch: 4, iters: 8944, time: 0.155, data: 0.010) loss: 2.433 
(epoch: 4, iters: 9024, time: 0.156, data: 0.000) loss: 2.171 
(epoch: 4, iters: 9104, time: 0.157, data: 0.000) loss: 3.139 
(epoch: 4, iters: 9184, time: 0.156, data: 0.016) loss: 2.642 
(epoch: 4, iters: 9264, time: 0.154, data: 0.018) loss: 2.414 
(epoch: 4, iters: 9344, time: 0.166, data: 0.000) loss: 2.387 
(epoch: 4, iters: 9424, time: 0.155, data: 0.017) loss: 2.188 
(epoch: 4, iters: 9504, time: 0.157, data: 0.000) loss: 2.350 
(epoch: 4, iters: 9584, time: 0.155, data: 0.000) loss: 2.167 
(epoch: 4, iters: 9664, time: 0.155, data: 0.005) loss: 2.350 
(epoch: 4, iters: 9744, time: 0.156, data: 0.000) loss: 2.804 
(epoch: 4, iters: 9824, time: 0.155, data: 0.020) loss: 2.049 
(epoch: 4, iters: 9904, time: 0.156, data: 0.000) loss: 2.431 
(epoch: 4, iters: 9984, time: 0.154, data: 0.018) loss: 2.616 
(epoch: 4, iters: 10064, time: 0.158, data: 0.000) loss: 2.585 
(epoch: 4, iters: 10144, time: 0.152, data: 0.000) loss: 1.918 
saving the model at the end of epoch 4, iters 40768
End of epoch 4 / 200 	 Time Taken: 1589 sec
learning rate = 0.0002000
saving the latest model (epoch 5, total_steps 40784)
(epoch: 5, iters: 32, time: 0.162, data: 0.004) loss: 2.625 
(epoch: 5, iters: 112, time: 0.157, data: 0.000) loss: 2.205 
(epoch: 5, iters: 192, time: 0.158, data: 0.000) loss: 2.371 
(epoch: 5, iters: 272, time: 0.158, data: 0.035) loss: 2.651 
(epoch: 5, iters: 352, time: 0.155, data: 0.000) loss: 2.293 
(epoch: 5, iters: 432, time: 0.157, data: 0.005) loss: 2.260 
(epoch: 5, iters: 512, time: 0.158, data: 0.005) loss: 2.681 
(epoch: 5, iters: 592, time: 0.157, data: 0.015) loss: 1.787 
(epoch: 5, iters: 672, time: 0.156, data: 0.008) loss: 2.771 
(epoch: 5, iters: 752, time: 0.155, data: 0.000) loss: 2.120 
(epoch: 5, iters: 832, time: 0.156, data: 0.000) loss: 2.513 
(epoch: 5, iters: 912, time: 0.157, data: 0.018) loss: 2.876 
(epoch: 5, iters: 992, time: 0.156, data: 0.000) loss: 2.098 
(epoch: 5, iters: 1072, time: 0.155, data: 0.021) loss: 1.894 
(epoch: 5, iters: 1152, time: 0.158, data: 0.000) loss: 1.925 
(epoch: 5, iters: 1232, time: 0.155, data: 0.008) loss: 2.286 
(epoch: 5, iters: 1312, time: 0.155, data: 0.005) loss: 2.517 
(epoch: 5, iters: 1392, time: 0.158, data: 0.009) loss: 1.778 
(epoch: 5, iters: 1472, time: 0.157, data: 0.000) loss: 2.652 
(epoch: 5, iters: 1552, time: 0.156, data: 0.005) loss: 2.405 
(epoch: 5, iters: 1632, time: 0.157, data: 0.000) loss: 2.462 
(epoch: 5, iters: 1712, time: 0.156, data: 0.015) loss: 2.383 
(epoch: 5, iters: 1792, time: 0.157, data: 0.000) loss: 1.900 
(epoch: 5, iters: 1872, time: 0.155, data: 0.000) loss: 1.993 
(epoch: 5, iters: 1952, time: 0.156, data: 0.005) loss: 2.898 
(epoch: 5, iters: 2032, time: 0.156, data: 0.005) loss: 2.586 
(epoch: 5, iters: 2112, time: 0.156, data: 0.000) loss: 1.917 
(epoch: 5, iters: 2192, time: 0.157, data: 0.009) loss: 1.920 
(epoch: 5, iters: 2272, time: 0.157, data: 0.032) loss: 2.299 
(epoch: 5, iters: 2352, time: 0.156, data: 0.000) loss: 1.693 
(epoch: 5, iters: 2432, time: 0.157, data: 0.000) loss: 2.346 
(epoch: 5, iters: 2512, time: 0.160, data: 0.005) loss: 2.209 
(epoch: 5, iters: 2592, time: 0.164, data: 0.011) loss: 2.013 
(epoch: 5, iters: 2672, time: 0.158, data: 0.000) loss: 2.335 
(epoch: 5, iters: 2752, time: 0.156, data: 0.012) loss: 2.339 
(epoch: 5, iters: 2832, time: 0.156, data: 0.015) loss: 2.638 
(epoch: 5, iters: 2912, time: 0.156, data: 0.000) loss: 2.062 
(epoch: 5, iters: 2992, time: 0.157, data: 0.000) loss: 2.617 
(epoch: 5, iters: 3072, time: 0.157, data: 0.021) loss: 2.068 
(epoch: 5, iters: 3152, time: 0.158, data: 0.005) loss: 2.143 
(epoch: 5, iters: 3232, time: 0.157, data: 0.005) loss: 1.853 
(epoch: 5, iters: 3312, time: 0.155, data: 0.005) loss: 1.630 
(epoch: 5, iters: 3392, time: 0.157, data: 0.000) loss: 2.180 
(epoch: 5, iters: 3472, time: 0.155, data: 0.000) loss: 2.187 
(epoch: 5, iters: 3552, time: 0.157, data: 0.020) loss: 2.601 
(epoch: 5, iters: 3632, time: 0.156, data: 0.005) loss: 2.322 
(epoch: 5, iters: 3712, time: 0.156, data: 0.018) loss: 2.437 
(epoch: 5, iters: 3792, time: 0.156, data: 0.000) loss: 2.543 
(epoch: 5, iters: 3872, time: 0.156, data: 0.005) loss: 2.568 
(epoch: 5, iters: 3952, time: 0.157, data: 0.008) loss: 2.295 
saving the latest model (epoch 5, total_steps 44784)
(epoch: 5, iters: 4032, time: 0.156, data: 0.009) loss: 2.057 
(epoch: 5, iters: 4112, time: 0.155, data: 0.008) loss: 2.627 
(epoch: 5, iters: 4192, time: 0.157, data: 0.000) loss: 2.855 
(epoch: 5, iters: 4272, time: 0.157, data: 0.000) loss: 2.110 
(epoch: 5, iters: 4352, time: 0.157, data: 0.005) loss: 2.386 
(epoch: 5, iters: 4432, time: 0.158, data: 0.000) loss: 2.003 
(epoch: 5, iters: 4512, time: 0.156, data: 0.041) loss: 1.796 
(epoch: 5, iters: 4592, time: 0.158, data: 0.000) loss: 2.147 
(epoch: 5, iters: 4672, time: 0.158, data: 0.000) loss: 2.057 
(epoch: 5, iters: 4752, time: 0.157, data: 0.000) loss: 2.481 
(epoch: 5, iters: 4832, time: 0.159, data: 0.023) loss: 2.195 
(epoch: 5, iters: 4912, time: 0.158, data: 0.000) loss: 1.858 
(epoch: 5, iters: 4992, time: 0.157, data: 0.005) loss: 1.549 
(epoch: 5, iters: 5072, time: 0.158, data: 0.000) loss: 2.527 
(epoch: 5, iters: 5152, time: 0.157, data: 0.010) loss: 2.254 
(epoch: 5, iters: 5232, time: 0.157, data: 0.000) loss: 2.199 
(epoch: 5, iters: 5312, time: 0.156, data: 0.000) loss: 2.840 
(epoch: 5, iters: 5392, time: 0.155, data: 0.000) loss: 1.881 
(epoch: 5, iters: 5472, time: 0.154, data: 0.000) loss: 2.359 
(epoch: 5, iters: 5552, time: 0.155, data: 0.000) loss: 2.261 
(epoch: 5, iters: 5632, time: 0.155, data: 0.005) loss: 2.315 
(epoch: 5, iters: 5712, time: 0.155, data: 0.000) loss: 2.402 
(epoch: 5, iters: 5792, time: 0.155, data: 0.029) loss: 1.922 
(epoch: 5, iters: 5872, time: 0.156, data: 0.000) loss: 2.165 
(epoch: 5, iters: 5952, time: 0.155, data: 0.000) loss: 2.024 
(epoch: 5, iters: 6032, time: 0.155, data: 0.000) loss: 2.081 
(epoch: 5, iters: 6112, time: 0.158, data: 0.000) loss: 2.158 
(epoch: 5, iters: 6192, time: 0.155, data: 0.000) loss: 2.384 
(epoch: 5, iters: 6272, time: 0.155, data: 0.005) loss: 1.598 
(epoch: 5, iters: 6352, time: 0.153, data: 0.000) loss: 1.914 
(epoch: 5, iters: 6432, time: 0.157, data: 0.035) loss: 2.914 
(epoch: 5, iters: 6512, time: 0.158, data: 0.000) loss: 2.239 
(epoch: 5, iters: 6592, time: 0.157, data: 0.000) loss: 2.350 
(epoch: 5, iters: 6672, time: 0.163, data: 0.005) loss: 2.012 
(epoch: 5, iters: 6752, time: 0.157, data: 0.000) loss: 2.258 
(epoch: 5, iters: 6832, time: 0.156, data: 0.018) loss: 2.111 
(epoch: 5, iters: 6912, time: 0.155, data: 0.000) loss: 1.916 
(epoch: 5, iters: 6992, time: 0.157, data: 0.008) loss: 2.303 
(epoch: 5, iters: 7072, time: 0.158, data: 0.000) loss: 2.501 
(epoch: 5, iters: 7152, time: 0.155, data: 0.000) loss: 2.021 
(epoch: 5, iters: 7232, time: 0.157, data: 0.000) loss: 2.471 
(epoch: 5, iters: 7312, time: 0.155, data: 0.000) loss: 2.519 
(epoch: 5, iters: 7392, time: 0.157, data: 0.000) loss: 1.917 
(epoch: 5, iters: 7472, time: 0.159, data: 0.022) loss: 1.494 
(epoch: 5, iters: 7552, time: 0.156, data: 0.000) loss: 2.590 
(epoch: 5, iters: 7632, time: 0.157, data: 0.000) loss: 2.471 
(epoch: 5, iters: 7712, time: 0.155, data: 0.008) loss: 2.517 
(epoch: 5, iters: 7792, time: 0.155, data: 0.000) loss: 2.128 
(epoch: 5, iters: 7872, time: 0.153, data: 0.006) loss: 2.113 
(epoch: 5, iters: 7952, time: 0.157, data: 0.000) loss: 2.427 
saving the latest model (epoch 5, total_steps 48784)
(epoch: 5, iters: 8032, time: 0.155, data: 0.008) loss: 1.975 
(epoch: 5, iters: 8112, time: 0.153, data: 0.005) loss: 2.724 
(epoch: 5, iters: 8192, time: 0.154, data: 0.000) loss: 1.928 
(epoch: 5, iters: 8272, time: 0.154, data: 0.022) loss: 1.900 
(epoch: 5, iters: 8352, time: 0.156, data: 0.000) loss: 2.098 
(epoch: 5, iters: 8432, time: 0.155, data: 0.024) loss: 2.163 
(epoch: 5, iters: 8512, time: 0.156, data: 0.032) loss: 2.481 
(epoch: 5, iters: 8592, time: 0.156, data: 0.000) loss: 2.137 
(epoch: 5, iters: 8672, time: 0.156, data: 0.000) loss: 2.284 
(epoch: 5, iters: 8752, time: 0.156, data: 0.005) loss: 2.239 
(epoch: 5, iters: 8832, time: 0.155, data: 0.000) loss: 2.305 
(epoch: 5, iters: 8912, time: 0.156, data: 0.000) loss: 2.668 
(epoch: 5, iters: 8992, time: 0.158, data: 0.021) loss: 2.495 
(epoch: 5, iters: 9072, time: 0.157, data: 0.000) loss: 2.414 
(epoch: 5, iters: 9152, time: 0.157, data: 0.031) loss: 2.167 
(epoch: 5, iters: 9232, time: 0.159, data: 0.000) loss: 2.164 
(epoch: 5, iters: 9312, time: 0.155, data: 0.019) loss: 2.964 
(epoch: 5, iters: 9392, time: 0.156, data: 0.000) loss: 2.345 
(epoch: 5, iters: 9472, time: 0.157, data: 0.005) loss: 2.278 
(epoch: 5, iters: 9552, time: 0.154, data: 0.000) loss: 2.769 
(epoch: 5, iters: 9632, time: 0.156, data: 0.000) loss: 2.126 
(epoch: 5, iters: 9712, time: 0.154, data: 0.000) loss: 1.965 
(epoch: 5, iters: 9792, time: 0.155, data: 0.000) loss: 2.352 
(epoch: 5, iters: 9872, time: 0.157, data: 0.000) loss: 2.132 
(epoch: 5, iters: 9952, time: 0.154, data: 0.000) loss: 2.357 
(epoch: 5, iters: 10032, time: 0.156, data: 0.014) loss: 2.260 
(epoch: 5, iters: 10112, time: 0.153, data: 0.021) loss: 2.493 
(epoch: 5, iters: 10192, time: 0.093, data: 0.000) loss: 2.673 
saving the model at the end of epoch 5, iters 50960
End of epoch 5 / 200 	 Time Taken: 1598 sec
learning rate = 0.0002000
saving the latest model (epoch 6, total_steps 50976)
(epoch: 6, iters: 80, time: 0.153, data: 0.648) loss: 2.396 
(epoch: 6, iters: 160, time: 0.153, data: 0.000) loss: 2.128 
(epoch: 6, iters: 240, time: 0.154, data: 0.000) loss: 2.021 
(epoch: 6, iters: 320, time: 0.153, data: 0.000) loss: 2.183 
(epoch: 6, iters: 400, time: 0.154, data: 0.005) loss: 2.026 
(epoch: 6, iters: 480, time: 0.156, data: 0.014) loss: 1.982 
(epoch: 6, iters: 560, time: 0.155, data: 0.016) loss: 2.802 
(epoch: 6, iters: 640, time: 0.154, data: 0.000) loss: 2.284 
(epoch: 6, iters: 720, time: 0.155, data: 0.005) loss: 2.514 
(epoch: 6, iters: 800, time: 0.153, data: 0.024) loss: 2.279 
(epoch: 6, iters: 880, time: 0.156, data: 0.000) loss: 2.263 
(epoch: 6, iters: 960, time: 0.155, data: 0.000) loss: 2.805 
(epoch: 6, iters: 1040, time: 0.155, data: 0.000) loss: 2.268 
(epoch: 6, iters: 1120, time: 0.157, data: 0.032) loss: 2.261 
(epoch: 6, iters: 1200, time: 0.154, data: 0.000) loss: 2.822 
(epoch: 6, iters: 1280, time: 0.153, data: 0.000) loss: 2.043 
(epoch: 6, iters: 1360, time: 0.152, data: 0.005) loss: 2.440 
(epoch: 6, iters: 1440, time: 0.162, data: 0.000) loss: 1.983 
(epoch: 6, iters: 1520, time: 0.153, data: 0.005) loss: 2.690 
(epoch: 6, iters: 1600, time: 0.152, data: 0.015) loss: 2.413 
(epoch: 6, iters: 1680, time: 0.153, data: 0.000) loss: 2.453 
(epoch: 6, iters: 1760, time: 0.154, data: 0.020) loss: 2.207 
(epoch: 6, iters: 1840, time: 0.153, data: 0.005) loss: 2.180 
(epoch: 6, iters: 1920, time: 0.162, data: 0.024) loss: 2.201 
(epoch: 6, iters: 2000, time: 0.154, data: 0.000) loss: 1.971 
(epoch: 6, iters: 2080, time: 0.155, data: 0.032) loss: 2.638 
(epoch: 6, iters: 2160, time: 0.155, data: 0.000) loss: 2.298 
(epoch: 6, iters: 2240, time: 0.163, data: 0.000) loss: 2.010 
(epoch: 6, iters: 2320, time: 0.155, data: 0.005) loss: 2.431 
(epoch: 6, iters: 2400, time: 0.156, data: 0.000) loss: 1.912 
(epoch: 6, iters: 2480, time: 0.154, data: 0.005) loss: 2.396 
(epoch: 6, iters: 2560, time: 0.156, data: 0.000) loss: 2.508 
(epoch: 6, iters: 2640, time: 0.154, data: 0.005) loss: 2.520 
(epoch: 6, iters: 2720, time: 0.154, data: 0.000) loss: 2.179 
(epoch: 6, iters: 2800, time: 0.156, data: 0.033) loss: 2.157 
(epoch: 6, iters: 2880, time: 0.157, data: 0.000) loss: 1.965 
(epoch: 6, iters: 2960, time: 0.155, data: 0.016) loss: 2.059 
(epoch: 6, iters: 3040, time: 0.155, data: 0.000) loss: 2.149 
(epoch: 6, iters: 3120, time: 0.156, data: 0.000) loss: 2.215 
(epoch: 6, iters: 3200, time: 0.155, data: 0.000) loss: 2.316 
(epoch: 6, iters: 3280, time: 0.154, data: 0.000) loss: 2.126 
(epoch: 6, iters: 3360, time: 0.157, data: 0.000) loss: 2.502 
(epoch: 6, iters: 3440, time: 0.156, data: 0.000) loss: 2.052 
(epoch: 6, iters: 3520, time: 0.155, data: 0.000) loss: 1.706 
(epoch: 6, iters: 3600, time: 0.155, data: 0.000) loss: 2.401 
(epoch: 6, iters: 3680, time: 0.156, data: 0.000) loss: 3.237 
(epoch: 6, iters: 3760, time: 0.155, data: 0.014) loss: 2.387 
(epoch: 6, iters: 3840, time: 0.154, data: 0.008) loss: 2.229 
(epoch: 6, iters: 3920, time: 0.155, data: 0.000) loss: 2.353 
(epoch: 6, iters: 4000, time: 0.152, data: 0.005) loss: 2.318 
saving the latest model (epoch 6, total_steps 54976)
(epoch: 6, iters: 4080, time: 0.156, data: 0.005) loss: 2.052 
(epoch: 6, iters: 4160, time: 0.154, data: 0.019) loss: 2.105 
(epoch: 6, iters: 4240, time: 0.153, data: 0.000) loss: 2.469 
(epoch: 6, iters: 4320, time: 0.152, data: 0.000) loss: 2.003 
(epoch: 6, iters: 4400, time: 0.152, data: 0.000) loss: 1.904 
(epoch: 6, iters: 4480, time: 0.154, data: 0.000) loss: 2.562 
(epoch: 6, iters: 4560, time: 0.157, data: 0.000) loss: 2.276 
(epoch: 6, iters: 4640, time: 0.155, data: 0.032) loss: 2.810 
(epoch: 6, iters: 4720, time: 0.153, data: 0.000) loss: 1.994 
(epoch: 6, iters: 4800, time: 0.154, data: 0.019) loss: 2.066 
(epoch: 6, iters: 4880, time: 0.157, data: 0.000) loss: 1.975 
(epoch: 6, iters: 4960, time: 0.159, data: 0.000) loss: 2.208 
(epoch: 6, iters: 5040, time: 0.156, data: 0.000) loss: 2.550 
(epoch: 6, iters: 5120, time: 0.155, data: 0.000) loss: 2.488 
(epoch: 6, iters: 5200, time: 0.155, data: 0.005) loss: 1.669 
(epoch: 6, iters: 5280, time: 0.156, data: 0.000) loss: 1.784 
(epoch: 6, iters: 5360, time: 0.158, data: 0.020) loss: 2.122 
(epoch: 6, iters: 5440, time: 0.155, data: 0.024) loss: 3.014 
(epoch: 6, iters: 5520, time: 0.153, data: 0.000) loss: 1.907 
(epoch: 6, iters: 5600, time: 0.158, data: 0.000) loss: 2.039 
(epoch: 6, iters: 5680, time: 0.156, data: 0.008) loss: 2.531 
(epoch: 6, iters: 5760, time: 0.156, data: 0.000) loss: 1.697 
(epoch: 6, iters: 5840, time: 0.154, data: 0.000) loss: 1.941 
(epoch: 6, iters: 5920, time: 0.154, data: 0.000) loss: 2.535 
(epoch: 6, iters: 6000, time: 0.152, data: 0.008) loss: 2.098 
(epoch: 6, iters: 6080, time: 0.155, data: 0.008) loss: 2.458 
(epoch: 6, iters: 6160, time: 0.153, data: 0.000) loss: 1.569 
(epoch: 6, iters: 6240, time: 0.155, data: 0.000) loss: 2.286 
(epoch: 6, iters: 6320, time: 0.154, data: 0.005) loss: 2.072 
(epoch: 6, iters: 6400, time: 0.154, data: 0.000) loss: 2.548 
(epoch: 6, iters: 6480, time: 0.154, data: 0.000) loss: 2.078 
(epoch: 6, iters: 6560, time: 0.155, data: 0.000) loss: 2.441 
(epoch: 6, iters: 6640, time: 0.154, data: 0.000) loss: 2.180 
(epoch: 6, iters: 6720, time: 0.154, data: 0.014) loss: 2.672 
(epoch: 6, iters: 6800, time: 0.156, data: 0.000) loss: 2.583 
(epoch: 6, iters: 6880, time: 0.156, data: 0.000) loss: 1.649 
(epoch: 6, iters: 6960, time: 0.157, data: 0.000) loss: 2.243 
(epoch: 6, iters: 7040, time: 0.157, data: 0.000) loss: 1.972 
(epoch: 6, iters: 7120, time: 0.154, data: 0.005) loss: 2.484 
(epoch: 6, iters: 7200, time: 0.158, data: 0.020) loss: 2.068 
(epoch: 6, iters: 7280, time: 0.156, data: 0.000) loss: 1.665 
(epoch: 6, iters: 7360, time: 0.156, data: 0.005) loss: 2.204 
(epoch: 6, iters: 7440, time: 0.155, data: 0.000) loss: 2.435 
(epoch: 6, iters: 7520, time: 0.156, data: 0.000) loss: 1.782 
(epoch: 6, iters: 7600, time: 0.157, data: 0.000) loss: 2.235 
(epoch: 6, iters: 7680, time: 0.156, data: 0.018) loss: 2.731 
(epoch: 6, iters: 7760, time: 0.154, data: 0.005) loss: 2.059 
(epoch: 6, iters: 7840, time: 0.158, data: 0.005) loss: 2.235 
(epoch: 6, iters: 7920, time: 0.155, data: 0.005) loss: 2.237 
(epoch: 6, iters: 8000, time: 0.157, data: 0.000) loss: 2.121 
saving the latest model (epoch 6, total_steps 58976)
(epoch: 6, iters: 8080, time: 0.155, data: 0.000) loss: 2.206 
(epoch: 6, iters: 8160, time: 0.156, data: 0.005) loss: 2.084 
(epoch: 6, iters: 8240, time: 0.157, data: 0.000) loss: 2.145 
(epoch: 6, iters: 8320, time: 0.157, data: 0.024) loss: 2.336 
(epoch: 6, iters: 8400, time: 0.156, data: 0.000) loss: 2.172 
(epoch: 6, iters: 8480, time: 0.155, data: 0.025) loss: 2.105 
(epoch: 6, iters: 8560, time: 0.155, data: 0.000) loss: 1.833 
(epoch: 6, iters: 8640, time: 0.156, data: 0.000) loss: 1.960 
(epoch: 6, iters: 8720, time: 0.156, data: 0.012) loss: 2.373 
(epoch: 6, iters: 8800, time: 0.155, data: 0.000) loss: 1.750 
(epoch: 6, iters: 8880, time: 0.158, data: 0.009) loss: 2.781 
(epoch: 6, iters: 8960, time: 0.157, data: 0.000) loss: 2.128 
(epoch: 6, iters: 9040, time: 0.156, data: 0.008) loss: 1.971 
(epoch: 6, iters: 9120, time: 0.158, data: 0.000) loss: 2.460 
(epoch: 6, iters: 9200, time: 0.158, data: 0.000) loss: 2.034 
(epoch: 6, iters: 9280, time: 0.161, data: 0.008) loss: 2.076 
(epoch: 6, iters: 9360, time: 0.156, data: 0.005) loss: 2.209 
(epoch: 6, iters: 9440, time: 0.156, data: 0.000) loss: 2.054 
(epoch: 6, iters: 9520, time: 0.154, data: 0.023) loss: 2.428 
(epoch: 6, iters: 9600, time: 0.155, data: 0.000) loss: 2.146 
(epoch: 6, iters: 9680, time: 0.155, data: 0.000) loss: 2.698 
(epoch: 6, iters: 9760, time: 0.153, data: 0.000) loss: 2.025 
(epoch: 6, iters: 9840, time: 0.158, data: 0.000) loss: 1.823 
(epoch: 6, iters: 9920, time: 0.157, data: 0.000) loss: 2.562 
(epoch: 6, iters: 10000, time: 0.158, data: 0.014) loss: 2.125 
(epoch: 6, iters: 10080, time: 0.156, data: 0.000) loss: 2.036 
(epoch: 6, iters: 10160, time: 0.155, data: 0.000) loss: 2.552 
saving the model at the end of epoch 6, iters 61152
End of epoch 6 / 200 	 Time Taken: 1588 sec
learning rate = 0.0002000
saving the latest model (epoch 7, total_steps 61168)
(epoch: 7, iters: 48, time: 0.161, data: 0.000) loss: 2.481 
(epoch: 7, iters: 128, time: 0.156, data: 0.032) loss: 1.964 
(epoch: 7, iters: 208, time: 0.155, data: 0.000) loss: 1.937 
(epoch: 7, iters: 288, time: 0.155, data: 0.009) loss: 2.010 
(epoch: 7, iters: 368, time: 0.156, data: 0.012) loss: 2.239 
(epoch: 7, iters: 448, time: 0.156, data: 0.023) loss: 2.158 
(epoch: 7, iters: 528, time: 0.154, data: 0.000) loss: 2.058 
(epoch: 7, iters: 608, time: 0.154, data: 0.005) loss: 2.507 
(epoch: 7, iters: 688, time: 0.154, data: 0.000) loss: 2.061 
(epoch: 7, iters: 768, time: 0.156, data: 0.000) loss: 2.037 
(epoch: 7, iters: 848, time: 0.156, data: 0.000) loss: 1.804 
(epoch: 7, iters: 928, time: 0.157, data: 0.000) loss: 1.897 
(epoch: 7, iters: 1008, time: 0.155, data: 0.012) loss: 2.110 
(epoch: 7, iters: 1088, time: 0.156, data: 0.005) loss: 1.702 
(epoch: 7, iters: 1168, time: 0.156, data: 0.005) loss: 2.430 
(epoch: 7, iters: 1248, time: 0.156, data: 0.000) loss: 1.806 
(epoch: 7, iters: 1328, time: 0.156, data: 0.000) loss: 2.192 
(epoch: 7, iters: 1408, time: 0.157, data: 0.000) loss: 1.816 
(epoch: 7, iters: 1488, time: 0.157, data: 0.010) loss: 1.859 
(epoch: 7, iters: 1568, time: 0.157, data: 0.000) loss: 1.389 
(epoch: 7, iters: 1648, time: 0.158, data: 0.000) loss: 2.748 
(epoch: 7, iters: 1728, time: 0.157, data: 0.005) loss: 2.205 
(epoch: 7, iters: 1808, time: 0.157, data: 0.000) loss: 2.336 
(epoch: 7, iters: 1888, time: 0.156, data: 0.000) loss: 2.284 
(epoch: 7, iters: 1968, time: 0.154, data: 0.021) loss: 1.941 
(epoch: 7, iters: 2048, time: 0.157, data: 0.008) loss: 2.510 
(epoch: 7, iters: 2128, time: 0.156, data: 0.000) loss: 1.477 
(epoch: 7, iters: 2208, time: 0.156, data: 0.026) loss: 2.240 
(epoch: 7, iters: 2288, time: 0.157, data: 0.000) loss: 2.539 
(epoch: 7, iters: 2368, time: 0.155, data: 0.025) loss: 2.169 
(epoch: 7, iters: 2448, time: 0.157, data: 0.000) loss: 3.378 
(epoch: 7, iters: 2528, time: 0.156, data: 0.005) loss: 2.268 
(epoch: 7, iters: 2608, time: 0.156, data: 0.000) loss: 2.518 
(epoch: 7, iters: 2688, time: 0.154, data: 0.005) loss: 2.499 
(epoch: 7, iters: 2768, time: 0.154, data: 0.000) loss: 1.773 
(epoch: 7, iters: 2848, time: 0.154, data: 0.011) loss: 1.847 
(epoch: 7, iters: 2928, time: 0.154, data: 0.000) loss: 2.204 
(epoch: 7, iters: 3008, time: 0.156, data: 0.010) loss: 2.990 
(epoch: 7, iters: 3088, time: 0.155, data: 0.000) loss: 1.627 
(epoch: 7, iters: 3168, time: 0.156, data: 0.000) loss: 1.585 
(epoch: 7, iters: 3248, time: 0.158, data: 0.000) loss: 2.586 
(epoch: 7, iters: 3328, time: 0.157, data: 0.000) loss: 2.354 
(epoch: 7, iters: 3408, time: 0.155, data: 0.005) loss: 1.744 
(epoch: 7, iters: 3488, time: 0.159, data: 0.000) loss: 2.571 
(epoch: 7, iters: 3568, time: 0.157, data: 0.005) loss: 1.926 
(epoch: 7, iters: 3648, time: 0.157, data: 0.000) loss: 2.311 
(epoch: 7, iters: 3728, time: 0.156, data: 0.000) loss: 2.222 
(epoch: 7, iters: 3808, time: 0.157, data: 0.016) loss: 2.310 
(epoch: 7, iters: 3888, time: 0.158, data: 0.000) loss: 2.108 
(epoch: 7, iters: 3968, time: 0.158, data: 0.000) loss: 2.080 
saving the latest model (epoch 7, total_steps 65168)
(epoch: 7, iters: 4048, time: 0.157, data: 0.024) loss: 1.919 
(epoch: 7, iters: 4128, time: 0.157, data: 0.000) loss: 2.237 
(epoch: 7, iters: 4208, time: 0.155, data: 0.000) loss: 1.522 
(epoch: 7, iters: 4288, time: 0.157, data: 0.000) loss: 1.998 
(epoch: 7, iters: 4368, time: 0.158, data: 0.009) loss: 1.852 
(epoch: 7, iters: 4448, time: 0.158, data: 0.008) loss: 2.614 
(epoch: 7, iters: 4528, time: 0.156, data: 0.000) loss: 2.041 
(epoch: 7, iters: 4608, time: 0.155, data: 0.000) loss: 2.248 
(epoch: 7, iters: 4688, time: 0.156, data: 0.008) loss: 1.579 
(epoch: 7, iters: 4768, time: 0.158, data: 0.000) loss: 2.692 
(epoch: 7, iters: 4848, time: 0.156, data: 0.000) loss: 2.000 
(epoch: 7, iters: 4928, time: 0.156, data: 0.010) loss: 1.961 
(epoch: 7, iters: 5008, time: 0.156, data: 0.000) loss: 2.385 
(epoch: 7, iters: 5088, time: 0.156, data: 0.023) loss: 1.744 
(epoch: 7, iters: 5168, time: 0.157, data: 0.000) loss: 2.140 
(epoch: 7, iters: 5248, time: 0.155, data: 0.024) loss: 2.133 
(epoch: 7, iters: 5328, time: 0.156, data: 0.000) loss: 1.756 
(epoch: 7, iters: 5408, time: 0.162, data: 0.000) loss: 2.619 
(epoch: 7, iters: 5488, time: 0.157, data: 0.000) loss: 1.521 
(epoch: 7, iters: 5568, time: 0.158, data: 0.000) loss: 1.755 
(epoch: 7, iters: 5648, time: 0.156, data: 0.000) loss: 1.588 
(epoch: 7, iters: 5728, time: 0.156, data: 0.000) loss: 2.422 
(epoch: 7, iters: 5808, time: 0.157, data: 0.013) loss: 2.061 
(epoch: 7, iters: 5888, time: 0.157, data: 0.005) loss: 1.927 
(epoch: 7, iters: 5968, time: 0.155, data: 0.000) loss: 1.770 
(epoch: 7, iters: 6048, time: 0.156, data: 0.014) loss: 2.557 
(epoch: 7, iters: 6128, time: 0.155, data: 0.005) loss: 1.988 
(epoch: 7, iters: 6208, time: 0.155, data: 0.010) loss: 1.769 
(epoch: 7, iters: 6288, time: 0.155, data: 0.000) loss: 1.791 
(epoch: 7, iters: 6368, time: 0.155, data: 0.000) loss: 1.953 
(epoch: 7, iters: 6448, time: 0.155, data: 0.021) loss: 2.526 
(epoch: 7, iters: 6528, time: 0.155, data: 0.005) loss: 1.754 
(epoch: 7, iters: 6608, time: 0.156, data: 0.000) loss: 2.807 
(epoch: 7, iters: 6688, time: 0.156, data: 0.020) loss: 1.715 
(epoch: 7, iters: 6768, time: 0.155, data: 0.015) loss: 2.200 
(epoch: 7, iters: 6848, time: 0.154, data: 0.022) loss: 2.135 
(epoch: 7, iters: 6928, time: 0.155, data: 0.008) loss: 1.881 
(epoch: 7, iters: 7008, time: 0.156, data: 0.005) loss: 2.062 
(epoch: 7, iters: 7088, time: 0.155, data: 0.000) loss: 2.075 
(epoch: 7, iters: 7168, time: 0.155, data: 0.000) loss: 2.737 
(epoch: 7, iters: 7248, time: 0.155, data: 0.000) loss: 1.826 
(epoch: 7, iters: 7328, time: 0.154, data: 0.000) loss: 2.186 
(epoch: 7, iters: 7408, time: 0.155, data: 0.008) loss: 1.998 
(epoch: 7, iters: 7488, time: 0.156, data: 0.000) loss: 1.692 
(epoch: 7, iters: 7568, time: 0.156, data: 0.005) loss: 2.383 
(epoch: 7, iters: 7648, time: 0.157, data: 0.014) loss: 2.804 
(epoch: 7, iters: 7728, time: 0.162, data: 0.000) loss: 1.837 
(epoch: 7, iters: 7808, time: 0.156, data: 0.000) loss: 2.534 
(epoch: 7, iters: 7888, time: 0.155, data: 0.000) loss: 2.019 
(epoch: 7, iters: 7968, time: 0.156, data: 0.013) loss: 1.584 
saving the latest model (epoch 7, total_steps 69168)
(epoch: 7, iters: 8048, time: 0.155, data: 0.000) loss: 2.162 
(epoch: 7, iters: 8128, time: 0.156, data: 0.020) loss: 2.182 
(epoch: 7, iters: 8208, time: 0.156, data: 0.005) loss: 2.191 
(epoch: 7, iters: 8288, time: 0.164, data: 0.005) loss: 1.988 
(epoch: 7, iters: 8368, time: 0.160, data: 0.000) loss: 2.153 
(epoch: 7, iters: 8448, time: 0.156, data: 0.013) loss: 2.296 
(epoch: 7, iters: 8528, time: 0.156, data: 0.000) loss: 1.813 
(epoch: 7, iters: 8608, time: 0.155, data: 0.000) loss: 2.576 
(epoch: 7, iters: 8688, time: 0.154, data: 0.005) loss: 1.988 
(epoch: 7, iters: 8768, time: 0.155, data: 0.005) loss: 2.422 
(epoch: 7, iters: 8848, time: 0.158, data: 0.005) loss: 2.014 
(epoch: 7, iters: 8928, time: 0.159, data: 0.000) loss: 2.199 
(epoch: 7, iters: 9008, time: 0.155, data: 0.033) loss: 1.777 
(epoch: 7, iters: 9088, time: 0.156, data: 0.000) loss: 1.442 
(epoch: 7, iters: 9168, time: 0.155, data: 0.000) loss: 2.468 
(epoch: 7, iters: 9248, time: 0.154, data: 0.005) loss: 2.354 
(epoch: 7, iters: 9328, time: 0.156, data: 0.022) loss: 2.090 
(epoch: 7, iters: 9408, time: 0.154, data: 0.000) loss: 1.871 
(epoch: 7, iters: 9488, time: 0.155, data: 0.000) loss: 1.863 
(epoch: 7, iters: 9568, time: 0.155, data: 0.024) loss: 1.361 
(epoch: 7, iters: 9648, time: 0.157, data: 0.000) loss: 1.720 
(epoch: 7, iters: 9728, time: 0.156, data: 0.000) loss: 2.039 
(epoch: 7, iters: 9808, time: 0.155, data: 0.013) loss: 2.095 
(epoch: 7, iters: 9888, time: 0.156, data: 0.005) loss: 2.788 
(epoch: 7, iters: 9968, time: 0.156, data: 0.000) loss: 2.517 
(epoch: 7, iters: 10048, time: 0.155, data: 0.017) loss: 1.806 
(epoch: 7, iters: 10128, time: 0.152, data: 0.000) loss: 1.922 
saving the model at the end of epoch 7, iters 71344
End of epoch 7 / 200 	 Time Taken: 1595 sec
learning rate = 0.0002000
(epoch: 8, iters: 16, time: 0.176, data: 0.008) loss: 2.021 
saving the latest model (epoch 8, total_steps 71360)
(epoch: 8, iters: 96, time: 0.153, data: 0.021) loss: 3.085 
(epoch: 8, iters: 176, time: 0.155, data: 0.000) loss: 2.538 
(epoch: 8, iters: 256, time: 0.154, data: 0.000) loss: 2.157 
(epoch: 8, iters: 336, time: 0.154, data: 0.005) loss: 2.152 
(epoch: 8, iters: 416, time: 0.153, data: 0.008) loss: 2.843 
(epoch: 8, iters: 496, time: 0.155, data: 0.000) loss: 2.420 
(epoch: 8, iters: 576, time: 0.156, data: 0.005) loss: 2.726 
(epoch: 8, iters: 656, time: 0.153, data: 0.000) loss: 1.683 
(epoch: 8, iters: 736, time: 0.155, data: 0.032) loss: 2.468 
(epoch: 8, iters: 816, time: 0.153, data: 0.000) loss: 1.909 
(epoch: 8, iters: 896, time: 0.160, data: 0.007) loss: 1.589 
(epoch: 8, iters: 976, time: 0.155, data: 0.005) loss: 1.896 
(epoch: 8, iters: 1056, time: 0.156, data: 0.000) loss: 1.889 
(epoch: 8, iters: 1136, time: 0.154, data: 0.005) loss: 2.090 
(epoch: 8, iters: 1216, time: 0.153, data: 0.008) loss: 1.991 
(epoch: 8, iters: 1296, time: 0.154, data: 0.008) loss: 2.020 
(epoch: 8, iters: 1376, time: 0.153, data: 0.000) loss: 1.909 
(epoch: 8, iters: 1456, time: 0.155, data: 0.000) loss: 2.225 
(epoch: 8, iters: 1536, time: 0.153, data: 0.018) loss: 2.424 
(epoch: 8, iters: 1616, time: 0.154, data: 0.033) loss: 1.615 
(epoch: 8, iters: 1696, time: 0.154, data: 0.000) loss: 1.971 
(epoch: 8, iters: 1776, time: 0.156, data: 0.000) loss: 2.384 
(epoch: 8, iters: 1856, time: 0.158, data: 0.000) loss: 1.478 
(epoch: 8, iters: 1936, time: 0.164, data: 0.005) loss: 1.555 
(epoch: 8, iters: 2016, time: 0.163, data: 0.000) loss: 1.647 
(epoch: 8, iters: 2096, time: 0.165, data: 0.000) loss: 2.094 
(epoch: 8, iters: 2176, time: 0.175, data: 0.000) loss: 1.926 
(epoch: 8, iters: 2256, time: 0.164, data: 0.005) loss: 2.183 
(epoch: 8, iters: 2336, time: 0.162, data: 0.013) loss: 2.214 
(epoch: 8, iters: 2416, time: 0.161, data: 0.015) loss: 1.806 
(epoch: 8, iters: 2496, time: 0.163, data: 0.000) loss: 1.745 
(epoch: 8, iters: 2576, time: 0.160, data: 0.009) loss: 1.959 
(epoch: 8, iters: 2656, time: 0.161, data: 0.000) loss: 2.774 
(epoch: 8, iters: 2736, time: 0.161, data: 0.010) loss: 2.001 
(epoch: 8, iters: 2816, time: 0.161, data: 0.000) loss: 0.956 
(epoch: 8, iters: 2896, time: 0.160, data: 0.000) loss: 2.070 
(epoch: 8, iters: 2976, time: 0.160, data: 0.008) loss: 2.045 
(epoch: 8, iters: 3056, time: 0.160, data: 0.000) loss: 2.057 
(epoch: 8, iters: 3136, time: 0.162, data: 0.000) loss: 1.607 
(epoch: 8, iters: 3216, time: 0.161, data: 0.005) loss: 1.893 
(epoch: 8, iters: 3296, time: 0.165, data: 0.029) loss: 2.210 
(epoch: 8, iters: 3376, time: 0.163, data: 0.000) loss: 2.093 
(epoch: 8, iters: 3456, time: 0.161, data: 0.031) loss: 2.166 
(epoch: 8, iters: 3536, time: 0.161, data: 0.000) loss: 1.917 
(epoch: 8, iters: 3616, time: 0.161, data: 0.025) loss: 2.040 
(epoch: 8, iters: 3696, time: 0.163, data: 0.000) loss: 2.194 
(epoch: 8, iters: 3776, time: 0.162, data: 0.024) loss: 2.692 
(epoch: 8, iters: 3856, time: 0.162, data: 0.000) loss: 2.051 
(epoch: 8, iters: 3936, time: 0.163, data: 0.000) loss: 1.474 
(epoch: 8, iters: 4016, time: 0.159, data: 0.000) loss: 1.910 
saving the latest model (epoch 8, total_steps 75360)
(epoch: 8, iters: 4096, time: 0.164, data: 0.009) loss: 2.101 
(epoch: 8, iters: 4176, time: 0.158, data: 0.008) loss: 2.003 
(epoch: 8, iters: 4256, time: 0.161, data: 0.000) loss: 1.859 
(epoch: 8, iters: 4336, time: 0.159, data: 0.005) loss: 1.770 
(epoch: 8, iters: 4416, time: 0.158, data: 0.005) loss: 1.797 
(epoch: 8, iters: 4496, time: 0.157, data: 0.000) loss: 2.563 
(epoch: 8, iters: 4576, time: 0.155, data: 0.000) loss: 1.777 
(epoch: 8, iters: 4656, time: 0.160, data: 0.023) loss: 2.038 
(epoch: 8, iters: 4736, time: 0.161, data: 0.000) loss: 2.342 
(epoch: 8, iters: 4816, time: 0.162, data: 0.000) loss: 2.175 
(epoch: 8, iters: 4896, time: 0.161, data: 0.027) loss: 2.400 
(epoch: 8, iters: 4976, time: 0.162, data: 0.000) loss: 1.814 
(epoch: 8, iters: 5056, time: 0.160, data: 0.000) loss: 2.352 
(epoch: 8, iters: 5136, time: 0.160, data: 0.011) loss: 2.095 
(epoch: 8, iters: 5216, time: 0.160, data: 0.005) loss: 1.825 
(epoch: 8, iters: 5296, time: 0.159, data: 0.000) loss: 1.669 
(epoch: 8, iters: 5376, time: 0.158, data: 0.005) loss: 2.258 
(epoch: 8, iters: 5456, time: 0.159, data: 0.019) loss: 2.114 
(epoch: 8, iters: 5536, time: 0.161, data: 0.000) loss: 2.469 
(epoch: 8, iters: 5616, time: 0.159, data: 0.000) loss: 2.400 
(epoch: 8, iters: 5696, time: 0.157, data: 0.027) loss: 1.870 
(epoch: 8, iters: 5776, time: 0.159, data: 0.000) loss: 1.436 
(epoch: 8, iters: 5856, time: 0.158, data: 0.000) loss: 1.996 
(epoch: 8, iters: 5936, time: 0.162, data: 0.009) loss: 2.013 
(epoch: 8, iters: 6016, time: 0.154, data: 0.009) loss: 1.685 
(epoch: 8, iters: 6096, time: 0.156, data: 0.026) loss: 2.073 
(epoch: 8, iters: 6176, time: 0.158, data: 0.000) loss: 1.974 
(epoch: 8, iters: 6256, time: 0.158, data: 0.000) loss: 2.066 
(epoch: 8, iters: 6336, time: 0.157, data: 0.009) loss: 1.423 
(epoch: 8, iters: 6416, time: 0.158, data: 0.009) loss: 2.056 
(epoch: 8, iters: 6496, time: 0.161, data: 0.000) loss: 2.252 
(epoch: 8, iters: 6576, time: 0.158, data: 0.014) loss: 1.783 
(epoch: 8, iters: 6656, time: 0.160, data: 0.000) loss: 1.726 
(epoch: 8, iters: 6736, time: 0.160, data: 0.015) loss: 2.351 
(epoch: 8, iters: 6816, time: 0.159, data: 0.008) loss: 1.557 
(epoch: 8, iters: 6896, time: 0.158, data: 0.000) loss: 2.060 
(epoch: 8, iters: 6976, time: 0.158, data: 0.013) loss: 2.330 
(epoch: 8, iters: 7056, time: 0.159, data: 0.000) loss: 2.060 
(epoch: 8, iters: 7136, time: 0.158, data: 0.000) loss: 1.777 
(epoch: 8, iters: 7216, time: 0.157, data: 0.000) loss: 2.224 
(epoch: 8, iters: 7296, time: 0.156, data: 0.000) loss: 2.763 
(epoch: 8, iters: 7376, time: 0.157, data: 0.000) loss: 1.769 
(epoch: 8, iters: 7456, time: 0.158, data: 0.000) loss: 2.233 
(epoch: 8, iters: 7536, time: 0.156, data: 0.000) loss: 1.903 
(epoch: 8, iters: 7616, time: 0.156, data: 0.005) loss: 1.872 
(epoch: 8, iters: 7696, time: 0.158, data: 0.000) loss: 1.959 
(epoch: 8, iters: 7776, time: 0.160, data: 0.005) loss: 1.944 
(epoch: 8, iters: 7856, time: 0.157, data: 0.000) loss: 2.233 
(epoch: 8, iters: 7936, time: 0.157, data: 0.000) loss: 2.061 
(epoch: 8, iters: 8016, time: 0.157, data: 0.000) loss: 1.714 
saving the latest model (epoch 8, total_steps 79360)
(epoch: 8, iters: 8096, time: 0.160, data: 0.021) loss: 1.933 
(epoch: 8, iters: 8176, time: 0.157, data: 0.000) loss: 2.168 
(epoch: 8, iters: 8256, time: 0.155, data: 0.000) loss: 1.902 
(epoch: 8, iters: 8336, time: 0.157, data: 0.000) loss: 2.137 
(epoch: 8, iters: 8416, time: 0.158, data: 0.009) loss: 1.699 
(epoch: 8, iters: 8496, time: 0.159, data: 0.000) loss: 1.511 
(epoch: 8, iters: 8576, time: 0.157, data: 0.000) loss: 1.681 
(epoch: 8, iters: 8656, time: 0.159, data: 0.015) loss: 2.027 
(epoch: 8, iters: 8736, time: 0.161, data: 0.000) loss: 2.180 
(epoch: 8, iters: 8816, time: 0.155, data: 0.015) loss: 1.730 
(epoch: 8, iters: 8896, time: 0.157, data: 0.004) loss: 1.663 
(epoch: 8, iters: 8976, time: 0.157, data: 0.009) loss: 2.168 
(epoch: 8, iters: 9056, time: 0.155, data: 0.000) loss: 1.823 
(epoch: 8, iters: 9136, time: 0.157, data: 0.021) loss: 2.113 
(epoch: 8, iters: 9216, time: 0.158, data: 0.005) loss: 2.103 
(epoch: 8, iters: 9296, time: 0.156, data: 0.000) loss: 2.479 
(epoch: 8, iters: 9376, time: 0.155, data: 0.024) loss: 2.538 
(epoch: 8, iters: 9456, time: 0.154, data: 0.000) loss: 1.794 
(epoch: 8, iters: 9536, time: 0.157, data: 0.005) loss: 2.029 
(epoch: 8, iters: 9616, time: 0.155, data: 0.000) loss: 2.018 
(epoch: 8, iters: 9696, time: 0.155, data: 0.000) loss: 2.480 
(epoch: 8, iters: 9776, time: 0.155, data: 0.036) loss: 2.284 
(epoch: 8, iters: 9856, time: 0.157, data: 0.000) loss: 1.391 
(epoch: 8, iters: 9936, time: 0.155, data: 0.031) loss: 1.934 
(epoch: 8, iters: 10016, time: 0.158, data: 0.000) loss: 2.258 
(epoch: 8, iters: 10096, time: 0.156, data: 0.000) loss: 1.629 
(epoch: 8, iters: 10176, time: 0.153, data: 0.032) loss: 2.105 
saving the model at the end of epoch 8, iters 81536
End of epoch 8 / 200 	 Time Taken: 1618 sec
learning rate = 0.0002000
saving the latest model (epoch 9, total_steps 81552)
(epoch: 9, iters: 64, time: 0.156, data: 0.000) loss: 2.133 
(epoch: 9, iters: 144, time: 0.150, data: 0.043) loss: 1.988 
(epoch: 9, iters: 224, time: 0.153, data: 0.000) loss: 1.630 
(epoch: 9, iters: 304, time: 0.152, data: 0.040) loss: 1.850 
(epoch: 9, iters: 384, time: 0.153, data: 0.000) loss: 2.066 
(epoch: 9, iters: 464, time: 0.152, data: 0.008) loss: 1.800 
(epoch: 9, iters: 544, time: 0.152, data: 0.000) loss: 1.637 
(epoch: 9, iters: 624, time: 0.152, data: 0.008) loss: 2.025 
(epoch: 9, iters: 704, time: 0.155, data: 0.000) loss: 1.984 
(epoch: 9, iters: 784, time: 0.154, data: 0.000) loss: 1.713 
(epoch: 9, iters: 864, time: 0.155, data: 0.005) loss: 1.944 
(epoch: 9, iters: 944, time: 0.153, data: 0.000) loss: 1.769 
(epoch: 9, iters: 1024, time: 0.156, data: 0.010) loss: 1.989 
(epoch: 9, iters: 1104, time: 0.154, data: 0.000) loss: 1.921 
(epoch: 9, iters: 1184, time: 0.155, data: 0.010) loss: 2.184 
(epoch: 9, iters: 1264, time: 0.155, data: 0.009) loss: 2.004 
(epoch: 9, iters: 1344, time: 0.153, data: 0.000) loss: 1.692 
(epoch: 9, iters: 1424, time: 0.157, data: 0.025) loss: 1.832 
(epoch: 9, iters: 1504, time: 0.155, data: 0.000) loss: 2.205 
(epoch: 9, iters: 1584, time: 0.155, data: 0.000) loss: 1.242 
(epoch: 9, iters: 1664, time: 0.154, data: 0.000) loss: 1.778 
(epoch: 9, iters: 1744, time: 0.154, data: 0.005) loss: 1.693 
(epoch: 9, iters: 1824, time: 0.154, data: 0.010) loss: 1.749 
(epoch: 9, iters: 1904, time: 0.154, data: 0.009) loss: 2.599 
(epoch: 9, iters: 1984, time: 0.154, data: 0.000) loss: 1.480 
(epoch: 9, iters: 2064, time: 0.153, data: 0.005) loss: 1.769 
(epoch: 9, iters: 2144, time: 0.154, data: 0.005) loss: 1.698 
(epoch: 9, iters: 2224, time: 0.154, data: 0.005) loss: 2.508 
(epoch: 9, iters: 2304, time: 0.154, data: 0.000) loss: 2.229 
(epoch: 9, iters: 2384, time: 0.156, data: 0.005) loss: 1.862 
(epoch: 9, iters: 2464, time: 0.155, data: 0.032) loss: 1.585 
(epoch: 9, iters: 2544, time: 0.153, data: 0.000) loss: 1.528 
(epoch: 9, iters: 2624, time: 0.153, data: 0.000) loss: 1.966 
(epoch: 9, iters: 2704, time: 0.155, data: 0.000) loss: 1.495 
(epoch: 9, iters: 2784, time: 0.155, data: 0.005) loss: 2.150 
(epoch: 9, iters: 2864, time: 0.156, data: 0.005) loss: 1.766 
(epoch: 9, iters: 2944, time: 0.156, data: 0.000) loss: 2.016 
(epoch: 9, iters: 3024, time: 0.154, data: 0.013) loss: 1.788 
(epoch: 9, iters: 3104, time: 0.153, data: 0.009) loss: 1.900 
(epoch: 9, iters: 3184, time: 0.154, data: 0.000) loss: 2.167 
(epoch: 9, iters: 3264, time: 0.153, data: 0.005) loss: 1.914 
(epoch: 9, iters: 3344, time: 0.153, data: 0.000) loss: 2.065 
(epoch: 9, iters: 3424, time: 0.156, data: 0.026) loss: 1.788 
(epoch: 9, iters: 3504, time: 0.154, data: 0.000) loss: 2.418 
(epoch: 9, iters: 3584, time: 0.155, data: 0.000) loss: 1.712 
(epoch: 9, iters: 3664, time: 0.153, data: 0.005) loss: 2.392 
(epoch: 9, iters: 3744, time: 0.153, data: 0.005) loss: 1.899 
(epoch: 9, iters: 3824, time: 0.154, data: 0.000) loss: 1.785 
(epoch: 9, iters: 3904, time: 0.151, data: 0.000) loss: 1.830 
(epoch: 9, iters: 3984, time: 0.151, data: 0.019) loss: 1.581 
saving the latest model (epoch 9, total_steps 85552)
(epoch: 9, iters: 4064, time: 0.153, data: 0.000) loss: 1.413 
(epoch: 9, iters: 4144, time: 0.152, data: 0.024) loss: 1.296 
(epoch: 9, iters: 4224, time: 0.151, data: 0.000) loss: 1.767 
(epoch: 9, iters: 4304, time: 0.155, data: 0.010) loss: 2.086 
(epoch: 9, iters: 4384, time: 0.151, data: 0.000) loss: 1.666 
(epoch: 9, iters: 4464, time: 0.151, data: 0.005) loss: 1.554 
(epoch: 9, iters: 4544, time: 0.153, data: 0.014) loss: 1.903 
(epoch: 9, iters: 4624, time: 0.153, data: 0.000) loss: 2.479 
(epoch: 9, iters: 4704, time: 0.153, data: 0.013) loss: 1.649 
(epoch: 9, iters: 4784, time: 0.155, data: 0.000) loss: 1.357 
(epoch: 9, iters: 4864, time: 0.153, data: 0.000) loss: 1.966 
(epoch: 9, iters: 4944, time: 0.153, data: 0.009) loss: 2.298 
(epoch: 9, iters: 5024, time: 0.156, data: 0.009) loss: 2.105 
(epoch: 9, iters: 5104, time: 0.154, data: 0.000) loss: 1.657 
(epoch: 9, iters: 5184, time: 0.151, data: 0.033) loss: 2.198 
(epoch: 9, iters: 5264, time: 0.152, data: 0.000) loss: 2.907 
(epoch: 9, iters: 5344, time: 0.152, data: 0.012) loss: 1.922 
(epoch: 9, iters: 5424, time: 0.152, data: 0.000) loss: 2.207 
(epoch: 9, iters: 5504, time: 0.152, data: 0.000) loss: 1.582 
(epoch: 9, iters: 5584, time: 0.152, data: 0.000) loss: 2.318 
(epoch: 9, iters: 5664, time: 0.152, data: 0.009) loss: 1.276 
(epoch: 9, iters: 5744, time: 0.151, data: 0.005) loss: 1.859 
(epoch: 9, iters: 5824, time: 0.152, data: 0.000) loss: 2.243 
(epoch: 9, iters: 5904, time: 0.151, data: 0.000) loss: 1.553 
(epoch: 9, iters: 5984, time: 0.152, data: 0.000) loss: 1.606 
(epoch: 9, iters: 6064, time: 0.152, data: 0.032) loss: 2.266 
(epoch: 9, iters: 6144, time: 0.152, data: 0.000) loss: 2.261 
(epoch: 9, iters: 6224, time: 0.155, data: 0.000) loss: 2.395 
(epoch: 9, iters: 6304, time: 0.152, data: 0.013) loss: 1.667 
(epoch: 9, iters: 6384, time: 0.152, data: 0.005) loss: 1.886 
(epoch: 9, iters: 6464, time: 0.153, data: 0.000) loss: 2.016 
(epoch: 9, iters: 6544, time: 0.155, data: 0.013) loss: 2.352 
(epoch: 9, iters: 6624, time: 0.155, data: 0.007) loss: 2.051 
(epoch: 9, iters: 6704, time: 0.154, data: 0.000) loss: 2.708 
(epoch: 9, iters: 6784, time: 0.154, data: 0.000) loss: 2.197 
(epoch: 9, iters: 6864, time: 0.153, data: 0.000) loss: 1.600 
(epoch: 9, iters: 6944, time: 0.152, data: 0.000) loss: 1.885 
(epoch: 9, iters: 7024, time: 0.152, data: 0.005) loss: 1.637 
(epoch: 9, iters: 7104, time: 0.154, data: 0.000) loss: 2.339 
(epoch: 9, iters: 7184, time: 0.162, data: 0.000) loss: 1.837 
(epoch: 9, iters: 7264, time: 0.155, data: 0.000) loss: 2.124 
(epoch: 9, iters: 7344, time: 0.158, data: 0.015) loss: 1.246 
(epoch: 9, iters: 7424, time: 0.157, data: 0.029) loss: 1.789 
(epoch: 9, iters: 7504, time: 0.156, data: 0.000) loss: 1.527 
(epoch: 9, iters: 7584, time: 0.158, data: 0.005) loss: 1.860 
(epoch: 9, iters: 7664, time: 0.160, data: 0.005) loss: 1.597 
(epoch: 9, iters: 7744, time: 0.157, data: 0.000) loss: 1.781 
(epoch: 9, iters: 7824, time: 0.157, data: 0.000) loss: 2.003 
(epoch: 9, iters: 7904, time: 0.157, data: 0.000) loss: 2.245 
(epoch: 9, iters: 7984, time: 0.157, data: 0.000) loss: 2.144 
saving the latest model (epoch 9, total_steps 89552)
(epoch: 9, iters: 8064, time: 0.156, data: 0.005) loss: 2.079 
(epoch: 9, iters: 8144, time: 0.156, data: 0.010) loss: 1.560 
(epoch: 9, iters: 8224, time: 0.157, data: 0.000) loss: 2.182 
(epoch: 9, iters: 8304, time: 0.159, data: 0.000) loss: 1.787 
(epoch: 9, iters: 8384, time: 0.159, data: 0.000) loss: 1.658 
(epoch: 9, iters: 8464, time: 0.155, data: 0.005) loss: 1.843 
(epoch: 9, iters: 8544, time: 0.158, data: 0.000) loss: 1.888 
(epoch: 9, iters: 8624, time: 0.157, data: 0.000) loss: 2.101 
(epoch: 9, iters: 8704, time: 0.157, data: 0.008) loss: 1.787 
(epoch: 9, iters: 8784, time: 0.155, data: 0.000) loss: 2.018 
(epoch: 9, iters: 8864, time: 0.156, data: 0.025) loss: 1.843 
(epoch: 9, iters: 8944, time: 0.156, data: 0.000) loss: 2.216 
(epoch: 9, iters: 9024, time: 0.156, data: 0.000) loss: 1.679 
(epoch: 9, iters: 9104, time: 0.158, data: 0.000) loss: 1.783 
(epoch: 9, iters: 9184, time: 0.155, data: 0.028) loss: 1.659 
(epoch: 9, iters: 9264, time: 0.157, data: 0.000) loss: 2.048 
(epoch: 9, iters: 9344, time: 0.155, data: 0.011) loss: 1.680 
(epoch: 9, iters: 9424, time: 0.155, data: 0.000) loss: 2.286 
(epoch: 9, iters: 9504, time: 0.156, data: 0.000) loss: 1.800 
(epoch: 9, iters: 9584, time: 0.155, data: 0.005) loss: 1.484 
(epoch: 9, iters: 9664, time: 0.154, data: 0.000) loss: 1.363 
(epoch: 9, iters: 9744, time: 0.154, data: 0.022) loss: 1.815 
(epoch: 9, iters: 9824, time: 0.157, data: 0.000) loss: 1.812 
(epoch: 9, iters: 9904, time: 0.156, data: 0.000) loss: 2.459 
(epoch: 9, iters: 9984, time: 0.154, data: 0.008) loss: 1.832 
(epoch: 9, iters: 10064, time: 0.155, data: 0.005) loss: 1.985 
(epoch: 9, iters: 10144, time: 0.149, data: 0.000) loss: 1.379 
saving the model at the end of epoch 9, iters 91728
End of epoch 9 / 200 	 Time Taken: 1576 sec
learning rate = 0.0002000
saving the latest model (epoch 10, total_steps 91744)
(epoch: 10, iters: 32, time: 0.157, data: 0.009) loss: 1.952 
(epoch: 10, iters: 112, time: 0.152, data: 0.000) loss: 1.367 
(epoch: 10, iters: 192, time: 0.152, data: 0.022) loss: 1.602 
(epoch: 10, iters: 272, time: 0.152, data: 0.010) loss: 1.441 
(epoch: 10, iters: 352, time: 0.154, data: 0.005) loss: 2.255 
(epoch: 10, iters: 432, time: 0.153, data: 0.000) loss: 1.540 
(epoch: 10, iters: 512, time: 0.155, data: 0.000) loss: 2.010 
(epoch: 10, iters: 592, time: 0.152, data: 0.016) loss: 1.940 
(epoch: 10, iters: 672, time: 0.154, data: 0.013) loss: 1.500 
(epoch: 10, iters: 752, time: 0.154, data: 0.000) loss: 1.415 
(epoch: 10, iters: 832, time: 0.155, data: 0.020) loss: 2.114 
(epoch: 10, iters: 912, time: 0.154, data: 0.010) loss: 1.974 
(epoch: 10, iters: 992, time: 0.155, data: 0.005) loss: 2.126 
(epoch: 10, iters: 1072, time: 0.154, data: 0.009) loss: 1.735 
(epoch: 10, iters: 1152, time: 0.157, data: 0.000) loss: 1.495 
(epoch: 10, iters: 1232, time: 0.155, data: 0.000) loss: 1.354 
(epoch: 10, iters: 1312, time: 0.154, data: 0.009) loss: 1.781 
(epoch: 10, iters: 1392, time: 0.156, data: 0.000) loss: 1.683 
(epoch: 10, iters: 1472, time: 0.154, data: 0.005) loss: 2.593 
(epoch: 10, iters: 1552, time: 0.154, data: 0.000) loss: 1.597 
(epoch: 10, iters: 1632, time: 0.154, data: 0.024) loss: 1.685 
(epoch: 10, iters: 1712, time: 0.154, data: 0.000) loss: 1.556 
(epoch: 10, iters: 1792, time: 0.154, data: 0.005) loss: 1.973 
(epoch: 10, iters: 1872, time: 0.154, data: 0.000) loss: 2.483 
(epoch: 10, iters: 1952, time: 0.156, data: 0.005) loss: 1.600 
(epoch: 10, iters: 2032, time: 0.154, data: 0.000) loss: 1.924 
(epoch: 10, iters: 2112, time: 0.154, data: 0.005) loss: 2.013 
(epoch: 10, iters: 2192, time: 0.154, data: 0.000) loss: 1.613 
(epoch: 10, iters: 2272, time: 0.154, data: 0.000) loss: 1.525 
(epoch: 10, iters: 2352, time: 0.154, data: 0.005) loss: 1.595 
(epoch: 10, iters: 2432, time: 0.155, data: 0.000) loss: 1.317 
(epoch: 10, iters: 2512, time: 0.154, data: 0.009) loss: 1.972 
(epoch: 10, iters: 2592, time: 0.155, data: 0.000) loss: 1.880 
(epoch: 10, iters: 2672, time: 0.154, data: 0.000) loss: 1.817 
(epoch: 10, iters: 2752, time: 0.158, data: 0.022) loss: 1.597 
(epoch: 10, iters: 2832, time: 0.155, data: 0.000) loss: 2.269 
(epoch: 10, iters: 2912, time: 0.155, data: 0.000) loss: 1.830 
(epoch: 10, iters: 2992, time: 0.157, data: 0.033) loss: 1.666 
(epoch: 10, iters: 3072, time: 0.155, data: 0.000) loss: 1.596 
(epoch: 10, iters: 3152, time: 0.154, data: 0.009) loss: 1.800 
(epoch: 10, iters: 3232, time: 0.156, data: 0.000) loss: 1.964 
(epoch: 10, iters: 3312, time: 0.152, data: 0.005) loss: 1.966 
(epoch: 10, iters: 3392, time: 0.153, data: 0.000) loss: 1.306 
(epoch: 10, iters: 3472, time: 0.154, data: 0.000) loss: 1.789 
(epoch: 10, iters: 3552, time: 0.153, data: 0.000) loss: 2.101 
(epoch: 10, iters: 3632, time: 0.154, data: 0.000) loss: 1.781 
(epoch: 10, iters: 3712, time: 0.155, data: 0.005) loss: 2.436 
(epoch: 10, iters: 3792, time: 0.154, data: 0.000) loss: 1.719 
(epoch: 10, iters: 3872, time: 0.154, data: 0.000) loss: 1.870 
(epoch: 10, iters: 3952, time: 0.154, data: 0.024) loss: 1.456 
saving the latest model (epoch 10, total_steps 95744)
(epoch: 10, iters: 4032, time: 0.154, data: 0.000) loss: 1.742 
(epoch: 10, iters: 4112, time: 0.154, data: 0.000) loss: 1.659 
(epoch: 10, iters: 4192, time: 0.155, data: 0.000) loss: 2.042 
(epoch: 10, iters: 4272, time: 0.155, data: 0.026) loss: 1.744 
(epoch: 10, iters: 4352, time: 0.153, data: 0.000) loss: 1.926 
(epoch: 10, iters: 4432, time: 0.154, data: 0.009) loss: 2.090 
(epoch: 10, iters: 4512, time: 0.153, data: 0.031) loss: 2.483 
(epoch: 10, iters: 4592, time: 0.155, data: 0.000) loss: 1.775 
(epoch: 10, iters: 4672, time: 0.158, data: 0.000) loss: 1.550 
(epoch: 10, iters: 4752, time: 0.154, data: 0.013) loss: 2.514 
(epoch: 10, iters: 4832, time: 0.153, data: 0.009) loss: 1.928 
(epoch: 10, iters: 4912, time: 0.154, data: 0.000) loss: 2.066 
(epoch: 10, iters: 4992, time: 0.154, data: 0.005) loss: 1.570 
(epoch: 10, iters: 5072, time: 0.154, data: 0.000) loss: 1.872 
(epoch: 10, iters: 5152, time: 0.155, data: 0.023) loss: 2.223 
(epoch: 10, iters: 5232, time: 0.154, data: 0.000) loss: 2.071 
(epoch: 10, iters: 5312, time: 0.154, data: 0.005) loss: 1.535 
(epoch: 10, iters: 5392, time: 0.155, data: 0.000) loss: 1.840 
(epoch: 10, iters: 5472, time: 0.153, data: 0.000) loss: 1.962 
(epoch: 10, iters: 5552, time: 0.156, data: 0.005) loss: 2.028 
(epoch: 10, iters: 5632, time: 0.155, data: 0.024) loss: 3.090 
(epoch: 10, iters: 5712, time: 0.153, data: 0.000) loss: 1.897 
(epoch: 10, iters: 5792, time: 0.155, data: 0.027) loss: 1.903 
(epoch: 10, iters: 5872, time: 0.154, data: 0.000) loss: 1.812 
(epoch: 10, iters: 5952, time: 0.154, data: 0.024) loss: 2.259 
(epoch: 10, iters: 6032, time: 0.154, data: 0.000) loss: 2.339 
(epoch: 10, iters: 6112, time: 0.154, data: 0.000) loss: 1.549 
(epoch: 10, iters: 6192, time: 0.153, data: 0.000) loss: 1.298 
(epoch: 10, iters: 6272, time: 0.156, data: 0.000) loss: 1.301 
(epoch: 10, iters: 6352, time: 0.154, data: 0.013) loss: 2.096 
(epoch: 10, iters: 6432, time: 0.154, data: 0.005) loss: 1.736 
(epoch: 10, iters: 6512, time: 0.154, data: 0.000) loss: 2.394 
(epoch: 10, iters: 6592, time: 0.154, data: 0.000) loss: 1.786 
(epoch: 10, iters: 6672, time: 0.154, data: 0.000) loss: 2.007 
(epoch: 10, iters: 6752, time: 0.157, data: 0.000) loss: 2.019 
(epoch: 10, iters: 6832, time: 0.155, data: 0.005) loss: 2.181 
(epoch: 10, iters: 6912, time: 0.154, data: 0.008) loss: 1.464 
(epoch: 10, iters: 6992, time: 0.156, data: 0.000) loss: 1.850 
(epoch: 10, iters: 7072, time: 0.155, data: 0.000) loss: 1.304 
(epoch: 10, iters: 7152, time: 0.155, data: 0.000) loss: 2.464 
(epoch: 10, iters: 7232, time: 0.154, data: 0.014) loss: 1.488 
(epoch: 10, iters: 7312, time: 0.156, data: 0.025) loss: 1.662 
(epoch: 10, iters: 7392, time: 0.153, data: 0.000) loss: 2.539 
(epoch: 10, iters: 7472, time: 0.156, data: 0.000) loss: 2.557 
(epoch: 10, iters: 7552, time: 0.155, data: 0.005) loss: 1.973 
(epoch: 10, iters: 7632, time: 0.152, data: 0.000) loss: 1.944 
(epoch: 10, iters: 7712, time: 0.155, data: 0.000) loss: 2.061 
(epoch: 10, iters: 7792, time: 0.156, data: 0.000) loss: 2.210 
(epoch: 10, iters: 7872, time: 0.155, data: 0.000) loss: 1.914 
(epoch: 10, iters: 7952, time: 0.160, data: 0.005) loss: 1.848 
saving the latest model (epoch 10, total_steps 99744)
(epoch: 10, iters: 8032, time: 0.155, data: 0.005) loss: 1.385 
(epoch: 10, iters: 8112, time: 0.156, data: 0.000) loss: 2.275 
(epoch: 10, iters: 8192, time: 0.160, data: 0.000) loss: 1.813 
(epoch: 10, iters: 8272, time: 0.158, data: 0.021) loss: 1.924 
(epoch: 10, iters: 8352, time: 0.165, data: 0.015) loss: 1.599 
(epoch: 10, iters: 8432, time: 0.160, data: 0.000) loss: 2.090 
(epoch: 10, iters: 8512, time: 0.161, data: 0.000) loss: 2.035 
(epoch: 10, iters: 8592, time: 0.158, data: 0.000) loss: 1.715 
(epoch: 10, iters: 8672, time: 0.159, data: 0.008) loss: 1.664 
(epoch: 10, iters: 8752, time: 0.160, data: 0.009) loss: 1.404 
(epoch: 10, iters: 8832, time: 0.159, data: 0.000) loss: 1.417 
(epoch: 10, iters: 8912, time: 0.157, data: 0.023) loss: 1.780 
(epoch: 10, iters: 8992, time: 0.161, data: 0.000) loss: 1.706 
(epoch: 10, iters: 9072, time: 0.162, data: 0.000) loss: 1.458 
(epoch: 10, iters: 9152, time: 0.158, data: 0.010) loss: 1.786 
(epoch: 10, iters: 9232, time: 0.158, data: 0.000) loss: 1.745 
(epoch: 10, iters: 9312, time: 0.154, data: 0.000) loss: 1.600 
(epoch: 10, iters: 9392, time: 0.159, data: 0.000) loss: 1.545 
(epoch: 10, iters: 9472, time: 0.169, data: 0.017) loss: 2.485 
(epoch: 10, iters: 9552, time: 0.156, data: 0.000) loss: 1.945 
(epoch: 10, iters: 9632, time: 0.155, data: 0.000) loss: 2.199 
(epoch: 10, iters: 9712, time: 0.158, data: 0.000) loss: 1.979 
(epoch: 10, iters: 9792, time: 0.154, data: 0.021) loss: 1.988 
(epoch: 10, iters: 9872, time: 0.157, data: 0.005) loss: 1.982 
(epoch: 10, iters: 9952, time: 0.154, data: 0.005) loss: 1.920 
(epoch: 10, iters: 10032, time: 0.155, data: 0.000) loss: 1.245 
(epoch: 10, iters: 10112, time: 0.152, data: 0.000) loss: 1.669 
(epoch: 10, iters: 10192, time: 0.092, data: 0.000) loss: 1.679 
saving the model at the end of epoch 10, iters 101920
End of epoch 10 / 200 	 Time Taken: 1587 sec
learning rate = 0.0002000
saving the latest model (epoch 11, total_steps 101936)
(epoch: 11, iters: 80, time: 0.166, data: 0.579) loss: 1.713 
(epoch: 11, iters: 160, time: 0.164, data: 0.000) loss: 1.680 
(epoch: 11, iters: 240, time: 0.157, data: 0.011) loss: 1.254 
(epoch: 11, iters: 320, time: 0.157, data: 0.020) loss: 1.844 
(epoch: 11, iters: 400, time: 0.156, data: 0.000) loss: 2.018 
(epoch: 11, iters: 480, time: 0.160, data: 0.005) loss: 1.540 
(epoch: 11, iters: 560, time: 0.156, data: 0.033) loss: 2.333 
(epoch: 11, iters: 640, time: 0.157, data: 0.000) loss: 1.813 
(epoch: 11, iters: 720, time: 0.160, data: 0.011) loss: 1.774 
(epoch: 11, iters: 800, time: 0.156, data: 0.000) loss: 1.053 
(epoch: 11, iters: 880, time: 0.157, data: 0.000) loss: 1.518 
(epoch: 11, iters: 960, time: 0.157, data: 0.031) loss: 1.617 
(epoch: 11, iters: 1040, time: 0.159, data: 0.000) loss: 1.551 
(epoch: 11, iters: 1120, time: 0.160, data: 0.000) loss: 2.059 
(epoch: 11, iters: 1200, time: 0.156, data: 0.000) loss: 1.683 
(epoch: 11, iters: 1280, time: 0.159, data: 0.000) loss: 1.839 
(epoch: 11, iters: 1360, time: 0.164, data: 0.016) loss: 2.137 
(epoch: 11, iters: 1440, time: 0.163, data: 0.000) loss: 1.913 
(epoch: 11, iters: 1520, time: 0.163, data: 0.000) loss: 2.134 
(epoch: 11, iters: 1600, time: 0.163, data: 0.000) loss: 2.342 
(epoch: 11, iters: 1680, time: 0.162, data: 0.033) loss: 1.702 
(epoch: 11, iters: 1760, time: 0.163, data: 0.000) loss: 2.311 
(epoch: 11, iters: 1840, time: 0.161, data: 0.000) loss: 1.504 
(epoch: 11, iters: 1920, time: 0.161, data: 0.000) loss: 1.831 
(epoch: 11, iters: 2000, time: 0.158, data: 0.020) loss: 1.179 
(epoch: 11, iters: 2080, time: 0.158, data: 0.021) loss: 1.130 
(epoch: 11, iters: 2160, time: 0.164, data: 0.000) loss: 2.382 
(epoch: 11, iters: 2240, time: 0.162, data: 0.000) loss: 1.674 
(epoch: 11, iters: 2320, time: 0.159, data: 0.000) loss: 1.977 
(epoch: 11, iters: 2400, time: 0.163, data: 0.014) loss: 1.680 
(epoch: 11, iters: 2480, time: 0.158, data: 0.000) loss: 1.240 
(epoch: 11, iters: 2560, time: 0.164, data: 0.005) loss: 2.315 
(epoch: 11, iters: 2640, time: 0.158, data: 0.000) loss: 2.047 
(epoch: 11, iters: 2720, time: 0.161, data: 0.005) loss: 1.430 
(epoch: 11, iters: 2800, time: 0.166, data: 0.021) loss: 2.349 
(epoch: 11, iters: 2880, time: 0.159, data: 0.005) loss: 1.472 
(epoch: 11, iters: 2960, time: 0.161, data: 0.024) loss: 1.748 
(epoch: 11, iters: 3040, time: 0.162, data: 0.000) loss: 1.846 
(epoch: 11, iters: 3120, time: 0.158, data: 0.009) loss: 1.981 
(epoch: 11, iters: 3200, time: 0.163, data: 0.042) loss: 2.532 
(epoch: 11, iters: 3280, time: 0.160, data: 0.000) loss: 1.354 
(epoch: 11, iters: 3360, time: 0.156, data: 0.008) loss: 1.614 
(epoch: 11, iters: 3440, time: 0.158, data: 0.000) loss: 2.425 
(epoch: 11, iters: 3520, time: 0.160, data: 0.000) loss: 1.708 
(epoch: 11, iters: 3600, time: 0.159, data: 0.005) loss: 2.503 
(epoch: 11, iters: 3680, time: 0.158, data: 0.000) loss: 1.196 
(epoch: 11, iters: 3760, time: 0.156, data: 0.000) loss: 1.773 
(epoch: 11, iters: 3840, time: 0.158, data: 0.010) loss: 1.665 
(epoch: 11, iters: 3920, time: 0.156, data: 0.014) loss: 1.891 
(epoch: 11, iters: 4000, time: 0.162, data: 0.008) loss: 1.176 
saving the latest model (epoch 11, total_steps 105936)
(epoch: 11, iters: 4080, time: 0.168, data: 0.025) loss: 1.421 
(epoch: 11, iters: 4160, time: 0.161, data: 0.000) loss: 2.264 
(epoch: 11, iters: 4240, time: 0.153, data: 0.000) loss: 1.057 
(epoch: 11, iters: 4320, time: 0.155, data: 0.015) loss: 1.245 
(epoch: 11, iters: 4400, time: 0.155, data: 0.020) loss: 2.166 
(epoch: 11, iters: 4480, time: 0.153, data: 0.000) loss: 1.461 
(epoch: 11, iters: 4560, time: 0.155, data: 0.015) loss: 2.264 
(epoch: 11, iters: 4640, time: 0.155, data: 0.000) loss: 1.612 
(epoch: 11, iters: 4720, time: 0.154, data: 0.034) loss: 1.817 
(epoch: 11, iters: 4800, time: 0.154, data: 0.000) loss: 2.188 
(epoch: 11, iters: 4880, time: 0.155, data: 0.000) loss: 2.249 
(epoch: 11, iters: 4960, time: 0.155, data: 0.013) loss: 1.646 
(epoch: 11, iters: 5040, time: 0.155, data: 0.000) loss: 1.832 
(epoch: 11, iters: 5120, time: 0.154, data: 0.005) loss: 1.587 
(epoch: 11, iters: 5200, time: 0.156, data: 0.005) loss: 2.324 
(epoch: 11, iters: 5280, time: 0.158, data: 0.009) loss: 2.275 
(epoch: 11, iters: 5360, time: 0.157, data: 0.022) loss: 1.858 
(epoch: 11, iters: 5440, time: 0.157, data: 0.000) loss: 1.339 
(epoch: 11, iters: 5520, time: 0.159, data: 0.035) loss: 2.016 
(epoch: 11, iters: 5600, time: 0.157, data: 0.000) loss: 1.249 
(epoch: 11, iters: 5680, time: 0.154, data: 0.000) loss: 1.401 
(epoch: 11, iters: 5760, time: 0.156, data: 0.019) loss: 1.482 
(epoch: 11, iters: 5840, time: 0.156, data: 0.000) loss: 1.467 
(epoch: 11, iters: 5920, time: 0.155, data: 0.009) loss: 1.795 
(epoch: 11, iters: 6000, time: 0.154, data: 0.000) loss: 1.569 
(epoch: 11, iters: 6080, time: 0.157, data: 0.019) loss: 1.711 
(epoch: 11, iters: 6160, time: 0.156, data: 0.017) loss: 1.383 
(epoch: 11, iters: 6240, time: 0.155, data: 0.000) loss: 2.204 
(epoch: 11, iters: 6320, time: 0.156, data: 0.000) loss: 1.934 
(epoch: 11, iters: 6400, time: 0.158, data: 0.009) loss: 1.910 
(epoch: 11, iters: 6480, time: 0.155, data: 0.006) loss: 2.233 
(epoch: 11, iters: 6560, time: 0.158, data: 0.000) loss: 1.628 
(epoch: 11, iters: 6640, time: 0.154, data: 0.009) loss: 2.732 
(epoch: 11, iters: 6720, time: 0.159, data: 0.019) loss: 2.611 
(epoch: 11, iters: 6800, time: 0.154, data: 0.014) loss: 1.983 
(epoch: 11, iters: 6880, time: 0.155, data: 0.005) loss: 2.520 
(epoch: 11, iters: 6960, time: 0.154, data: 0.000) loss: 1.540 
(epoch: 11, iters: 7040, time: 0.155, data: 0.028) loss: 1.359 
(epoch: 11, iters: 7120, time: 0.158, data: 0.000) loss: 1.767 
(epoch: 11, iters: 7200, time: 0.156, data: 0.008) loss: 1.915 
(epoch: 11, iters: 7280, time: 0.156, data: 0.000) loss: 2.181 
(epoch: 11, iters: 7360, time: 0.155, data: 0.000) loss: 1.672 
(epoch: 11, iters: 7440, time: 0.154, data: 0.000) loss: 1.637 
(epoch: 11, iters: 7520, time: 0.158, data: 0.036) loss: 2.164 
(epoch: 11, iters: 7600, time: 0.156, data: 0.000) loss: 1.758 
(epoch: 11, iters: 7680, time: 0.154, data: 0.000) loss: 1.694 
(epoch: 11, iters: 7760, time: 0.155, data: 0.000) loss: 1.429 
(epoch: 11, iters: 7840, time: 0.155, data: 0.013) loss: 2.060 
(epoch: 11, iters: 7920, time: 0.158, data: 0.000) loss: 1.474 
(epoch: 11, iters: 8000, time: 0.154, data: 0.009) loss: 1.950 
saving the latest model (epoch 11, total_steps 109936)
(epoch: 11, iters: 8080, time: 0.157, data: 0.000) loss: 1.891 
(epoch: 11, iters: 8160, time: 0.156, data: 0.000) loss: 2.397 
(epoch: 11, iters: 8240, time: 0.158, data: 0.000) loss: 1.778 
(epoch: 11, iters: 8320, time: 0.160, data: 0.000) loss: 1.565 
(epoch: 11, iters: 8400, time: 0.156, data: 0.000) loss: 1.538 
(epoch: 11, iters: 8480, time: 0.155, data: 0.033) loss: 1.610 
(epoch: 11, iters: 8560, time: 0.154, data: 0.000) loss: 1.489 
(epoch: 11, iters: 8640, time: 0.154, data: 0.000) loss: 1.506 
(epoch: 11, iters: 8720, time: 0.159, data: 0.005) loss: 2.272 
(epoch: 11, iters: 8800, time: 0.156, data: 0.012) loss: 1.909 
(epoch: 11, iters: 8880, time: 0.153, data: 0.000) loss: 1.458 
(epoch: 11, iters: 8960, time: 0.155, data: 0.000) loss: 1.365 
(epoch: 11, iters: 9040, time: 0.156, data: 0.011) loss: 1.943 
(epoch: 11, iters: 9120, time: 0.159, data: 0.000) loss: 1.744 
(epoch: 11, iters: 9200, time: 0.155, data: 0.010) loss: 1.905 
(epoch: 11, iters: 9280, time: 0.155, data: 0.000) loss: 1.696 
(epoch: 11, iters: 9360, time: 0.156, data: 0.009) loss: 1.783 
(epoch: 11, iters: 9440, time: 0.158, data: 0.000) loss: 2.180 
(epoch: 11, iters: 9520, time: 0.160, data: 0.008) loss: 1.639 
(epoch: 11, iters: 9600, time: 0.154, data: 0.000) loss: 1.344 
(epoch: 11, iters: 9680, time: 0.156, data: 0.000) loss: 1.563 
(epoch: 11, iters: 9760, time: 0.157, data: 0.042) loss: 1.451 
(epoch: 11, iters: 9840, time: 0.155, data: 0.000) loss: 2.105 
(epoch: 11, iters: 9920, time: 0.164, data: 0.000) loss: 1.654 
(epoch: 11, iters: 10000, time: 0.157, data: 0.008) loss: 1.843 
(epoch: 11, iters: 10080, time: 0.155, data: 0.000) loss: 1.533 
(epoch: 11, iters: 10160, time: 0.151, data: 0.000) loss: 1.878 
saving the model at the end of epoch 11, iters 112112
End of epoch 11 / 200 	 Time Taken: 1607 sec
learning rate = 0.0002000
saving the latest model (epoch 12, total_steps 112128)
(epoch: 12, iters: 48, time: 0.155, data: 0.000) loss: 1.751 
(epoch: 12, iters: 128, time: 0.153, data: 0.024) loss: 2.192 
(epoch: 12, iters: 208, time: 0.154, data: 0.005) loss: 1.655 
(epoch: 12, iters: 288, time: 0.154, data: 0.000) loss: 1.623 
(epoch: 12, iters: 368, time: 0.154, data: 0.008) loss: 1.845 
(epoch: 12, iters: 448, time: 0.153, data: 0.000) loss: 1.669 
(epoch: 12, iters: 528, time: 0.154, data: 0.000) loss: 1.844 
(epoch: 12, iters: 608, time: 0.154, data: 0.000) loss: 1.327 
(epoch: 12, iters: 688, time: 0.152, data: 0.033) loss: 1.027 
(epoch: 12, iters: 768, time: 0.152, data: 0.000) loss: 1.770 
(epoch: 12, iters: 848, time: 0.152, data: 0.000) loss: 1.330 
(epoch: 12, iters: 928, time: 0.152, data: 0.029) loss: 1.336 
(epoch: 12, iters: 1008, time: 0.153, data: 0.000) loss: 1.488 
(epoch: 12, iters: 1088, time: 0.153, data: 0.000) loss: 1.763 
(epoch: 12, iters: 1168, time: 0.153, data: 0.010) loss: 1.454 
(epoch: 12, iters: 1248, time: 0.153, data: 0.000) loss: 2.772 
(epoch: 12, iters: 1328, time: 0.154, data: 0.000) loss: 1.764 
(epoch: 12, iters: 1408, time: 0.152, data: 0.000) loss: 2.216 
(epoch: 12, iters: 1488, time: 0.153, data: 0.010) loss: 1.691 
(epoch: 12, iters: 1568, time: 0.152, data: 0.000) loss: 2.137 
(epoch: 12, iters: 1648, time: 0.153, data: 0.000) loss: 1.583 
(epoch: 12, iters: 1728, time: 0.154, data: 0.000) loss: 1.648 
(epoch: 12, iters: 1808, time: 0.154, data: 0.014) loss: 1.593 
(epoch: 12, iters: 1888, time: 0.153, data: 0.014) loss: 1.879 
(epoch: 12, iters: 1968, time: 0.155, data: 0.000) loss: 2.198 
(epoch: 12, iters: 2048, time: 0.152, data: 0.000) loss: 2.391 
(epoch: 12, iters: 2128, time: 0.153, data: 0.008) loss: 1.666 
(epoch: 12, iters: 2208, time: 0.155, data: 0.005) loss: 1.480 
(epoch: 12, iters: 2288, time: 0.155, data: 0.020) loss: 1.669 
(epoch: 12, iters: 2368, time: 0.153, data: 0.005) loss: 2.300 
(epoch: 12, iters: 2448, time: 0.151, data: 0.000) loss: 1.518 
(epoch: 12, iters: 2528, time: 0.153, data: 0.000) loss: 1.314 
(epoch: 12, iters: 2608, time: 0.155, data: 0.015) loss: 1.202 
(epoch: 12, iters: 2688, time: 0.155, data: 0.005) loss: 1.980 
(epoch: 12, iters: 2768, time: 0.154, data: 0.000) loss: 2.332 
(epoch: 12, iters: 2848, time: 0.154, data: 0.005) loss: 1.324 
(epoch: 12, iters: 2928, time: 0.155, data: 0.000) loss: 2.065 
(epoch: 12, iters: 3008, time: 0.154, data: 0.000) loss: 2.064 
(epoch: 12, iters: 3088, time: 0.154, data: 0.005) loss: 1.980 
(epoch: 12, iters: 3168, time: 0.155, data: 0.000) loss: 1.941 
(epoch: 12, iters: 3248, time: 0.168, data: 0.008) loss: 1.773 
(epoch: 12, iters: 3328, time: 0.173, data: 0.029) loss: 1.557 
(epoch: 12, iters: 3408, time: 0.158, data: 0.025) loss: 1.597 
(epoch: 12, iters: 3488, time: 0.159, data: 0.000) loss: 2.266 
(epoch: 12, iters: 3568, time: 0.161, data: 0.017) loss: 1.703 
(epoch: 12, iters: 3648, time: 0.158, data: 0.000) loss: 2.178 
(epoch: 12, iters: 3728, time: 0.155, data: 0.009) loss: 1.587 
(epoch: 12, iters: 3808, time: 0.154, data: 0.000) loss: 2.163 
(epoch: 12, iters: 3888, time: 0.157, data: 0.040) loss: 1.317 
(epoch: 12, iters: 3968, time: 0.160, data: 0.000) loss: 2.165 
saving the latest model (epoch 12, total_steps 116128)
(epoch: 12, iters: 4048, time: 0.158, data: 0.000) loss: 1.787 
(epoch: 12, iters: 4128, time: 0.158, data: 0.000) loss: 1.859 
(epoch: 12, iters: 4208, time: 0.159, data: 0.005) loss: 1.511 
(epoch: 12, iters: 4288, time: 0.156, data: 0.018) loss: 1.835 
(epoch: 12, iters: 4368, time: 0.160, data: 0.000) loss: 1.215 
(epoch: 12, iters: 4448, time: 0.157, data: 0.025) loss: 2.355 
(epoch: 12, iters: 4528, time: 0.159, data: 0.000) loss: 1.778 
(epoch: 12, iters: 4608, time: 0.160, data: 0.000) loss: 1.668 
(epoch: 12, iters: 4688, time: 0.153, data: 0.005) loss: 1.838 
(epoch: 12, iters: 4768, time: 0.156, data: 0.000) loss: 2.096 
(epoch: 12, iters: 4848, time: 0.155, data: 0.005) loss: 1.637 
(epoch: 12, iters: 4928, time: 0.157, data: 0.000) loss: 2.192 
(epoch: 12, iters: 5008, time: 0.157, data: 0.027) loss: 2.155 
(epoch: 12, iters: 5088, time: 0.156, data: 0.000) loss: 1.976 
(epoch: 12, iters: 5168, time: 0.157, data: 0.013) loss: 1.848 
(epoch: 12, iters: 5248, time: 0.159, data: 0.000) loss: 1.272 
(epoch: 12, iters: 5328, time: 0.155, data: 0.000) loss: 1.919 
(epoch: 12, iters: 5408, time: 0.155, data: 0.018) loss: 1.729 
(epoch: 12, iters: 5488, time: 0.155, data: 0.000) loss: 2.354 
(epoch: 12, iters: 5568, time: 0.157, data: 0.000) loss: 1.412 
(epoch: 12, iters: 5648, time: 0.157, data: 0.000) loss: 1.531 
(epoch: 12, iters: 5728, time: 0.155, data: 0.005) loss: 1.729 
(epoch: 12, iters: 5808, time: 0.158, data: 0.029) loss: 1.686 
(epoch: 12, iters: 5888, time: 0.153, data: 0.000) loss: 1.622 
(epoch: 12, iters: 5968, time: 0.152, data: 0.031) loss: 1.750 
(epoch: 12, iters: 6048, time: 0.155, data: 0.000) loss: 1.967 
(epoch: 12, iters: 6128, time: 0.156, data: 0.033) loss: 1.508 
(epoch: 12, iters: 6208, time: 0.157, data: 0.000) loss: 2.016 
(epoch: 12, iters: 6288, time: 0.155, data: 0.000) loss: 0.981 
(epoch: 12, iters: 6368, time: 0.156, data: 0.000) loss: 2.617 
(epoch: 12, iters: 6448, time: 0.155, data: 0.005) loss: 1.747 
(epoch: 12, iters: 6528, time: 0.153, data: 0.000) loss: 2.687 
(epoch: 12, iters: 6608, time: 0.152, data: 0.000) loss: 2.076 
(epoch: 12, iters: 6688, time: 0.152, data: 0.024) loss: 2.095 
(epoch: 12, iters: 6768, time: 0.154, data: 0.000) loss: 1.609 
(epoch: 12, iters: 6848, time: 0.152, data: 0.030) loss: 1.427 
(epoch: 12, iters: 6928, time: 0.154, data: 0.000) loss: 1.472 
(epoch: 12, iters: 7008, time: 0.152, data: 0.005) loss: 2.105 
(epoch: 12, iters: 7088, time: 0.153, data: 0.000) loss: 2.090 
(epoch: 12, iters: 7168, time: 0.153, data: 0.033) loss: 2.243 
(epoch: 12, iters: 7248, time: 0.151, data: 0.000) loss: 1.474 
(epoch: 12, iters: 7328, time: 0.154, data: 0.000) loss: 1.888 
(epoch: 12, iters: 7408, time: 0.151, data: 0.000) loss: 1.502 
(epoch: 12, iters: 7488, time: 0.154, data: 0.000) loss: 1.731 
(epoch: 12, iters: 7568, time: 0.153, data: 0.005) loss: 2.013 
(epoch: 12, iters: 7648, time: 0.153, data: 0.005) loss: 1.276 
(epoch: 12, iters: 7728, time: 0.156, data: 0.000) loss: 1.943 
(epoch: 12, iters: 7808, time: 0.154, data: 0.005) loss: 2.291 
(epoch: 12, iters: 7888, time: 0.156, data: 0.027) loss: 1.959 
(epoch: 12, iters: 7968, time: 0.156, data: 0.005) loss: 1.718 
saving the latest model (epoch 12, total_steps 120128)
(epoch: 12, iters: 8048, time: 0.154, data: 0.000) loss: 1.804 
(epoch: 12, iters: 8128, time: 0.157, data: 0.034) loss: 2.515 
(epoch: 12, iters: 8208, time: 0.155, data: 0.000) loss: 1.929 
(epoch: 12, iters: 8288, time: 0.154, data: 0.000) loss: 1.809 
(epoch: 12, iters: 8368, time: 0.154, data: 0.005) loss: 1.684 
(epoch: 12, iters: 8448, time: 0.154, data: 0.000) loss: 1.843 
(epoch: 12, iters: 8528, time: 0.152, data: 0.000) loss: 1.788 
(epoch: 12, iters: 8608, time: 0.154, data: 0.005) loss: 1.780 
(epoch: 12, iters: 8688, time: 0.153, data: 0.000) loss: 2.119 
(epoch: 12, iters: 8768, time: 0.153, data: 0.000) loss: 1.330 
(epoch: 12, iters: 8848, time: 0.157, data: 0.005) loss: 1.358 
(epoch: 12, iters: 8928, time: 0.154, data: 0.000) loss: 1.279 
(epoch: 12, iters: 9008, time: 0.153, data: 0.000) loss: 1.633 
(epoch: 12, iters: 9088, time: 0.153, data: 0.016) loss: 1.625 
(epoch: 12, iters: 9168, time: 0.154, data: 0.026) loss: 1.760 
(epoch: 12, iters: 9248, time: 0.152, data: 0.000) loss: 2.207 
(epoch: 12, iters: 9328, time: 0.155, data: 0.000) loss: 1.670 
(epoch: 12, iters: 9408, time: 0.154, data: 0.000) loss: 1.194 
(epoch: 12, iters: 9488, time: 0.154, data: 0.026) loss: 1.092 
(epoch: 12, iters: 9568, time: 0.155, data: 0.000) loss: 1.465 
(epoch: 12, iters: 9648, time: 0.156, data: 0.000) loss: 2.154 
(epoch: 12, iters: 9728, time: 0.155, data: 0.014) loss: 0.961 
(epoch: 12, iters: 9808, time: 0.157, data: 0.026) loss: 2.011 
(epoch: 12, iters: 9888, time: 0.155, data: 0.000) loss: 1.931 
(epoch: 12, iters: 9968, time: 0.154, data: 0.014) loss: 1.342 
(epoch: 12, iters: 10048, time: 0.155, data: 0.000) loss: 1.900 
(epoch: 12, iters: 10128, time: 0.152, data: 0.032) loss: 1.945 
saving the model at the end of epoch 12, iters 122304
End of epoch 12 / 200 	 Time Taken: 1583 sec
learning rate = 0.0002000
(epoch: 13, iters: 16, time: 0.179, data: 0.000) loss: 1.919 
saving the latest model (epoch 13, total_steps 122320)
(epoch: 13, iters: 96, time: 0.156, data: 0.019) loss: 1.042 
(epoch: 13, iters: 176, time: 0.155, data: 0.028) loss: 2.197 
(epoch: 13, iters: 256, time: 0.155, data: 0.000) loss: 1.979 
(epoch: 13, iters: 336, time: 0.153, data: 0.005) loss: 2.191 
(epoch: 13, iters: 416, time: 0.155, data: 0.000) loss: 1.293 
(epoch: 13, iters: 496, time: 0.154, data: 0.000) loss: 1.603 
(epoch: 13, iters: 576, time: 0.155, data: 0.000) loss: 1.673 
(epoch: 13, iters: 656, time: 0.153, data: 0.005) loss: 2.138 
(epoch: 13, iters: 736, time: 0.155, data: 0.000) loss: 1.550 
(epoch: 13, iters: 816, time: 0.152, data: 0.025) loss: 1.887 
(epoch: 13, iters: 896, time: 0.153, data: 0.000) loss: 1.320 
(epoch: 13, iters: 976, time: 0.153, data: 0.000) loss: 1.575 
(epoch: 13, iters: 1056, time: 0.154, data: 0.008) loss: 1.601 
(epoch: 13, iters: 1136, time: 0.154, data: 0.009) loss: 1.733 
(epoch: 13, iters: 1216, time: 0.153, data: 0.000) loss: 1.608 
(epoch: 13, iters: 1296, time: 0.154, data: 0.008) loss: 1.432 
(epoch: 13, iters: 1376, time: 0.153, data: 0.000) loss: 1.788 
(epoch: 13, iters: 1456, time: 0.154, data: 0.000) loss: 1.892 
(epoch: 13, iters: 1536, time: 0.153, data: 0.023) loss: 1.401 
(epoch: 13, iters: 1616, time: 0.153, data: 0.000) loss: 1.621 
(epoch: 13, iters: 1696, time: 0.152, data: 0.000) loss: 2.658 
(epoch: 13, iters: 1776, time: 0.154, data: 0.000) loss: 1.574 
(epoch: 13, iters: 1856, time: 0.153, data: 0.000) loss: 1.045 
(epoch: 13, iters: 1936, time: 0.155, data: 0.000) loss: 2.030 
(epoch: 13, iters: 2016, time: 0.154, data: 0.009) loss: 1.339 
(epoch: 13, iters: 2096, time: 0.153, data: 0.000) loss: 1.805 
(epoch: 13, iters: 2176, time: 0.154, data: 0.005) loss: 1.750 
(epoch: 13, iters: 2256, time: 0.154, data: 0.005) loss: 1.468 
(epoch: 13, iters: 2336, time: 0.154, data: 0.000) loss: 1.898 
(epoch: 13, iters: 2416, time: 0.152, data: 0.014) loss: 1.593 
(epoch: 13, iters: 2496, time: 0.154, data: 0.000) loss: 1.825 
(epoch: 13, iters: 2576, time: 0.153, data: 0.011) loss: 1.971 
(epoch: 13, iters: 2656, time: 0.153, data: 0.000) loss: 1.289 
(epoch: 13, iters: 2736, time: 0.154, data: 0.000) loss: 2.467 
(epoch: 13, iters: 2816, time: 0.156, data: 0.000) loss: 1.926 
(epoch: 13, iters: 2896, time: 0.154, data: 0.015) loss: 1.380 
(epoch: 13, iters: 2976, time: 0.156, data: 0.000) loss: 1.561 
(epoch: 13, iters: 3056, time: 0.155, data: 0.000) loss: 1.404 
(epoch: 13, iters: 3136, time: 0.154, data: 0.005) loss: 2.055 
(epoch: 13, iters: 3216, time: 0.155, data: 0.000) loss: 1.875 
(epoch: 13, iters: 3296, time: 0.155, data: 0.020) loss: 1.737 
(epoch: 13, iters: 3376, time: 0.154, data: 0.022) loss: 1.875 
(epoch: 13, iters: 3456, time: 0.154, data: 0.009) loss: 2.326 
(epoch: 13, iters: 3536, time: 0.153, data: 0.000) loss: 1.329 
(epoch: 13, iters: 3616, time: 0.155, data: 0.008) loss: 1.837 
(epoch: 13, iters: 3696, time: 0.152, data: 0.000) loss: 1.651 
(epoch: 13, iters: 3776, time: 0.152, data: 0.016) loss: 1.688 
(epoch: 13, iters: 3856, time: 0.154, data: 0.025) loss: 2.440 
(epoch: 13, iters: 3936, time: 0.154, data: 0.000) loss: 1.434 
(epoch: 13, iters: 4016, time: 0.153, data: 0.022) loss: 1.040 
saving the latest model (epoch 13, total_steps 126320)
(epoch: 13, iters: 4096, time: 0.154, data: 0.000) loss: 1.940 
(epoch: 13, iters: 4176, time: 0.153, data: 0.000) loss: 1.625 
(epoch: 13, iters: 4256, time: 0.153, data: 0.020) loss: 1.852 
(epoch: 13, iters: 4336, time: 0.155, data: 0.009) loss: 1.446 
(epoch: 13, iters: 4416, time: 0.152, data: 0.000) loss: 0.874 
(epoch: 13, iters: 4496, time: 0.152, data: 0.013) loss: 2.087 
(epoch: 13, iters: 4576, time: 0.152, data: 0.000) loss: 1.862 
(epoch: 13, iters: 4656, time: 0.156, data: 0.000) loss: 1.928 
(epoch: 13, iters: 4736, time: 0.154, data: 0.023) loss: 2.344 
(epoch: 13, iters: 4816, time: 0.153, data: 0.000) loss: 1.767 
(epoch: 13, iters: 4896, time: 0.154, data: 0.000) loss: 1.715 
(epoch: 13, iters: 4976, time: 0.153, data: 0.005) loss: 1.309 
(epoch: 13, iters: 5056, time: 0.153, data: 0.000) loss: 1.660 
(epoch: 13, iters: 5136, time: 0.154, data: 0.000) loss: 1.630 
(epoch: 13, iters: 5216, time: 0.156, data: 0.019) loss: 1.255 
(epoch: 13, iters: 5296, time: 0.153, data: 0.000) loss: 1.957 
(epoch: 13, iters: 5376, time: 0.154, data: 0.000) loss: 1.080 
(epoch: 13, iters: 5456, time: 0.155, data: 0.013) loss: 1.822 
(epoch: 13, iters: 5536, time: 0.153, data: 0.005) loss: 1.369 
(epoch: 13, iters: 5616, time: 0.155, data: 0.014) loss: 1.505 
(epoch: 13, iters: 5696, time: 0.154, data: 0.000) loss: 1.523 
(epoch: 13, iters: 5776, time: 0.154, data: 0.005) loss: 1.499 
(epoch: 13, iters: 5856, time: 0.154, data: 0.000) loss: 2.248 
(epoch: 13, iters: 5936, time: 0.153, data: 0.009) loss: 1.404 
(epoch: 13, iters: 6016, time: 0.153, data: 0.005) loss: 2.040 
(epoch: 13, iters: 6096, time: 0.153, data: 0.017) loss: 1.342 
(epoch: 13, iters: 6176, time: 0.154, data: 0.000) loss: 0.870 
(epoch: 13, iters: 6256, time: 0.153, data: 0.022) loss: 1.940 
(epoch: 13, iters: 6336, time: 0.151, data: 0.000) loss: 2.012 
(epoch: 13, iters: 6416, time: 0.150, data: 0.005) loss: 1.533 
(epoch: 13, iters: 6496, time: 0.154, data: 0.029) loss: 1.575 
(epoch: 13, iters: 6576, time: 0.153, data: 0.000) loss: 1.600 
(epoch: 13, iters: 6656, time: 0.154, data: 0.019) loss: 2.496 
(epoch: 13, iters: 6736, time: 0.153, data: 0.000) loss: 2.227 
(epoch: 13, iters: 6816, time: 0.153, data: 0.000) loss: 1.559 
(epoch: 13, iters: 6896, time: 0.154, data: 0.005) loss: 1.571 
(epoch: 13, iters: 6976, time: 0.155, data: 0.010) loss: 2.252 
(epoch: 13, iters: 7056, time: 0.154, data: 0.000) loss: 2.456 
(epoch: 13, iters: 7136, time: 0.153, data: 0.000) loss: 2.210 
(epoch: 13, iters: 7216, time: 0.155, data: 0.000) loss: 1.866 
(epoch: 13, iters: 7296, time: 0.153, data: 0.000) loss: 1.327 
(epoch: 13, iters: 7376, time: 0.152, data: 0.000) loss: 1.286 
(epoch: 13, iters: 7456, time: 0.152, data: 0.000) loss: 1.284 
(epoch: 13, iters: 7536, time: 0.153, data: 0.000) loss: 1.985 
(epoch: 13, iters: 7616, time: 0.153, data: 0.000) loss: 1.870 
(epoch: 13, iters: 7696, time: 0.153, data: 0.000) loss: 2.011 
(epoch: 13, iters: 7776, time: 0.154, data: 0.006) loss: 2.056 
(epoch: 13, iters: 7856, time: 0.153, data: 0.000) loss: 1.526 
(epoch: 13, iters: 7936, time: 0.153, data: 0.005) loss: 2.467 
(epoch: 13, iters: 8016, time: 0.155, data: 0.000) loss: 1.650 
saving the latest model (epoch 13, total_steps 130320)
(epoch: 13, iters: 8096, time: 0.152, data: 0.010) loss: 1.479 
(epoch: 13, iters: 8176, time: 0.153, data: 0.000) loss: 2.074 
(epoch: 13, iters: 8256, time: 0.152, data: 0.010) loss: 1.996 
(epoch: 13, iters: 8336, time: 0.154, data: 0.000) loss: 1.038 
(epoch: 13, iters: 8416, time: 0.152, data: 0.000) loss: 1.508 
(epoch: 13, iters: 8496, time: 0.152, data: 0.017) loss: 1.413 
(epoch: 13, iters: 8576, time: 0.153, data: 0.034) loss: 1.407 
(epoch: 13, iters: 8656, time: 0.152, data: 0.000) loss: 1.834 
(epoch: 13, iters: 8736, time: 0.155, data: 0.021) loss: 1.415 
(epoch: 13, iters: 8816, time: 0.153, data: 0.000) loss: 1.601 
(epoch: 13, iters: 8896, time: 0.152, data: 0.015) loss: 1.632 
(epoch: 13, iters: 8976, time: 0.150, data: 0.000) loss: 1.248 
(epoch: 13, iters: 9056, time: 0.151, data: 0.033) loss: 1.997 
(epoch: 13, iters: 9136, time: 0.154, data: 0.000) loss: 1.666 
(epoch: 13, iters: 9216, time: 0.153, data: 0.000) loss: 1.456 
(epoch: 13, iters: 9296, time: 0.154, data: 0.000) loss: 2.074 
(epoch: 13, iters: 9376, time: 0.151, data: 0.005) loss: 1.938 
(epoch: 13, iters: 9456, time: 0.153, data: 0.000) loss: 1.875 
(epoch: 13, iters: 9536, time: 0.155, data: 0.000) loss: 1.918 
(epoch: 13, iters: 9616, time: 0.154, data: 0.022) loss: 1.857 
(epoch: 13, iters: 9696, time: 0.154, data: 0.000) loss: 1.572 
(epoch: 13, iters: 9776, time: 0.153, data: 0.020) loss: 1.801 
(epoch: 13, iters: 9856, time: 0.154, data: 0.000) loss: 1.716 
(epoch: 13, iters: 9936, time: 0.155, data: 0.000) loss: 2.099 
(epoch: 13, iters: 10016, time: 0.153, data: 0.020) loss: 1.588 
(epoch: 13, iters: 10096, time: 0.151, data: 0.000) loss: 1.109 
(epoch: 13, iters: 10176, time: 0.148, data: 0.000) loss: 2.064 
saving the model at the end of epoch 13, iters 132496
End of epoch 13 / 200 	 Time Taken: 1568 sec
learning rate = 0.0002000
saving the latest model (epoch 14, total_steps 132512)
(epoch: 14, iters: 64, time: 0.153, data: 0.000) loss: 2.085 
(epoch: 14, iters: 144, time: 0.151, data: 0.027) loss: 1.415 
(epoch: 14, iters: 224, time: 0.154, data: 0.000) loss: 1.450 
(epoch: 14, iters: 304, time: 0.151, data: 0.008) loss: 1.350 
(epoch: 14, iters: 384, time: 0.153, data: 0.000) loss: 1.203 
(epoch: 14, iters: 464, time: 0.153, data: 0.000) loss: 1.387 
(epoch: 14, iters: 544, time: 0.153, data: 0.000) loss: 1.753 
(epoch: 14, iters: 624, time: 0.152, data: 0.035) loss: 1.951 
(epoch: 14, iters: 704, time: 0.151, data: 0.000) loss: 1.521 
(epoch: 14, iters: 784, time: 0.152, data: 0.006) loss: 2.113 
(epoch: 14, iters: 864, time: 0.154, data: 0.019) loss: 1.948 
(epoch: 14, iters: 944, time: 0.155, data: 0.000) loss: 1.774 
(epoch: 14, iters: 1024, time: 0.153, data: 0.000) loss: 2.067 
(epoch: 14, iters: 1104, time: 0.153, data: 0.000) loss: 2.078 
(epoch: 14, iters: 1184, time: 0.156, data: 0.000) loss: 2.233 
(epoch: 14, iters: 1264, time: 0.154, data: 0.000) loss: 1.308 
(epoch: 14, iters: 1344, time: 0.153, data: 0.015) loss: 1.519 
(epoch: 14, iters: 1424, time: 0.151, data: 0.000) loss: 1.410 
(epoch: 14, iters: 1504, time: 0.152, data: 0.005) loss: 2.486 
(epoch: 14, iters: 1584, time: 0.155, data: 0.005) loss: 1.716 
(epoch: 14, iters: 1664, time: 0.154, data: 0.008) loss: 1.664 
(epoch: 14, iters: 1744, time: 0.153, data: 0.017) loss: 1.514 
(epoch: 14, iters: 1824, time: 0.152, data: 0.000) loss: 1.269 
(epoch: 14, iters: 1904, time: 0.153, data: 0.000) loss: 1.560 
(epoch: 14, iters: 1984, time: 0.153, data: 0.014) loss: 1.684 
(epoch: 14, iters: 2064, time: 0.153, data: 0.000) loss: 1.262 
(epoch: 14, iters: 2144, time: 0.155, data: 0.014) loss: 1.411 
(epoch: 14, iters: 2224, time: 0.154, data: 0.000) loss: 1.344 
(epoch: 14, iters: 2304, time: 0.154, data: 0.010) loss: 1.996 
(epoch: 14, iters: 2384, time: 0.153, data: 0.005) loss: 2.122 
(epoch: 14, iters: 2464, time: 0.151, data: 0.000) loss: 1.661 
(epoch: 14, iters: 2544, time: 0.152, data: 0.000) loss: 1.990 
(epoch: 14, iters: 2624, time: 0.152, data: 0.000) loss: 1.734 
(epoch: 14, iters: 2704, time: 0.153, data: 0.000) loss: 1.668 
(epoch: 14, iters: 2784, time: 0.153, data: 0.000) loss: 1.608 
(epoch: 14, iters: 2864, time: 0.153, data: 0.000) loss: 0.866 
(epoch: 14, iters: 2944, time: 0.152, data: 0.000) loss: 1.480 
(epoch: 14, iters: 3024, time: 0.153, data: 0.031) loss: 1.751 
(epoch: 14, iters: 3104, time: 0.160, data: 0.014) loss: 1.338 
(epoch: 14, iters: 3184, time: 0.154, data: 0.005) loss: 1.327 
(epoch: 14, iters: 3264, time: 0.156, data: 0.000) loss: 1.975 
(epoch: 14, iters: 3344, time: 0.154, data: 0.014) loss: 1.135 
(epoch: 14, iters: 3424, time: 0.153, data: 0.000) loss: 1.747 
(epoch: 14, iters: 3504, time: 0.163, data: 0.000) loss: 0.852 
(epoch: 14, iters: 3584, time: 0.153, data: 0.014) loss: 1.382 
(epoch: 14, iters: 3664, time: 0.154, data: 0.005) loss: 1.720 
(epoch: 14, iters: 3744, time: 0.155, data: 0.005) loss: 1.133 
(epoch: 14, iters: 3824, time: 0.153, data: 0.005) loss: 1.854 
(epoch: 14, iters: 3904, time: 0.158, data: 0.005) loss: 1.545 
(epoch: 14, iters: 3984, time: 0.154, data: 0.005) loss: 1.211 
saving the latest model (epoch 14, total_steps 136512)
(epoch: 14, iters: 4064, time: 0.153, data: 0.000) loss: 1.691 
(epoch: 14, iters: 4144, time: 0.158, data: 0.000) loss: 1.956 
(epoch: 14, iters: 4224, time: 0.159, data: 0.005) loss: 1.167 
(epoch: 14, iters: 4304, time: 0.158, data: 0.000) loss: 1.721 
(epoch: 14, iters: 4384, time: 0.157, data: 0.010) loss: 2.420 
(epoch: 14, iters: 4464, time: 0.157, data: 0.000) loss: 2.221 
(epoch: 14, iters: 4544, time: 0.157, data: 0.026) loss: 1.716 
(epoch: 14, iters: 4624, time: 0.157, data: 0.000) loss: 1.746 
(epoch: 14, iters: 4704, time: 0.157, data: 0.012) loss: 1.348 
(epoch: 14, iters: 4784, time: 0.157, data: 0.000) loss: 1.531 
(epoch: 14, iters: 4864, time: 0.159, data: 0.000) loss: 1.415 
(epoch: 14, iters: 4944, time: 0.157, data: 0.016) loss: 1.790 
(epoch: 14, iters: 5024, time: 0.157, data: 0.005) loss: 1.105 
(epoch: 14, iters: 5104, time: 0.161, data: 0.000) loss: 1.385 
(epoch: 14, iters: 5184, time: 0.158, data: 0.000) loss: 1.627 
(epoch: 14, iters: 5264, time: 0.159, data: 0.000) loss: 1.453 
(epoch: 14, iters: 5344, time: 0.158, data: 0.000) loss: 1.647 
(epoch: 14, iters: 5424, time: 0.160, data: 0.000) loss: 2.242 
(epoch: 14, iters: 5504, time: 0.158, data: 0.026) loss: 1.513 
(epoch: 14, iters: 5584, time: 0.159, data: 0.000) loss: 1.330 
(epoch: 14, iters: 5664, time: 0.158, data: 0.011) loss: 2.505 
(epoch: 14, iters: 5744, time: 0.156, data: 0.000) loss: 1.454 
(epoch: 14, iters: 5824, time: 0.157, data: 0.004) loss: 1.733 
(epoch: 14, iters: 5904, time: 0.156, data: 0.000) loss: 1.586 
(epoch: 14, iters: 5984, time: 0.159, data: 0.000) loss: 1.319 
(epoch: 14, iters: 6064, time: 0.158, data: 0.005) loss: 2.304 
(epoch: 14, iters: 6144, time: 0.158, data: 0.000) loss: 1.208 
(epoch: 14, iters: 6224, time: 0.159, data: 0.005) loss: 2.149 
(epoch: 14, iters: 6304, time: 0.158, data: 0.006) loss: 2.295 
(epoch: 14, iters: 6384, time: 0.161, data: 0.026) loss: 1.143 
(epoch: 14, iters: 6464, time: 0.158, data: 0.000) loss: 1.134 
(epoch: 14, iters: 6544, time: 0.157, data: 0.000) loss: 1.845 
(epoch: 14, iters: 6624, time: 0.155, data: 0.000) loss: 1.595 
(epoch: 14, iters: 6704, time: 0.154, data: 0.000) loss: 1.895 
(epoch: 14, iters: 6784, time: 0.156, data: 0.000) loss: 1.642 
(epoch: 14, iters: 6864, time: 0.153, data: 0.009) loss: 1.267 
(epoch: 14, iters: 6944, time: 0.153, data: 0.000) loss: 0.804 
(epoch: 14, iters: 7024, time: 0.153, data: 0.025) loss: 0.875 
(epoch: 14, iters: 7104, time: 0.155, data: 0.000) loss: 1.901 
(epoch: 14, iters: 7184, time: 0.157, data: 0.005) loss: 1.317 
(epoch: 14, iters: 7264, time: 0.156, data: 0.009) loss: 1.846 
(epoch: 14, iters: 7344, time: 0.156, data: 0.000) loss: 1.413 
(epoch: 14, iters: 7424, time: 0.155, data: 0.000) loss: 1.081 
(epoch: 14, iters: 7504, time: 0.156, data: 0.015) loss: 1.916 
(epoch: 14, iters: 7584, time: 0.159, data: 0.000) loss: 1.950 
(epoch: 14, iters: 7664, time: 0.157, data: 0.000) loss: 1.138 
(epoch: 14, iters: 7744, time: 0.155, data: 0.005) loss: 1.649 
(epoch: 14, iters: 7824, time: 0.155, data: 0.000) loss: 1.584 
(epoch: 14, iters: 7904, time: 0.153, data: 0.005) loss: 1.870 
(epoch: 14, iters: 7984, time: 0.155, data: 0.000) loss: 1.335 
saving the latest model (epoch 14, total_steps 140512)
(epoch: 14, iters: 8064, time: 0.157, data: 0.011) loss: 1.414 
(epoch: 14, iters: 8144, time: 0.155, data: 0.005) loss: 1.569 
(epoch: 14, iters: 8224, time: 0.154, data: 0.023) loss: 1.341 
(epoch: 14, iters: 8304, time: 0.156, data: 0.005) loss: 1.940 
(epoch: 14, iters: 8384, time: 0.154, data: 0.000) loss: 1.353 
(epoch: 14, iters: 8464, time: 0.156, data: 0.011) loss: 1.448 
(epoch: 14, iters: 8544, time: 0.153, data: 0.000) loss: 2.531 
(epoch: 14, iters: 8624, time: 0.155, data: 0.015) loss: 1.679 
(epoch: 14, iters: 8704, time: 0.154, data: 0.000) loss: 1.356 
(epoch: 14, iters: 8784, time: 0.155, data: 0.014) loss: 1.694 
(epoch: 14, iters: 8864, time: 0.158, data: 0.033) loss: 1.521 
(epoch: 14, iters: 8944, time: 0.156, data: 0.000) loss: 1.322 
(epoch: 14, iters: 9024, time: 0.155, data: 0.000) loss: 1.313 
(epoch: 14, iters: 9104, time: 0.156, data: 0.017) loss: 2.095 
(epoch: 14, iters: 9184, time: 0.157, data: 0.005) loss: 1.652 
(epoch: 14, iters: 9264, time: 0.156, data: 0.000) loss: 1.255 
(epoch: 14, iters: 9344, time: 0.158, data: 0.000) loss: 1.786 
(epoch: 14, iters: 9424, time: 0.156, data: 0.009) loss: 1.727 
(epoch: 14, iters: 9504, time: 0.154, data: 0.000) loss: 1.860 
(epoch: 14, iters: 9584, time: 0.156, data: 0.000) loss: 1.686 
(epoch: 14, iters: 9664, time: 0.155, data: 0.005) loss: 1.261 
(epoch: 14, iters: 9744, time: 0.158, data: 0.000) loss: 1.844 
(epoch: 14, iters: 9824, time: 0.156, data: 0.005) loss: 2.038 
(epoch: 14, iters: 9904, time: 0.155, data: 0.005) loss: 1.468 
(epoch: 14, iters: 9984, time: 0.156, data: 0.009) loss: 1.625 
(epoch: 14, iters: 10064, time: 0.155, data: 0.020) loss: 2.088 
(epoch: 14, iters: 10144, time: 0.151, data: 0.017) loss: 1.456 
saving the model at the end of epoch 14, iters 142688
End of epoch 14 / 200 	 Time Taken: 1585 sec
learning rate = 0.0002000
saving the latest model (epoch 15, total_steps 142704)
(epoch: 15, iters: 32, time: 0.159, data: 0.000) loss: 1.643 
(epoch: 15, iters: 112, time: 0.155, data: 0.000) loss: 1.898 
(epoch: 15, iters: 192, time: 0.154, data: 0.000) loss: 2.038 
(epoch: 15, iters: 272, time: 0.154, data: 0.009) loss: 1.834 
(epoch: 15, iters: 352, time: 0.154, data: 0.000) loss: 2.124 
(epoch: 15, iters: 432, time: 0.155, data: 0.017) loss: 1.648 
(epoch: 15, iters: 512, time: 0.154, data: 0.000) loss: 1.712 
(epoch: 15, iters: 592, time: 0.153, data: 0.000) loss: 1.786 
(epoch: 15, iters: 672, time: 0.151, data: 0.015) loss: 1.289 
(epoch: 15, iters: 752, time: 0.154, data: 0.005) loss: 2.135 
(epoch: 15, iters: 832, time: 0.154, data: 0.005) loss: 2.395 
(epoch: 15, iters: 912, time: 0.154, data: 0.000) loss: 1.164 
(epoch: 15, iters: 992, time: 0.153, data: 0.000) loss: 2.082 
(epoch: 15, iters: 1072, time: 0.152, data: 0.015) loss: 1.085 
(epoch: 15, iters: 1152, time: 0.153, data: 0.029) loss: 1.061 
(epoch: 15, iters: 1232, time: 0.155, data: 0.024) loss: 2.273 
(epoch: 15, iters: 1312, time: 0.153, data: 0.000) loss: 1.566 
(epoch: 15, iters: 1392, time: 0.154, data: 0.014) loss: 2.299 
(epoch: 15, iters: 1472, time: 0.153, data: 0.024) loss: 1.605 
(epoch: 15, iters: 1552, time: 0.155, data: 0.000) loss: 0.632 
(epoch: 15, iters: 1632, time: 0.153, data: 0.000) loss: 1.526 
(epoch: 15, iters: 1712, time: 0.154, data: 0.000) loss: 1.345 
(epoch: 15, iters: 1792, time: 0.154, data: 0.000) loss: 1.978 
(epoch: 15, iters: 1872, time: 0.154, data: 0.000) loss: 1.168 
(epoch: 15, iters: 1952, time: 0.155, data: 0.000) loss: 1.198 
(epoch: 15, iters: 2032, time: 0.170, data: 0.000) loss: 1.521 
(epoch: 15, iters: 2112, time: 0.156, data: 0.008) loss: 1.637 
(epoch: 15, iters: 2192, time: 0.153, data: 0.000) loss: 1.733 
(epoch: 15, iters: 2272, time: 0.155, data: 0.005) loss: 1.674 
(epoch: 15, iters: 2352, time: 0.155, data: 0.000) loss: 1.971 
(epoch: 15, iters: 2432, time: 0.153, data: 0.008) loss: 1.744 
(epoch: 15, iters: 2512, time: 0.155, data: 0.000) loss: 0.941 
(epoch: 15, iters: 2592, time: 0.153, data: 0.000) loss: 1.710 
(epoch: 15, iters: 2672, time: 0.154, data: 0.014) loss: 1.541 
(epoch: 15, iters: 2752, time: 0.156, data: 0.000) loss: 1.103 
(epoch: 15, iters: 2832, time: 0.154, data: 0.025) loss: 1.870 
(epoch: 15, iters: 2912, time: 0.154, data: 0.000) loss: 1.258 
(epoch: 15, iters: 2992, time: 0.153, data: 0.009) loss: 2.777 
(epoch: 15, iters: 3072, time: 0.153, data: 0.000) loss: 1.763 
(epoch: 15, iters: 3152, time: 0.154, data: 0.008) loss: 1.829 
(epoch: 15, iters: 3232, time: 0.152, data: 0.000) loss: 1.713 
(epoch: 15, iters: 3312, time: 0.154, data: 0.000) loss: 1.821 
(epoch: 15, iters: 3392, time: 0.153, data: 0.008) loss: 1.859 
(epoch: 15, iters: 3472, time: 0.153, data: 0.025) loss: 1.545 
(epoch: 15, iters: 3552, time: 0.153, data: 0.000) loss: 1.955 
(epoch: 15, iters: 3632, time: 0.154, data: 0.005) loss: 1.912 
(epoch: 15, iters: 3712, time: 0.155, data: 0.005) loss: 2.901 
(epoch: 15, iters: 3792, time: 0.154, data: 0.000) loss: 1.449 
(epoch: 15, iters: 3872, time: 0.155, data: 0.005) loss: 1.829 
(epoch: 15, iters: 3952, time: 0.155, data: 0.000) loss: 1.957 
saving the latest model (epoch 15, total_steps 146704)
(epoch: 15, iters: 4032, time: 0.155, data: 0.014) loss: 1.776 
(epoch: 15, iters: 4112, time: 0.155, data: 0.000) loss: 2.001 
(epoch: 15, iters: 4192, time: 0.153, data: 0.014) loss: 1.890 
(epoch: 15, iters: 4272, time: 0.154, data: 0.000) loss: 1.719 
(epoch: 15, iters: 4352, time: 0.155, data: 0.005) loss: 1.793 
(epoch: 15, iters: 4432, time: 0.154, data: 0.009) loss: 1.624 
(epoch: 15, iters: 4512, time: 0.153, data: 0.000) loss: 1.358 
(epoch: 15, iters: 4592, time: 0.153, data: 0.005) loss: 1.161 
(epoch: 15, iters: 4672, time: 0.154, data: 0.000) loss: 1.822 
(epoch: 15, iters: 4752, time: 0.153, data: 0.000) loss: 1.269 
(epoch: 15, iters: 4832, time: 0.155, data: 0.000) loss: 1.636 
(epoch: 15, iters: 4912, time: 0.154, data: 0.000) loss: 2.210 
(epoch: 15, iters: 4992, time: 0.155, data: 0.000) loss: 1.231 
(epoch: 15, iters: 5072, time: 0.151, data: 0.000) loss: 1.768 
(epoch: 15, iters: 5152, time: 0.151, data: 0.000) loss: 1.832 
(epoch: 15, iters: 5232, time: 0.153, data: 0.005) loss: 1.934 
(epoch: 15, iters: 5312, time: 0.152, data: 0.000) loss: 1.806 
(epoch: 15, iters: 5392, time: 0.152, data: 0.014) loss: 1.340 
(epoch: 15, iters: 5472, time: 0.154, data: 0.000) loss: 1.262 
(epoch: 15, iters: 5552, time: 0.152, data: 0.024) loss: 1.171 
(epoch: 15, iters: 5632, time: 0.151, data: 0.000) loss: 1.693 
(epoch: 15, iters: 5712, time: 0.155, data: 0.023) loss: 1.085 
(epoch: 15, iters: 5792, time: 0.151, data: 0.000) loss: 1.912 
(epoch: 15, iters: 5872, time: 0.152, data: 0.000) loss: 1.814 
(epoch: 15, iters: 5952, time: 0.151, data: 0.000) loss: 1.906 
(epoch: 15, iters: 6032, time: 0.151, data: 0.000) loss: 1.551 
(epoch: 15, iters: 6112, time: 0.150, data: 0.008) loss: 1.532 
(epoch: 15, iters: 6192, time: 0.154, data: 0.000) loss: 1.608 
(epoch: 15, iters: 6272, time: 0.152, data: 0.009) loss: 0.894 
(epoch: 15, iters: 6352, time: 0.152, data: 0.000) loss: 1.601 
(epoch: 15, iters: 6432, time: 0.153, data: 0.009) loss: 1.444 
(epoch: 15, iters: 6512, time: 0.155, data: 0.000) loss: 1.354 
(epoch: 15, iters: 6592, time: 0.152, data: 0.009) loss: 1.472 
(epoch: 15, iters: 6672, time: 0.155, data: 0.000) loss: 1.485 
(epoch: 15, iters: 6752, time: 0.154, data: 0.000) loss: 1.635 
(epoch: 15, iters: 6832, time: 0.153, data: 0.008) loss: 1.869 
(epoch: 15, iters: 6912, time: 0.153, data: 0.024) loss: 1.505 
(epoch: 15, iters: 6992, time: 0.152, data: 0.000) loss: 2.117 
(epoch: 15, iters: 7072, time: 0.152, data: 0.000) loss: 1.433 
(epoch: 15, iters: 7152, time: 0.152, data: 0.035) loss: 1.148 
(epoch: 15, iters: 7232, time: 0.153, data: 0.000) loss: 1.771 
(epoch: 15, iters: 7312, time: 0.154, data: 0.000) loss: 1.018 
(epoch: 15, iters: 7392, time: 0.153, data: 0.000) loss: 1.600 
(epoch: 15, iters: 7472, time: 0.154, data: 0.015) loss: 1.382 
(epoch: 15, iters: 7552, time: 0.153, data: 0.000) loss: 2.259 
(epoch: 15, iters: 7632, time: 0.153, data: 0.000) loss: 1.429 
(epoch: 15, iters: 7712, time: 0.153, data: 0.000) loss: 2.178 
(epoch: 15, iters: 7792, time: 0.152, data: 0.017) loss: 1.349 
(epoch: 15, iters: 7872, time: 0.154, data: 0.000) loss: 2.463 
(epoch: 15, iters: 7952, time: 0.151, data: 0.005) loss: 1.662 
saving the latest model (epoch 15, total_steps 150704)
(epoch: 15, iters: 8032, time: 0.155, data: 0.000) loss: 1.758 
(epoch: 15, iters: 8112, time: 0.153, data: 0.024) loss: 0.965 
(epoch: 15, iters: 8192, time: 0.153, data: 0.000) loss: 1.569 
(epoch: 15, iters: 8272, time: 0.151, data: 0.010) loss: 0.805 
(epoch: 15, iters: 8352, time: 0.153, data: 0.005) loss: 1.559 
(epoch: 15, iters: 8432, time: 0.153, data: 0.000) loss: 1.835 
(epoch: 15, iters: 8512, time: 0.152, data: 0.000) loss: 0.873 
(epoch: 15, iters: 8592, time: 0.151, data: 0.008) loss: 1.429 
(epoch: 15, iters: 8672, time: 0.151, data: 0.017) loss: 1.590 
(epoch: 15, iters: 8752, time: 0.150, data: 0.005) loss: 1.168 
(epoch: 15, iters: 8832, time: 0.152, data: 0.015) loss: 1.425 
(epoch: 15, iters: 8912, time: 0.152, data: 0.005) loss: 0.935 
(epoch: 15, iters: 8992, time: 0.154, data: 0.008) loss: 1.729 
(epoch: 15, iters: 9072, time: 0.151, data: 0.000) loss: 1.719 
(epoch: 15, iters: 9152, time: 0.152, data: 0.000) loss: 1.912 
(epoch: 15, iters: 9232, time: 0.153, data: 0.000) loss: 1.824 
(epoch: 15, iters: 9312, time: 0.152, data: 0.000) loss: 1.237 
(epoch: 15, iters: 9392, time: 0.152, data: 0.017) loss: 1.078 
(epoch: 15, iters: 9472, time: 0.155, data: 0.005) loss: 2.067 
(epoch: 15, iters: 9552, time: 0.153, data: 0.000) loss: 1.306 
(epoch: 15, iters: 9632, time: 0.157, data: 0.000) loss: 1.814 
(epoch: 15, iters: 9712, time: 0.155, data: 0.005) loss: 1.656 
(epoch: 15, iters: 9792, time: 0.154, data: 0.000) loss: 1.153 
(epoch: 15, iters: 9872, time: 0.155, data: 0.005) loss: 1.096 
(epoch: 15, iters: 9952, time: 0.153, data: 0.000) loss: 1.382 
(epoch: 15, iters: 10032, time: 0.153, data: 0.010) loss: 1.376 
(epoch: 15, iters: 10112, time: 0.149, data: 0.000) loss: 1.593 
(epoch: 15, iters: 10192, time: 0.092, data: 0.000) loss: 1.038 
saving the model at the end of epoch 15, iters 152880
End of epoch 15 / 200 	 Time Taken: 1565 sec
learning rate = 0.0002000
saving the latest model (epoch 16, total_steps 152896)
(epoch: 16, iters: 80, time: 0.153, data: 0.593) loss: 1.769 
(epoch: 16, iters: 160, time: 0.152, data: 0.009) loss: 0.932 
(epoch: 16, iters: 240, time: 0.153, data: 0.009) loss: 1.504 
(epoch: 16, iters: 320, time: 0.151, data: 0.005) loss: 0.922 
(epoch: 16, iters: 400, time: 0.153, data: 0.000) loss: 1.569 
(epoch: 16, iters: 480, time: 0.152, data: 0.016) loss: 1.800 
(epoch: 16, iters: 560, time: 0.153, data: 0.000) loss: 2.033 
(epoch: 16, iters: 640, time: 0.150, data: 0.026) loss: 1.535 
(epoch: 16, iters: 720, time: 0.152, data: 0.000) loss: 1.730 
(epoch: 16, iters: 800, time: 0.153, data: 0.000) loss: 0.734 
(epoch: 16, iters: 880, time: 0.151, data: 0.013) loss: 1.506 
(epoch: 16, iters: 960, time: 0.152, data: 0.000) loss: 2.157 
(epoch: 16, iters: 1040, time: 0.150, data: 0.009) loss: 1.145 
(epoch: 16, iters: 1120, time: 0.153, data: 0.005) loss: 1.436 
(epoch: 16, iters: 1200, time: 0.151, data: 0.000) loss: 0.958 
(epoch: 16, iters: 1280, time: 0.150, data: 0.034) loss: 2.199 
(epoch: 16, iters: 1360, time: 0.151, data: 0.000) loss: 1.358 
(epoch: 16, iters: 1440, time: 0.150, data: 0.000) loss: 1.627 
(epoch: 16, iters: 1520, time: 0.152, data: 0.000) loss: 1.411 
(epoch: 16, iters: 1600, time: 0.154, data: 0.031) loss: 1.238 
(epoch: 16, iters: 1680, time: 0.154, data: 0.000) loss: 1.583 
(epoch: 16, iters: 1760, time: 0.152, data: 0.000) loss: 1.477 
(epoch: 16, iters: 1840, time: 0.152, data: 0.005) loss: 1.118 
(epoch: 16, iters: 1920, time: 0.153, data: 0.008) loss: 1.995 
(epoch: 16, iters: 2000, time: 0.151, data: 0.000) loss: 1.641 
(epoch: 16, iters: 2080, time: 0.152, data: 0.005) loss: 1.671 
(epoch: 16, iters: 2160, time: 0.155, data: 0.005) loss: 1.468 
(epoch: 16, iters: 2240, time: 0.154, data: 0.010) loss: 2.165 
(epoch: 16, iters: 2320, time: 0.154, data: 0.000) loss: 1.232 
(epoch: 16, iters: 2400, time: 0.154, data: 0.005) loss: 2.251 
(epoch: 16, iters: 2480, time: 0.154, data: 0.000) loss: 2.066 
(epoch: 16, iters: 2560, time: 0.154, data: 0.013) loss: 0.924 
(epoch: 16, iters: 2640, time: 0.152, data: 0.005) loss: 1.399 
(epoch: 16, iters: 2720, time: 0.153, data: 0.000) loss: 2.032 
(epoch: 16, iters: 2800, time: 0.153, data: 0.015) loss: 1.121 
(epoch: 16, iters: 2880, time: 0.153, data: 0.000) loss: 1.940 
(epoch: 16, iters: 2960, time: 0.153, data: 0.000) loss: 1.901 
(epoch: 16, iters: 3040, time: 0.153, data: 0.000) loss: 1.136 
(epoch: 16, iters: 3120, time: 0.153, data: 0.000) loss: 1.257 
(epoch: 16, iters: 3200, time: 0.152, data: 0.009) loss: 2.358 
(epoch: 16, iters: 3280, time: 0.152, data: 0.005) loss: 1.522 
(epoch: 16, iters: 3360, time: 0.153, data: 0.000) loss: 2.254 
(epoch: 16, iters: 3440, time: 0.151, data: 0.000) loss: 1.549 
(epoch: 16, iters: 3520, time: 0.152, data: 0.033) loss: 1.892 
(epoch: 16, iters: 3600, time: 0.153, data: 0.000) loss: 1.549 
(epoch: 16, iters: 3680, time: 0.153, data: 0.013) loss: 1.554 
(epoch: 16, iters: 3760, time: 0.151, data: 0.000) loss: 1.974 
(epoch: 16, iters: 3840, time: 0.153, data: 0.014) loss: 1.113 
(epoch: 16, iters: 3920, time: 0.154, data: 0.000) loss: 1.359 
(epoch: 16, iters: 4000, time: 0.152, data: 0.010) loss: 1.853 
saving the latest model (epoch 16, total_steps 156896)
(epoch: 16, iters: 4080, time: 0.153, data: 0.006) loss: 1.753 
(epoch: 16, iters: 4160, time: 0.152, data: 0.000) loss: 1.410 
(epoch: 16, iters: 4240, time: 0.153, data: 0.000) loss: 1.877 
(epoch: 16, iters: 4320, time: 0.153, data: 0.000) loss: 1.682 
(epoch: 16, iters: 4400, time: 0.150, data: 0.000) loss: 1.582 
(epoch: 16, iters: 4480, time: 0.153, data: 0.000) loss: 1.808 
(epoch: 16, iters: 4560, time: 0.153, data: 0.000) loss: 1.582 
(epoch: 16, iters: 4640, time: 0.153, data: 0.000) loss: 1.886 
(epoch: 16, iters: 4720, time: 0.153, data: 0.005) loss: 1.663 
(epoch: 16, iters: 4800, time: 0.153, data: 0.000) loss: 1.599 
(epoch: 16, iters: 4880, time: 0.152, data: 0.022) loss: 1.837 
(epoch: 16, iters: 4960, time: 0.152, data: 0.000) loss: 1.453 
(epoch: 16, iters: 5040, time: 0.153, data: 0.013) loss: 1.794 
(epoch: 16, iters: 5120, time: 0.152, data: 0.005) loss: 1.617 
(epoch: 16, iters: 5200, time: 0.154, data: 0.000) loss: 1.463 
(epoch: 16, iters: 5280, time: 0.151, data: 0.005) loss: 1.866 
(epoch: 16, iters: 5360, time: 0.152, data: 0.000) loss: 1.732 
(epoch: 16, iters: 5440, time: 0.153, data: 0.000) loss: 1.870 
(epoch: 16, iters: 5520, time: 0.153, data: 0.008) loss: 1.258 
(epoch: 16, iters: 5600, time: 0.153, data: 0.000) loss: 1.805 
(epoch: 16, iters: 5680, time: 0.153, data: 0.024) loss: 1.848 
(epoch: 16, iters: 5760, time: 0.154, data: 0.024) loss: 2.006 
(epoch: 16, iters: 5840, time: 0.153, data: 0.000) loss: 1.684 
(epoch: 16, iters: 5920, time: 0.155, data: 0.005) loss: 1.070 
(epoch: 16, iters: 6000, time: 0.153, data: 0.000) loss: 1.427 
(epoch: 16, iters: 6080, time: 0.154, data: 0.008) loss: 1.586 
(epoch: 16, iters: 6160, time: 0.154, data: 0.000) loss: 1.777 
(epoch: 16, iters: 6240, time: 0.154, data: 0.010) loss: 1.827 
(epoch: 16, iters: 6320, time: 0.154, data: 0.005) loss: 1.961 
(epoch: 16, iters: 6400, time: 0.154, data: 0.000) loss: 1.232 
(epoch: 16, iters: 6480, time: 0.154, data: 0.017) loss: 1.308 
(epoch: 16, iters: 6560, time: 0.153, data: 0.000) loss: 1.607 
(epoch: 16, iters: 6640, time: 0.152, data: 0.005) loss: 1.290 
(epoch: 16, iters: 6720, time: 0.150, data: 0.000) loss: 1.333 
(epoch: 16, iters: 6800, time: 0.153, data: 0.005) loss: 1.543 
(epoch: 16, iters: 6880, time: 0.153, data: 0.000) loss: 1.739 
(epoch: 16, iters: 6960, time: 0.152, data: 0.000) loss: 1.227 
(epoch: 16, iters: 7040, time: 0.152, data: 0.000) loss: 1.343 
(epoch: 16, iters: 7120, time: 0.153, data: 0.005) loss: 1.785 
(epoch: 16, iters: 7200, time: 0.152, data: 0.005) loss: 1.886 
(epoch: 16, iters: 7280, time: 0.152, data: 0.000) loss: 1.489 
(epoch: 16, iters: 7360, time: 0.152, data: 0.014) loss: 1.585 
(epoch: 16, iters: 7440, time: 0.151, data: 0.014) loss: 1.585 
(epoch: 16, iters: 7520, time: 0.152, data: 0.000) loss: 1.686 
(epoch: 16, iters: 7600, time: 0.152, data: 0.024) loss: 1.557 
(epoch: 16, iters: 7680, time: 0.153, data: 0.000) loss: 1.269 
(epoch: 16, iters: 7760, time: 0.154, data: 0.030) loss: 2.051 
(epoch: 16, iters: 7840, time: 0.152, data: 0.000) loss: 1.181 
(epoch: 16, iters: 7920, time: 0.150, data: 0.000) loss: 1.843 
(epoch: 16, iters: 8000, time: 0.151, data: 0.005) loss: 1.644 
saving the latest model (epoch 16, total_steps 160896)
(epoch: 16, iters: 8080, time: 0.152, data: 0.008) loss: 1.456 
(epoch: 16, iters: 8160, time: 0.152, data: 0.000) loss: 1.341 
(epoch: 16, iters: 8240, time: 0.152, data: 0.008) loss: 1.688 
(epoch: 16, iters: 8320, time: 0.153, data: 0.000) loss: 1.060 
(epoch: 16, iters: 8400, time: 0.154, data: 0.008) loss: 2.234 
(epoch: 16, iters: 8480, time: 0.153, data: 0.005) loss: 1.063 
(epoch: 16, iters: 8560, time: 0.152, data: 0.011) loss: 1.345 
(epoch: 16, iters: 8640, time: 0.151, data: 0.000) loss: 1.577 
(epoch: 16, iters: 8720, time: 0.152, data: 0.005) loss: 1.080 
(epoch: 16, iters: 8800, time: 0.153, data: 0.008) loss: 1.897 
(epoch: 16, iters: 8880, time: 0.153, data: 0.005) loss: 2.213 
(epoch: 16, iters: 8960, time: 0.153, data: 0.005) loss: 2.403 
(epoch: 16, iters: 9040, time: 0.152, data: 0.005) loss: 1.590 
(epoch: 16, iters: 9120, time: 0.153, data: 0.010) loss: 2.042 
(epoch: 16, iters: 9200, time: 0.154, data: 0.000) loss: 1.006 
(epoch: 16, iters: 9280, time: 0.159, data: 0.025) loss: 0.800 
(epoch: 16, iters: 9360, time: 0.160, data: 0.000) loss: 1.117 
(epoch: 16, iters: 9440, time: 0.159, data: 0.025) loss: 1.090 
(epoch: 16, iters: 9520, time: 0.157, data: 0.000) loss: 1.085 
(epoch: 16, iters: 9600, time: 0.160, data: 0.000) loss: 1.350 
(epoch: 16, iters: 9680, time: 0.159, data: 0.000) loss: 1.795 
(epoch: 16, iters: 9760, time: 0.156, data: 0.000) loss: 1.888 
(epoch: 16, iters: 9840, time: 0.157, data: 0.015) loss: 1.834 
(epoch: 16, iters: 9920, time: 0.156, data: 0.000) loss: 1.380 
(epoch: 16, iters: 10000, time: 0.157, data: 0.030) loss: 1.171 
(epoch: 16, iters: 10080, time: 0.159, data: 0.000) loss: 1.763 
(epoch: 16, iters: 10160, time: 0.154, data: 0.032) loss: 1.853 
saving the model at the end of epoch 16, iters 163072
End of epoch 16 / 200 	 Time Taken: 1562 sec
learning rate = 0.0002000
saving the latest model (epoch 17, total_steps 163088)
(epoch: 17, iters: 48, time: 0.155, data: 0.000) loss: 1.721 
(epoch: 17, iters: 128, time: 0.153, data: 0.019) loss: 1.196 
(epoch: 17, iters: 208, time: 0.153, data: 0.010) loss: 1.476 
(epoch: 17, iters: 288, time: 0.154, data: 0.016) loss: 1.403 
(epoch: 17, iters: 368, time: 0.157, data: 0.000) loss: 1.954 
(epoch: 17, iters: 448, time: 0.154, data: 0.017) loss: 1.403 
(epoch: 17, iters: 528, time: 0.154, data: 0.008) loss: 1.224 
(epoch: 17, iters: 608, time: 0.155, data: 0.000) loss: 1.580 
(epoch: 17, iters: 688, time: 0.157, data: 0.017) loss: 1.265 
(epoch: 17, iters: 768, time: 0.155, data: 0.000) loss: 0.997 
(epoch: 17, iters: 848, time: 0.155, data: 0.000) loss: 1.438 
(epoch: 17, iters: 928, time: 0.154, data: 0.000) loss: 1.148 
(epoch: 17, iters: 1008, time: 0.155, data: 0.000) loss: 2.283 
(epoch: 17, iters: 1088, time: 0.152, data: 0.019) loss: 1.162 
(epoch: 17, iters: 1168, time: 0.156, data: 0.016) loss: 1.747 
(epoch: 17, iters: 1248, time: 0.152, data: 0.000) loss: 1.794 
(epoch: 17, iters: 1328, time: 0.152, data: 0.000) loss: 1.693 
(epoch: 17, iters: 1408, time: 0.150, data: 0.000) loss: 1.778 
(epoch: 17, iters: 1488, time: 0.153, data: 0.008) loss: 1.273 
(epoch: 17, iters: 1568, time: 0.153, data: 0.000) loss: 1.291 
(epoch: 17, iters: 1648, time: 0.154, data: 0.005) loss: 0.813 
(epoch: 17, iters: 1728, time: 0.154, data: 0.000) loss: 1.389 
(epoch: 17, iters: 1808, time: 0.155, data: 0.000) loss: 1.776 
(epoch: 17, iters: 1888, time: 0.152, data: 0.033) loss: 2.024 
(epoch: 17, iters: 1968, time: 0.152, data: 0.000) loss: 1.684 
(epoch: 17, iters: 2048, time: 0.153, data: 0.000) loss: 1.829 
(epoch: 17, iters: 2128, time: 0.151, data: 0.015) loss: 2.247 
(epoch: 17, iters: 2208, time: 0.152, data: 0.000) loss: 0.791 
(epoch: 17, iters: 2288, time: 0.153, data: 0.005) loss: 1.878 
(epoch: 17, iters: 2368, time: 0.153, data: 0.024) loss: 2.004 
(epoch: 17, iters: 2448, time: 0.153, data: 0.000) loss: 1.525 
(epoch: 17, iters: 2528, time: 0.152, data: 0.009) loss: 2.099 
(epoch: 17, iters: 2608, time: 0.151, data: 0.005) loss: 1.795 
(epoch: 17, iters: 2688, time: 0.151, data: 0.025) loss: 1.205 
(epoch: 17, iters: 2768, time: 0.151, data: 0.000) loss: 1.344 
(epoch: 17, iters: 2848, time: 0.152, data: 0.010) loss: 1.381 
(epoch: 17, iters: 2928, time: 0.151, data: 0.000) loss: 1.397 
(epoch: 17, iters: 3008, time: 0.153, data: 0.000) loss: 1.672 
(epoch: 17, iters: 3088, time: 0.152, data: 0.000) loss: 2.097 
(epoch: 17, iters: 3168, time: 0.153, data: 0.005) loss: 1.362 
(epoch: 17, iters: 3248, time: 0.153, data: 0.000) loss: 0.758 
(epoch: 17, iters: 3328, time: 0.153, data: 0.000) loss: 1.496 
(epoch: 17, iters: 3408, time: 0.153, data: 0.000) loss: 1.918 
(epoch: 17, iters: 3488, time: 0.153, data: 0.009) loss: 1.811 
(epoch: 17, iters: 3568, time: 0.152, data: 0.000) loss: 2.150 
(epoch: 17, iters: 3648, time: 0.153, data: 0.008) loss: 1.480 
(epoch: 17, iters: 3728, time: 0.151, data: 0.000) loss: 1.627 
(epoch: 17, iters: 3808, time: 0.152, data: 0.005) loss: 1.453 
(epoch: 17, iters: 3888, time: 0.152, data: 0.000) loss: 1.040 
(epoch: 17, iters: 3968, time: 0.151, data: 0.030) loss: 1.244 
saving the latest model (epoch 17, total_steps 167088)
(epoch: 17, iters: 4048, time: 0.152, data: 0.000) loss: 1.667 
(epoch: 17, iters: 4128, time: 0.152, data: 0.028) loss: 1.697 
(epoch: 17, iters: 4208, time: 0.150, data: 0.005) loss: 1.498 
(epoch: 17, iters: 4288, time: 0.153, data: 0.000) loss: 1.437 
(epoch: 17, iters: 4368, time: 0.153, data: 0.008) loss: 1.642 
(epoch: 17, iters: 4448, time: 0.152, data: 0.010) loss: 1.596 
(epoch: 17, iters: 4528, time: 0.152, data: 0.000) loss: 0.977 
(epoch: 17, iters: 4608, time: 0.151, data: 0.000) loss: 1.956 
(epoch: 17, iters: 4688, time: 0.154, data: 0.021) loss: 1.211 
(epoch: 17, iters: 4768, time: 0.153, data: 0.000) loss: 1.596 
(epoch: 17, iters: 4848, time: 0.151, data: 0.000) loss: 1.455 
(epoch: 17, iters: 4928, time: 0.153, data: 0.005) loss: 1.196 
(epoch: 17, iters: 5008, time: 0.152, data: 0.000) loss: 1.169 
(epoch: 17, iters: 5088, time: 0.152, data: 0.005) loss: 2.314 
(epoch: 17, iters: 5168, time: 0.154, data: 0.010) loss: 0.964 
(epoch: 17, iters: 5248, time: 0.150, data: 0.000) loss: 1.146 
(epoch: 17, iters: 5328, time: 0.153, data: 0.016) loss: 1.345 
(epoch: 17, iters: 5408, time: 0.152, data: 0.000) loss: 1.232 
(epoch: 17, iters: 5488, time: 0.151, data: 0.005) loss: 1.807 
(epoch: 17, iters: 5568, time: 0.152, data: 0.005) loss: 1.681 
(epoch: 17, iters: 5648, time: 0.154, data: 0.032) loss: 1.307 
(epoch: 17, iters: 5728, time: 0.152, data: 0.000) loss: 2.425 
(epoch: 17, iters: 5808, time: 0.151, data: 0.000) loss: 1.494 
(epoch: 17, iters: 5888, time: 0.154, data: 0.010) loss: 1.455 
(epoch: 17, iters: 5968, time: 0.153, data: 0.000) loss: 1.442 
(epoch: 17, iters: 6048, time: 0.152, data: 0.019) loss: 1.963 
(epoch: 17, iters: 6128, time: 0.152, data: 0.000) loss: 1.665 
(epoch: 17, iters: 6208, time: 0.152, data: 0.019) loss: 2.442 
(epoch: 17, iters: 6288, time: 0.152, data: 0.018) loss: 1.718 
(epoch: 17, iters: 6368, time: 0.153, data: 0.000) loss: 1.342 
(epoch: 17, iters: 6448, time: 0.152, data: 0.000) loss: 1.291 
(epoch: 17, iters: 6528, time: 0.152, data: 0.000) loss: 1.668 
(epoch: 17, iters: 6608, time: 0.154, data: 0.014) loss: 1.644 
(epoch: 17, iters: 6688, time: 0.154, data: 0.000) loss: 1.483 
(epoch: 17, iters: 6768, time: 0.154, data: 0.000) loss: 1.180 
(epoch: 17, iters: 6848, time: 0.153, data: 0.005) loss: 1.290 
(epoch: 17, iters: 6928, time: 0.154, data: 0.000) loss: 1.205 
(epoch: 17, iters: 7008, time: 0.153, data: 0.000) loss: 1.613 
(epoch: 17, iters: 7088, time: 0.153, data: 0.008) loss: 1.651 
(epoch: 17, iters: 7168, time: 0.152, data: 0.008) loss: 0.919 
(epoch: 17, iters: 7248, time: 0.151, data: 0.000) loss: 0.970 
(epoch: 17, iters: 7328, time: 0.152, data: 0.005) loss: 1.810 
(epoch: 17, iters: 7408, time: 0.150, data: 0.000) loss: 1.348 
(epoch: 17, iters: 7488, time: 0.151, data: 0.005) loss: 1.079 
(epoch: 17, iters: 7568, time: 0.151, data: 0.000) loss: 1.693 
(epoch: 17, iters: 7648, time: 0.154, data: 0.005) loss: 1.333 
(epoch: 17, iters: 7728, time: 0.152, data: 0.000) loss: 1.334 
(epoch: 17, iters: 7808, time: 0.151, data: 0.000) loss: 1.702 
(epoch: 17, iters: 7888, time: 0.152, data: 0.017) loss: 1.815 
(epoch: 17, iters: 7968, time: 0.152, data: 0.013) loss: 1.408 
saving the latest model (epoch 17, total_steps 171088)
(epoch: 17, iters: 8048, time: 0.152, data: 0.000) loss: 1.456 
(epoch: 17, iters: 8128, time: 0.151, data: 0.000) loss: 1.343 
(epoch: 17, iters: 8208, time: 0.153, data: 0.000) loss: 1.203 
(epoch: 17, iters: 8288, time: 0.153, data: 0.034) loss: 2.080 
(epoch: 17, iters: 8368, time: 0.151, data: 0.000) loss: 1.691 
(epoch: 17, iters: 8448, time: 0.152, data: 0.000) loss: 1.087 
(epoch: 17, iters: 8528, time: 0.152, data: 0.000) loss: 1.748 
(epoch: 17, iters: 8608, time: 0.153, data: 0.008) loss: 1.420 
(epoch: 17, iters: 8688, time: 0.153, data: 0.000) loss: 1.643 
(epoch: 17, iters: 8768, time: 0.153, data: 0.025) loss: 1.959 
(epoch: 17, iters: 8848, time: 0.153, data: 0.000) loss: 1.611 
(epoch: 17, iters: 8928, time: 0.154, data: 0.006) loss: 1.169 
(epoch: 17, iters: 9008, time: 0.154, data: 0.008) loss: 1.420 
(epoch: 17, iters: 9088, time: 0.152, data: 0.000) loss: 1.319 
(epoch: 17, iters: 9168, time: 0.151, data: 0.005) loss: 1.939 
(epoch: 17, iters: 9248, time: 0.152, data: 0.000) loss: 1.553 
(epoch: 17, iters: 9328, time: 0.151, data: 0.000) loss: 1.645 
(epoch: 17, iters: 9408, time: 0.154, data: 0.000) loss: 1.818 
(epoch: 17, iters: 9488, time: 0.152, data: 0.005) loss: 2.001 
(epoch: 17, iters: 9568, time: 0.154, data: 0.000) loss: 2.028 
(epoch: 17, iters: 9648, time: 0.153, data: 0.005) loss: 1.469 
(epoch: 17, iters: 9728, time: 0.153, data: 0.000) loss: 1.490 
(epoch: 17, iters: 9808, time: 0.152, data: 0.000) loss: 1.126 
(epoch: 17, iters: 9888, time: 0.153, data: 0.025) loss: 1.500 
(epoch: 17, iters: 9968, time: 0.153, data: 0.000) loss: 1.396 
(epoch: 17, iters: 10048, time: 0.152, data: 0.042) loss: 1.249 
(epoch: 17, iters: 10128, time: 0.150, data: 0.000) loss: 1.278 
saving the model at the end of epoch 17, iters 173264
End of epoch 17 / 200 	 Time Taken: 1558 sec
learning rate = 0.0002000
(epoch: 18, iters: 16, time: 0.173, data: 0.007) loss: 1.005 
saving the latest model (epoch 18, total_steps 173280)
(epoch: 18, iters: 96, time: 0.152, data: 0.000) loss: 0.886 
(epoch: 18, iters: 176, time: 0.151, data: 0.020) loss: 1.752 
(epoch: 18, iters: 256, time: 0.154, data: 0.000) loss: 1.550 
(epoch: 18, iters: 336, time: 0.152, data: 0.009) loss: 1.518 
(epoch: 18, iters: 416, time: 0.154, data: 0.000) loss: 1.342 
(epoch: 18, iters: 496, time: 0.158, data: 0.000) loss: 1.274 
(epoch: 18, iters: 576, time: 0.154, data: 0.000) loss: 1.561 
(epoch: 18, iters: 656, time: 0.156, data: 0.000) loss: 1.481 
(epoch: 18, iters: 736, time: 0.153, data: 0.005) loss: 1.569 
(epoch: 18, iters: 816, time: 0.153, data: 0.005) loss: 0.723 
(epoch: 18, iters: 896, time: 0.155, data: 0.005) loss: 1.349 
(epoch: 18, iters: 976, time: 0.151, data: 0.000) loss: 1.613 
(epoch: 18, iters: 1056, time: 0.153, data: 0.000) loss: 1.030 
(epoch: 18, iters: 1136, time: 0.155, data: 0.000) loss: 1.287 
(epoch: 18, iters: 1216, time: 0.155, data: 0.000) loss: 1.386 
(epoch: 18, iters: 1296, time: 0.156, data: 0.009) loss: 1.148 
(epoch: 18, iters: 1376, time: 0.155, data: 0.000) loss: 1.785 
(epoch: 18, iters: 1456, time: 0.154, data: 0.000) loss: 1.829 
(epoch: 18, iters: 1536, time: 0.152, data: 0.015) loss: 1.780 
(epoch: 18, iters: 1616, time: 0.152, data: 0.004) loss: 0.798 
(epoch: 18, iters: 1696, time: 0.153, data: 0.005) loss: 1.941 
(epoch: 18, iters: 1776, time: 0.152, data: 0.000) loss: 1.243 
(epoch: 18, iters: 1856, time: 0.151, data: 0.009) loss: 1.095 
(epoch: 18, iters: 1936, time: 0.153, data: 0.000) loss: 1.666 
(epoch: 18, iters: 2016, time: 0.152, data: 0.000) loss: 1.508 
(epoch: 18, iters: 2096, time: 0.154, data: 0.008) loss: 1.040 
(epoch: 18, iters: 2176, time: 0.153, data: 0.000) loss: 1.536 
(epoch: 18, iters: 2256, time: 0.154, data: 0.023) loss: 0.959 
(epoch: 18, iters: 2336, time: 0.153, data: 0.020) loss: 1.263 
(epoch: 18, iters: 2416, time: 0.153, data: 0.000) loss: 1.419 
(epoch: 18, iters: 2496, time: 0.152, data: 0.025) loss: 1.007 
(epoch: 18, iters: 2576, time: 0.153, data: 0.000) loss: 1.416 
(epoch: 18, iters: 2656, time: 0.150, data: 0.005) loss: 1.563 
(epoch: 18, iters: 2736, time: 0.150, data: 0.000) loss: 0.871 
(epoch: 18, iters: 2816, time: 0.151, data: 0.005) loss: 1.732 
(epoch: 18, iters: 2896, time: 0.150, data: 0.000) loss: 1.015 
(epoch: 18, iters: 2976, time: 0.151, data: 0.000) loss: 0.501 
(epoch: 18, iters: 3056, time: 0.151, data: 0.000) loss: 1.110 
(epoch: 18, iters: 3136, time: 0.153, data: 0.006) loss: 1.457 
(epoch: 18, iters: 3216, time: 0.154, data: 0.000) loss: 0.861 
(epoch: 18, iters: 3296, time: 0.151, data: 0.000) loss: 1.064 
(epoch: 18, iters: 3376, time: 0.154, data: 0.017) loss: 0.754 
(epoch: 18, iters: 3456, time: 0.153, data: 0.000) loss: 0.891 
(epoch: 18, iters: 3536, time: 0.152, data: 0.005) loss: 1.386 
(epoch: 18, iters: 3616, time: 0.153, data: 0.006) loss: 1.174 
(epoch: 18, iters: 3696, time: 0.152, data: 0.008) loss: 2.115 
(epoch: 18, iters: 3776, time: 0.152, data: 0.000) loss: 1.325 
(epoch: 18, iters: 3856, time: 0.152, data: 0.008) loss: 1.158 
(epoch: 18, iters: 3936, time: 0.151, data: 0.000) loss: 1.577 
(epoch: 18, iters: 4016, time: 0.151, data: 0.005) loss: 1.390 
saving the latest model (epoch 18, total_steps 177280)
(epoch: 18, iters: 4096, time: 0.154, data: 0.000) loss: 1.367 
(epoch: 18, iters: 4176, time: 0.154, data: 0.005) loss: 2.082 
(epoch: 18, iters: 4256, time: 0.152, data: 0.000) loss: 1.421 
(epoch: 18, iters: 4336, time: 0.155, data: 0.008) loss: 1.023 
(epoch: 18, iters: 4416, time: 0.153, data: 0.000) loss: 1.323 
(epoch: 18, iters: 4496, time: 0.156, data: 0.000) loss: 1.502 
(epoch: 18, iters: 4576, time: 0.153, data: 0.000) loss: 1.058 
(epoch: 18, iters: 4656, time: 0.151, data: 0.000) loss: 1.228 
(epoch: 18, iters: 4736, time: 0.153, data: 0.005) loss: 1.065 
(epoch: 18, iters: 4816, time: 0.153, data: 0.024) loss: 1.013 
(epoch: 18, iters: 4896, time: 0.152, data: 0.000) loss: 2.334 
(epoch: 18, iters: 4976, time: 0.154, data: 0.000) loss: 1.924 
(epoch: 18, iters: 5056, time: 0.153, data: 0.000) loss: 1.697 
(epoch: 18, iters: 5136, time: 0.153, data: 0.025) loss: 1.635 
(epoch: 18, iters: 5216, time: 0.152, data: 0.000) loss: 2.148 
(epoch: 18, iters: 5296, time: 0.153, data: 0.000) loss: 1.079 
(epoch: 18, iters: 5376, time: 0.153, data: 0.005) loss: 1.789 
(epoch: 18, iters: 5456, time: 0.152, data: 0.000) loss: 1.957 
(epoch: 18, iters: 5536, time: 0.152, data: 0.000) loss: 2.201 
(epoch: 18, iters: 5616, time: 0.150, data: 0.014) loss: 1.003 
(epoch: 18, iters: 5696, time: 0.154, data: 0.010) loss: 1.408 
(epoch: 18, iters: 5776, time: 0.154, data: 0.000) loss: 1.287 
(epoch: 18, iters: 5856, time: 0.149, data: 0.000) loss: 1.273 
(epoch: 18, iters: 5936, time: 0.150, data: 0.005) loss: 1.516 
(epoch: 18, iters: 6016, time: 0.150, data: 0.000) loss: 1.304 
(epoch: 18, iters: 6096, time: 0.151, data: 0.000) loss: 1.798 
(epoch: 18, iters: 6176, time: 0.149, data: 0.008) loss: 1.473 
(epoch: 18, iters: 6256, time: 0.150, data: 0.000) loss: 1.425 
(epoch: 18, iters: 6336, time: 0.153, data: 0.000) loss: 1.447 
(epoch: 18, iters: 6416, time: 0.153, data: 0.010) loss: 1.784 
(epoch: 18, iters: 6496, time: 0.156, data: 0.005) loss: 1.759 
(epoch: 18, iters: 6576, time: 0.155, data: 0.000) loss: 1.591 
(epoch: 18, iters: 6656, time: 0.155, data: 0.000) loss: 1.486 
(epoch: 18, iters: 6736, time: 0.154, data: 0.000) loss: 1.246 
(epoch: 18, iters: 6816, time: 0.153, data: 0.015) loss: 1.385 
(epoch: 18, iters: 6896, time: 0.152, data: 0.000) loss: 1.371 
(epoch: 18, iters: 6976, time: 0.154, data: 0.000) loss: 1.554 
(epoch: 18, iters: 7056, time: 0.153, data: 0.032) loss: 2.015 
(epoch: 18, iters: 7136, time: 0.154, data: 0.000) loss: 1.523 
(epoch: 18, iters: 7216, time: 0.151, data: 0.011) loss: 1.969 
(epoch: 18, iters: 7296, time: 0.151, data: 0.005) loss: 0.843 
(epoch: 18, iters: 7376, time: 0.150, data: 0.010) loss: 0.666 
(epoch: 18, iters: 7456, time: 0.149, data: 0.000) loss: 1.643 
(epoch: 18, iters: 7536, time: 0.153, data: 0.015) loss: 2.289 
(epoch: 18, iters: 7616, time: 0.151, data: 0.000) loss: 1.240 
(epoch: 18, iters: 7696, time: 0.154, data: 0.014) loss: 2.386 
(epoch: 18, iters: 7776, time: 0.151, data: 0.015) loss: 1.143 
(epoch: 18, iters: 7856, time: 0.153, data: 0.005) loss: 1.520 
(epoch: 18, iters: 7936, time: 0.153, data: 0.008) loss: 1.548 
(epoch: 18, iters: 8016, time: 0.151, data: 0.005) loss: 2.159 
saving the latest model (epoch 18, total_steps 181280)
(epoch: 18, iters: 8096, time: 0.153, data: 0.009) loss: 1.401 
(epoch: 18, iters: 8176, time: 0.152, data: 0.000) loss: 1.181 
(epoch: 18, iters: 8256, time: 0.153, data: 0.005) loss: 1.677 
(epoch: 18, iters: 8336, time: 0.153, data: 0.000) loss: 1.351 
(epoch: 18, iters: 8416, time: 0.152, data: 0.008) loss: 1.555 
(epoch: 18, iters: 8496, time: 0.154, data: 0.000) loss: 1.764 
(epoch: 18, iters: 8576, time: 0.152, data: 0.000) loss: 1.586 
(epoch: 18, iters: 8656, time: 0.153, data: 0.033) loss: 1.007 
(epoch: 18, iters: 8736, time: 0.152, data: 0.000) loss: 1.041 
(epoch: 18, iters: 8816, time: 0.152, data: 0.010) loss: 1.216 
(epoch: 18, iters: 8896, time: 0.150, data: 0.000) loss: 1.511 
(epoch: 18, iters: 8976, time: 0.150, data: 0.005) loss: 0.978 
(epoch: 18, iters: 9056, time: 0.151, data: 0.011) loss: 0.750 
(epoch: 18, iters: 9136, time: 0.151, data: 0.015) loss: 1.407 
(epoch: 18, iters: 9216, time: 0.151, data: 0.005) loss: 1.900 
(epoch: 18, iters: 9296, time: 0.150, data: 0.000) loss: 1.150 
(epoch: 18, iters: 9376, time: 0.149, data: 0.000) loss: 1.755 
(epoch: 18, iters: 9456, time: 0.149, data: 0.000) loss: 1.236 
(epoch: 18, iters: 9536, time: 0.150, data: 0.023) loss: 2.281 
(epoch: 18, iters: 9616, time: 0.153, data: 0.000) loss: 1.989 
(epoch: 18, iters: 9696, time: 0.152, data: 0.000) loss: 1.412 
(epoch: 18, iters: 9776, time: 0.149, data: 0.000) loss: 1.414 
(epoch: 18, iters: 9856, time: 0.151, data: 0.013) loss: 1.222 
(epoch: 18, iters: 9936, time: 0.150, data: 0.000) loss: 1.209 
(epoch: 18, iters: 10016, time: 0.151, data: 0.000) loss: 0.908 
(epoch: 18, iters: 10096, time: 0.150, data: 0.005) loss: 1.821 
(epoch: 18, iters: 10176, time: 0.148, data: 0.000) loss: 1.046 
saving the model at the end of epoch 18, iters 183456
End of epoch 18 / 200 	 Time Taken: 1554 sec
learning rate = 0.0002000
saving the latest model (epoch 19, total_steps 183472)
(epoch: 19, iters: 64, time: 0.155, data: 0.003) loss: 1.005 
(epoch: 19, iters: 144, time: 0.152, data: 0.034) loss: 1.326 
(epoch: 19, iters: 224, time: 0.154, data: 0.000) loss: 1.966 
(epoch: 19, iters: 304, time: 0.151, data: 0.006) loss: 1.211 
(epoch: 19, iters: 384, time: 0.152, data: 0.000) loss: 1.629 
(epoch: 19, iters: 464, time: 0.152, data: 0.027) loss: 1.717 
(epoch: 19, iters: 544, time: 0.153, data: 0.000) loss: 1.225 
(epoch: 19, iters: 624, time: 0.152, data: 0.040) loss: 1.368 
(epoch: 19, iters: 704, time: 0.152, data: 0.000) loss: 1.845 
(epoch: 19, iters: 784, time: 0.153, data: 0.000) loss: 1.180 
(epoch: 19, iters: 864, time: 0.154, data: 0.010) loss: 1.743 
(epoch: 19, iters: 944, time: 0.152, data: 0.000) loss: 1.396 
(epoch: 19, iters: 1024, time: 0.154, data: 0.000) loss: 1.423 
(epoch: 19, iters: 1104, time: 0.152, data: 0.000) loss: 1.144 
(epoch: 19, iters: 1184, time: 0.152, data: 0.010) loss: 0.866 
(epoch: 19, iters: 1264, time: 0.153, data: 0.007) loss: 2.156 
(epoch: 19, iters: 1344, time: 0.154, data: 0.005) loss: 1.571 
(epoch: 19, iters: 1424, time: 0.153, data: 0.000) loss: 1.412 
(epoch: 19, iters: 1504, time: 0.152, data: 0.000) loss: 1.488 
(epoch: 19, iters: 1584, time: 0.151, data: 0.000) loss: 1.972 
(epoch: 19, iters: 1664, time: 0.152, data: 0.000) loss: 1.155 
(epoch: 19, iters: 1744, time: 0.152, data: 0.005) loss: 2.169 
(epoch: 19, iters: 1824, time: 0.149, data: 0.000) loss: 1.674 
(epoch: 19, iters: 1904, time: 0.152, data: 0.000) loss: 1.399 
(epoch: 19, iters: 1984, time: 0.153, data: 0.016) loss: 0.961 
(epoch: 19, iters: 2064, time: 0.151, data: 0.000) loss: 1.049 
(epoch: 19, iters: 2144, time: 0.152, data: 0.013) loss: 1.698 
(epoch: 19, iters: 2224, time: 0.153, data: 0.017) loss: 1.526 
(epoch: 19, iters: 2304, time: 0.150, data: 0.019) loss: 0.979 
(epoch: 19, iters: 2384, time: 0.153, data: 0.000) loss: 1.600 
(epoch: 19, iters: 2464, time: 0.152, data: 0.014) loss: 1.589 
(epoch: 19, iters: 2544, time: 0.154, data: 0.000) loss: 0.852 
(epoch: 19, iters: 2624, time: 0.154, data: 0.000) loss: 1.861 
(epoch: 19, iters: 2704, time: 0.150, data: 0.009) loss: 1.378 
(epoch: 19, iters: 2784, time: 0.153, data: 0.000) loss: 2.016 
(epoch: 19, iters: 2864, time: 0.153, data: 0.030) loss: 1.444 
(epoch: 19, iters: 2944, time: 0.154, data: 0.000) loss: 1.344 
(epoch: 19, iters: 3024, time: 0.153, data: 0.009) loss: 1.321 
(epoch: 19, iters: 3104, time: 0.153, data: 0.000) loss: 1.510 
(epoch: 19, iters: 3184, time: 0.151, data: 0.009) loss: 0.927 
(epoch: 19, iters: 3264, time: 0.150, data: 0.009) loss: 1.816 
(epoch: 19, iters: 3344, time: 0.152, data: 0.013) loss: 1.045 
(epoch: 19, iters: 3424, time: 0.153, data: 0.000) loss: 1.596 
(epoch: 19, iters: 3504, time: 0.151, data: 0.008) loss: 0.984 
(epoch: 19, iters: 3584, time: 0.152, data: 0.000) loss: 0.864 
(epoch: 19, iters: 3664, time: 0.150, data: 0.005) loss: 1.091 
(epoch: 19, iters: 3744, time: 0.151, data: 0.000) loss: 1.775 
(epoch: 19, iters: 3824, time: 0.151, data: 0.010) loss: 1.059 
(epoch: 19, iters: 3904, time: 0.152, data: 0.000) loss: 1.566 
(epoch: 19, iters: 3984, time: 0.152, data: 0.000) loss: 1.266 
saving the latest model (epoch 19, total_steps 187472)
(epoch: 19, iters: 4064, time: 0.154, data: 0.008) loss: 2.033 
(epoch: 19, iters: 4144, time: 0.152, data: 0.005) loss: 0.707 
(epoch: 19, iters: 4224, time: 0.152, data: 0.000) loss: 0.995 
(epoch: 19, iters: 4304, time: 0.151, data: 0.010) loss: 1.196 
(epoch: 19, iters: 4384, time: 0.155, data: 0.000) loss: 1.208 
(epoch: 19, iters: 4464, time: 0.152, data: 0.000) loss: 1.541 
(epoch: 19, iters: 4544, time: 0.152, data: 0.005) loss: 1.433 
(epoch: 19, iters: 4624, time: 0.151, data: 0.000) loss: 1.861 
(epoch: 19, iters: 4704, time: 0.153, data: 0.015) loss: 1.299 
(epoch: 19, iters: 4784, time: 0.153, data: 0.000) loss: 1.322 
(epoch: 19, iters: 4864, time: 0.152, data: 0.005) loss: 1.462 
(epoch: 19, iters: 4944, time: 0.152, data: 0.000) loss: 1.276 
(epoch: 19, iters: 5024, time: 0.152, data: 0.016) loss: 1.051 
(epoch: 19, iters: 5104, time: 0.150, data: 0.005) loss: 1.832 
(epoch: 19, iters: 5184, time: 0.151, data: 0.000) loss: 1.585 
(epoch: 19, iters: 5264, time: 0.153, data: 0.010) loss: 1.212 
(epoch: 19, iters: 5344, time: 0.152, data: 0.000) loss: 1.247 
(epoch: 19, iters: 5424, time: 0.152, data: 0.000) loss: 1.135 
(epoch: 19, iters: 5504, time: 0.153, data: 0.006) loss: 1.999 
(epoch: 19, iters: 5584, time: 0.154, data: 0.000) loss: 1.494 
(epoch: 19, iters: 5664, time: 0.157, data: 0.000) loss: 1.920 
(epoch: 19, iters: 5744, time: 0.154, data: 0.005) loss: 1.849 
(epoch: 19, iters: 5824, time: 0.153, data: 0.000) loss: 1.103 
(epoch: 19, iters: 5904, time: 0.152, data: 0.000) loss: 1.935 
(epoch: 19, iters: 5984, time: 0.152, data: 0.000) loss: 1.656 
(epoch: 19, iters: 6064, time: 0.152, data: 0.017) loss: 0.778 
(epoch: 19, iters: 6144, time: 0.152, data: 0.000) loss: 1.172 
(epoch: 19, iters: 6224, time: 0.153, data: 0.000) loss: 1.474 
(epoch: 19, iters: 6304, time: 0.155, data: 0.021) loss: 2.025 
(epoch: 19, iters: 6384, time: 0.153, data: 0.008) loss: 1.365 
(epoch: 19, iters: 6464, time: 0.153, data: 0.018) loss: 1.242 
(epoch: 19, iters: 6544, time: 0.152, data: 0.000) loss: 1.435 
(epoch: 19, iters: 6624, time: 0.154, data: 0.000) loss: 1.597 
(epoch: 19, iters: 6704, time: 0.153, data: 0.015) loss: 1.538 
(epoch: 19, iters: 6784, time: 0.150, data: 0.030) loss: 1.507 
(epoch: 19, iters: 6864, time: 0.152, data: 0.005) loss: 1.068 
(epoch: 19, iters: 6944, time: 0.153, data: 0.025) loss: 1.129 
(epoch: 19, iters: 7024, time: 0.152, data: 0.000) loss: 1.973 
(epoch: 19, iters: 7104, time: 0.153, data: 0.000) loss: 1.441 
(epoch: 19, iters: 7184, time: 0.155, data: 0.000) loss: 2.011 
(epoch: 19, iters: 7264, time: 0.153, data: 0.000) loss: 1.183 
(epoch: 19, iters: 7344, time: 0.154, data: 0.000) loss: 1.033 
(epoch: 19, iters: 7424, time: 0.154, data: 0.005) loss: 1.110 
(epoch: 19, iters: 7504, time: 0.153, data: 0.000) loss: 1.252 
(epoch: 19, iters: 7584, time: 0.152, data: 0.000) loss: 1.459 
(epoch: 19, iters: 7664, time: 0.153, data: 0.009) loss: 1.515 
(epoch: 19, iters: 7744, time: 0.154, data: 0.005) loss: 1.715 
(epoch: 19, iters: 7824, time: 0.152, data: 0.010) loss: 1.384 
(epoch: 19, iters: 7904, time: 0.156, data: 0.000) loss: 1.504 
(epoch: 19, iters: 7984, time: 0.152, data: 0.005) loss: 1.274 
saving the latest model (epoch 19, total_steps 191472)
(epoch: 19, iters: 8064, time: 0.153, data: 0.030) loss: 1.709 
(epoch: 19, iters: 8144, time: 0.152, data: 0.000) loss: 1.432 
(epoch: 19, iters: 8224, time: 0.154, data: 0.009) loss: 1.083 
(epoch: 19, iters: 8304, time: 0.154, data: 0.000) loss: 1.094 
(epoch: 19, iters: 8384, time: 0.153, data: 0.020) loss: 1.683 
(epoch: 19, iters: 8464, time: 0.150, data: 0.000) loss: 1.315 
(epoch: 19, iters: 8544, time: 0.153, data: 0.017) loss: 1.727 
(epoch: 19, iters: 8624, time: 0.153, data: 0.011) loss: 1.221 
(epoch: 19, iters: 8704, time: 0.153, data: 0.033) loss: 0.971 
(epoch: 19, iters: 8784, time: 0.152, data: 0.000) loss: 1.140 
(epoch: 19, iters: 8864, time: 0.152, data: 0.005) loss: 2.025 
(epoch: 19, iters: 8944, time: 0.152, data: 0.000) loss: 1.111 
(epoch: 19, iters: 9024, time: 0.153, data: 0.006) loss: 1.849 
(epoch: 19, iters: 9104, time: 0.152, data: 0.000) loss: 1.506 
(epoch: 19, iters: 9184, time: 0.153, data: 0.008) loss: 1.718 
(epoch: 19, iters: 9264, time: 0.154, data: 0.000) loss: 1.034 
(epoch: 19, iters: 9344, time: 0.154, data: 0.005) loss: 1.422 
(epoch: 19, iters: 9424, time: 0.152, data: 0.000) loss: 0.951 
(epoch: 19, iters: 9504, time: 0.151, data: 0.000) loss: 1.850 
(epoch: 19, iters: 9584, time: 0.150, data: 0.009) loss: 1.480 
(epoch: 19, iters: 9664, time: 0.153, data: 0.000) loss: 1.052 
(epoch: 19, iters: 9744, time: 0.150, data: 0.014) loss: 2.149 
(epoch: 19, iters: 9824, time: 0.153, data: 0.000) loss: 1.029 
(epoch: 19, iters: 9904, time: 0.151, data: 0.005) loss: 1.189 
(epoch: 19, iters: 9984, time: 0.151, data: 0.000) loss: 1.288 
(epoch: 19, iters: 10064, time: 0.153, data: 0.005) loss: 0.745 
(epoch: 19, iters: 10144, time: 0.149, data: 0.000) loss: 1.781 
saving the model at the end of epoch 19, iters 193648
End of epoch 19 / 200 	 Time Taken: 1556 sec
learning rate = 0.0002000
saving the latest model (epoch 20, total_steps 193664)
(epoch: 20, iters: 32, time: 0.156, data: 0.007) loss: 1.579 
(epoch: 20, iters: 112, time: 0.151, data: 0.000) loss: 1.876 
(epoch: 20, iters: 192, time: 0.150, data: 0.000) loss: 1.611 
(epoch: 20, iters: 272, time: 0.152, data: 0.022) loss: 0.853 
(epoch: 20, iters: 352, time: 0.152, data: 0.007) loss: 1.131 
(epoch: 20, iters: 432, time: 0.150, data: 0.000) loss: 0.924 
(epoch: 20, iters: 512, time: 0.152, data: 0.005) loss: 1.955 
(epoch: 20, iters: 592, time: 0.150, data: 0.021) loss: 1.896 
(epoch: 20, iters: 672, time: 0.149, data: 0.000) loss: 0.942 
(epoch: 20, iters: 752, time: 0.154, data: 0.011) loss: 1.511 
(epoch: 20, iters: 832, time: 0.153, data: 0.008) loss: 1.317 
(epoch: 20, iters: 912, time: 0.150, data: 0.000) loss: 1.175 
(epoch: 20, iters: 992, time: 0.150, data: 0.000) loss: 1.704 
(epoch: 20, iters: 1072, time: 0.151, data: 0.000) loss: 1.587 
(epoch: 20, iters: 1152, time: 0.150, data: 0.005) loss: 0.855 
(epoch: 20, iters: 1232, time: 0.151, data: 0.000) loss: 0.976 
(epoch: 20, iters: 1312, time: 0.152, data: 0.005) loss: 1.141 
(epoch: 20, iters: 1392, time: 0.151, data: 0.000) loss: 1.538 
(epoch: 20, iters: 1472, time: 0.152, data: 0.000) loss: 1.034 
(epoch: 20, iters: 1552, time: 0.153, data: 0.021) loss: 0.827 
(epoch: 20, iters: 1632, time: 0.151, data: 0.000) loss: 0.998 
(epoch: 20, iters: 1712, time: 0.149, data: 0.009) loss: 1.282 
(epoch: 20, iters: 1792, time: 0.151, data: 0.000) loss: 1.800 
(epoch: 20, iters: 1872, time: 0.151, data: 0.000) loss: 1.504 
(epoch: 20, iters: 1952, time: 0.150, data: 0.005) loss: 1.437 
(epoch: 20, iters: 2032, time: 0.153, data: 0.020) loss: 1.531 
(epoch: 20, iters: 2112, time: 0.152, data: 0.000) loss: 1.417 
(epoch: 20, iters: 2192, time: 0.151, data: 0.000) loss: 1.233 
(epoch: 20, iters: 2272, time: 0.152, data: 0.000) loss: 1.096 
(epoch: 20, iters: 2352, time: 0.151, data: 0.016) loss: 1.054 
(epoch: 20, iters: 2432, time: 0.152, data: 0.000) loss: 1.472 
(epoch: 20, iters: 2512, time: 0.153, data: 0.010) loss: 1.477 
(epoch: 20, iters: 2592, time: 0.152, data: 0.000) loss: 1.270 
(epoch: 20, iters: 2672, time: 0.150, data: 0.000) loss: 1.170 
(epoch: 20, iters: 2752, time: 0.151, data: 0.015) loss: 1.525 
(epoch: 20, iters: 2832, time: 0.151, data: 0.008) loss: 0.944 
(epoch: 20, iters: 2912, time: 0.150, data: 0.000) loss: 1.747 
(epoch: 20, iters: 2992, time: 0.150, data: 0.009) loss: 1.241 
(epoch: 20, iters: 3072, time: 0.153, data: 0.023) loss: 1.345 
(epoch: 20, iters: 3152, time: 0.153, data: 0.005) loss: 0.771 
(epoch: 20, iters: 3232, time: 0.152, data: 0.000) loss: 1.434 
(epoch: 20, iters: 3312, time: 0.152, data: 0.015) loss: 1.278 
(epoch: 20, iters: 3392, time: 0.153, data: 0.000) loss: 1.182 
(epoch: 20, iters: 3472, time: 0.153, data: 0.005) loss: 1.111 
(epoch: 20, iters: 3552, time: 0.151, data: 0.000) loss: 1.727 
(epoch: 20, iters: 3632, time: 0.152, data: 0.021) loss: 1.212 
(epoch: 20, iters: 3712, time: 0.152, data: 0.010) loss: 1.361 
(epoch: 20, iters: 3792, time: 0.151, data: 0.000) loss: 1.276 
(epoch: 20, iters: 3872, time: 0.150, data: 0.009) loss: 2.157 
(epoch: 20, iters: 3952, time: 0.152, data: 0.000) loss: 2.163 
saving the latest model (epoch 20, total_steps 197664)
(epoch: 20, iters: 4032, time: 0.154, data: 0.005) loss: 1.514 
(epoch: 20, iters: 4112, time: 0.149, data: 0.000) loss: 1.649 
(epoch: 20, iters: 4192, time: 0.149, data: 0.000) loss: 1.079 
(epoch: 20, iters: 4272, time: 0.151, data: 0.008) loss: 1.274 
(epoch: 20, iters: 4352, time: 0.153, data: 0.000) loss: 0.868 
(epoch: 20, iters: 4432, time: 0.151, data: 0.000) loss: 1.313 
(epoch: 20, iters: 4512, time: 0.151, data: 0.023) loss: 1.142 
(epoch: 20, iters: 4592, time: 0.152, data: 0.000) loss: 1.225 
(epoch: 20, iters: 4672, time: 0.152, data: 0.025) loss: 1.036 
(epoch: 20, iters: 4752, time: 0.152, data: 0.000) loss: 1.091 
(epoch: 20, iters: 4832, time: 0.152, data: 0.000) loss: 1.710 
(epoch: 20, iters: 4912, time: 0.149, data: 0.009) loss: 1.643 
(epoch: 20, iters: 4992, time: 0.149, data: 0.008) loss: 0.863 
(epoch: 20, iters: 5072, time: 0.149, data: 0.000) loss: 1.394 
(epoch: 20, iters: 5152, time: 0.154, data: 0.021) loss: 1.482 
(epoch: 20, iters: 5232, time: 0.151, data: 0.000) loss: 1.264 
(epoch: 20, iters: 5312, time: 0.154, data: 0.000) loss: 1.693 
(epoch: 20, iters: 5392, time: 0.153, data: 0.008) loss: 1.671 
(epoch: 20, iters: 5472, time: 0.153, data: 0.008) loss: 1.624 
(epoch: 20, iters: 5552, time: 0.152, data: 0.005) loss: 1.221 
(epoch: 20, iters: 5632, time: 0.152, data: 0.024) loss: 2.337 
(epoch: 20, iters: 5712, time: 0.152, data: 0.000) loss: 1.235 
(epoch: 20, iters: 5792, time: 0.152, data: 0.000) loss: 1.208 
(epoch: 20, iters: 5872, time: 0.151, data: 0.000) loss: 1.462 
(epoch: 20, iters: 5952, time: 0.153, data: 0.019) loss: 1.435 
(epoch: 20, iters: 6032, time: 0.151, data: 0.005) loss: 1.059 
(epoch: 20, iters: 6112, time: 0.153, data: 0.000) loss: 0.973 
(epoch: 20, iters: 6192, time: 0.152, data: 0.000) loss: 1.493 
(epoch: 20, iters: 6272, time: 0.150, data: 0.000) loss: 1.205 
(epoch: 20, iters: 6352, time: 0.150, data: 0.020) loss: 2.246 
(epoch: 20, iters: 6432, time: 0.150, data: 0.011) loss: 2.026 
(epoch: 20, iters: 6512, time: 0.151, data: 0.000) loss: 1.080 
(epoch: 20, iters: 6592, time: 0.153, data: 0.010) loss: 1.504 
(epoch: 20, iters: 6672, time: 0.152, data: 0.005) loss: 1.324 
(epoch: 20, iters: 6752, time: 0.153, data: 0.005) loss: 1.414 
(epoch: 20, iters: 6832, time: 0.154, data: 0.000) loss: 1.540 
(epoch: 20, iters: 6912, time: 0.152, data: 0.024) loss: 1.695 
(epoch: 20, iters: 6992, time: 0.151, data: 0.000) loss: 1.185 
(epoch: 20, iters: 7072, time: 0.153, data: 0.017) loss: 2.125 
(epoch: 20, iters: 7152, time: 0.151, data: 0.000) loss: 0.625 
(epoch: 20, iters: 7232, time: 0.151, data: 0.000) loss: 1.579 
(epoch: 20, iters: 7312, time: 0.153, data: 0.000) loss: 2.162 
(epoch: 20, iters: 7392, time: 0.151, data: 0.009) loss: 1.601 
(epoch: 20, iters: 7472, time: 0.150, data: 0.000) loss: 1.151 
(epoch: 20, iters: 7552, time: 0.149, data: 0.000) loss: 1.020 
(epoch: 20, iters: 7632, time: 0.150, data: 0.005) loss: 1.583 
(epoch: 20, iters: 7712, time: 0.150, data: 0.000) loss: 1.412 
(epoch: 20, iters: 7792, time: 0.150, data: 0.005) loss: 1.815 
(epoch: 20, iters: 7872, time: 0.152, data: 0.000) loss: 1.531 
(epoch: 20, iters: 7952, time: 0.151, data: 0.000) loss: 1.632 
saving the latest model (epoch 20, total_steps 201664)
(epoch: 20, iters: 8032, time: 0.152, data: 0.024) loss: 0.971 
(epoch: 20, iters: 8112, time: 0.152, data: 0.000) loss: 1.773 
(epoch: 20, iters: 8192, time: 0.153, data: 0.005) loss: 1.227 
(epoch: 20, iters: 8272, time: 0.151, data: 0.000) loss: 1.138 
(epoch: 20, iters: 8352, time: 0.150, data: 0.000) loss: 1.413 
(epoch: 20, iters: 8432, time: 0.152, data: 0.005) loss: 1.622 
(epoch: 20, iters: 8512, time: 0.152, data: 0.026) loss: 2.508 
(epoch: 20, iters: 8592, time: 0.150, data: 0.000) loss: 1.292 
(epoch: 20, iters: 8672, time: 0.150, data: 0.005) loss: 1.329 
(epoch: 20, iters: 8752, time: 0.150, data: 0.000) loss: 2.088 
(epoch: 20, iters: 8832, time: 0.150, data: 0.015) loss: 1.591 
(epoch: 20, iters: 8912, time: 0.150, data: 0.000) loss: 1.337 
(epoch: 20, iters: 8992, time: 0.152, data: 0.000) loss: 1.180 
(epoch: 20, iters: 9072, time: 0.152, data: 0.008) loss: 1.405 
(epoch: 20, iters: 9152, time: 0.152, data: 0.018) loss: 1.159 
(epoch: 20, iters: 9232, time: 0.151, data: 0.016) loss: 1.812 
(epoch: 20, iters: 9312, time: 0.153, data: 0.000) loss: 1.607 
(epoch: 20, iters: 9392, time: 0.153, data: 0.005) loss: 1.445 
(epoch: 20, iters: 9472, time: 0.152, data: 0.014) loss: 1.026 
(epoch: 20, iters: 9552, time: 0.151, data: 0.000) loss: 1.437 
(epoch: 20, iters: 9632, time: 0.153, data: 0.000) loss: 0.987 
(epoch: 20, iters: 9712, time: 0.152, data: 0.000) loss: 0.886 
(epoch: 20, iters: 9792, time: 0.153, data: 0.000) loss: 1.509 
(epoch: 20, iters: 9872, time: 0.152, data: 0.008) loss: 0.633 
(epoch: 20, iters: 9952, time: 0.151, data: 0.010) loss: 1.738 
(epoch: 20, iters: 10032, time: 0.152, data: 0.005) loss: 0.970 
(epoch: 20, iters: 10112, time: 0.148, data: 0.000) loss: 1.315 
(epoch: 20, iters: 10192, time: 0.089, data: 0.019) loss: 1.041 
saving the model at the end of epoch 20, iters 203840
End of epoch 20 / 200 	 Time Taken: 1547 sec
learning rate = 0.0002000
saving the latest model (epoch 21, total_steps 203856)
(epoch: 21, iters: 80, time: 0.154, data: 0.366) loss: 1.155 
(epoch: 21, iters: 160, time: 0.153, data: 0.000) loss: 1.274 
(epoch: 21, iters: 240, time: 0.150, data: 0.000) loss: 2.056 
(epoch: 21, iters: 320, time: 0.153, data: 0.000) loss: 1.347 
(epoch: 21, iters: 400, time: 0.153, data: 0.027) loss: 1.130 
(epoch: 21, iters: 480, time: 0.151, data: 0.000) loss: 1.968 
(epoch: 21, iters: 560, time: 0.154, data: 0.009) loss: 1.119 
(epoch: 21, iters: 640, time: 0.151, data: 0.000) loss: 2.209 
(epoch: 21, iters: 720, time: 0.151, data: 0.000) loss: 0.787 
(epoch: 21, iters: 800, time: 0.152, data: 0.017) loss: 1.362 
(epoch: 21, iters: 880, time: 0.152, data: 0.023) loss: 1.343 
(epoch: 21, iters: 960, time: 0.153, data: 0.000) loss: 1.299 
(epoch: 21, iters: 1040, time: 0.152, data: 0.000) loss: 1.314 
(epoch: 21, iters: 1120, time: 0.151, data: 0.000) loss: 1.829 
(epoch: 21, iters: 1200, time: 0.152, data: 0.008) loss: 1.821 
(epoch: 21, iters: 1280, time: 0.152, data: 0.024) loss: 1.125 
(epoch: 21, iters: 1360, time: 0.151, data: 0.000) loss: 1.066 
(epoch: 21, iters: 1440, time: 0.151, data: 0.016) loss: 1.599 
(epoch: 21, iters: 1520, time: 0.150, data: 0.000) loss: 1.349 
(epoch: 21, iters: 1600, time: 0.152, data: 0.000) loss: 1.436 
(epoch: 21, iters: 1680, time: 0.151, data: 0.000) loss: 0.852 
(epoch: 21, iters: 1760, time: 0.151, data: 0.000) loss: 1.101 
(epoch: 21, iters: 1840, time: 0.152, data: 0.000) loss: 1.272 
(epoch: 21, iters: 1920, time: 0.150, data: 0.000) loss: 1.137 
(epoch: 21, iters: 2000, time: 0.151, data: 0.017) loss: 1.507 
(epoch: 21, iters: 2080, time: 0.150, data: 0.000) loss: 1.414 
(epoch: 21, iters: 2160, time: 0.151, data: 0.025) loss: 0.953 
(epoch: 21, iters: 2240, time: 0.150, data: 0.000) loss: 1.268 
(epoch: 21, iters: 2320, time: 0.152, data: 0.008) loss: 1.072 
(epoch: 21, iters: 2400, time: 0.151, data: 0.000) loss: 1.379 
(epoch: 21, iters: 2480, time: 0.151, data: 0.000) loss: 1.070 
(epoch: 21, iters: 2560, time: 0.153, data: 0.016) loss: 1.719 
(epoch: 21, iters: 2640, time: 0.152, data: 0.000) loss: 1.307 
(epoch: 21, iters: 2720, time: 0.152, data: 0.005) loss: 1.238 
(epoch: 21, iters: 2800, time: 0.152, data: 0.000) loss: 1.217 
(epoch: 21, iters: 2880, time: 0.152, data: 0.000) loss: 0.889 
(epoch: 21, iters: 2960, time: 0.154, data: 0.000) loss: 1.843 
(epoch: 21, iters: 3040, time: 0.152, data: 0.000) loss: 0.997 
(epoch: 21, iters: 3120, time: 0.151, data: 0.000) loss: 0.932 
(epoch: 21, iters: 3200, time: 0.153, data: 0.005) loss: 1.575 
(epoch: 21, iters: 3280, time: 0.153, data: 0.005) loss: 0.862 
(epoch: 21, iters: 3360, time: 0.151, data: 0.014) loss: 1.538 
(epoch: 21, iters: 3440, time: 0.151, data: 0.014) loss: 1.546 
(epoch: 21, iters: 3520, time: 0.152, data: 0.000) loss: 1.474 
(epoch: 21, iters: 3600, time: 0.151, data: 0.005) loss: 1.113 
(epoch: 21, iters: 3680, time: 0.152, data: 0.017) loss: 1.461 
(epoch: 21, iters: 3760, time: 0.153, data: 0.000) loss: 1.510 
(epoch: 21, iters: 3840, time: 0.149, data: 0.000) loss: 1.309 
(epoch: 21, iters: 3920, time: 0.150, data: 0.017) loss: 1.384 
(epoch: 21, iters: 4000, time: 0.151, data: 0.000) loss: 0.894 
saving the latest model (epoch 21, total_steps 207856)
(epoch: 21, iters: 4080, time: 0.151, data: 0.017) loss: 1.617 
(epoch: 21, iters: 4160, time: 0.149, data: 0.023) loss: 1.351 
(epoch: 21, iters: 4240, time: 0.151, data: 0.000) loss: 1.174 
(epoch: 21, iters: 4320, time: 0.152, data: 0.010) loss: 0.772 
(epoch: 21, iters: 4400, time: 0.153, data: 0.005) loss: 1.550 
(epoch: 21, iters: 4480, time: 0.150, data: 0.000) loss: 1.577 
(epoch: 21, iters: 4560, time: 0.153, data: 0.008) loss: 1.042 
(epoch: 21, iters: 4640, time: 0.151, data: 0.000) loss: 1.798 
(epoch: 21, iters: 4720, time: 0.150, data: 0.000) loss: 0.957 
(epoch: 21, iters: 4800, time: 0.152, data: 0.005) loss: 1.503 
(epoch: 21, iters: 4880, time: 0.152, data: 0.000) loss: 0.656 
(epoch: 21, iters: 4960, time: 0.153, data: 0.009) loss: 1.562 
(epoch: 21, iters: 5040, time: 0.156, data: 0.000) loss: 1.410 
(epoch: 21, iters: 5120, time: 0.152, data: 0.008) loss: 1.707 
(epoch: 21, iters: 5200, time: 0.152, data: 0.000) loss: 1.481 
(epoch: 21, iters: 5280, time: 0.153, data: 0.027) loss: 1.668 
(epoch: 21, iters: 5360, time: 0.153, data: 0.005) loss: 1.584 
(epoch: 21, iters: 5440, time: 0.153, data: 0.000) loss: 2.015 
(epoch: 21, iters: 5520, time: 0.151, data: 0.013) loss: 1.340 
(epoch: 21, iters: 5600, time: 0.151, data: 0.005) loss: 0.805 
(epoch: 21, iters: 5680, time: 0.152, data: 0.000) loss: 1.684 
(epoch: 21, iters: 5760, time: 0.152, data: 0.009) loss: 1.557 
(epoch: 21, iters: 5840, time: 0.149, data: 0.000) loss: 1.111 
(epoch: 21, iters: 5920, time: 0.151, data: 0.000) loss: 1.566 
(epoch: 21, iters: 6000, time: 0.152, data: 0.000) loss: 1.479 
(epoch: 21, iters: 6080, time: 0.152, data: 0.014) loss: 1.887 
(epoch: 21, iters: 6160, time: 0.152, data: 0.021) loss: 1.270 
(epoch: 21, iters: 6240, time: 0.150, data: 0.000) loss: 1.340 
(epoch: 21, iters: 6320, time: 0.151, data: 0.027) loss: 1.809 
(epoch: 21, iters: 6400, time: 0.152, data: 0.000) loss: 1.830 
(epoch: 21, iters: 6480, time: 0.153, data: 0.000) loss: 1.303 
(epoch: 21, iters: 6560, time: 0.153, data: 0.000) loss: 1.992 
(epoch: 21, iters: 6640, time: 0.151, data: 0.020) loss: 1.242 
(epoch: 21, iters: 6720, time: 0.152, data: 0.005) loss: 1.329 
(epoch: 21, iters: 6800, time: 0.150, data: 0.005) loss: 1.067 
(epoch: 21, iters: 6880, time: 0.152, data: 0.000) loss: 1.110 
(epoch: 21, iters: 6960, time: 0.149, data: 0.000) loss: 0.622 
(epoch: 21, iters: 7040, time: 0.150, data: 0.014) loss: 1.652 
(epoch: 21, iters: 7120, time: 0.151, data: 0.024) loss: 1.821 
(epoch: 21, iters: 7200, time: 0.152, data: 0.000) loss: 1.626 
(epoch: 21, iters: 7280, time: 0.152, data: 0.000) loss: 1.383 
(epoch: 21, iters: 7360, time: 0.150, data: 0.005) loss: 1.818 
(epoch: 21, iters: 7440, time: 0.150, data: 0.029) loss: 1.343 
(epoch: 21, iters: 7520, time: 0.152, data: 0.005) loss: 1.817 
(epoch: 21, iters: 7600, time: 0.151, data: 0.000) loss: 1.566 
(epoch: 21, iters: 7680, time: 0.153, data: 0.000) loss: 1.561 
(epoch: 21, iters: 7760, time: 0.151, data: 0.000) loss: 1.787 
(epoch: 21, iters: 7840, time: 0.150, data: 0.024) loss: 0.925 
(epoch: 21, iters: 7920, time: 0.152, data: 0.000) loss: 1.652 
(epoch: 21, iters: 8000, time: 0.152, data: 0.000) loss: 1.420 
saving the latest model (epoch 21, total_steps 211856)
(epoch: 21, iters: 8080, time: 0.151, data: 0.005) loss: 1.424 
(epoch: 21, iters: 8160, time: 0.151, data: 0.005) loss: 1.262 
(epoch: 21, iters: 8240, time: 0.152, data: 0.000) loss: 1.379 
(epoch: 21, iters: 8320, time: 0.154, data: 0.005) loss: 1.191 
(epoch: 21, iters: 8400, time: 0.151, data: 0.010) loss: 2.134 
(epoch: 21, iters: 8480, time: 0.152, data: 0.000) loss: 1.218 
(epoch: 21, iters: 8560, time: 0.152, data: 0.000) loss: 1.400 
(epoch: 21, iters: 8640, time: 0.151, data: 0.000) loss: 1.082 
(epoch: 21, iters: 8720, time: 0.152, data: 0.005) loss: 0.934 
(epoch: 21, iters: 8800, time: 0.151, data: 0.000) loss: 1.249 
(epoch: 21, iters: 8880, time: 0.150, data: 0.005) loss: 1.498 
(epoch: 21, iters: 8960, time: 0.152, data: 0.000) loss: 0.717 
(epoch: 21, iters: 9040, time: 0.152, data: 0.013) loss: 1.812 
(epoch: 21, iters: 9120, time: 0.150, data: 0.009) loss: 1.628 
(epoch: 21, iters: 9200, time: 0.150, data: 0.000) loss: 1.454 
(epoch: 21, iters: 9280, time: 0.149, data: 0.005) loss: 0.674 
(epoch: 21, iters: 9360, time: 0.150, data: 0.009) loss: 1.562 
(epoch: 21, iters: 9440, time: 0.152, data: 0.000) loss: 1.021 
(epoch: 21, iters: 9520, time: 0.150, data: 0.005) loss: 1.784 
(epoch: 21, iters: 9600, time: 0.149, data: 0.000) loss: 1.550 
(epoch: 21, iters: 9680, time: 0.152, data: 0.026) loss: 0.905 
(epoch: 21, iters: 9760, time: 0.152, data: 0.000) loss: 1.599 
(epoch: 21, iters: 9840, time: 0.153, data: 0.000) loss: 2.012 
(epoch: 21, iters: 9920, time: 0.152, data: 0.000) loss: 1.787 
(epoch: 21, iters: 10000, time: 0.150, data: 0.014) loss: 1.015 
(epoch: 21, iters: 10080, time: 0.151, data: 0.010) loss: 1.374 
(epoch: 21, iters: 10160, time: 0.152, data: 0.000) loss: 1.334 
saving the model at the end of epoch 21, iters 214032
End of epoch 21 / 200 	 Time Taken: 1547 sec
learning rate = 0.0002000
saving the latest model (epoch 22, total_steps 214048)
(epoch: 22, iters: 48, time: 0.153, data: 0.000) loss: 1.394 
(epoch: 22, iters: 128, time: 0.151, data: 0.027) loss: 1.374 
(epoch: 22, iters: 208, time: 0.150, data: 0.000) loss: 1.161 
(epoch: 22, iters: 288, time: 0.151, data: 0.000) loss: 0.605 
(epoch: 22, iters: 368, time: 0.155, data: 0.016) loss: 0.932 
(epoch: 22, iters: 448, time: 0.152, data: 0.000) loss: 1.262 
(epoch: 22, iters: 528, time: 0.154, data: 0.000) loss: 1.586 
(epoch: 22, iters: 608, time: 0.155, data: 0.005) loss: 1.468 
(epoch: 22, iters: 688, time: 0.155, data: 0.000) loss: 1.304 
(epoch: 22, iters: 768, time: 0.152, data: 0.000) loss: 1.083 
(epoch: 22, iters: 848, time: 0.153, data: 0.008) loss: 0.988 
(epoch: 22, iters: 928, time: 0.152, data: 0.000) loss: 1.010 
(epoch: 22, iters: 1008, time: 0.154, data: 0.000) loss: 2.185 
(epoch: 22, iters: 1088, time: 0.152, data: 0.007) loss: 1.410 
(epoch: 22, iters: 1168, time: 0.156, data: 0.000) loss: 1.126 
(epoch: 22, iters: 1248, time: 0.152, data: 0.010) loss: 1.158 
(epoch: 22, iters: 1328, time: 0.155, data: 0.008) loss: 0.996 
(epoch: 22, iters: 1408, time: 0.154, data: 0.000) loss: 1.370 
(epoch: 22, iters: 1488, time: 0.150, data: 0.000) loss: 1.470 
(epoch: 22, iters: 1568, time: 0.153, data: 0.000) loss: 1.233 
(epoch: 22, iters: 1648, time: 0.151, data: 0.005) loss: 2.121 
(epoch: 22, iters: 1728, time: 0.152, data: 0.005) loss: 1.256 
(epoch: 22, iters: 1808, time: 0.154, data: 0.000) loss: 1.133 
(epoch: 22, iters: 1888, time: 0.153, data: 0.038) loss: 0.919 
(epoch: 22, iters: 1968, time: 0.153, data: 0.000) loss: 1.475 
(epoch: 22, iters: 2048, time: 0.153, data: 0.000) loss: 1.818 
(epoch: 22, iters: 2128, time: 0.156, data: 0.000) loss: 1.388 
(epoch: 22, iters: 2208, time: 0.154, data: 0.015) loss: 1.417 
(epoch: 22, iters: 2288, time: 0.154, data: 0.000) loss: 1.531 
(epoch: 22, iters: 2368, time: 0.150, data: 0.000) loss: 2.278 
(epoch: 22, iters: 2448, time: 0.150, data: 0.005) loss: 1.498 
(epoch: 22, iters: 2528, time: 0.153, data: 0.000) loss: 1.673 
(epoch: 22, iters: 2608, time: 0.152, data: 0.005) loss: 1.210 
(epoch: 22, iters: 2688, time: 0.151, data: 0.000) loss: 1.246 
(epoch: 22, iters: 2768, time: 0.154, data: 0.005) loss: 1.576 
(epoch: 22, iters: 2848, time: 0.155, data: 0.000) loss: 0.982 
(epoch: 22, iters: 2928, time: 0.152, data: 0.016) loss: 1.288 
(epoch: 22, iters: 3008, time: 0.154, data: 0.008) loss: 1.170 
(epoch: 22, iters: 3088, time: 0.152, data: 0.013) loss: 0.937 
(epoch: 22, iters: 3168, time: 0.152, data: 0.005) loss: 1.394 
(epoch: 22, iters: 3248, time: 0.151, data: 0.005) loss: 1.589 
(epoch: 22, iters: 3328, time: 0.153, data: 0.005) loss: 0.963 
(epoch: 22, iters: 3408, time: 0.153, data: 0.000) loss: 1.503 
(epoch: 22, iters: 3488, time: 0.155, data: 0.005) loss: 1.026 
(epoch: 22, iters: 3568, time: 0.151, data: 0.005) loss: 0.783 
(epoch: 22, iters: 3648, time: 0.155, data: 0.005) loss: 1.107 
(epoch: 22, iters: 3728, time: 0.154, data: 0.000) loss: 0.878 
(epoch: 22, iters: 3808, time: 0.155, data: 0.000) loss: 1.504 
(epoch: 22, iters: 3888, time: 0.149, data: 0.014) loss: 1.222 
(epoch: 22, iters: 3968, time: 0.153, data: 0.000) loss: 2.074 
saving the latest model (epoch 22, total_steps 218048)
(epoch: 22, iters: 4048, time: 0.150, data: 0.023) loss: 1.284 
(epoch: 22, iters: 4128, time: 0.151, data: 0.000) loss: 1.475 
(epoch: 22, iters: 4208, time: 0.154, data: 0.020) loss: 1.661 
(epoch: 22, iters: 4288, time: 0.153, data: 0.000) loss: 1.104 
(epoch: 22, iters: 4368, time: 0.155, data: 0.014) loss: 1.260 
(epoch: 22, iters: 4448, time: 0.155, data: 0.000) loss: 1.274 
(epoch: 22, iters: 4528, time: 0.153, data: 0.018) loss: 2.009 
(epoch: 22, iters: 4608, time: 0.153, data: 0.011) loss: 2.105 
(epoch: 22, iters: 4688, time: 0.150, data: 0.000) loss: 1.279 
(epoch: 22, iters: 4768, time: 0.154, data: 0.000) loss: 1.188 
(epoch: 22, iters: 4848, time: 0.153, data: 0.000) loss: 0.985 
(epoch: 22, iters: 4928, time: 0.152, data: 0.008) loss: 1.699 
(epoch: 22, iters: 5008, time: 0.151, data: 0.000) loss: 1.122 
(epoch: 22, iters: 5088, time: 0.154, data: 0.000) loss: 0.633 
(epoch: 22, iters: 5168, time: 0.152, data: 0.016) loss: 0.974 
(epoch: 22, iters: 5248, time: 0.153, data: 0.000) loss: 1.097 
(epoch: 22, iters: 5328, time: 0.150, data: 0.000) loss: 1.684 
(epoch: 22, iters: 5408, time: 0.152, data: 0.005) loss: 0.733 
(epoch: 22, iters: 5488, time: 0.149, data: 0.005) loss: 1.583 
(epoch: 22, iters: 5568, time: 0.149, data: 0.000) loss: 1.258 
(epoch: 22, iters: 5648, time: 0.149, data: 0.000) loss: 1.240 
(epoch: 22, iters: 5728, time: 0.149, data: 0.000) loss: 1.068 
(epoch: 22, iters: 5808, time: 0.150, data: 0.000) loss: 0.643 
(epoch: 22, iters: 5888, time: 0.150, data: 0.000) loss: 1.369 
(epoch: 22, iters: 5968, time: 0.151, data: 0.014) loss: 0.889 
(epoch: 22, iters: 6048, time: 0.149, data: 0.000) loss: 0.814 
(epoch: 22, iters: 6128, time: 0.152, data: 0.013) loss: 1.362 
(epoch: 22, iters: 6208, time: 0.152, data: 0.000) loss: 1.633 
(epoch: 22, iters: 6288, time: 0.153, data: 0.000) loss: 1.708 
(epoch: 22, iters: 6368, time: 0.153, data: 0.000) loss: 1.379 
(epoch: 22, iters: 6448, time: 0.153, data: 0.013) loss: 2.344 
(epoch: 22, iters: 6528, time: 0.151, data: 0.000) loss: 1.503 
(epoch: 22, iters: 6608, time: 0.152, data: 0.005) loss: 1.488 
(epoch: 22, iters: 6688, time: 0.149, data: 0.019) loss: 1.342 
(epoch: 22, iters: 6768, time: 0.148, data: 0.000) loss: 0.774 
(epoch: 22, iters: 6848, time: 0.148, data: 0.000) loss: 1.554 
(epoch: 22, iters: 6928, time: 0.150, data: 0.000) loss: 2.062 
(epoch: 22, iters: 7008, time: 0.151, data: 0.015) loss: 2.108 
(epoch: 22, iters: 7088, time: 0.150, data: 0.000) loss: 1.038 
(epoch: 22, iters: 7168, time: 0.150, data: 0.005) loss: 1.627 
(epoch: 22, iters: 7248, time: 0.149, data: 0.000) loss: 1.703 
(epoch: 22, iters: 7328, time: 0.151, data: 0.008) loss: 1.461 
(epoch: 22, iters: 7408, time: 0.152, data: 0.000) loss: 1.636 
(epoch: 22, iters: 7488, time: 0.150, data: 0.016) loss: 0.761 
(epoch: 22, iters: 7568, time: 0.148, data: 0.000) loss: 1.124 
(epoch: 22, iters: 7648, time: 0.152, data: 0.005) loss: 1.286 
(epoch: 22, iters: 7728, time: 0.152, data: 0.000) loss: 1.454 
(epoch: 22, iters: 7808, time: 0.153, data: 0.010) loss: 1.521 
(epoch: 22, iters: 7888, time: 0.155, data: 0.000) loss: 1.449 
(epoch: 22, iters: 7968, time: 0.152, data: 0.024) loss: 1.346 
saving the latest model (epoch 22, total_steps 222048)
(epoch: 22, iters: 8048, time: 0.155, data: 0.000) loss: 1.371 
(epoch: 22, iters: 8128, time: 0.152, data: 0.014) loss: 2.139 
(epoch: 22, iters: 8208, time: 0.152, data: 0.005) loss: 1.755 
(epoch: 22, iters: 8288, time: 0.153, data: 0.000) loss: 1.289 
(epoch: 22, iters: 8368, time: 0.151, data: 0.032) loss: 1.284 
(epoch: 22, iters: 8448, time: 0.152, data: 0.000) loss: 1.108 
(epoch: 22, iters: 8528, time: 0.153, data: 0.000) loss: 1.149 
(epoch: 22, iters: 8608, time: 0.154, data: 0.014) loss: 1.254 
(epoch: 22, iters: 8688, time: 0.153, data: 0.015) loss: 1.240 
(epoch: 22, iters: 8768, time: 0.152, data: 0.005) loss: 1.658 
(epoch: 22, iters: 8848, time: 0.151, data: 0.009) loss: 1.032 
(epoch: 22, iters: 8928, time: 0.152, data: 0.005) loss: 2.040 
(epoch: 22, iters: 9008, time: 0.151, data: 0.000) loss: 1.191 
(epoch: 22, iters: 9088, time: 0.153, data: 0.000) loss: 1.456 
(epoch: 22, iters: 9168, time: 0.149, data: 0.006) loss: 1.011 
(epoch: 22, iters: 9248, time: 0.151, data: 0.006) loss: 0.945 
(epoch: 22, iters: 9328, time: 0.152, data: 0.005) loss: 1.260 
(epoch: 22, iters: 9408, time: 0.154, data: 0.000) loss: 0.992 
(epoch: 22, iters: 9488, time: 0.152, data: 0.013) loss: 1.403 
(epoch: 22, iters: 9568, time: 0.155, data: 0.005) loss: 2.375 
(epoch: 22, iters: 9648, time: 0.151, data: 0.000) loss: 0.865 
(epoch: 22, iters: 9728, time: 0.151, data: 0.000) loss: 0.835 
(epoch: 22, iters: 9808, time: 0.149, data: 0.000) loss: 0.898 
(epoch: 22, iters: 9888, time: 0.152, data: 0.016) loss: 1.513 
(epoch: 22, iters: 9968, time: 0.154, data: 0.000) loss: 1.038 
(epoch: 22, iters: 10048, time: 0.152, data: 0.009) loss: 1.323 
(epoch: 22, iters: 10128, time: 0.151, data: 0.000) loss: 1.289 
saving the model at the end of epoch 22, iters 224224
End of epoch 22 / 200 	 Time Taken: 1554 sec
learning rate = 0.0002000
(epoch: 23, iters: 16, time: 0.174, data: 0.000) loss: 1.305 
saving the latest model (epoch 23, total_steps 224240)
(epoch: 23, iters: 96, time: 0.153, data: 0.000) loss: 1.231 
(epoch: 23, iters: 176, time: 0.153, data: 0.000) loss: 0.671 
(epoch: 23, iters: 256, time: 0.153, data: 0.013) loss: 0.964 
(epoch: 23, iters: 336, time: 0.152, data: 0.008) loss: 1.113 
(epoch: 23, iters: 416, time: 0.151, data: 0.000) loss: 1.665 
(epoch: 23, iters: 496, time: 0.150, data: 0.000) loss: 1.885 
(epoch: 23, iters: 576, time: 0.151, data: 0.000) loss: 1.523 
(epoch: 23, iters: 656, time: 0.151, data: 0.009) loss: 1.093 
(epoch: 23, iters: 736, time: 0.151, data: 0.000) loss: 0.815 
(epoch: 23, iters: 816, time: 0.150, data: 0.009) loss: 1.211 
(epoch: 23, iters: 896, time: 0.150, data: 0.010) loss: 0.797 
(epoch: 23, iters: 976, time: 0.149, data: 0.000) loss: 1.461 
(epoch: 23, iters: 1056, time: 0.151, data: 0.000) loss: 0.763 
(epoch: 23, iters: 1136, time: 0.154, data: 0.000) loss: 1.549 
(epoch: 23, iters: 1216, time: 0.148, data: 0.005) loss: 1.508 
(epoch: 23, iters: 1296, time: 0.147, data: 0.000) loss: 1.782 
(epoch: 23, iters: 1376, time: 0.150, data: 0.015) loss: 1.235 
(epoch: 23, iters: 1456, time: 0.151, data: 0.000) loss: 1.788 
(epoch: 23, iters: 1536, time: 0.149, data: 0.000) loss: 1.856 
(epoch: 23, iters: 1616, time: 0.149, data: 0.006) loss: 1.384 
(epoch: 23, iters: 1696, time: 0.148, data: 0.000) loss: 1.241 
(epoch: 23, iters: 1776, time: 0.150, data: 0.000) loss: 0.983 
(epoch: 23, iters: 1856, time: 0.148, data: 0.000) loss: 1.152 
(epoch: 23, iters: 1936, time: 0.150, data: 0.014) loss: 1.396 
(epoch: 23, iters: 2016, time: 0.149, data: 0.000) loss: 1.762 
(epoch: 23, iters: 2096, time: 0.150, data: 0.000) loss: 1.477 
(epoch: 23, iters: 2176, time: 0.151, data: 0.021) loss: 1.676 
(epoch: 23, iters: 2256, time: 0.149, data: 0.022) loss: 1.221 
(epoch: 23, iters: 2336, time: 0.151, data: 0.000) loss: 1.407 
(epoch: 23, iters: 2416, time: 0.151, data: 0.022) loss: 1.131 
(epoch: 23, iters: 2496, time: 0.152, data: 0.005) loss: 1.522 
(epoch: 23, iters: 2576, time: 0.149, data: 0.000) loss: 1.807 
(epoch: 23, iters: 2656, time: 0.152, data: 0.000) loss: 1.512 
(epoch: 23, iters: 2736, time: 0.152, data: 0.000) loss: 1.258 
(epoch: 23, iters: 2816, time: 0.152, data: 0.000) loss: 1.030 
(epoch: 23, iters: 2896, time: 0.152, data: 0.031) loss: 2.059 
(epoch: 23, iters: 2976, time: 0.151, data: 0.000) loss: 1.685 
(epoch: 23, iters: 3056, time: 0.149, data: 0.000) loss: 1.297 
(epoch: 23, iters: 3136, time: 0.153, data: 0.005) loss: 1.131 
(epoch: 23, iters: 3216, time: 0.151, data: 0.000) loss: 1.235 
(epoch: 23, iters: 3296, time: 0.153, data: 0.014) loss: 1.742 
(epoch: 23, iters: 3376, time: 0.151, data: 0.000) loss: 0.973 
(epoch: 23, iters: 3456, time: 0.151, data: 0.008) loss: 1.555 
(epoch: 23, iters: 3536, time: 0.150, data: 0.006) loss: 1.044 
(epoch: 23, iters: 3616, time: 0.150, data: 0.008) loss: 1.097 
(epoch: 23, iters: 3696, time: 0.155, data: 0.005) loss: 0.863 
(epoch: 23, iters: 3776, time: 0.152, data: 0.000) loss: 0.881 
(epoch: 23, iters: 3856, time: 0.153, data: 0.009) loss: 1.214 
(epoch: 23, iters: 3936, time: 0.153, data: 0.000) loss: 1.075 
(epoch: 23, iters: 4016, time: 0.154, data: 0.005) loss: 1.984 
saving the latest model (epoch 23, total_steps 228240)
(epoch: 23, iters: 4096, time: 0.152, data: 0.000) loss: 1.672 
(epoch: 23, iters: 4176, time: 0.154, data: 0.000) loss: 1.597 
(epoch: 23, iters: 4256, time: 0.151, data: 0.027) loss: 1.999 
(epoch: 23, iters: 4336, time: 0.153, data: 0.000) loss: 1.538 
(epoch: 23, iters: 4416, time: 0.152, data: 0.013) loss: 1.513 
(epoch: 23, iters: 4496, time: 0.151, data: 0.018) loss: 1.196 
(epoch: 23, iters: 4576, time: 0.151, data: 0.014) loss: 0.538 
(epoch: 23, iters: 4656, time: 0.153, data: 0.000) loss: 1.322 
(epoch: 23, iters: 4736, time: 0.152, data: 0.000) loss: 1.647 
(epoch: 23, iters: 4816, time: 0.153, data: 0.000) loss: 1.511 
(epoch: 23, iters: 4896, time: 0.154, data: 0.005) loss: 1.750 
(epoch: 23, iters: 4976, time: 0.153, data: 0.010) loss: 0.716 
(epoch: 23, iters: 5056, time: 0.153, data: 0.000) loss: 1.299 
(epoch: 23, iters: 5136, time: 0.153, data: 0.000) loss: 2.152 
(epoch: 23, iters: 5216, time: 0.152, data: 0.000) loss: 0.779 
(epoch: 23, iters: 5296, time: 0.152, data: 0.000) loss: 1.000 
(epoch: 23, iters: 5376, time: 0.153, data: 0.000) loss: 1.002 
(epoch: 23, iters: 5456, time: 0.152, data: 0.005) loss: 0.688 
(epoch: 23, iters: 5536, time: 0.150, data: 0.000) loss: 0.893 
(epoch: 23, iters: 5616, time: 0.156, data: 0.032) loss: 1.031 
(epoch: 23, iters: 5696, time: 0.152, data: 0.000) loss: 2.207 
(epoch: 23, iters: 5776, time: 0.154, data: 0.000) loss: 1.607 
(epoch: 23, iters: 5856, time: 0.154, data: 0.000) loss: 1.544 
(epoch: 23, iters: 5936, time: 0.153, data: 0.000) loss: 1.813 
(epoch: 23, iters: 6016, time: 0.152, data: 0.022) loss: 1.660 
(epoch: 23, iters: 6096, time: 0.152, data: 0.000) loss: 1.031 
(epoch: 23, iters: 6176, time: 0.152, data: 0.005) loss: 0.950 
(epoch: 23, iters: 6256, time: 0.154, data: 0.000) loss: 1.108 
(epoch: 23, iters: 6336, time: 0.152, data: 0.000) loss: 1.318 
(epoch: 23, iters: 6416, time: 0.152, data: 0.000) loss: 1.671 
(epoch: 23, iters: 6496, time: 0.152, data: 0.000) loss: 0.911 
(epoch: 23, iters: 6576, time: 0.152, data: 0.000) loss: 1.181 
(epoch: 23, iters: 6656, time: 0.153, data: 0.005) loss: 0.991 
(epoch: 23, iters: 6736, time: 0.152, data: 0.000) loss: 1.021 
(epoch: 23, iters: 6816, time: 0.152, data: 0.009) loss: 1.612 
(epoch: 23, iters: 6896, time: 0.151, data: 0.000) loss: 1.903 
(epoch: 23, iters: 6976, time: 0.153, data: 0.023) loss: 1.041 
(epoch: 23, iters: 7056, time: 0.154, data: 0.000) loss: 0.919 
(epoch: 23, iters: 7136, time: 0.153, data: 0.000) loss: 1.625 
(epoch: 23, iters: 7216, time: 0.152, data: 0.000) loss: 1.356 
(epoch: 23, iters: 7296, time: 0.151, data: 0.009) loss: 1.059 
(epoch: 23, iters: 7376, time: 0.152, data: 0.000) loss: 1.253 
(epoch: 23, iters: 7456, time: 0.152, data: 0.000) loss: 0.650 
(epoch: 23, iters: 7536, time: 0.152, data: 0.039) loss: 1.432 
(epoch: 23, iters: 7616, time: 0.152, data: 0.000) loss: 1.581 
(epoch: 23, iters: 7696, time: 0.151, data: 0.000) loss: 1.058 
(epoch: 23, iters: 7776, time: 0.154, data: 0.000) loss: 1.266 
(epoch: 23, iters: 7856, time: 0.153, data: 0.005) loss: 0.806 
(epoch: 23, iters: 7936, time: 0.152, data: 0.000) loss: 1.116 
(epoch: 23, iters: 8016, time: 0.151, data: 0.017) loss: 1.949 
saving the latest model (epoch 23, total_steps 232240)
(epoch: 23, iters: 8096, time: 0.153, data: 0.000) loss: 1.731 
(epoch: 23, iters: 8176, time: 0.152, data: 0.014) loss: 1.413 
(epoch: 23, iters: 8256, time: 0.153, data: 0.008) loss: 1.527 
(epoch: 23, iters: 8336, time: 0.152, data: 0.000) loss: 0.866 
(epoch: 23, iters: 8416, time: 0.153, data: 0.010) loss: 1.286 
(epoch: 23, iters: 8496, time: 0.152, data: 0.015) loss: 0.869 
(epoch: 23, iters: 8576, time: 0.150, data: 0.025) loss: 1.693 
(epoch: 23, iters: 8656, time: 0.154, data: 0.000) loss: 1.391 
(epoch: 23, iters: 8736, time: 0.153, data: 0.000) loss: 1.177 
(epoch: 23, iters: 8816, time: 0.151, data: 0.000) loss: 0.781 
(epoch: 23, iters: 8896, time: 0.151, data: 0.021) loss: 1.093 
(epoch: 23, iters: 8976, time: 0.152, data: 0.024) loss: 1.571 
(epoch: 23, iters: 9056, time: 0.151, data: 0.000) loss: 1.099 
(epoch: 23, iters: 9136, time: 0.152, data: 0.009) loss: 1.570 
(epoch: 23, iters: 9216, time: 0.151, data: 0.010) loss: 1.165 
(epoch: 23, iters: 9296, time: 0.152, data: 0.009) loss: 1.154 
(epoch: 23, iters: 9376, time: 0.152, data: 0.024) loss: 1.318 
(epoch: 23, iters: 9456, time: 0.152, data: 0.000) loss: 1.237 
(epoch: 23, iters: 9536, time: 0.152, data: 0.000) loss: 0.833 
(epoch: 23, iters: 9616, time: 0.153, data: 0.005) loss: 1.407 
(epoch: 23, iters: 9696, time: 0.152, data: 0.005) loss: 1.670 
(epoch: 23, iters: 9776, time: 0.152, data: 0.009) loss: 1.420 
(epoch: 23, iters: 9856, time: 0.152, data: 0.005) loss: 0.828 
(epoch: 23, iters: 9936, time: 0.150, data: 0.000) loss: 1.622 
(epoch: 23, iters: 10016, time: 0.152, data: 0.022) loss: 1.235 
(epoch: 23, iters: 10096, time: 0.153, data: 0.008) loss: 1.140 
(epoch: 23, iters: 10176, time: 0.150, data: 0.000) loss: 1.181 
saving the model at the end of epoch 23, iters 234416
End of epoch 23 / 200 	 Time Taken: 1550 sec
learning rate = 0.0002000
saving the latest model (epoch 24, total_steps 234432)
(epoch: 24, iters: 64, time: 0.152, data: 0.003) loss: 0.944 
(epoch: 24, iters: 144, time: 0.152, data: 0.020) loss: 1.485 
(epoch: 24, iters: 224, time: 0.151, data: 0.021) loss: 1.062 
(epoch: 24, iters: 304, time: 0.152, data: 0.026) loss: 0.768 
(epoch: 24, iters: 384, time: 0.152, data: 0.000) loss: 1.366 
(epoch: 24, iters: 464, time: 0.148, data: 0.000) loss: 0.793 
(epoch: 24, iters: 544, time: 0.150, data: 0.016) loss: 1.541 
(epoch: 24, iters: 624, time: 0.152, data: 0.000) loss: 1.072 
(epoch: 24, iters: 704, time: 0.151, data: 0.020) loss: 1.196 
(epoch: 24, iters: 784, time: 0.150, data: 0.000) loss: 1.649 
(epoch: 24, iters: 864, time: 0.152, data: 0.016) loss: 1.297 
(epoch: 24, iters: 944, time: 0.152, data: 0.000) loss: 1.346 
(epoch: 24, iters: 1024, time: 0.149, data: 0.012) loss: 1.175 
(epoch: 24, iters: 1104, time: 0.151, data: 0.000) loss: 1.434 
(epoch: 24, iters: 1184, time: 0.150, data: 0.005) loss: 1.746 
(epoch: 24, iters: 1264, time: 0.150, data: 0.005) loss: 1.654 
(epoch: 24, iters: 1344, time: 0.152, data: 0.008) loss: 1.536 
(epoch: 24, iters: 1424, time: 0.150, data: 0.020) loss: 1.532 
(epoch: 24, iters: 1504, time: 0.151, data: 0.009) loss: 1.338 
(epoch: 24, iters: 1584, time: 0.152, data: 0.000) loss: 0.989 
(epoch: 24, iters: 1664, time: 0.152, data: 0.000) loss: 1.211 
(epoch: 24, iters: 1744, time: 0.150, data: 0.000) loss: 1.793 
(epoch: 24, iters: 1824, time: 0.152, data: 0.008) loss: 2.657 
(epoch: 24, iters: 1904, time: 0.151, data: 0.000) loss: 1.614 
(epoch: 24, iters: 1984, time: 0.153, data: 0.008) loss: 1.288 
(epoch: 24, iters: 2064, time: 0.151, data: 0.009) loss: 1.971 
(epoch: 24, iters: 2144, time: 0.148, data: 0.006) loss: 1.478 
(epoch: 24, iters: 2224, time: 0.149, data: 0.026) loss: 0.531 
(epoch: 24, iters: 2304, time: 0.151, data: 0.000) loss: 0.708 
(epoch: 24, iters: 2384, time: 0.152, data: 0.000) loss: 1.549 
(epoch: 24, iters: 2464, time: 0.150, data: 0.000) loss: 0.674 
(epoch: 24, iters: 2544, time: 0.151, data: 0.000) loss: 0.768 
(epoch: 24, iters: 2624, time: 0.151, data: 0.000) loss: 1.125 
(epoch: 24, iters: 2704, time: 0.153, data: 0.000) loss: 1.436 
(epoch: 24, iters: 2784, time: 0.150, data: 0.000) loss: 0.979 
(epoch: 24, iters: 2864, time: 0.152, data: 0.022) loss: 1.417 
(epoch: 24, iters: 2944, time: 0.151, data: 0.000) loss: 1.050 
(epoch: 24, iters: 3024, time: 0.150, data: 0.000) loss: 0.765 
(epoch: 24, iters: 3104, time: 0.149, data: 0.005) loss: 0.861 
(epoch: 24, iters: 3184, time: 0.151, data: 0.023) loss: 1.130 
(epoch: 24, iters: 3264, time: 0.153, data: 0.000) loss: 1.408 
(epoch: 24, iters: 3344, time: 0.150, data: 0.000) loss: 1.423 
(epoch: 24, iters: 3424, time: 0.150, data: 0.009) loss: 1.539 
(epoch: 24, iters: 3504, time: 0.147, data: 0.000) loss: 1.017 
(epoch: 24, iters: 3584, time: 0.151, data: 0.015) loss: 1.477 
(epoch: 24, iters: 3664, time: 0.151, data: 0.000) loss: 1.317 
(epoch: 24, iters: 3744, time: 0.151, data: 0.000) loss: 1.193 
(epoch: 24, iters: 3824, time: 0.150, data: 0.000) loss: 0.733 
(epoch: 24, iters: 3904, time: 0.152, data: 0.000) loss: 0.778 
(epoch: 24, iters: 3984, time: 0.149, data: 0.040) loss: 0.484 
saving the latest model (epoch 24, total_steps 238432)
(epoch: 24, iters: 4064, time: 0.150, data: 0.000) loss: 1.605 
(epoch: 24, iters: 4144, time: 0.152, data: 0.000) loss: 1.610 
(epoch: 24, iters: 4224, time: 0.153, data: 0.000) loss: 0.915 
(epoch: 24, iters: 4304, time: 0.152, data: 0.000) loss: 1.577 
(epoch: 24, iters: 4384, time: 0.152, data: 0.000) loss: 1.093 
(epoch: 24, iters: 4464, time: 0.152, data: 0.005) loss: 2.160 
(epoch: 24, iters: 4544, time: 0.151, data: 0.000) loss: 0.991 
(epoch: 24, iters: 4624, time: 0.151, data: 0.005) loss: 0.751 
(epoch: 24, iters: 4704, time: 0.150, data: 0.006) loss: 1.124 
(epoch: 24, iters: 4784, time: 0.151, data: 0.000) loss: 0.697 
(epoch: 24, iters: 4864, time: 0.152, data: 0.000) loss: 1.304 
(epoch: 24, iters: 4944, time: 0.152, data: 0.005) loss: 1.180 
(epoch: 24, iters: 5024, time: 0.152, data: 0.008) loss: 1.281 
(epoch: 24, iters: 5104, time: 0.152, data: 0.000) loss: 1.370 
(epoch: 24, iters: 5184, time: 0.154, data: 0.011) loss: 1.361 
(epoch: 24, iters: 5264, time: 0.150, data: 0.000) loss: 1.111 
(epoch: 24, iters: 5344, time: 0.149, data: 0.010) loss: 1.657 
(epoch: 24, iters: 5424, time: 0.152, data: 0.000) loss: 1.747 
(epoch: 24, iters: 5504, time: 0.150, data: 0.000) loss: 1.217 
(epoch: 24, iters: 5584, time: 0.150, data: 0.018) loss: 1.111 
(epoch: 24, iters: 5664, time: 0.152, data: 0.013) loss: 1.078 
(epoch: 24, iters: 5744, time: 0.150, data: 0.000) loss: 1.456 
(epoch: 24, iters: 5824, time: 0.150, data: 0.018) loss: 1.640 
(epoch: 24, iters: 5904, time: 0.150, data: 0.027) loss: 1.273 
(epoch: 24, iters: 5984, time: 0.150, data: 0.000) loss: 1.045 
(epoch: 24, iters: 6064, time: 0.151, data: 0.000) loss: 1.581 
(epoch: 24, iters: 6144, time: 0.151, data: 0.030) loss: 1.277 
(epoch: 24, iters: 6224, time: 0.151, data: 0.000) loss: 1.689 
(epoch: 24, iters: 6304, time: 0.148, data: 0.014) loss: 1.299 
(epoch: 24, iters: 6384, time: 0.152, data: 0.005) loss: 1.080 
(epoch: 24, iters: 6464, time: 0.150, data: 0.009) loss: 1.324 
(epoch: 24, iters: 6544, time: 0.151, data: 0.000) loss: 0.578 
(epoch: 24, iters: 6624, time: 0.147, data: 0.006) loss: 1.661 
(epoch: 24, iters: 6704, time: 0.151, data: 0.000) loss: 1.009 
(epoch: 24, iters: 6784, time: 0.152, data: 0.005) loss: 1.380 
(epoch: 24, iters: 6864, time: 0.149, data: 0.000) loss: 2.106 
(epoch: 24, iters: 6944, time: 0.151, data: 0.005) loss: 1.324 
(epoch: 24, iters: 7024, time: 0.150, data: 0.000) loss: 1.040 
(epoch: 24, iters: 7104, time: 0.151, data: 0.008) loss: 1.129 
(epoch: 24, iters: 7184, time: 0.150, data: 0.000) loss: 1.310 
(epoch: 24, iters: 7264, time: 0.150, data: 0.023) loss: 1.086 
(epoch: 24, iters: 7344, time: 0.151, data: 0.000) loss: 1.452 
(epoch: 24, iters: 7424, time: 0.150, data: 0.000) loss: 0.661 
(epoch: 24, iters: 7504, time: 0.153, data: 0.000) loss: 0.950 
(epoch: 24, iters: 7584, time: 0.153, data: 0.000) loss: 1.048 
(epoch: 24, iters: 7664, time: 0.150, data: 0.000) loss: 2.041 
(epoch: 24, iters: 7744, time: 0.151, data: 0.010) loss: 1.047 
(epoch: 24, iters: 7824, time: 0.151, data: 0.015) loss: 1.162 
(epoch: 24, iters: 7904, time: 0.150, data: 0.005) loss: 0.686 
(epoch: 24, iters: 7984, time: 0.149, data: 0.005) loss: 1.710 
saving the latest model (epoch 24, total_steps 242432)
(epoch: 24, iters: 8064, time: 0.151, data: 0.000) loss: 1.278 
(epoch: 24, iters: 8144, time: 0.151, data: 0.014) loss: 1.139 
(epoch: 24, iters: 8224, time: 0.150, data: 0.014) loss: 1.289 
(epoch: 24, iters: 8304, time: 0.150, data: 0.006) loss: 1.484 
(epoch: 24, iters: 8384, time: 0.150, data: 0.018) loss: 1.147 
(epoch: 24, iters: 8464, time: 0.150, data: 0.008) loss: 0.744 
(epoch: 24, iters: 8544, time: 0.150, data: 0.000) loss: 0.919 
(epoch: 24, iters: 8624, time: 0.151, data: 0.000) loss: 1.063 
(epoch: 24, iters: 8704, time: 0.151, data: 0.009) loss: 1.342 
(epoch: 24, iters: 8784, time: 0.151, data: 0.000) loss: 1.449 
(epoch: 24, iters: 8864, time: 0.151, data: 0.005) loss: 0.972 
(epoch: 24, iters: 8944, time: 0.151, data: 0.000) loss: 1.515 
(epoch: 24, iters: 9024, time: 0.151, data: 0.000) loss: 0.493 
(epoch: 24, iters: 9104, time: 0.151, data: 0.025) loss: 1.030 
(epoch: 24, iters: 9184, time: 0.150, data: 0.000) loss: 0.822 
(epoch: 24, iters: 9264, time: 0.150, data: 0.015) loss: 1.572 
(epoch: 24, iters: 9344, time: 0.151, data: 0.000) loss: 1.175 
(epoch: 24, iters: 9424, time: 0.150, data: 0.015) loss: 1.055 
(epoch: 24, iters: 9504, time: 0.152, data: 0.025) loss: 1.176 
(epoch: 24, iters: 9584, time: 0.151, data: 0.000) loss: 1.693 
(epoch: 24, iters: 9664, time: 0.150, data: 0.005) loss: 1.416 
(epoch: 24, iters: 9744, time: 0.150, data: 0.005) loss: 1.133 
(epoch: 24, iters: 9824, time: 0.150, data: 0.000) loss: 1.257 
(epoch: 24, iters: 9904, time: 0.149, data: 0.008) loss: 1.433 
(epoch: 24, iters: 9984, time: 0.150, data: 0.000) loss: 1.233 
(epoch: 24, iters: 10064, time: 0.151, data: 0.005) loss: 1.018 
(epoch: 24, iters: 10144, time: 0.148, data: 0.000) loss: 1.408 
saving the model at the end of epoch 24, iters 244608
End of epoch 24 / 200 	 Time Taken: 1540 sec
learning rate = 0.0002000
saving the latest model (epoch 25, total_steps 244624)
(epoch: 25, iters: 32, time: 0.158, data: 0.009) loss: 0.896 
(epoch: 25, iters: 112, time: 0.151, data: 0.015) loss: 0.894 
(epoch: 25, iters: 192, time: 0.152, data: 0.009) loss: 1.168 
(epoch: 25, iters: 272, time: 0.150, data: 0.017) loss: 1.808 
(epoch: 25, iters: 352, time: 0.151, data: 0.005) loss: 1.168 
(epoch: 25, iters: 432, time: 0.152, data: 0.000) loss: 1.069 
(epoch: 25, iters: 512, time: 0.154, data: 0.000) loss: 0.807 
(epoch: 25, iters: 592, time: 0.154, data: 0.005) loss: 1.292 
(epoch: 25, iters: 672, time: 0.153, data: 0.000) loss: 1.226 
(epoch: 25, iters: 752, time: 0.153, data: 0.005) loss: 2.225 
(epoch: 25, iters: 832, time: 0.151, data: 0.000) loss: 1.155 
(epoch: 25, iters: 912, time: 0.151, data: 0.000) loss: 1.948 
(epoch: 25, iters: 992, time: 0.151, data: 0.000) loss: 1.820 
(epoch: 25, iters: 1072, time: 0.151, data: 0.025) loss: 1.160 
(epoch: 25, iters: 1152, time: 0.153, data: 0.000) loss: 1.203 
(epoch: 25, iters: 1232, time: 0.152, data: 0.000) loss: 0.996 
(epoch: 25, iters: 1312, time: 0.151, data: 0.000) loss: 1.178 
(epoch: 25, iters: 1392, time: 0.156, data: 0.010) loss: 1.562 
(epoch: 25, iters: 1472, time: 0.157, data: 0.000) loss: 0.676 
(epoch: 25, iters: 1552, time: 0.153, data: 0.000) loss: 1.493 
(epoch: 25, iters: 1632, time: 0.154, data: 0.008) loss: 1.033 
(epoch: 25, iters: 1712, time: 0.153, data: 0.000) loss: 1.005 
(epoch: 25, iters: 1792, time: 0.153, data: 0.006) loss: 1.166 
(epoch: 25, iters: 1872, time: 0.153, data: 0.000) loss: 0.909 
(epoch: 25, iters: 1952, time: 0.157, data: 0.000) loss: 0.864 
(epoch: 25, iters: 2032, time: 0.154, data: 0.009) loss: 1.675 
(epoch: 25, iters: 2112, time: 0.155, data: 0.006) loss: 1.617 
(epoch: 25, iters: 2192, time: 0.153, data: 0.000) loss: 1.574 
(epoch: 25, iters: 2272, time: 0.153, data: 0.000) loss: 1.469 
(epoch: 25, iters: 2352, time: 0.153, data: 0.025) loss: 1.561 
(epoch: 25, iters: 2432, time: 0.153, data: 0.000) loss: 1.084 
(epoch: 25, iters: 2512, time: 0.155, data: 0.000) loss: 1.615 
(epoch: 25, iters: 2592, time: 0.159, data: 0.000) loss: 1.129 
(epoch: 25, iters: 2672, time: 0.154, data: 0.000) loss: 1.023 
(epoch: 25, iters: 2752, time: 0.157, data: 0.000) loss: 1.203 
(epoch: 25, iters: 2832, time: 0.153, data: 0.000) loss: 1.057 
(epoch: 25, iters: 2912, time: 0.153, data: 0.013) loss: 1.527 
(epoch: 25, iters: 2992, time: 0.152, data: 0.000) loss: 1.093 
(epoch: 25, iters: 3072, time: 0.152, data: 0.005) loss: 0.407 
(epoch: 25, iters: 3152, time: 0.152, data: 0.000) loss: 1.137 
(epoch: 25, iters: 3232, time: 0.152, data: 0.005) loss: 1.626 
(epoch: 25, iters: 3312, time: 0.150, data: 0.000) loss: 1.185 
(epoch: 25, iters: 3392, time: 0.152, data: 0.031) loss: 1.044 
(epoch: 25, iters: 3472, time: 0.153, data: 0.000) loss: 1.507 
(epoch: 25, iters: 3552, time: 0.152, data: 0.032) loss: 0.972 
(epoch: 25, iters: 3632, time: 0.153, data: 0.000) loss: 1.151 
(epoch: 25, iters: 3712, time: 0.153, data: 0.000) loss: 1.198 
(epoch: 25, iters: 3792, time: 0.151, data: 0.000) loss: 1.296 
(epoch: 25, iters: 3872, time: 0.149, data: 0.014) loss: 0.762 
(epoch: 25, iters: 3952, time: 0.153, data: 0.009) loss: 1.150 
saving the latest model (epoch 25, total_steps 248624)
(epoch: 25, iters: 4032, time: 0.152, data: 0.000) loss: 1.188 
(epoch: 25, iters: 4112, time: 0.150, data: 0.009) loss: 1.016 
(epoch: 25, iters: 4192, time: 0.151, data: 0.000) loss: 1.160 
(epoch: 25, iters: 4272, time: 0.151, data: 0.005) loss: 2.088 
(epoch: 25, iters: 4352, time: 0.152, data: 0.000) loss: 1.076 
(epoch: 25, iters: 4432, time: 0.153, data: 0.000) loss: 0.928 
(epoch: 25, iters: 4512, time: 0.152, data: 0.000) loss: 1.307 
(epoch: 25, iters: 4592, time: 0.156, data: 0.000) loss: 1.492 
(epoch: 25, iters: 4672, time: 0.152, data: 0.000) loss: 1.367 
(epoch: 25, iters: 4752, time: 0.156, data: 0.000) loss: 1.015 
(epoch: 25, iters: 4832, time: 0.154, data: 0.000) loss: 0.891 
(epoch: 25, iters: 4912, time: 0.151, data: 0.009) loss: 1.062 
(epoch: 25, iters: 4992, time: 0.154, data: 0.005) loss: 1.254 
(epoch: 25, iters: 5072, time: 0.155, data: 0.006) loss: 1.219 
(epoch: 25, iters: 5152, time: 0.154, data: 0.024) loss: 0.845 
(epoch: 25, iters: 5232, time: 0.155, data: 0.000) loss: 0.853 
(epoch: 25, iters: 5312, time: 0.154, data: 0.019) loss: 1.336 
(epoch: 25, iters: 5392, time: 0.153, data: 0.000) loss: 1.154 
(epoch: 25, iters: 5472, time: 0.152, data: 0.008) loss: 1.690 
(epoch: 25, iters: 5552, time: 0.153, data: 0.000) loss: 1.165 
(epoch: 25, iters: 5632, time: 0.153, data: 0.005) loss: 1.190 
(epoch: 25, iters: 5712, time: 0.154, data: 0.010) loss: 1.625 
(epoch: 25, iters: 5792, time: 0.151, data: 0.000) loss: 0.725 
(epoch: 25, iters: 5872, time: 0.151, data: 0.025) loss: 1.347 
(epoch: 25, iters: 5952, time: 0.152, data: 0.005) loss: 1.105 
(epoch: 25, iters: 6032, time: 0.156, data: 0.005) loss: 2.300 
(epoch: 25, iters: 6112, time: 0.155, data: 0.005) loss: 0.908 
(epoch: 25, iters: 6192, time: 0.152, data: 0.005) loss: 0.977 
(epoch: 25, iters: 6272, time: 0.152, data: 0.000) loss: 1.310 
(epoch: 25, iters: 6352, time: 0.150, data: 0.030) loss: 0.874 
(epoch: 25, iters: 6432, time: 0.153, data: 0.000) loss: 1.117 
(epoch: 25, iters: 6512, time: 0.151, data: 0.000) loss: 1.341 
(epoch: 25, iters: 6592, time: 0.153, data: 0.012) loss: 1.820 
(epoch: 25, iters: 6672, time: 0.153, data: 0.000) loss: 1.108 
(epoch: 25, iters: 6752, time: 0.151, data: 0.009) loss: 1.341 
(epoch: 25, iters: 6832, time: 0.152, data: 0.005) loss: 1.818 
(epoch: 25, iters: 6912, time: 0.153, data: 0.000) loss: 1.598 
(epoch: 25, iters: 6992, time: 0.154, data: 0.000) loss: 0.715 
(epoch: 25, iters: 7072, time: 0.151, data: 0.015) loss: 1.353 
(epoch: 25, iters: 7152, time: 0.155, data: 0.000) loss: 1.273 
(epoch: 25, iters: 7232, time: 0.155, data: 0.014) loss: 1.185 
(epoch: 25, iters: 7312, time: 0.151, data: 0.023) loss: 0.978 
(epoch: 25, iters: 7392, time: 0.153, data: 0.000) loss: 1.674 
(epoch: 25, iters: 7472, time: 0.153, data: 0.000) loss: 1.277 
(epoch: 25, iters: 7552, time: 0.154, data: 0.000) loss: 1.083 
(epoch: 25, iters: 7632, time: 0.153, data: 0.000) loss: 1.718 
(epoch: 25, iters: 7712, time: 0.153, data: 0.000) loss: 1.513 
(epoch: 25, iters: 7792, time: 0.153, data: 0.000) loss: 0.861 
(epoch: 25, iters: 7872, time: 0.150, data: 0.000) loss: 0.651 
(epoch: 25, iters: 7952, time: 0.150, data: 0.005) loss: 1.607 
saving the latest model (epoch 25, total_steps 252624)
(epoch: 25, iters: 8032, time: 0.148, data: 0.019) loss: 0.883 
(epoch: 25, iters: 8112, time: 0.150, data: 0.000) loss: 1.075 
(epoch: 25, iters: 8192, time: 0.150, data: 0.037) loss: 0.743 
(epoch: 25, iters: 8272, time: 0.150, data: 0.000) loss: 1.294 
(epoch: 25, iters: 8352, time: 0.153, data: 0.000) loss: 0.974 
(epoch: 25, iters: 8432, time: 0.149, data: 0.021) loss: 2.059 
(epoch: 25, iters: 8512, time: 0.151, data: 0.005) loss: 1.530 
(epoch: 25, iters: 8592, time: 0.150, data: 0.022) loss: 1.275 
(epoch: 25, iters: 8672, time: 0.147, data: 0.000) loss: 1.370 
(epoch: 25, iters: 8752, time: 0.152, data: 0.000) loss: 1.362 
(epoch: 25, iters: 8832, time: 0.152, data: 0.000) loss: 0.996 
(epoch: 25, iters: 8912, time: 0.151, data: 0.021) loss: 1.672 
(epoch: 25, iters: 8992, time: 0.151, data: 0.000) loss: 0.914 
(epoch: 25, iters: 9072, time: 0.151, data: 0.000) loss: 0.997 
(epoch: 25, iters: 9152, time: 0.154, data: 0.018) loss: 0.566 
(epoch: 25, iters: 9232, time: 0.154, data: 0.014) loss: 1.250 
(epoch: 25, iters: 9312, time: 0.150, data: 0.000) loss: 1.192 
(epoch: 25, iters: 9392, time: 0.152, data: 0.000) loss: 1.223 
(epoch: 25, iters: 9472, time: 0.151, data: 0.000) loss: 1.191 
(epoch: 25, iters: 9552, time: 0.152, data: 0.000) loss: 1.477 
(epoch: 25, iters: 9632, time: 0.151, data: 0.005) loss: 1.091 
(epoch: 25, iters: 9712, time: 0.153, data: 0.011) loss: 1.055 
(epoch: 25, iters: 9792, time: 0.151, data: 0.000) loss: 0.773 
(epoch: 25, iters: 9872, time: 0.153, data: 0.000) loss: 1.430 
(epoch: 25, iters: 9952, time: 0.151, data: 0.015) loss: 0.472 
(epoch: 25, iters: 10032, time: 0.152, data: 0.009) loss: 1.061 
(epoch: 25, iters: 10112, time: 0.151, data: 0.000) loss: 1.309 
(epoch: 25, iters: 10192, time: 0.091, data: 0.018) loss: 1.058 
saving the model at the end of epoch 25, iters 254800
End of epoch 25 / 200 	 Time Taken: 1556 sec
learning rate = 0.0002000
saving the latest model (epoch 26, total_steps 254816)
(epoch: 26, iters: 80, time: 0.150, data: 0.399) loss: 1.379 
(epoch: 26, iters: 160, time: 0.152, data: 0.013) loss: 1.304 
(epoch: 26, iters: 240, time: 0.151, data: 0.000) loss: 0.944 
(epoch: 26, iters: 320, time: 0.151, data: 0.016) loss: 1.148 
(epoch: 26, iters: 400, time: 0.149, data: 0.015) loss: 1.386 
(epoch: 26, iters: 480, time: 0.150, data: 0.000) loss: 1.349 
(epoch: 26, iters: 560, time: 0.150, data: 0.005) loss: 0.805 
(epoch: 26, iters: 640, time: 0.152, data: 0.005) loss: 0.927 
(epoch: 26, iters: 720, time: 0.151, data: 0.000) loss: 0.861 
(epoch: 26, iters: 800, time: 0.147, data: 0.000) loss: 1.373 
(epoch: 26, iters: 880, time: 0.151, data: 0.008) loss: 0.980 
(epoch: 26, iters: 960, time: 0.150, data: 0.000) loss: 1.281 
(epoch: 26, iters: 1040, time: 0.151, data: 0.000) loss: 0.826 
(epoch: 26, iters: 1120, time: 0.149, data: 0.015) loss: 0.998 
(epoch: 26, iters: 1200, time: 0.150, data: 0.000) loss: 1.008 
(epoch: 26, iters: 1280, time: 0.150, data: 0.013) loss: 1.617 
(epoch: 26, iters: 1360, time: 0.150, data: 0.000) loss: 1.185 
(epoch: 26, iters: 1440, time: 0.150, data: 0.024) loss: 1.508 
(epoch: 26, iters: 1520, time: 0.151, data: 0.000) loss: 1.073 
(epoch: 26, iters: 1600, time: 0.151, data: 0.017) loss: 1.250 
(epoch: 26, iters: 1680, time: 0.149, data: 0.005) loss: 1.140 
(epoch: 26, iters: 1760, time: 0.151, data: 0.024) loss: 1.602 
(epoch: 26, iters: 1840, time: 0.151, data: 0.000) loss: 0.688 
(epoch: 26, iters: 1920, time: 0.151, data: 0.000) loss: 1.235 
(epoch: 26, iters: 2000, time: 0.151, data: 0.024) loss: 1.592 
(epoch: 26, iters: 2080, time: 0.150, data: 0.000) loss: 1.191 
(epoch: 26, iters: 2160, time: 0.150, data: 0.013) loss: 1.007 
(epoch: 26, iters: 2240, time: 0.147, data: 0.000) loss: 1.477 
(epoch: 26, iters: 2320, time: 0.149, data: 0.010) loss: 0.783 
(epoch: 26, iters: 2400, time: 0.150, data: 0.005) loss: 0.895 
(epoch: 26, iters: 2480, time: 0.149, data: 0.033) loss: 1.273 
(epoch: 26, iters: 2560, time: 0.149, data: 0.000) loss: 1.732 
(epoch: 26, iters: 2640, time: 0.149, data: 0.000) loss: 1.021 
(epoch: 26, iters: 2720, time: 0.150, data: 0.000) loss: 1.610 
(epoch: 26, iters: 2800, time: 0.151, data: 0.015) loss: 1.853 
(epoch: 26, iters: 2880, time: 0.150, data: 0.000) loss: 0.729 
(epoch: 26, iters: 2960, time: 0.150, data: 0.032) loss: 0.859 
(epoch: 26, iters: 3040, time: 0.146, data: 0.000) loss: 1.946 
(epoch: 26, iters: 3120, time: 0.150, data: 0.000) loss: 1.544 
(epoch: 26, iters: 3200, time: 0.151, data: 0.000) loss: 1.211 
(epoch: 26, iters: 3280, time: 0.149, data: 0.023) loss: 1.551 
(epoch: 26, iters: 3360, time: 0.152, data: 0.000) loss: 0.777 
(epoch: 26, iters: 3440, time: 0.150, data: 0.000) loss: 0.963 
(epoch: 26, iters: 3520, time: 0.152, data: 0.000) loss: 1.313 
(epoch: 26, iters: 3600, time: 0.149, data: 0.005) loss: 0.805 
(epoch: 26, iters: 3680, time: 0.152, data: 0.000) loss: 2.545 
(epoch: 26, iters: 3760, time: 0.148, data: 0.009) loss: 1.377 
(epoch: 26, iters: 3840, time: 0.150, data: 0.005) loss: 1.169 
(epoch: 26, iters: 3920, time: 0.150, data: 0.000) loss: 0.871 
(epoch: 26, iters: 4000, time: 0.149, data: 0.011) loss: 1.546 
saving the latest model (epoch 26, total_steps 258816)
(epoch: 26, iters: 4080, time: 0.146, data: 0.000) loss: 1.465 
(epoch: 26, iters: 4160, time: 0.150, data: 0.018) loss: 0.762 
(epoch: 26, iters: 4240, time: 0.149, data: 0.000) loss: 0.660 
(epoch: 26, iters: 4320, time: 0.150, data: 0.008) loss: 1.465 
(epoch: 26, iters: 4400, time: 0.150, data: 0.027) loss: 1.260 
(epoch: 26, iters: 4480, time: 0.151, data: 0.000) loss: 0.938 
(epoch: 26, iters: 4560, time: 0.151, data: 0.000) loss: 0.964 
(epoch: 26, iters: 4640, time: 0.149, data: 0.000) loss: 1.215 
(epoch: 26, iters: 4720, time: 0.148, data: 0.009) loss: 0.955 
(epoch: 26, iters: 4800, time: 0.151, data: 0.000) loss: 1.543 
(epoch: 26, iters: 4880, time: 0.148, data: 0.000) loss: 1.363 
(epoch: 26, iters: 4960, time: 0.149, data: 0.000) loss: 1.051 
(epoch: 26, iters: 5040, time: 0.151, data: 0.015) loss: 1.388 
(epoch: 26, iters: 5120, time: 0.149, data: 0.024) loss: 1.691 
(epoch: 26, iters: 5200, time: 0.149, data: 0.000) loss: 1.205 
(epoch: 26, iters: 5280, time: 0.152, data: 0.000) loss: 1.105 
(epoch: 26, iters: 5360, time: 0.150, data: 0.000) loss: 1.051 
(epoch: 26, iters: 5440, time: 0.152, data: 0.000) loss: 1.401 
(epoch: 26, iters: 5520, time: 0.147, data: 0.000) loss: 1.282 
(epoch: 26, iters: 5600, time: 0.150, data: 0.000) loss: 1.042 
(epoch: 26, iters: 5680, time: 0.151, data: 0.008) loss: 1.336 
(epoch: 26, iters: 5760, time: 0.152, data: 0.000) loss: 1.101 
(epoch: 26, iters: 5840, time: 0.152, data: 0.010) loss: 0.952 
(epoch: 26, iters: 5920, time: 0.151, data: 0.006) loss: 0.673 
(epoch: 26, iters: 6000, time: 0.150, data: 0.000) loss: 1.472 
(epoch: 26, iters: 6080, time: 0.153, data: 0.005) loss: 1.439 
(epoch: 26, iters: 6160, time: 0.152, data: 0.022) loss: 1.038 
(epoch: 26, iters: 6240, time: 0.151, data: 0.000) loss: 0.938 
(epoch: 26, iters: 6320, time: 0.151, data: 0.000) loss: 1.432 
(epoch: 26, iters: 6400, time: 0.149, data: 0.029) loss: 0.890 
(epoch: 26, iters: 6480, time: 0.150, data: 0.000) loss: 1.423 
(epoch: 26, iters: 6560, time: 0.153, data: 0.000) loss: 1.145 
(epoch: 26, iters: 6640, time: 0.152, data: 0.000) loss: 1.212 
(epoch: 26, iters: 6720, time: 0.151, data: 0.010) loss: 0.521 
(epoch: 26, iters: 6800, time: 0.151, data: 0.005) loss: 1.033 
(epoch: 26, iters: 6880, time: 0.150, data: 0.000) loss: 1.620 
(epoch: 26, iters: 6960, time: 0.150, data: 0.008) loss: 0.874 
(epoch: 26, iters: 7040, time: 0.151, data: 0.024) loss: 0.928 
(epoch: 26, iters: 7120, time: 0.151, data: 0.000) loss: 0.685 
(epoch: 26, iters: 7200, time: 0.151, data: 0.005) loss: 1.639 
(epoch: 26, iters: 7280, time: 0.150, data: 0.000) loss: 0.783 
(epoch: 26, iters: 7360, time: 0.151, data: 0.005) loss: 0.821 
(epoch: 26, iters: 7440, time: 0.150, data: 0.000) loss: 1.112 
(epoch: 26, iters: 7520, time: 0.150, data: 0.005) loss: 0.709 
(epoch: 26, iters: 7600, time: 0.150, data: 0.000) loss: 1.371 
(epoch: 26, iters: 7680, time: 0.151, data: 0.000) loss: 1.193 
(epoch: 26, iters: 7760, time: 0.152, data: 0.025) loss: 1.106 
(epoch: 26, iters: 7840, time: 0.150, data: 0.000) loss: 1.858 
(epoch: 26, iters: 7920, time: 0.149, data: 0.020) loss: 1.099 
(epoch: 26, iters: 8000, time: 0.150, data: 0.005) loss: 1.864 
saving the latest model (epoch 26, total_steps 262816)
(epoch: 26, iters: 8080, time: 0.151, data: 0.000) loss: 1.471 
(epoch: 26, iters: 8160, time: 0.150, data: 0.005) loss: 0.991 
(epoch: 26, iters: 8240, time: 0.151, data: 0.020) loss: 0.826 
(epoch: 26, iters: 8320, time: 0.150, data: 0.009) loss: 1.047 
(epoch: 26, iters: 8400, time: 0.151, data: 0.005) loss: 1.430 
(epoch: 26, iters: 8480, time: 0.150, data: 0.005) loss: 1.400 
(epoch: 26, iters: 8560, time: 0.150, data: 0.008) loss: 1.294 
(epoch: 26, iters: 8640, time: 0.152, data: 0.014) loss: 0.705 
(epoch: 26, iters: 8720, time: 0.151, data: 0.012) loss: 1.109 
(epoch: 26, iters: 8800, time: 0.150, data: 0.008) loss: 1.649 
(epoch: 26, iters: 8880, time: 0.150, data: 0.000) loss: 1.631 
(epoch: 26, iters: 8960, time: 0.151, data: 0.000) loss: 1.411 
(epoch: 26, iters: 9040, time: 0.152, data: 0.013) loss: 1.376 
(epoch: 26, iters: 9120, time: 0.150, data: 0.021) loss: 1.643 
(epoch: 26, iters: 9200, time: 0.150, data: 0.000) loss: 0.833 
(epoch: 26, iters: 9280, time: 0.149, data: 0.000) loss: 1.266 
(epoch: 26, iters: 9360, time: 0.151, data: 0.000) loss: 1.859 
(epoch: 26, iters: 9440, time: 0.151, data: 0.000) loss: 1.034 
(epoch: 26, iters: 9520, time: 0.149, data: 0.005) loss: 0.859 
(epoch: 26, iters: 9600, time: 0.151, data: 0.000) loss: 1.125 
(epoch: 26, iters: 9680, time: 0.150, data: 0.015) loss: 1.153 
(epoch: 26, iters: 9760, time: 0.149, data: 0.021) loss: 0.870 
(epoch: 26, iters: 9840, time: 0.152, data: 0.000) loss: 1.251 
(epoch: 26, iters: 9920, time: 0.149, data: 0.028) loss: 1.324 
(epoch: 26, iters: 10000, time: 0.151, data: 0.000) loss: 1.005 
(epoch: 26, iters: 10080, time: 0.150, data: 0.000) loss: 0.733 
(epoch: 26, iters: 10160, time: 0.148, data: 0.005) loss: 1.151 
saving the model at the end of epoch 26, iters 264992
End of epoch 26 / 200 	 Time Taken: 1535 sec
learning rate = 0.0002000
saving the latest model (epoch 27, total_steps 265008)
(epoch: 27, iters: 48, time: 0.155, data: 0.000) loss: 1.499 
(epoch: 27, iters: 128, time: 0.152, data: 0.028) loss: 1.625 
(epoch: 27, iters: 208, time: 0.151, data: 0.016) loss: 1.351 
(epoch: 27, iters: 288, time: 0.151, data: 0.005) loss: 0.816 
(epoch: 27, iters: 368, time: 0.151, data: 0.000) loss: 0.891 
(epoch: 27, iters: 448, time: 0.150, data: 0.017) loss: 1.547 
(epoch: 27, iters: 528, time: 0.151, data: 0.000) loss: 1.360 
(epoch: 27, iters: 608, time: 0.152, data: 0.000) loss: 1.148 
(epoch: 27, iters: 688, time: 0.152, data: 0.015) loss: 1.388 
(epoch: 27, iters: 768, time: 0.147, data: 0.000) loss: 1.513 
(epoch: 27, iters: 848, time: 0.148, data: 0.005) loss: 1.083 
(epoch: 27, iters: 928, time: 0.150, data: 0.000) loss: 0.979 
(epoch: 27, iters: 1008, time: 0.152, data: 0.016) loss: 1.781 
(epoch: 27, iters: 1088, time: 0.150, data: 0.005) loss: 0.976 
(epoch: 27, iters: 1168, time: 0.151, data: 0.000) loss: 0.929 
(epoch: 27, iters: 1248, time: 0.151, data: 0.005) loss: 1.028 
(epoch: 27, iters: 1328, time: 0.152, data: 0.000) loss: 0.814 
(epoch: 27, iters: 1408, time: 0.152, data: 0.016) loss: 1.214 
(epoch: 27, iters: 1488, time: 0.151, data: 0.014) loss: 0.980 
(epoch: 27, iters: 1568, time: 0.150, data: 0.008) loss: 1.262 
(epoch: 27, iters: 1648, time: 0.150, data: 0.000) loss: 0.738 
(epoch: 27, iters: 1728, time: 0.150, data: 0.020) loss: 1.101 
(epoch: 27, iters: 1808, time: 0.150, data: 0.005) loss: 1.242 
(epoch: 27, iters: 1888, time: 0.149, data: 0.000) loss: 1.608 
(epoch: 27, iters: 1968, time: 0.151, data: 0.008) loss: 1.158 
(epoch: 27, iters: 2048, time: 0.150, data: 0.005) loss: 1.027 
(epoch: 27, iters: 2128, time: 0.151, data: 0.013) loss: 0.678 
(epoch: 27, iters: 2208, time: 0.149, data: 0.000) loss: 1.031 
(epoch: 27, iters: 2288, time: 0.150, data: 0.000) loss: 1.346 
(epoch: 27, iters: 2368, time: 0.151, data: 0.008) loss: 1.018 
(epoch: 27, iters: 2448, time: 0.149, data: 0.000) loss: 1.293 
(epoch: 27, iters: 2528, time: 0.151, data: 0.018) loss: 0.666 
(epoch: 27, iters: 2608, time: 0.149, data: 0.000) loss: 1.295 
(epoch: 27, iters: 2688, time: 0.150, data: 0.023) loss: 0.861 
(epoch: 27, iters: 2768, time: 0.147, data: 0.000) loss: 1.368 
(epoch: 27, iters: 2848, time: 0.152, data: 0.005) loss: 1.030 
(epoch: 27, iters: 2928, time: 0.152, data: 0.005) loss: 1.185 
(epoch: 27, iters: 3008, time: 0.152, data: 0.020) loss: 1.487 
(epoch: 27, iters: 3088, time: 0.151, data: 0.000) loss: 0.625 
(epoch: 27, iters: 3168, time: 0.149, data: 0.000) loss: 0.925 
(epoch: 27, iters: 3248, time: 0.150, data: 0.006) loss: 0.716 
(epoch: 27, iters: 3328, time: 0.151, data: 0.000) loss: 1.071 
(epoch: 27, iters: 3408, time: 0.153, data: 0.000) loss: 1.036 
(epoch: 27, iters: 3488, time: 0.151, data: 0.000) loss: 1.450 
(epoch: 27, iters: 3568, time: 0.151, data: 0.000) loss: 0.657 
(epoch: 27, iters: 3648, time: 0.153, data: 0.000) loss: 1.241 
(epoch: 27, iters: 3728, time: 0.150, data: 0.015) loss: 1.769 
(epoch: 27, iters: 3808, time: 0.152, data: 0.000) loss: 1.572 
(epoch: 27, iters: 3888, time: 0.151, data: 0.023) loss: 1.037 
(epoch: 27, iters: 3968, time: 0.151, data: 0.000) loss: 1.154 
saving the latest model (epoch 27, total_steps 269008)
(epoch: 27, iters: 4048, time: 0.150, data: 0.000) loss: 1.589 
(epoch: 27, iters: 4128, time: 0.151, data: 0.000) loss: 1.360 
(epoch: 27, iters: 4208, time: 0.151, data: 0.005) loss: 0.833 
(epoch: 27, iters: 4288, time: 0.151, data: 0.000) loss: 1.750 
(epoch: 27, iters: 4368, time: 0.151, data: 0.000) loss: 1.285 
(epoch: 27, iters: 4448, time: 0.149, data: 0.000) loss: 0.961 
(epoch: 27, iters: 4528, time: 0.152, data: 0.005) loss: 1.294 
(epoch: 27, iters: 4608, time: 0.147, data: 0.000) loss: 1.526 
(epoch: 27, iters: 4688, time: 0.151, data: 0.000) loss: 1.185 
(epoch: 27, iters: 4768, time: 0.150, data: 0.006) loss: 0.692 
(epoch: 27, iters: 4848, time: 0.153, data: 0.000) loss: 1.061 
(epoch: 27, iters: 4928, time: 0.151, data: 0.005) loss: 1.215 
(epoch: 27, iters: 5008, time: 0.152, data: 0.000) loss: 1.070 
(epoch: 27, iters: 5088, time: 0.153, data: 0.021) loss: 1.503 
(epoch: 27, iters: 5168, time: 0.149, data: 0.016) loss: 1.321 
(epoch: 27, iters: 5248, time: 0.152, data: 0.000) loss: 0.676 
(epoch: 27, iters: 5328, time: 0.148, data: 0.023) loss: 1.319 
(epoch: 27, iters: 5408, time: 0.151, data: 0.000) loss: 0.757 
(epoch: 27, iters: 5488, time: 0.152, data: 0.026) loss: 1.289 
(epoch: 27, iters: 5568, time: 0.151, data: 0.000) loss: 1.412 
(epoch: 27, iters: 5648, time: 0.150, data: 0.008) loss: 1.179 
(epoch: 27, iters: 5728, time: 0.150, data: 0.000) loss: 1.404 
(epoch: 27, iters: 5808, time: 0.148, data: 0.000) loss: 1.044 
(epoch: 27, iters: 5888, time: 0.151, data: 0.000) loss: 0.953 
(epoch: 27, iters: 5968, time: 0.151, data: 0.020) loss: 0.674 
(epoch: 27, iters: 6048, time: 0.149, data: 0.032) loss: 1.661 
(epoch: 27, iters: 6128, time: 0.150, data: 0.000) loss: 1.187 
(epoch: 27, iters: 6208, time: 0.150, data: 0.000) loss: 0.488 
(epoch: 27, iters: 6288, time: 0.151, data: 0.000) loss: 0.618 
(epoch: 27, iters: 6368, time: 0.152, data: 0.005) loss: 0.912 
(epoch: 27, iters: 6448, time: 0.151, data: 0.029) loss: 1.492 
(epoch: 27, iters: 6528, time: 0.152, data: 0.000) loss: 0.783 
(epoch: 27, iters: 6608, time: 0.151, data: 0.010) loss: 1.166 
(epoch: 27, iters: 6688, time: 0.151, data: 0.000) loss: 1.407 
(epoch: 27, iters: 6768, time: 0.152, data: 0.031) loss: 0.950 
(epoch: 27, iters: 6848, time: 0.151, data: 0.000) loss: 1.305 
(epoch: 27, iters: 6928, time: 0.151, data: 0.000) loss: 1.633 
(epoch: 27, iters: 7008, time: 0.152, data: 0.000) loss: 1.071 
(epoch: 27, iters: 7088, time: 0.152, data: 0.000) loss: 1.579 
(epoch: 27, iters: 7168, time: 0.152, data: 0.000) loss: 1.643 
(epoch: 27, iters: 7248, time: 0.152, data: 0.010) loss: 0.796 
(epoch: 27, iters: 7328, time: 0.151, data: 0.000) loss: 1.833 
(epoch: 27, iters: 7408, time: 0.153, data: 0.024) loss: 1.126 
(epoch: 27, iters: 7488, time: 0.153, data: 0.000) loss: 0.770 
(epoch: 27, iters: 7568, time: 0.151, data: 0.000) loss: 1.014 
(epoch: 27, iters: 7648, time: 0.152, data: 0.000) loss: 1.247 
(epoch: 27, iters: 7728, time: 0.151, data: 0.010) loss: 1.281 
(epoch: 27, iters: 7808, time: 0.151, data: 0.000) loss: 1.109 
(epoch: 27, iters: 7888, time: 0.152, data: 0.000) loss: 0.965 
(epoch: 27, iters: 7968, time: 0.149, data: 0.000) loss: 0.700 
saving the latest model (epoch 27, total_steps 273008)
(epoch: 27, iters: 8048, time: 0.152, data: 0.005) loss: 1.125 
(epoch: 27, iters: 8128, time: 0.150, data: 0.006) loss: 1.381 
(epoch: 27, iters: 8208, time: 0.151, data: 0.008) loss: 0.833 
(epoch: 27, iters: 8288, time: 0.150, data: 0.000) loss: 1.667 
(epoch: 27, iters: 8368, time: 0.150, data: 0.000) loss: 1.464 
(epoch: 27, iters: 8448, time: 0.152, data: 0.000) loss: 1.159 
(epoch: 27, iters: 8528, time: 0.151, data: 0.005) loss: 1.054 
(epoch: 27, iters: 8608, time: 0.153, data: 0.000) loss: 1.397 
(epoch: 27, iters: 8688, time: 0.150, data: 0.005) loss: 1.557 
(epoch: 27, iters: 8768, time: 0.150, data: 0.014) loss: 0.634 
(epoch: 27, iters: 8848, time: 0.149, data: 0.000) loss: 1.867 
(epoch: 27, iters: 8928, time: 0.151, data: 0.028) loss: 1.406 
(epoch: 27, iters: 9008, time: 0.152, data: 0.021) loss: 1.417 
(epoch: 27, iters: 9088, time: 0.152, data: 0.000) loss: 1.042 
(epoch: 27, iters: 9168, time: 0.151, data: 0.009) loss: 1.453 
(epoch: 27, iters: 9248, time: 0.152, data: 0.000) loss: 1.349 
(epoch: 27, iters: 9328, time: 0.152, data: 0.018) loss: 0.894 
(epoch: 27, iters: 9408, time: 0.152, data: 0.006) loss: 2.474 
(epoch: 27, iters: 9488, time: 0.151, data: 0.000) loss: 0.932 
(epoch: 27, iters: 9568, time: 0.151, data: 0.000) loss: 0.987 
(epoch: 27, iters: 9648, time: 0.150, data: 0.018) loss: 1.628 
(epoch: 27, iters: 9728, time: 0.151, data: 0.000) loss: 1.635 
(epoch: 27, iters: 9808, time: 0.149, data: 0.010) loss: 1.248 
(epoch: 27, iters: 9888, time: 0.150, data: 0.000) loss: 1.367 
(epoch: 27, iters: 9968, time: 0.150, data: 0.000) loss: 0.671 
(epoch: 27, iters: 10048, time: 0.150, data: 0.005) loss: 1.293 
(epoch: 27, iters: 10128, time: 0.149, data: 0.013) loss: 1.523 
saving the model at the end of epoch 27, iters 275184
End of epoch 27 / 200 	 Time Taken: 1538 sec
learning rate = 0.0002000
(epoch: 28, iters: 16, time: 0.172, data: 0.000) loss: 0.820 
saving the latest model (epoch 28, total_steps 275200)
(epoch: 28, iters: 96, time: 0.152, data: 0.000) loss: 1.528 
(epoch: 28, iters: 176, time: 0.152, data: 0.000) loss: 1.394 
(epoch: 28, iters: 256, time: 0.148, data: 0.005) loss: 1.340 
(epoch: 28, iters: 336, time: 0.152, data: 0.005) loss: 1.522 
(epoch: 28, iters: 416, time: 0.153, data: 0.000) loss: 1.295 
(epoch: 28, iters: 496, time: 0.149, data: 0.000) loss: 0.574 
(epoch: 28, iters: 576, time: 0.151, data: 0.008) loss: 1.044 
(epoch: 28, iters: 656, time: 0.150, data: 0.000) loss: 1.326 
(epoch: 28, iters: 736, time: 0.148, data: 0.013) loss: 1.705 
(epoch: 28, iters: 816, time: 0.150, data: 0.010) loss: 0.518 
(epoch: 28, iters: 896, time: 0.151, data: 0.000) loss: 0.713 
(epoch: 28, iters: 976, time: 0.147, data: 0.000) loss: 0.940 
(epoch: 28, iters: 1056, time: 0.150, data: 0.005) loss: 1.413 
(epoch: 28, iters: 1136, time: 0.148, data: 0.000) loss: 1.365 
(epoch: 28, iters: 1216, time: 0.149, data: 0.000) loss: 1.227 
(epoch: 28, iters: 1296, time: 0.152, data: 0.000) loss: 1.301 
(epoch: 28, iters: 1376, time: 0.151, data: 0.014) loss: 1.739 
(epoch: 28, iters: 1456, time: 0.147, data: 0.000) loss: 0.697 
(epoch: 28, iters: 1536, time: 0.154, data: 0.005) loss: 1.136 
(epoch: 28, iters: 1616, time: 0.149, data: 0.000) loss: 0.774 
(epoch: 28, iters: 1696, time: 0.155, data: 0.000) loss: 1.153 
(epoch: 28, iters: 1776, time: 0.151, data: 0.005) loss: 1.009 
(epoch: 28, iters: 1856, time: 0.148, data: 0.000) loss: 0.939 
(epoch: 28, iters: 1936, time: 0.151, data: 0.005) loss: 1.199 
(epoch: 28, iters: 2016, time: 0.150, data: 0.000) loss: 1.210 
(epoch: 28, iters: 2096, time: 0.149, data: 0.000) loss: 0.614 
(epoch: 28, iters: 2176, time: 0.150, data: 0.005) loss: 1.180 
(epoch: 28, iters: 2256, time: 0.151, data: 0.000) loss: 1.594 
(epoch: 28, iters: 2336, time: 0.149, data: 0.005) loss: 1.185 
(epoch: 28, iters: 2416, time: 0.151, data: 0.000) loss: 2.075 
(epoch: 28, iters: 2496, time: 0.148, data: 0.005) loss: 1.329 
(epoch: 28, iters: 2576, time: 0.149, data: 0.000) loss: 1.134 
(epoch: 28, iters: 2656, time: 0.152, data: 0.042) loss: 1.371 
(epoch: 28, iters: 2736, time: 0.150, data: 0.000) loss: 0.989 
(epoch: 28, iters: 2816, time: 0.150, data: 0.000) loss: 1.355 
(epoch: 28, iters: 2896, time: 0.152, data: 0.000) loss: 0.917 
(epoch: 28, iters: 2976, time: 0.147, data: 0.000) loss: 1.270 
(epoch: 28, iters: 3056, time: 0.148, data: 0.008) loss: 0.748 
(epoch: 28, iters: 3136, time: 0.152, data: 0.000) loss: 1.098 
(epoch: 28, iters: 3216, time: 0.149, data: 0.032) loss: 1.687 
(epoch: 28, iters: 3296, time: 0.152, data: 0.000) loss: 1.055 
(epoch: 28, iters: 3376, time: 0.151, data: 0.000) loss: 1.051 
(epoch: 28, iters: 3456, time: 0.152, data: 0.000) loss: 1.013 
(epoch: 28, iters: 3536, time: 0.149, data: 0.006) loss: 1.635 
(epoch: 28, iters: 3616, time: 0.151, data: 0.000) loss: 1.081 
(epoch: 28, iters: 3696, time: 0.153, data: 0.015) loss: 0.750 
(epoch: 28, iters: 3776, time: 0.149, data: 0.010) loss: 1.178 
(epoch: 28, iters: 3856, time: 0.151, data: 0.000) loss: 1.161 
(epoch: 28, iters: 3936, time: 0.151, data: 0.000) loss: 1.044 
(epoch: 28, iters: 4016, time: 0.151, data: 0.000) loss: 1.738 
saving the latest model (epoch 28, total_steps 279200)
(epoch: 28, iters: 4096, time: 0.151, data: 0.000) loss: 1.071 
(epoch: 28, iters: 4176, time: 0.148, data: 0.000) loss: 0.982 
(epoch: 28, iters: 4256, time: 0.149, data: 0.017) loss: 1.239 
(epoch: 28, iters: 4336, time: 0.150, data: 0.000) loss: 1.489 
(epoch: 28, iters: 4416, time: 0.150, data: 0.000) loss: 0.720 
(epoch: 28, iters: 4496, time: 0.150, data: 0.000) loss: 2.251 
(epoch: 28, iters: 4576, time: 0.152, data: 0.005) loss: 1.250 
(epoch: 28, iters: 4656, time: 0.152, data: 0.018) loss: 1.432 
(epoch: 28, iters: 4736, time: 0.152, data: 0.000) loss: 1.305 
(epoch: 28, iters: 4816, time: 0.153, data: 0.024) loss: 1.538 
(epoch: 28, iters: 4896, time: 0.153, data: 0.000) loss: 0.830 
(epoch: 28, iters: 4976, time: 0.151, data: 0.000) loss: 0.802 
(epoch: 28, iters: 5056, time: 0.150, data: 0.000) loss: 0.890 
(epoch: 28, iters: 5136, time: 0.153, data: 0.024) loss: 0.870 
(epoch: 28, iters: 5216, time: 0.153, data: 0.005) loss: 0.931 
(epoch: 28, iters: 5296, time: 0.152, data: 0.011) loss: 0.965 
(epoch: 28, iters: 5376, time: 0.152, data: 0.005) loss: 1.760 
(epoch: 28, iters: 5456, time: 0.154, data: 0.005) loss: 0.488 
(epoch: 28, iters: 5536, time: 0.152, data: 0.005) loss: 0.869 
(epoch: 28, iters: 5616, time: 0.152, data: 0.000) loss: 1.049 
(epoch: 28, iters: 5696, time: 0.151, data: 0.000) loss: 0.885 
(epoch: 28, iters: 5776, time: 0.152, data: 0.000) loss: 0.799 
(epoch: 28, iters: 5856, time: 0.153, data: 0.000) loss: 1.005 
(epoch: 28, iters: 5936, time: 0.152, data: 0.009) loss: 0.939 
(epoch: 28, iters: 6016, time: 0.150, data: 0.000) loss: 1.251 
(epoch: 28, iters: 6096, time: 0.154, data: 0.000) loss: 1.403 
(epoch: 28, iters: 6176, time: 0.150, data: 0.009) loss: 0.806 
(epoch: 28, iters: 6256, time: 0.149, data: 0.000) loss: 0.830 
(epoch: 28, iters: 6336, time: 0.150, data: 0.000) loss: 1.145 
(epoch: 28, iters: 6416, time: 0.152, data: 0.008) loss: 0.608 
(epoch: 28, iters: 6496, time: 0.151, data: 0.000) loss: 0.972 
(epoch: 28, iters: 6576, time: 0.151, data: 0.011) loss: 0.853 
(epoch: 28, iters: 6656, time: 0.152, data: 0.000) loss: 1.468 
(epoch: 28, iters: 6736, time: 0.152, data: 0.000) loss: 1.248 
(epoch: 28, iters: 6816, time: 0.149, data: 0.000) loss: 0.629 
(epoch: 28, iters: 6896, time: 0.151, data: 0.000) loss: 1.539 
(epoch: 28, iters: 6976, time: 0.148, data: 0.008) loss: 1.605 
(epoch: 28, iters: 7056, time: 0.150, data: 0.041) loss: 1.605 
(epoch: 28, iters: 7136, time: 0.152, data: 0.000) loss: 1.874 
(epoch: 28, iters: 7216, time: 0.151, data: 0.005) loss: 1.707 
(epoch: 28, iters: 7296, time: 0.151, data: 0.014) loss: 0.694 
(epoch: 28, iters: 7376, time: 0.153, data: 0.013) loss: 1.257 
(epoch: 28, iters: 7456, time: 0.151, data: 0.000) loss: 1.333 
(epoch: 28, iters: 7536, time: 0.152, data: 0.005) loss: 1.259 
(epoch: 28, iters: 7616, time: 0.149, data: 0.000) loss: 1.295 
(epoch: 28, iters: 7696, time: 0.151, data: 0.005) loss: 0.995 
(epoch: 28, iters: 7776, time: 0.151, data: 0.009) loss: 0.655 
(epoch: 28, iters: 7856, time: 0.150, data: 0.008) loss: 1.054 
(epoch: 28, iters: 7936, time: 0.153, data: 0.005) loss: 1.332 
(epoch: 28, iters: 8016, time: 0.148, data: 0.009) loss: 1.701 
saving the latest model (epoch 28, total_steps 283200)
(epoch: 28, iters: 8096, time: 0.150, data: 0.017) loss: 1.165 
(epoch: 28, iters: 8176, time: 0.152, data: 0.000) loss: 1.824 
(epoch: 28, iters: 8256, time: 0.151, data: 0.019) loss: 0.778 
(epoch: 28, iters: 8336, time: 0.149, data: 0.000) loss: 0.924 
(epoch: 28, iters: 8416, time: 0.151, data: 0.005) loss: 1.355 
(epoch: 28, iters: 8496, time: 0.152, data: 0.000) loss: 1.371 
(epoch: 28, iters: 8576, time: 0.149, data: 0.013) loss: 0.860 
(epoch: 28, iters: 8656, time: 0.152, data: 0.005) loss: 1.325 
(epoch: 28, iters: 8736, time: 0.153, data: 0.000) loss: 1.939 
(epoch: 28, iters: 8816, time: 0.149, data: 0.016) loss: 1.249 
(epoch: 28, iters: 8896, time: 0.150, data: 0.000) loss: 1.043 
(epoch: 28, iters: 8976, time: 0.151, data: 0.033) loss: 0.489 
(epoch: 28, iters: 9056, time: 0.151, data: 0.000) loss: 1.429 
(epoch: 28, iters: 9136, time: 0.149, data: 0.042) loss: 1.008 
(epoch: 28, iters: 9216, time: 0.153, data: 0.000) loss: 1.552 
(epoch: 28, iters: 9296, time: 0.153, data: 0.037) loss: 1.093 
(epoch: 28, iters: 9376, time: 0.153, data: 0.000) loss: 0.783 
(epoch: 28, iters: 9456, time: 0.152, data: 0.014) loss: 0.794 
(epoch: 28, iters: 9536, time: 0.152, data: 0.016) loss: 1.262 
(epoch: 28, iters: 9616, time: 0.148, data: 0.000) loss: 1.315 
(epoch: 28, iters: 9696, time: 0.152, data: 0.008) loss: 1.287 
(epoch: 28, iters: 9776, time: 0.150, data: 0.009) loss: 0.913 
(epoch: 28, iters: 9856, time: 0.149, data: 0.000) loss: 1.398 
(epoch: 28, iters: 9936, time: 0.151, data: 0.000) loss: 0.577 
(epoch: 28, iters: 10016, time: 0.153, data: 0.000) loss: 0.747 
(epoch: 28, iters: 10096, time: 0.152, data: 0.000) loss: 1.329 
(epoch: 28, iters: 10176, time: 0.150, data: 0.000) loss: 0.927 
saving the model at the end of epoch 28, iters 285376
End of epoch 28 / 200 	 Time Taken: 1541 sec
learning rate = 0.0002000
saving the latest model (epoch 29, total_steps 285392)
(epoch: 29, iters: 64, time: 0.153, data: 0.003) loss: 1.129 
(epoch: 29, iters: 144, time: 0.153, data: 0.022) loss: 1.351 
(epoch: 29, iters: 224, time: 0.151, data: 0.000) loss: 1.387 
(epoch: 29, iters: 304, time: 0.152, data: 0.014) loss: 0.521 
(epoch: 29, iters: 384, time: 0.152, data: 0.000) loss: 0.455 
(epoch: 29, iters: 464, time: 0.151, data: 0.000) loss: 0.931 
(epoch: 29, iters: 544, time: 0.152, data: 0.000) loss: 1.457 
(epoch: 29, iters: 624, time: 0.152, data: 0.024) loss: 0.322 
(epoch: 29, iters: 704, time: 0.151, data: 0.000) loss: 1.054 
(epoch: 29, iters: 784, time: 0.154, data: 0.012) loss: 0.903 
(epoch: 29, iters: 864, time: 0.153, data: 0.005) loss: 1.031 
(epoch: 29, iters: 944, time: 0.151, data: 0.000) loss: 0.602 
(epoch: 29, iters: 1024, time: 0.151, data: 0.010) loss: 1.075 
(epoch: 29, iters: 1104, time: 0.153, data: 0.000) loss: 0.749 
(epoch: 29, iters: 1184, time: 0.153, data: 0.000) loss: 1.237 
(epoch: 29, iters: 1264, time: 0.150, data: 0.000) loss: 0.984 
(epoch: 29, iters: 1344, time: 0.150, data: 0.000) loss: 1.287 
(epoch: 29, iters: 1424, time: 0.153, data: 0.000) loss: 0.932 
(epoch: 29, iters: 1504, time: 0.150, data: 0.027) loss: 1.363 
(epoch: 29, iters: 1584, time: 0.151, data: 0.013) loss: 0.971 
(epoch: 29, iters: 1664, time: 0.153, data: 0.000) loss: 0.972 
(epoch: 29, iters: 1744, time: 0.153, data: 0.000) loss: 0.993 
(epoch: 29, iters: 1824, time: 0.149, data: 0.018) loss: 0.636 
(epoch: 29, iters: 1904, time: 0.151, data: 0.013) loss: 1.601 
(epoch: 29, iters: 1984, time: 0.151, data: 0.000) loss: 0.740 
(epoch: 29, iters: 2064, time: 0.150, data: 0.023) loss: 0.869 
(epoch: 29, iters: 2144, time: 0.154, data: 0.000) loss: 0.892 
(epoch: 29, iters: 2224, time: 0.153, data: 0.006) loss: 1.084 
(epoch: 29, iters: 2304, time: 0.151, data: 0.005) loss: 1.125 
(epoch: 29, iters: 2384, time: 0.153, data: 0.000) loss: 0.890 
(epoch: 29, iters: 2464, time: 0.148, data: 0.005) loss: 1.224 
(epoch: 29, iters: 2544, time: 0.152, data: 0.000) loss: 1.700 
(epoch: 29, iters: 2624, time: 0.151, data: 0.000) loss: 0.913 
(epoch: 29, iters: 2704, time: 0.152, data: 0.000) loss: 1.227 
(epoch: 29, iters: 2784, time: 0.150, data: 0.000) loss: 1.021 
(epoch: 29, iters: 2864, time: 0.151, data: 0.000) loss: 1.281 
(epoch: 29, iters: 2944, time: 0.153, data: 0.020) loss: 0.906 
(epoch: 29, iters: 3024, time: 0.149, data: 0.008) loss: 0.605 
(epoch: 29, iters: 3104, time: 0.148, data: 0.000) loss: 1.438 
(epoch: 29, iters: 3184, time: 0.152, data: 0.025) loss: 1.166 
(epoch: 29, iters: 3264, time: 0.150, data: 0.000) loss: 0.831 
(epoch: 29, iters: 3344, time: 0.149, data: 0.000) loss: 0.650 
(epoch: 29, iters: 3424, time: 0.151, data: 0.010) loss: 1.060 
(epoch: 29, iters: 3504, time: 0.152, data: 0.005) loss: 0.531 
(epoch: 29, iters: 3584, time: 0.151, data: 0.000) loss: 0.982 
(epoch: 29, iters: 3664, time: 0.148, data: 0.015) loss: 1.416 
(epoch: 29, iters: 3744, time: 0.151, data: 0.005) loss: 1.660 
(epoch: 29, iters: 3824, time: 0.151, data: 0.006) loss: 1.734 
(epoch: 29, iters: 3904, time: 0.151, data: 0.000) loss: 1.105 
(epoch: 29, iters: 3984, time: 0.153, data: 0.014) loss: 1.419 
saving the latest model (epoch 29, total_steps 289392)
(epoch: 29, iters: 4064, time: 0.154, data: 0.012) loss: 0.653 
(epoch: 29, iters: 4144, time: 0.150, data: 0.000) loss: 1.185 
(epoch: 29, iters: 4224, time: 0.152, data: 0.000) loss: 1.185 
(epoch: 29, iters: 4304, time: 0.150, data: 0.016) loss: 1.242 
(epoch: 29, iters: 4384, time: 0.151, data: 0.000) loss: 1.419 
(epoch: 29, iters: 4464, time: 0.152, data: 0.032) loss: 1.025 
(epoch: 29, iters: 4544, time: 0.150, data: 0.000) loss: 1.235 
(epoch: 29, iters: 4624, time: 0.149, data: 0.000) loss: 1.108 
(epoch: 29, iters: 4704, time: 0.151, data: 0.000) loss: 1.277 
(epoch: 29, iters: 4784, time: 0.152, data: 0.000) loss: 1.314 
(epoch: 29, iters: 4864, time: 0.152, data: 0.000) loss: 1.071 
(epoch: 29, iters: 4944, time: 0.153, data: 0.000) loss: 1.493 
(epoch: 29, iters: 5024, time: 0.153, data: 0.005) loss: 1.423 
(epoch: 29, iters: 5104, time: 0.153, data: 0.005) loss: 1.153 
(epoch: 29, iters: 5184, time: 0.152, data: 0.000) loss: 0.733 
(epoch: 29, iters: 5264, time: 0.152, data: 0.014) loss: 0.781 
(epoch: 29, iters: 5344, time: 0.151, data: 0.005) loss: 0.907 
(epoch: 29, iters: 5424, time: 0.152, data: 0.000) loss: 1.344 
(epoch: 29, iters: 5504, time: 0.150, data: 0.024) loss: 1.429 
(epoch: 29, iters: 5584, time: 0.149, data: 0.000) loss: 1.235 
(epoch: 29, iters: 5664, time: 0.152, data: 0.022) loss: 1.464 
(epoch: 29, iters: 5744, time: 0.154, data: 0.011) loss: 1.147 
(epoch: 29, iters: 5824, time: 0.150, data: 0.000) loss: 0.817 
(epoch: 29, iters: 5904, time: 0.152, data: 0.026) loss: 1.281 
(epoch: 29, iters: 5984, time: 0.151, data: 0.000) loss: 1.318 
(epoch: 29, iters: 6064, time: 0.151, data: 0.005) loss: 1.290 
(epoch: 29, iters: 6144, time: 0.153, data: 0.000) loss: 1.318 
(epoch: 29, iters: 6224, time: 0.150, data: 0.009) loss: 0.772 
(epoch: 29, iters: 6304, time: 0.151, data: 0.000) loss: 0.873 
(epoch: 29, iters: 6384, time: 0.152, data: 0.008) loss: 0.935 
(epoch: 29, iters: 6464, time: 0.150, data: 0.005) loss: 1.323 
(epoch: 29, iters: 6544, time: 0.150, data: 0.000) loss: 1.238 
(epoch: 29, iters: 6624, time: 0.151, data: 0.033) loss: 1.310 
(epoch: 29, iters: 6704, time: 0.152, data: 0.000) loss: 1.336 
(epoch: 29, iters: 6784, time: 0.151, data: 0.000) loss: 1.143 
(epoch: 29, iters: 6864, time: 0.152, data: 0.000) loss: 1.043 
(epoch: 29, iters: 6944, time: 0.153, data: 0.031) loss: 1.280 
(epoch: 29, iters: 7024, time: 0.149, data: 0.000) loss: 1.165 
(epoch: 29, iters: 7104, time: 0.149, data: 0.017) loss: 0.921 
(epoch: 29, iters: 7184, time: 0.151, data: 0.005) loss: 1.369 
(epoch: 29, iters: 7264, time: 0.152, data: 0.000) loss: 1.707 
(epoch: 29, iters: 7344, time: 0.153, data: 0.013) loss: 0.779 
(epoch: 29, iters: 7424, time: 0.152, data: 0.000) loss: 0.946 
(epoch: 29, iters: 7504, time: 0.151, data: 0.005) loss: 1.617 
(epoch: 29, iters: 7584, time: 0.150, data: 0.000) loss: 0.736 
(epoch: 29, iters: 7664, time: 0.153, data: 0.005) loss: 1.573 
(epoch: 29, iters: 7744, time: 0.153, data: 0.000) loss: 1.629 
(epoch: 29, iters: 7824, time: 0.150, data: 0.005) loss: 0.919 
(epoch: 29, iters: 7904, time: 0.152, data: 0.000) loss: 0.828 
(epoch: 29, iters: 7984, time: 0.149, data: 0.005) loss: 0.797 
saving the latest model (epoch 29, total_steps 293392)
(epoch: 29, iters: 8064, time: 0.151, data: 0.005) loss: 1.193 
(epoch: 29, iters: 8144, time: 0.152, data: 0.005) loss: 0.692 
(epoch: 29, iters: 8224, time: 0.153, data: 0.000) loss: 0.816 
(epoch: 29, iters: 8304, time: 0.152, data: 0.022) loss: 2.107 
(epoch: 29, iters: 8384, time: 0.150, data: 0.000) loss: 1.939 
(epoch: 29, iters: 8464, time: 0.148, data: 0.000) loss: 1.820 
(epoch: 29, iters: 8544, time: 0.152, data: 0.000) loss: 1.300 
(epoch: 29, iters: 8624, time: 0.149, data: 0.013) loss: 1.445 
(epoch: 29, iters: 8704, time: 0.151, data: 0.000) loss: 1.133 
(epoch: 29, iters: 8784, time: 0.150, data: 0.000) loss: 1.502 
(epoch: 29, iters: 8864, time: 0.150, data: 0.009) loss: 1.456 
(epoch: 29, iters: 8944, time: 0.150, data: 0.000) loss: 1.186 
(epoch: 29, iters: 9024, time: 0.150, data: 0.025) loss: 0.833 
(epoch: 29, iters: 9104, time: 0.152, data: 0.005) loss: 1.614 
(epoch: 29, iters: 9184, time: 0.149, data: 0.000) loss: 0.931 
(epoch: 29, iters: 9264, time: 0.151, data: 0.010) loss: 0.588 
(epoch: 29, iters: 9344, time: 0.152, data: 0.034) loss: 1.314 
(epoch: 29, iters: 9424, time: 0.153, data: 0.000) loss: 0.853 
(epoch: 29, iters: 9504, time: 0.151, data: 0.000) loss: 0.941 
(epoch: 29, iters: 9584, time: 0.150, data: 0.000) loss: 1.366 
(epoch: 29, iters: 9664, time: 0.150, data: 0.000) loss: 0.657 
(epoch: 29, iters: 9744, time: 0.148, data: 0.014) loss: 0.968 
(epoch: 29, iters: 9824, time: 0.152, data: 0.031) loss: 1.374 
(epoch: 29, iters: 9904, time: 0.153, data: 0.000) loss: 1.233 
(epoch: 29, iters: 9984, time: 0.151, data: 0.000) loss: 1.465 
(epoch: 29, iters: 10064, time: 0.152, data: 0.000) loss: 1.595 
(epoch: 29, iters: 10144, time: 0.151, data: 0.005) loss: 0.869 
saving the model at the end of epoch 29, iters 295568
End of epoch 29 / 200 	 Time Taken: 1543 sec
learning rate = 0.0002000
saving the latest model (epoch 30, total_steps 295584)
(epoch: 30, iters: 32, time: 0.156, data: 0.000) loss: 1.139 
(epoch: 30, iters: 112, time: 0.150, data: 0.000) loss: 1.520 
(epoch: 30, iters: 192, time: 0.153, data: 0.000) loss: 0.959 
(epoch: 30, iters: 272, time: 0.149, data: 0.005) loss: 1.025 
(epoch: 30, iters: 352, time: 0.149, data: 0.000) loss: 0.891 
(epoch: 30, iters: 432, time: 0.150, data: 0.008) loss: 0.740 
(epoch: 30, iters: 512, time: 0.147, data: 0.000) loss: 1.136 
(epoch: 30, iters: 592, time: 0.150, data: 0.026) loss: 0.531 
(epoch: 30, iters: 672, time: 0.147, data: 0.000) loss: 1.280 
(epoch: 30, iters: 752, time: 0.148, data: 0.015) loss: 1.254 
(epoch: 30, iters: 832, time: 0.147, data: 0.000) loss: 0.775 
(epoch: 30, iters: 912, time: 0.149, data: 0.025) loss: 1.250 
(epoch: 30, iters: 992, time: 0.149, data: 0.005) loss: 1.224 
(epoch: 30, iters: 1072, time: 0.147, data: 0.008) loss: 1.045 
(epoch: 30, iters: 1152, time: 0.150, data: 0.013) loss: 0.771 
(epoch: 30, iters: 1232, time: 0.148, data: 0.000) loss: 0.684 
(epoch: 30, iters: 1312, time: 0.150, data: 0.011) loss: 1.341 
(epoch: 30, iters: 1392, time: 0.152, data: 0.000) loss: 0.628 
(epoch: 30, iters: 1472, time: 0.150, data: 0.000) loss: 1.695 
(epoch: 30, iters: 1552, time: 0.150, data: 0.032) loss: 1.193 
(epoch: 30, iters: 1632, time: 0.151, data: 0.000) loss: 0.868 
(epoch: 30, iters: 1712, time: 0.151, data: 0.000) loss: 1.385 
(epoch: 30, iters: 1792, time: 0.152, data: 0.000) loss: 1.063 
(epoch: 30, iters: 1872, time: 0.149, data: 0.006) loss: 1.182 
(epoch: 30, iters: 1952, time: 0.152, data: 0.025) loss: 2.103 
(epoch: 30, iters: 2032, time: 0.149, data: 0.000) loss: 0.817 
(epoch: 30, iters: 2112, time: 0.151, data: 0.000) loss: 1.016 
(epoch: 30, iters: 2192, time: 0.150, data: 0.006) loss: 1.718 
(epoch: 30, iters: 2272, time: 0.147, data: 0.023) loss: 1.284 
(epoch: 30, iters: 2352, time: 0.149, data: 0.000) loss: 1.002 
(epoch: 30, iters: 2432, time: 0.152, data: 0.000) loss: 1.484 
(epoch: 30, iters: 2512, time: 0.151, data: 0.000) loss: 1.444 
(epoch: 30, iters: 2592, time: 0.149, data: 0.000) loss: 1.573 
(epoch: 30, iters: 2672, time: 0.152, data: 0.000) loss: 0.732 
(epoch: 30, iters: 2752, time: 0.150, data: 0.000) loss: 1.477 
(epoch: 30, iters: 2832, time: 0.149, data: 0.020) loss: 1.240 
(epoch: 30, iters: 2912, time: 0.151, data: 0.005) loss: 0.851 
(epoch: 30, iters: 2992, time: 0.150, data: 0.000) loss: 0.874 
(epoch: 30, iters: 3072, time: 0.150, data: 0.013) loss: 0.855 
(epoch: 30, iters: 3152, time: 0.148, data: 0.015) loss: 0.855 
(epoch: 30, iters: 3232, time: 0.148, data: 0.000) loss: 1.095 
(epoch: 30, iters: 3312, time: 0.150, data: 0.000) loss: 1.241 
(epoch: 30, iters: 3392, time: 0.151, data: 0.030) loss: 1.254 
(epoch: 30, iters: 3472, time: 0.150, data: 0.023) loss: 1.134 
(epoch: 30, iters: 3552, time: 0.149, data: 0.032) loss: 0.862 
(epoch: 30, iters: 3632, time: 0.151, data: 0.000) loss: 1.211 
(epoch: 30, iters: 3712, time: 0.150, data: 0.000) loss: 0.910 
(epoch: 30, iters: 3792, time: 0.149, data: 0.000) loss: 0.893 
(epoch: 30, iters: 3872, time: 0.150, data: 0.000) loss: 1.016 
(epoch: 30, iters: 3952, time: 0.151, data: 0.018) loss: 0.971 
saving the latest model (epoch 30, total_steps 299584)
(epoch: 30, iters: 4032, time: 0.150, data: 0.000) loss: 0.941 
(epoch: 30, iters: 4112, time: 0.151, data: 0.010) loss: 1.346 
(epoch: 30, iters: 4192, time: 0.147, data: 0.000) loss: 0.842 
(epoch: 30, iters: 4272, time: 0.149, data: 0.000) loss: 1.348 
(epoch: 30, iters: 4352, time: 0.150, data: 0.009) loss: 0.648 
(epoch: 30, iters: 4432, time: 0.149, data: 0.000) loss: 1.298 
(epoch: 30, iters: 4512, time: 0.149, data: 0.005) loss: 1.385 
(epoch: 30, iters: 4592, time: 0.150, data: 0.000) loss: 0.787 
(epoch: 30, iters: 4672, time: 0.150, data: 0.000) loss: 1.082 
(epoch: 30, iters: 4752, time: 0.150, data: 0.006) loss: 0.792 
(epoch: 30, iters: 4832, time: 0.151, data: 0.000) loss: 1.339 
(epoch: 30, iters: 4912, time: 0.150, data: 0.021) loss: 1.191 
(epoch: 30, iters: 4992, time: 0.150, data: 0.007) loss: 1.741 
(epoch: 30, iters: 5072, time: 0.150, data: 0.000) loss: 0.474 
(epoch: 30, iters: 5152, time: 0.150, data: 0.006) loss: 0.619 
(epoch: 30, iters: 5232, time: 0.151, data: 0.006) loss: 0.835 
(epoch: 30, iters: 5312, time: 0.150, data: 0.011) loss: 0.799 
(epoch: 30, iters: 5392, time: 0.153, data: 0.000) loss: 0.911 
(epoch: 30, iters: 5472, time: 0.154, data: 0.000) loss: 1.108 
(epoch: 30, iters: 5552, time: 0.148, data: 0.013) loss: 0.749 
(epoch: 30, iters: 5632, time: 0.150, data: 0.000) loss: 0.999 
(epoch: 30, iters: 5712, time: 0.151, data: 0.000) loss: 1.295 
(epoch: 30, iters: 5792, time: 0.150, data: 0.005) loss: 1.114 
(epoch: 30, iters: 5872, time: 0.149, data: 0.025) loss: 1.518 
(epoch: 30, iters: 5952, time: 0.150, data: 0.000) loss: 1.697 
(epoch: 30, iters: 6032, time: 0.152, data: 0.008) loss: 1.601 
(epoch: 30, iters: 6112, time: 0.150, data: 0.000) loss: 0.627 
(epoch: 30, iters: 6192, time: 0.150, data: 0.033) loss: 1.013 
(epoch: 30, iters: 6272, time: 0.150, data: 0.000) loss: 1.498 
(epoch: 30, iters: 6352, time: 0.150, data: 0.025) loss: 1.042 
(epoch: 30, iters: 6432, time: 0.148, data: 0.000) loss: 1.394 
(epoch: 30, iters: 6512, time: 0.150, data: 0.024) loss: 1.080 
(epoch: 30, iters: 6592, time: 0.148, data: 0.000) loss: 1.183 
(epoch: 30, iters: 6672, time: 0.150, data: 0.000) loss: 1.386 
(epoch: 30, iters: 6752, time: 0.147, data: 0.005) loss: 1.290 
(epoch: 30, iters: 6832, time: 0.151, data: 0.014) loss: 0.971 
(epoch: 30, iters: 6912, time: 0.151, data: 0.000) loss: 0.482 
(epoch: 30, iters: 6992, time: 0.150, data: 0.006) loss: 1.205 
(epoch: 30, iters: 7072, time: 0.151, data: 0.000) loss: 0.785 
(epoch: 30, iters: 7152, time: 0.149, data: 0.018) loss: 0.801 
(epoch: 30, iters: 7232, time: 0.152, data: 0.000) loss: 0.900 
(epoch: 30, iters: 7312, time: 0.149, data: 0.034) loss: 0.801 
(epoch: 30, iters: 7392, time: 0.152, data: 0.000) loss: 1.273 
(epoch: 30, iters: 7472, time: 0.151, data: 0.017) loss: 1.147 
(epoch: 30, iters: 7552, time: 0.150, data: 0.000) loss: 1.310 
(epoch: 30, iters: 7632, time: 0.151, data: 0.023) loss: 1.377 
(epoch: 30, iters: 7712, time: 0.151, data: 0.000) loss: 1.065 
(epoch: 30, iters: 7792, time: 0.151, data: 0.009) loss: 1.030 
(epoch: 30, iters: 7872, time: 0.152, data: 0.000) loss: 1.104 
(epoch: 30, iters: 7952, time: 0.150, data: 0.025) loss: 1.215 
saving the latest model (epoch 30, total_steps 303584)
(epoch: 30, iters: 8032, time: 0.150, data: 0.000) loss: 0.916 
(epoch: 30, iters: 8112, time: 0.150, data: 0.000) loss: 0.799 
(epoch: 30, iters: 8192, time: 0.149, data: 0.016) loss: 0.965 
(epoch: 30, iters: 8272, time: 0.148, data: 0.014) loss: 1.058 
(epoch: 30, iters: 8352, time: 0.148, data: 0.020) loss: 1.279 
(epoch: 30, iters: 8432, time: 0.148, data: 0.024) loss: 1.159 
(epoch: 30, iters: 8512, time: 0.150, data: 0.000) loss: 1.026 
(epoch: 30, iters: 8592, time: 0.149, data: 0.000) loss: 0.977 
(epoch: 30, iters: 8672, time: 0.149, data: 0.000) loss: 0.806 
(epoch: 30, iters: 8752, time: 0.151, data: 0.005) loss: 1.361 
(epoch: 30, iters: 8832, time: 0.149, data: 0.005) loss: 1.457 
(epoch: 30, iters: 8912, time: 0.152, data: 0.000) loss: 1.456 
(epoch: 30, iters: 8992, time: 0.149, data: 0.000) loss: 1.389 
(epoch: 30, iters: 9072, time: 0.152, data: 0.009) loss: 1.264 
(epoch: 30, iters: 9152, time: 0.150, data: 0.009) loss: 0.880 
(epoch: 30, iters: 9232, time: 0.150, data: 0.010) loss: 1.312 
(epoch: 30, iters: 9312, time: 0.152, data: 0.005) loss: 0.846 
(epoch: 30, iters: 9392, time: 0.152, data: 0.010) loss: 0.924 
(epoch: 30, iters: 9472, time: 0.151, data: 0.000) loss: 0.689 
(epoch: 30, iters: 9552, time: 0.153, data: 0.000) loss: 1.555 
(epoch: 30, iters: 9632, time: 0.154, data: 0.024) loss: 1.106 
(epoch: 30, iters: 9712, time: 0.152, data: 0.000) loss: 1.523 
(epoch: 30, iters: 9792, time: 0.152, data: 0.000) loss: 0.983 
(epoch: 30, iters: 9872, time: 0.153, data: 0.007) loss: 2.283 
(epoch: 30, iters: 9952, time: 0.152, data: 0.005) loss: 0.680 
(epoch: 30, iters: 10032, time: 0.149, data: 0.000) loss: 0.828 
(epoch: 30, iters: 10112, time: 0.148, data: 0.000) loss: 1.206 
(epoch: 30, iters: 10192, time: 0.092, data: 0.000) loss: 1.562 
saving the model at the end of epoch 30, iters 305760
End of epoch 30 / 200 	 Time Taken: 1535 sec
learning rate = 0.0002000
saving the latest model (epoch 31, total_steps 305776)
(epoch: 31, iters: 80, time: 0.156, data: 0.362) loss: 1.441 
(epoch: 31, iters: 160, time: 0.155, data: 0.000) loss: 1.090 
(epoch: 31, iters: 240, time: 0.154, data: 0.012) loss: 0.782 
(epoch: 31, iters: 320, time: 0.153, data: 0.000) loss: 1.441 
(epoch: 31, iters: 400, time: 0.152, data: 0.015) loss: 1.143 
(epoch: 31, iters: 480, time: 0.153, data: 0.000) loss: 1.591 
(epoch: 31, iters: 560, time: 0.151, data: 0.000) loss: 0.894 
(epoch: 31, iters: 640, time: 0.149, data: 0.016) loss: 0.931 
(epoch: 31, iters: 720, time: 0.150, data: 0.000) loss: 1.126 
(epoch: 31, iters: 800, time: 0.150, data: 0.025) loss: 0.502 
(epoch: 31, iters: 880, time: 0.154, data: 0.000) loss: 1.093 
(epoch: 31, iters: 960, time: 0.151, data: 0.009) loss: 0.602 
(epoch: 31, iters: 1040, time: 0.151, data: 0.000) loss: 0.878 
(epoch: 31, iters: 1120, time: 0.152, data: 0.005) loss: 1.392 
(epoch: 31, iters: 1200, time: 0.151, data: 0.000) loss: 0.912 
(epoch: 31, iters: 1280, time: 0.151, data: 0.000) loss: 1.164 
(epoch: 31, iters: 1360, time: 0.152, data: 0.000) loss: 1.375 
(epoch: 31, iters: 1440, time: 0.148, data: 0.000) loss: 0.795 
(epoch: 31, iters: 1520, time: 0.149, data: 0.000) loss: 1.156 
(epoch: 31, iters: 1600, time: 0.151, data: 0.000) loss: 1.037 
(epoch: 31, iters: 1680, time: 0.148, data: 0.000) loss: 0.807 
(epoch: 31, iters: 1760, time: 0.151, data: 0.008) loss: 1.374 
(epoch: 31, iters: 1840, time: 0.152, data: 0.000) loss: 1.693 
(epoch: 31, iters: 1920, time: 0.153, data: 0.005) loss: 1.443 
(epoch: 31, iters: 2000, time: 0.153, data: 0.000) loss: 1.045 
(epoch: 31, iters: 2080, time: 0.151, data: 0.000) loss: 0.576 
(epoch: 31, iters: 2160, time: 0.153, data: 0.000) loss: 1.156 
(epoch: 31, iters: 2240, time: 0.153, data: 0.000) loss: 1.638 
(epoch: 31, iters: 2320, time: 0.154, data: 0.000) loss: 1.407 
(epoch: 31, iters: 2400, time: 0.153, data: 0.000) loss: 0.977 
(epoch: 31, iters: 2480, time: 0.154, data: 0.015) loss: 0.862 
(epoch: 31, iters: 2560, time: 0.153, data: 0.000) loss: 1.219 
(epoch: 31, iters: 2640, time: 0.153, data: 0.000) loss: 1.119 
(epoch: 31, iters: 2720, time: 0.151, data: 0.011) loss: 0.838 
(epoch: 31, iters: 2800, time: 0.153, data: 0.000) loss: 0.578 
(epoch: 31, iters: 2880, time: 0.153, data: 0.000) loss: 0.918 
(epoch: 31, iters: 2960, time: 0.152, data: 0.000) loss: 1.300 
(epoch: 31, iters: 3040, time: 0.152, data: 0.009) loss: 0.806 
(epoch: 31, iters: 3120, time: 0.153, data: 0.000) loss: 0.764 
(epoch: 31, iters: 3200, time: 0.152, data: 0.033) loss: 1.044 
(epoch: 31, iters: 3280, time: 0.152, data: 0.000) loss: 1.027 
(epoch: 31, iters: 3360, time: 0.148, data: 0.008) loss: 0.382 
(epoch: 31, iters: 3440, time: 0.152, data: 0.000) loss: 0.899 
(epoch: 31, iters: 3520, time: 0.150, data: 0.014) loss: 0.846 
(epoch: 31, iters: 3600, time: 0.151, data: 0.005) loss: 1.109 
(epoch: 31, iters: 3680, time: 0.153, data: 0.014) loss: 1.394 
(epoch: 31, iters: 3760, time: 0.150, data: 0.000) loss: 0.551 
(epoch: 31, iters: 3840, time: 0.151, data: 0.005) loss: 1.194 
(epoch: 31, iters: 3920, time: 0.154, data: 0.014) loss: 0.689 
(epoch: 31, iters: 4000, time: 0.150, data: 0.016) loss: 0.932 
saving the latest model (epoch 31, total_steps 309776)
(epoch: 31, iters: 4080, time: 0.151, data: 0.000) loss: 1.337 
(epoch: 31, iters: 4160, time: 0.151, data: 0.029) loss: 1.567 
(epoch: 31, iters: 4240, time: 0.152, data: 0.008) loss: 1.255 
(epoch: 31, iters: 4320, time: 0.153, data: 0.000) loss: 1.206 
(epoch: 31, iters: 4400, time: 0.152, data: 0.000) loss: 0.873 
(epoch: 31, iters: 4480, time: 0.150, data: 0.005) loss: 1.320 
(epoch: 31, iters: 4560, time: 0.154, data: 0.011) loss: 1.759 
(epoch: 31, iters: 4640, time: 0.152, data: 0.000) loss: 0.649 
(epoch: 31, iters: 4720, time: 0.152, data: 0.000) loss: 1.360 
(epoch: 31, iters: 4800, time: 0.152, data: 0.016) loss: 1.716 
(epoch: 31, iters: 4880, time: 0.152, data: 0.000) loss: 1.117 
(epoch: 31, iters: 4960, time: 0.152, data: 0.000) loss: 0.756 
(epoch: 31, iters: 5040, time: 0.151, data: 0.000) loss: 0.880 
(epoch: 31, iters: 5120, time: 0.152, data: 0.008) loss: 1.288 
(epoch: 31, iters: 5200, time: 0.153, data: 0.005) loss: 0.851 
(epoch: 31, iters: 5280, time: 0.149, data: 0.000) loss: 1.399 
(epoch: 31, iters: 5360, time: 0.150, data: 0.024) loss: 0.762 
(epoch: 31, iters: 5440, time: 0.149, data: 0.000) loss: 1.005 
(epoch: 31, iters: 5520, time: 0.151, data: 0.000) loss: 0.960 
(epoch: 31, iters: 5600, time: 0.150, data: 0.000) loss: 1.386 
(epoch: 31, iters: 5680, time: 0.150, data: 0.023) loss: 1.355 
(epoch: 31, iters: 5760, time: 0.151, data: 0.000) loss: 1.062 
(epoch: 31, iters: 5840, time: 0.150, data: 0.008) loss: 0.950 
(epoch: 31, iters: 5920, time: 0.154, data: 0.000) loss: 1.202 
(epoch: 31, iters: 6000, time: 0.151, data: 0.015) loss: 0.988 
(epoch: 31, iters: 6080, time: 0.151, data: 0.018) loss: 1.669 
(epoch: 31, iters: 6160, time: 0.154, data: 0.000) loss: 0.907 
(epoch: 31, iters: 6240, time: 0.153, data: 0.000) loss: 0.553 
(epoch: 31, iters: 6320, time: 0.152, data: 0.005) loss: 1.377 
(epoch: 31, iters: 6400, time: 0.152, data: 0.009) loss: 1.033 
(epoch: 31, iters: 6480, time: 0.149, data: 0.000) loss: 1.148 
(epoch: 31, iters: 6560, time: 0.150, data: 0.000) loss: 1.356 
(epoch: 31, iters: 6640, time: 0.151, data: 0.000) loss: 1.248 
(epoch: 31, iters: 6720, time: 0.151, data: 0.021) loss: 1.267 
(epoch: 31, iters: 6800, time: 0.152, data: 0.015) loss: 0.694 
(epoch: 31, iters: 6880, time: 0.151, data: 0.005) loss: 0.963 
(epoch: 31, iters: 6960, time: 0.152, data: 0.021) loss: 1.341 
(epoch: 31, iters: 7040, time: 0.153, data: 0.000) loss: 0.500 
(epoch: 31, iters: 7120, time: 0.151, data: 0.005) loss: 1.264 
(epoch: 31, iters: 7200, time: 0.153, data: 0.000) loss: 0.951 
(epoch: 31, iters: 7280, time: 0.150, data: 0.000) loss: 1.834 
(epoch: 31, iters: 7360, time: 0.151, data: 0.000) loss: 0.535 
(epoch: 31, iters: 7440, time: 0.152, data: 0.009) loss: 1.291 
(epoch: 31, iters: 7520, time: 0.152, data: 0.018) loss: 0.829 
(epoch: 31, iters: 7600, time: 0.151, data: 0.000) loss: 0.794 
(epoch: 31, iters: 7680, time: 0.152, data: 0.000) loss: 1.404 
(epoch: 31, iters: 7760, time: 0.152, data: 0.008) loss: 1.571 
(epoch: 31, iters: 7840, time: 0.150, data: 0.021) loss: 1.531 
(epoch: 31, iters: 7920, time: 0.151, data: 0.016) loss: 0.921 
(epoch: 31, iters: 8000, time: 0.152, data: 0.000) loss: 0.783 
saving the latest model (epoch 31, total_steps 313776)
(epoch: 31, iters: 8080, time: 0.152, data: 0.008) loss: 1.187 
(epoch: 31, iters: 8160, time: 0.153, data: 0.000) loss: 0.417 
(epoch: 31, iters: 8240, time: 0.153, data: 0.000) loss: 1.643 
(epoch: 31, iters: 8320, time: 0.152, data: 0.000) loss: 1.841 
(epoch: 31, iters: 8400, time: 0.151, data: 0.005) loss: 2.125 
(epoch: 31, iters: 8480, time: 0.152, data: 0.025) loss: 1.151 
(epoch: 31, iters: 8560, time: 0.153, data: 0.000) loss: 1.563 
(epoch: 31, iters: 8640, time: 0.149, data: 0.000) loss: 1.271 
(epoch: 31, iters: 8720, time: 0.149, data: 0.022) loss: 1.261 
(epoch: 31, iters: 8800, time: 0.151, data: 0.000) loss: 1.405 
(epoch: 31, iters: 8880, time: 0.149, data: 0.000) loss: 1.699 
(epoch: 31, iters: 8960, time: 0.150, data: 0.000) loss: 1.833 
(epoch: 31, iters: 9040, time: 0.153, data: 0.000) loss: 1.293 
(epoch: 31, iters: 9120, time: 0.152, data: 0.014) loss: 1.033 
(epoch: 31, iters: 9200, time: 0.153, data: 0.000) loss: 1.081 
(epoch: 31, iters: 9280, time: 0.153, data: 0.000) loss: 0.968 
(epoch: 31, iters: 9360, time: 0.153, data: 0.005) loss: 0.769 
(epoch: 31, iters: 9440, time: 0.153, data: 0.000) loss: 1.302 
(epoch: 31, iters: 9520, time: 0.151, data: 0.005) loss: 1.471 
(epoch: 31, iters: 9600, time: 0.153, data: 0.011) loss: 1.068 
(epoch: 31, iters: 9680, time: 0.151, data: 0.000) loss: 0.750 
(epoch: 31, iters: 9760, time: 0.152, data: 0.006) loss: 0.901 
(epoch: 31, iters: 9840, time: 0.151, data: 0.000) loss: 0.941 
(epoch: 31, iters: 9920, time: 0.153, data: 0.019) loss: 1.330 
(epoch: 31, iters: 10000, time: 0.153, data: 0.000) loss: 0.626 
(epoch: 31, iters: 10080, time: 0.151, data: 0.000) loss: 1.011 
(epoch: 31, iters: 10160, time: 0.150, data: 0.000) loss: 1.172 
saving the model at the end of epoch 31, iters 315952
End of epoch 31 / 200 	 Time Taken: 1548 sec
learning rate = 0.0002000
saving the latest model (epoch 32, total_steps 315968)
(epoch: 32, iters: 48, time: 0.154, data: 0.007) loss: 0.813 
(epoch: 32, iters: 128, time: 0.150, data: 0.032) loss: 1.371 
(epoch: 32, iters: 208, time: 0.150, data: 0.022) loss: 1.319 
(epoch: 32, iters: 288, time: 0.152, data: 0.000) loss: 1.266 
(epoch: 32, iters: 368, time: 0.152, data: 0.005) loss: 1.104 
(epoch: 32, iters: 448, time: 0.151, data: 0.005) loss: 1.033 
(epoch: 32, iters: 528, time: 0.152, data: 0.000) loss: 0.880 
(epoch: 32, iters: 608, time: 0.149, data: 0.017) loss: 1.187 
(epoch: 32, iters: 688, time: 0.150, data: 0.000) loss: 1.296 
(epoch: 32, iters: 768, time: 0.151, data: 0.000) loss: 1.136 
(epoch: 32, iters: 848, time: 0.150, data: 0.000) loss: 0.936 
(epoch: 32, iters: 928, time: 0.153, data: 0.015) loss: 1.373 
(epoch: 32, iters: 1008, time: 0.151, data: 0.000) loss: 1.551 
(epoch: 32, iters: 1088, time: 0.151, data: 0.028) loss: 1.459 
(epoch: 32, iters: 1168, time: 0.149, data: 0.005) loss: 0.951 
(epoch: 32, iters: 1248, time: 0.150, data: 0.000) loss: 1.022 
(epoch: 32, iters: 1328, time: 0.151, data: 0.006) loss: 0.599 
(epoch: 32, iters: 1408, time: 0.149, data: 0.000) loss: 0.839 
(epoch: 32, iters: 1488, time: 0.151, data: 0.006) loss: 1.174 
(epoch: 32, iters: 1568, time: 0.152, data: 0.005) loss: 0.617 
(epoch: 32, iters: 1648, time: 0.151, data: 0.000) loss: 1.423 
(epoch: 32, iters: 1728, time: 0.151, data: 0.006) loss: 0.541 
(epoch: 32, iters: 1808, time: 0.150, data: 0.000) loss: 0.993 
(epoch: 32, iters: 1888, time: 0.152, data: 0.010) loss: 1.192 
(epoch: 32, iters: 1968, time: 0.149, data: 0.005) loss: 1.498 
(epoch: 32, iters: 2048, time: 0.149, data: 0.000) loss: 0.852 
(epoch: 32, iters: 2128, time: 0.149, data: 0.005) loss: 1.386 
(epoch: 32, iters: 2208, time: 0.148, data: 0.000) loss: 1.015 
(epoch: 32, iters: 2288, time: 0.150, data: 0.023) loss: 0.947 
(epoch: 32, iters: 2368, time: 0.150, data: 0.023) loss: 1.304 
(epoch: 32, iters: 2448, time: 0.148, data: 0.000) loss: 1.268 
(epoch: 32, iters: 2528, time: 0.150, data: 0.000) loss: 0.480 
(epoch: 32, iters: 2608, time: 0.152, data: 0.005) loss: 0.977 
(epoch: 32, iters: 2688, time: 0.150, data: 0.000) loss: 1.884 
(epoch: 32, iters: 2768, time: 0.149, data: 0.008) loss: 0.845 
(epoch: 32, iters: 2848, time: 0.152, data: 0.009) loss: 0.594 
(epoch: 32, iters: 2928, time: 0.152, data: 0.000) loss: 0.843 
(epoch: 32, iters: 3008, time: 0.149, data: 0.000) loss: 0.639 
(epoch: 32, iters: 3088, time: 0.150, data: 0.014) loss: 0.985 
(epoch: 32, iters: 3168, time: 0.150, data: 0.000) loss: 1.423 
(epoch: 32, iters: 3248, time: 0.150, data: 0.020) loss: 1.051 
(epoch: 32, iters: 3328, time: 0.151, data: 0.000) loss: 0.997 
(epoch: 32, iters: 3408, time: 0.150, data: 0.000) loss: 0.998 
(epoch: 32, iters: 3488, time: 0.152, data: 0.005) loss: 0.888 
(epoch: 32, iters: 3568, time: 0.150, data: 0.000) loss: 1.213 
(epoch: 32, iters: 3648, time: 0.149, data: 0.000) loss: 0.640 
(epoch: 32, iters: 3728, time: 0.150, data: 0.009) loss: 0.885 
(epoch: 32, iters: 3808, time: 0.152, data: 0.000) loss: 1.340 
(epoch: 32, iters: 3888, time: 0.150, data: 0.000) loss: 1.461 
(epoch: 32, iters: 3968, time: 0.150, data: 0.000) loss: 1.150 
saving the latest model (epoch 32, total_steps 319968)
(epoch: 32, iters: 4048, time: 0.153, data: 0.000) loss: 0.847 
(epoch: 32, iters: 4128, time: 0.150, data: 0.014) loss: 0.513 
(epoch: 32, iters: 4208, time: 0.149, data: 0.005) loss: 0.468 
(epoch: 32, iters: 4288, time: 0.152, data: 0.000) loss: 0.801 
(epoch: 32, iters: 4368, time: 0.151, data: 0.005) loss: 1.078 
(epoch: 32, iters: 4448, time: 0.152, data: 0.000) loss: 0.906 
(epoch: 32, iters: 4528, time: 0.151, data: 0.000) loss: 1.308 
(epoch: 32, iters: 4608, time: 0.149, data: 0.018) loss: 1.562 
(epoch: 32, iters: 4688, time: 0.151, data: 0.000) loss: 1.086 
(epoch: 32, iters: 4768, time: 0.153, data: 0.000) loss: 0.642 
(epoch: 32, iters: 4848, time: 0.152, data: 0.000) loss: 0.821 
(epoch: 32, iters: 4928, time: 0.151, data: 0.005) loss: 1.658 
(epoch: 32, iters: 5008, time: 0.150, data: 0.000) loss: 0.908 
(epoch: 32, iters: 5088, time: 0.151, data: 0.010) loss: 1.399 
(epoch: 32, iters: 5168, time: 0.150, data: 0.014) loss: 0.720 
(epoch: 32, iters: 5248, time: 0.149, data: 0.000) loss: 1.250 
(epoch: 32, iters: 5328, time: 0.151, data: 0.009) loss: 1.019 
(epoch: 32, iters: 5408, time: 0.152, data: 0.013) loss: 1.392 
(epoch: 32, iters: 5488, time: 0.150, data: 0.000) loss: 1.246 
(epoch: 32, iters: 5568, time: 0.150, data: 0.000) loss: 1.781 
(epoch: 32, iters: 5648, time: 0.151, data: 0.021) loss: 1.115 
(epoch: 32, iters: 5728, time: 0.149, data: 0.005) loss: 0.865 
(epoch: 32, iters: 5808, time: 0.148, data: 0.000) loss: 1.030 
(epoch: 32, iters: 5888, time: 0.151, data: 0.000) loss: 1.267 
(epoch: 32, iters: 5968, time: 0.149, data: 0.025) loss: 0.694 
(epoch: 32, iters: 6048, time: 0.150, data: 0.000) loss: 0.670 
(epoch: 32, iters: 6128, time: 0.149, data: 0.000) loss: 0.530 
(epoch: 32, iters: 6208, time: 0.150, data: 0.035) loss: 1.357 
(epoch: 32, iters: 6288, time: 0.150, data: 0.000) loss: 1.072 
(epoch: 32, iters: 6368, time: 0.150, data: 0.000) loss: 1.724 
(epoch: 32, iters: 6448, time: 0.149, data: 0.000) loss: 1.351 
(epoch: 32, iters: 6528, time: 0.149, data: 0.005) loss: 1.606 
(epoch: 32, iters: 6608, time: 0.153, data: 0.000) loss: 1.166 
(epoch: 32, iters: 6688, time: 0.152, data: 0.008) loss: 0.612 
(epoch: 32, iters: 6768, time: 0.151, data: 0.000) loss: 0.904 
(epoch: 32, iters: 6848, time: 0.151, data: 0.000) loss: 0.980 
(epoch: 32, iters: 6928, time: 0.149, data: 0.000) loss: 1.020 
(epoch: 32, iters: 7008, time: 0.151, data: 0.023) loss: 1.091 
(epoch: 32, iters: 7088, time: 0.151, data: 0.000) loss: 1.241 
(epoch: 32, iters: 7168, time: 0.150, data: 0.026) loss: 0.857 
(epoch: 32, iters: 7248, time: 0.151, data: 0.000) loss: 0.728 
(epoch: 32, iters: 7328, time: 0.150, data: 0.000) loss: 0.914 
(epoch: 32, iters: 7408, time: 0.150, data: 0.000) loss: 0.667 
(epoch: 32, iters: 7488, time: 0.150, data: 0.010) loss: 0.921 
(epoch: 32, iters: 7568, time: 0.152, data: 0.000) loss: 1.530 
(epoch: 32, iters: 7648, time: 0.151, data: 0.000) loss: 1.254 
(epoch: 32, iters: 7728, time: 0.152, data: 0.012) loss: 0.922 
(epoch: 32, iters: 7808, time: 0.149, data: 0.000) loss: 0.943 
(epoch: 32, iters: 7888, time: 0.149, data: 0.008) loss: 1.044 
(epoch: 32, iters: 7968, time: 0.152, data: 0.005) loss: 0.795 
saving the latest model (epoch 32, total_steps 323968)
(epoch: 32, iters: 8048, time: 0.152, data: 0.026) loss: 1.205 
(epoch: 32, iters: 8128, time: 0.155, data: 0.000) loss: 1.737 
(epoch: 32, iters: 8208, time: 0.151, data: 0.033) loss: 0.775 
(epoch: 32, iters: 8288, time: 0.150, data: 0.000) loss: 0.787 
(epoch: 32, iters: 8368, time: 0.150, data: 0.000) loss: 0.379 
(epoch: 32, iters: 8448, time: 0.151, data: 0.006) loss: 1.002 
(epoch: 32, iters: 8528, time: 0.152, data: 0.021) loss: 0.672 
(epoch: 32, iters: 8608, time: 0.149, data: 0.021) loss: 1.103 
(epoch: 32, iters: 8688, time: 0.151, data: 0.000) loss: 1.269 
(epoch: 32, iters: 8768, time: 0.149, data: 0.018) loss: 0.822 
(epoch: 32, iters: 8848, time: 0.150, data: 0.017) loss: 1.326 
(epoch: 32, iters: 8928, time: 0.152, data: 0.000) loss: 0.689 
(epoch: 32, iters: 9008, time: 0.151, data: 0.000) loss: 1.044 
(epoch: 32, iters: 9088, time: 0.151, data: 0.015) loss: 1.398 
(epoch: 32, iters: 9168, time: 0.149, data: 0.000) loss: 0.708 
(epoch: 32, iters: 9248, time: 0.150, data: 0.000) loss: 1.290 
(epoch: 32, iters: 9328, time: 0.151, data: 0.016) loss: 0.927 
(epoch: 32, iters: 9408, time: 0.151, data: 0.028) loss: 1.102 
(epoch: 32, iters: 9488, time: 0.149, data: 0.000) loss: 0.681 
(epoch: 32, iters: 9568, time: 0.151, data: 0.000) loss: 0.819 
(epoch: 32, iters: 9648, time: 0.151, data: 0.015) loss: 0.615 
(epoch: 32, iters: 9728, time: 0.151, data: 0.000) loss: 0.518 
(epoch: 32, iters: 9808, time: 0.152, data: 0.015) loss: 1.201 
(epoch: 32, iters: 9888, time: 0.153, data: 0.017) loss: 1.652 
(epoch: 32, iters: 9968, time: 0.152, data: 0.000) loss: 1.066 
(epoch: 32, iters: 10048, time: 0.152, data: 0.000) loss: 1.570 
(epoch: 32, iters: 10128, time: 0.149, data: 0.000) loss: 1.141 
saving the model at the end of epoch 32, iters 326144
End of epoch 32 / 200 	 Time Taken: 1536 sec
learning rate = 0.0002000
(epoch: 33, iters: 16, time: 0.179, data: 0.020) loss: 1.496 
saving the latest model (epoch 33, total_steps 326160)
(epoch: 33, iters: 96, time: 0.152, data: 0.035) loss: 1.002 
(epoch: 33, iters: 176, time: 0.150, data: 0.006) loss: 1.397 
(epoch: 33, iters: 256, time: 0.152, data: 0.000) loss: 1.453 
(epoch: 33, iters: 336, time: 0.152, data: 0.008) loss: 1.215 
(epoch: 33, iters: 416, time: 0.148, data: 0.000) loss: 1.018 
(epoch: 33, iters: 496, time: 0.151, data: 0.000) loss: 1.025 
(epoch: 33, iters: 576, time: 0.150, data: 0.000) loss: 0.489 
(epoch: 33, iters: 656, time: 0.150, data: 0.000) loss: 1.462 
(epoch: 33, iters: 736, time: 0.150, data: 0.005) loss: 0.627 
(epoch: 33, iters: 816, time: 0.149, data: 0.018) loss: 0.735 
(epoch: 33, iters: 896, time: 0.148, data: 0.000) loss: 0.898 
(epoch: 33, iters: 976, time: 0.150, data: 0.000) loss: 1.339 
(epoch: 33, iters: 1056, time: 0.152, data: 0.000) loss: 1.364 
(epoch: 33, iters: 1136, time: 0.150, data: 0.021) loss: 1.016 
(epoch: 33, iters: 1216, time: 0.151, data: 0.000) loss: 1.293 
(epoch: 33, iters: 1296, time: 0.149, data: 0.032) loss: 1.349 
(epoch: 33, iters: 1376, time: 0.149, data: 0.000) loss: 0.836 
(epoch: 33, iters: 1456, time: 0.152, data: 0.000) loss: 1.989 
(epoch: 33, iters: 1536, time: 0.153, data: 0.000) loss: 1.319 
(epoch: 33, iters: 1616, time: 0.151, data: 0.009) loss: 0.489 
(epoch: 33, iters: 1696, time: 0.151, data: 0.000) loss: 1.228 
(epoch: 33, iters: 1776, time: 0.151, data: 0.005) loss: 0.763 
(epoch: 33, iters: 1856, time: 0.153, data: 0.000) loss: 1.444 
(epoch: 33, iters: 1936, time: 0.148, data: 0.000) loss: 0.779 
(epoch: 33, iters: 2016, time: 0.149, data: 0.017) loss: 1.189 
(epoch: 33, iters: 2096, time: 0.148, data: 0.000) loss: 1.150 
(epoch: 33, iters: 2176, time: 0.152, data: 0.024) loss: 1.089 
(epoch: 33, iters: 2256, time: 0.149, data: 0.000) loss: 1.912 
(epoch: 33, iters: 2336, time: 0.152, data: 0.010) loss: 1.050 
(epoch: 33, iters: 2416, time: 0.151, data: 0.000) loss: 1.127 
(epoch: 33, iters: 2496, time: 0.151, data: 0.000) loss: 1.005 
(epoch: 33, iters: 2576, time: 0.152, data: 0.000) loss: 0.881 
(epoch: 33, iters: 2656, time: 0.151, data: 0.000) loss: 0.902 
(epoch: 33, iters: 2736, time: 0.151, data: 0.000) loss: 1.135 
(epoch: 33, iters: 2816, time: 0.149, data: 0.024) loss: 1.519 
(epoch: 33, iters: 2896, time: 0.152, data: 0.000) loss: 0.919 
(epoch: 33, iters: 2976, time: 0.153, data: 0.000) loss: 0.772 
(epoch: 33, iters: 3056, time: 0.152, data: 0.005) loss: 0.803 
(epoch: 33, iters: 3136, time: 0.152, data: 0.023) loss: 1.235 
(epoch: 33, iters: 3216, time: 0.151, data: 0.000) loss: 0.753 
(epoch: 33, iters: 3296, time: 0.150, data: 0.000) loss: 1.034 
(epoch: 33, iters: 3376, time: 0.153, data: 0.000) loss: 0.984 
(epoch: 33, iters: 3456, time: 0.151, data: 0.000) loss: 0.804 
(epoch: 33, iters: 3536, time: 0.148, data: 0.015) loss: 0.862 
(epoch: 33, iters: 3616, time: 0.152, data: 0.022) loss: 0.893 
(epoch: 33, iters: 3696, time: 0.151, data: 0.000) loss: 0.880 
(epoch: 33, iters: 3776, time: 0.153, data: 0.016) loss: 1.186 
(epoch: 33, iters: 3856, time: 0.150, data: 0.000) loss: 0.640 
(epoch: 33, iters: 3936, time: 0.150, data: 0.000) loss: 1.744 
(epoch: 33, iters: 4016, time: 0.152, data: 0.034) loss: 1.078 
saving the latest model (epoch 33, total_steps 330160)
(epoch: 33, iters: 4096, time: 0.152, data: 0.000) loss: 1.233 
(epoch: 33, iters: 4176, time: 0.152, data: 0.005) loss: 1.072 
(epoch: 33, iters: 4256, time: 0.151, data: 0.000) loss: 1.078 
(epoch: 33, iters: 4336, time: 0.152, data: 0.000) loss: 0.679 
(epoch: 33, iters: 4416, time: 0.151, data: 0.005) loss: 0.978 
(epoch: 33, iters: 4496, time: 0.153, data: 0.005) loss: 1.531 
(epoch: 33, iters: 4576, time: 0.151, data: 0.000) loss: 0.778 
(epoch: 33, iters: 4656, time: 0.155, data: 0.024) loss: 1.625 
(epoch: 33, iters: 4736, time: 0.151, data: 0.000) loss: 0.878 
(epoch: 33, iters: 4816, time: 0.151, data: 0.013) loss: 1.469 
(epoch: 33, iters: 4896, time: 0.149, data: 0.000) loss: 1.444 
(epoch: 33, iters: 4976, time: 0.150, data: 0.025) loss: 0.976 
(epoch: 33, iters: 5056, time: 0.148, data: 0.000) loss: 1.320 
(epoch: 33, iters: 5136, time: 0.149, data: 0.000) loss: 1.398 
(epoch: 33, iters: 5216, time: 0.151, data: 0.008) loss: 1.064 
(epoch: 33, iters: 5296, time: 0.150, data: 0.013) loss: 1.428 
(epoch: 33, iters: 5376, time: 0.148, data: 0.009) loss: 0.739 
(epoch: 33, iters: 5456, time: 0.149, data: 0.000) loss: 0.756 
(epoch: 33, iters: 5536, time: 0.151, data: 0.031) loss: 1.051 
(epoch: 33, iters: 5616, time: 0.153, data: 0.000) loss: 0.233 
(epoch: 33, iters: 5696, time: 0.152, data: 0.022) loss: 0.711 
(epoch: 33, iters: 5776, time: 0.152, data: 0.000) loss: 0.632 
(epoch: 33, iters: 5856, time: 0.152, data: 0.000) loss: 0.943 
(epoch: 33, iters: 5936, time: 0.149, data: 0.000) loss: 1.692 
(epoch: 33, iters: 6016, time: 0.148, data: 0.008) loss: 1.227 
(epoch: 33, iters: 6096, time: 0.149, data: 0.005) loss: 1.687 
(epoch: 33, iters: 6176, time: 0.151, data: 0.011) loss: 0.781 
(epoch: 33, iters: 6256, time: 0.151, data: 0.005) loss: 1.357 
(epoch: 33, iters: 6336, time: 0.150, data: 0.000) loss: 1.057 
(epoch: 33, iters: 6416, time: 0.151, data: 0.014) loss: 1.623 
(epoch: 33, iters: 6496, time: 0.152, data: 0.000) loss: 1.155 
(epoch: 33, iters: 6576, time: 0.149, data: 0.027) loss: 0.685 
(epoch: 33, iters: 6656, time: 0.149, data: 0.023) loss: 0.981 
(epoch: 33, iters: 6736, time: 0.152, data: 0.000) loss: 0.439 
(epoch: 33, iters: 6816, time: 0.150, data: 0.000) loss: 0.818 
(epoch: 33, iters: 6896, time: 0.152, data: 0.020) loss: 0.652 
(epoch: 33, iters: 6976, time: 0.148, data: 0.000) loss: 0.928 
(epoch: 33, iters: 7056, time: 0.150, data: 0.016) loss: 0.808 
(epoch: 33, iters: 7136, time: 0.150, data: 0.000) loss: 0.537 
(epoch: 33, iters: 7216, time: 0.153, data: 0.005) loss: 0.961 
(epoch: 33, iters: 7296, time: 0.149, data: 0.024) loss: 1.214 
(epoch: 33, iters: 7376, time: 0.152, data: 0.000) loss: 1.297 
(epoch: 33, iters: 7456, time: 0.147, data: 0.000) loss: 1.055 
(epoch: 33, iters: 7536, time: 0.148, data: 0.000) loss: 0.841 
(epoch: 33, iters: 7616, time: 0.149, data: 0.005) loss: 0.794 
(epoch: 33, iters: 7696, time: 0.148, data: 0.005) loss: 1.287 
(epoch: 33, iters: 7776, time: 0.150, data: 0.000) loss: 0.976 
(epoch: 33, iters: 7856, time: 0.152, data: 0.005) loss: 1.326 
(epoch: 33, iters: 7936, time: 0.149, data: 0.005) loss: 0.618 
(epoch: 33, iters: 8016, time: 0.151, data: 0.005) loss: 1.097 
saving the latest model (epoch 33, total_steps 334160)
(epoch: 33, iters: 8096, time: 0.151, data: 0.005) loss: 0.658 
(epoch: 33, iters: 8176, time: 0.150, data: 0.005) loss: 2.017 
(epoch: 33, iters: 8256, time: 0.151, data: 0.023) loss: 1.335 
(epoch: 33, iters: 8336, time: 0.150, data: 0.000) loss: 1.571 
(epoch: 33, iters: 8416, time: 0.151, data: 0.000) loss: 0.830 
(epoch: 33, iters: 8496, time: 0.150, data: 0.000) loss: 0.877 
(epoch: 33, iters: 8576, time: 0.149, data: 0.009) loss: 1.707 
(epoch: 33, iters: 8656, time: 0.151, data: 0.000) loss: 1.662 
(epoch: 33, iters: 8736, time: 0.148, data: 0.018) loss: 0.640 
(epoch: 33, iters: 8816, time: 0.148, data: 0.013) loss: 1.718 
(epoch: 33, iters: 8896, time: 0.147, data: 0.015) loss: 0.808 
(epoch: 33, iters: 8976, time: 0.152, data: 0.018) loss: 1.484 
(epoch: 33, iters: 9056, time: 0.151, data: 0.005) loss: 1.303 
(epoch: 33, iters: 9136, time: 0.151, data: 0.000) loss: 0.681 
(epoch: 33, iters: 9216, time: 0.149, data: 0.021) loss: 1.608 
(epoch: 33, iters: 9296, time: 0.150, data: 0.008) loss: 1.084 
(epoch: 33, iters: 9376, time: 0.150, data: 0.000) loss: 0.980 
(epoch: 33, iters: 9456, time: 0.150, data: 0.000) loss: 0.940 
(epoch: 33, iters: 9536, time: 0.148, data: 0.020) loss: 0.871 
(epoch: 33, iters: 9616, time: 0.150, data: 0.008) loss: 1.521 
(epoch: 33, iters: 9696, time: 0.148, data: 0.005) loss: 0.710 
(epoch: 33, iters: 9776, time: 0.154, data: 0.000) loss: 1.646 
(epoch: 33, iters: 9856, time: 0.149, data: 0.000) loss: 0.828 
(epoch: 33, iters: 9936, time: 0.152, data: 0.000) loss: 0.698 
(epoch: 33, iters: 10016, time: 0.152, data: 0.021) loss: 1.005 
(epoch: 33, iters: 10096, time: 0.148, data: 0.000) loss: 1.291 
(epoch: 33, iters: 10176, time: 0.148, data: 0.000) loss: 1.353 
saving the model at the end of epoch 33, iters 336336
End of epoch 33 / 200 	 Time Taken: 1538 sec
learning rate = 0.0002000
saving the latest model (epoch 34, total_steps 336352)
(epoch: 34, iters: 64, time: 0.154, data: 0.000) loss: 1.074 
(epoch: 34, iters: 144, time: 0.151, data: 0.010) loss: 1.386 
(epoch: 34, iters: 224, time: 0.147, data: 0.036) loss: 0.982 
(epoch: 34, iters: 304, time: 0.150, data: 0.000) loss: 0.753 
(epoch: 34, iters: 384, time: 0.151, data: 0.034) loss: 0.730 
(epoch: 34, iters: 464, time: 0.149, data: 0.000) loss: 0.888 
(epoch: 34, iters: 544, time: 0.150, data: 0.000) loss: 0.826 
(epoch: 34, iters: 624, time: 0.149, data: 0.018) loss: 0.504 
(epoch: 34, iters: 704, time: 0.150, data: 0.000) loss: 1.277 
(epoch: 34, iters: 784, time: 0.149, data: 0.005) loss: 1.375 
(epoch: 34, iters: 864, time: 0.150, data: 0.010) loss: 1.169 
(epoch: 34, iters: 944, time: 0.152, data: 0.000) loss: 0.901 
(epoch: 34, iters: 1024, time: 0.149, data: 0.000) loss: 1.814 
(epoch: 34, iters: 1104, time: 0.147, data: 0.000) loss: 0.705 
(epoch: 34, iters: 1184, time: 0.149, data: 0.008) loss: 0.752 
(epoch: 34, iters: 1264, time: 0.149, data: 0.000) loss: 1.095 
(epoch: 34, iters: 1344, time: 0.146, data: 0.033) loss: 0.838 
(epoch: 34, iters: 1424, time: 0.146, data: 0.000) loss: 0.298 
(epoch: 34, iters: 1504, time: 0.149, data: 0.000) loss: 1.565 
(epoch: 34, iters: 1584, time: 0.149, data: 0.005) loss: 1.187 
(epoch: 34, iters: 1664, time: 0.149, data: 0.000) loss: 0.891 
(epoch: 34, iters: 1744, time: 0.147, data: 0.017) loss: 1.443 
(epoch: 34, iters: 1824, time: 0.148, data: 0.010) loss: 1.404 
(epoch: 34, iters: 1904, time: 0.149, data: 0.000) loss: 1.045 
(epoch: 34, iters: 1984, time: 0.146, data: 0.000) loss: 1.098 
(epoch: 34, iters: 2064, time: 0.148, data: 0.000) loss: 1.286 
(epoch: 34, iters: 2144, time: 0.149, data: 0.000) loss: 0.876 
(epoch: 34, iters: 2224, time: 0.147, data: 0.013) loss: 1.525 
(epoch: 34, iters: 2304, time: 0.149, data: 0.000) loss: 0.974 
(epoch: 34, iters: 2384, time: 0.150, data: 0.009) loss: 0.797 
(epoch: 34, iters: 2464, time: 0.150, data: 0.008) loss: 0.886 
(epoch: 34, iters: 2544, time: 0.151, data: 0.000) loss: 1.329 
(epoch: 34, iters: 2624, time: 0.151, data: 0.008) loss: 1.079 
(epoch: 34, iters: 2704, time: 0.151, data: 0.000) loss: 1.021 
(epoch: 34, iters: 2784, time: 0.151, data: 0.020) loss: 2.182 
(epoch: 34, iters: 2864, time: 0.150, data: 0.000) loss: 1.164 
(epoch: 34, iters: 2944, time: 0.149, data: 0.021) loss: 1.194 
(epoch: 34, iters: 3024, time: 0.151, data: 0.000) loss: 0.789 
(epoch: 34, iters: 3104, time: 0.148, data: 0.000) loss: 1.175 
(epoch: 34, iters: 3184, time: 0.148, data: 0.017) loss: 1.060 
(epoch: 34, iters: 3264, time: 0.149, data: 0.000) loss: 0.804 
(epoch: 34, iters: 3344, time: 0.152, data: 0.010) loss: 1.485 
(epoch: 34, iters: 3424, time: 0.147, data: 0.000) loss: 1.225 
(epoch: 34, iters: 3504, time: 0.152, data: 0.011) loss: 0.920 
(epoch: 34, iters: 3584, time: 0.148, data: 0.000) loss: 1.825 
(epoch: 34, iters: 3664, time: 0.150, data: 0.000) loss: 0.786 
(epoch: 34, iters: 3744, time: 0.149, data: 0.013) loss: 1.126 
(epoch: 34, iters: 3824, time: 0.150, data: 0.000) loss: 0.479 
(epoch: 34, iters: 3904, time: 0.149, data: 0.000) loss: 1.335 
(epoch: 34, iters: 3984, time: 0.151, data: 0.005) loss: 1.502 
saving the latest model (epoch 34, total_steps 340352)
(epoch: 34, iters: 4064, time: 0.149, data: 0.000) loss: 1.066 
(epoch: 34, iters: 4144, time: 0.147, data: 0.000) loss: 1.126 
(epoch: 34, iters: 4224, time: 0.148, data: 0.013) loss: 0.916 
(epoch: 34, iters: 4304, time: 0.152, data: 0.000) loss: 1.467 
(epoch: 34, iters: 4384, time: 0.151, data: 0.005) loss: 0.629 
(epoch: 34, iters: 4464, time: 0.151, data: 0.000) loss: 1.169 
(epoch: 34, iters: 4544, time: 0.149, data: 0.000) loss: 1.283 
(epoch: 34, iters: 4624, time: 0.153, data: 0.000) loss: 0.991 
(epoch: 34, iters: 4704, time: 0.149, data: 0.007) loss: 1.075 
(epoch: 34, iters: 4784, time: 0.151, data: 0.005) loss: 0.672 
(epoch: 34, iters: 4864, time: 0.155, data: 0.000) loss: 0.515 
(epoch: 34, iters: 4944, time: 0.150, data: 0.000) loss: 0.674 
(epoch: 34, iters: 5024, time: 0.153, data: 0.000) loss: 1.636 
(epoch: 34, iters: 5104, time: 0.152, data: 0.014) loss: 0.766 
(epoch: 34, iters: 5184, time: 0.151, data: 0.016) loss: 1.320 
(epoch: 34, iters: 5264, time: 0.150, data: 0.022) loss: 1.154 
(epoch: 34, iters: 5344, time: 0.150, data: 0.000) loss: 1.460 
(epoch: 34, iters: 5424, time: 0.151, data: 0.018) loss: 0.937 
(epoch: 34, iters: 5504, time: 0.149, data: 0.000) loss: 0.675 
(epoch: 34, iters: 5584, time: 0.151, data: 0.000) loss: 0.751 
(epoch: 34, iters: 5664, time: 0.152, data: 0.000) loss: 1.374 
(epoch: 34, iters: 5744, time: 0.150, data: 0.000) loss: 0.914 
(epoch: 34, iters: 5824, time: 0.150, data: 0.010) loss: 1.067 
(epoch: 34, iters: 5904, time: 0.150, data: 0.000) loss: 0.687 
(epoch: 34, iters: 5984, time: 0.149, data: 0.000) loss: 1.248 
(epoch: 34, iters: 6064, time: 0.150, data: 0.008) loss: 1.083 
(epoch: 34, iters: 6144, time: 0.150, data: 0.000) loss: 0.662 
(epoch: 34, iters: 6224, time: 0.149, data: 0.000) loss: 1.322 
(epoch: 34, iters: 6304, time: 0.151, data: 0.000) loss: 1.092 
(epoch: 34, iters: 6384, time: 0.151, data: 0.018) loss: 1.363 
(epoch: 34, iters: 6464, time: 0.148, data: 0.000) loss: 1.233 
(epoch: 34, iters: 6544, time: 0.151, data: 0.031) loss: 1.804 
(epoch: 34, iters: 6624, time: 0.151, data: 0.000) loss: 0.900 
(epoch: 34, iters: 6704, time: 0.153, data: 0.032) loss: 0.696 
(epoch: 34, iters: 6784, time: 0.149, data: 0.000) loss: 1.266 
(epoch: 34, iters: 6864, time: 0.149, data: 0.000) loss: 1.496 
(epoch: 34, iters: 6944, time: 0.148, data: 0.008) loss: 1.371 
(epoch: 34, iters: 7024, time: 0.149, data: 0.005) loss: 0.911 
(epoch: 34, iters: 7104, time: 0.155, data: 0.008) loss: 1.045 
(epoch: 34, iters: 7184, time: 0.150, data: 0.000) loss: 1.163 
(epoch: 34, iters: 7264, time: 0.149, data: 0.000) loss: 1.125 
(epoch: 34, iters: 7344, time: 0.148, data: 0.009) loss: 0.856 
(epoch: 34, iters: 7424, time: 0.148, data: 0.019) loss: 1.573 
(epoch: 34, iters: 7504, time: 0.150, data: 0.000) loss: 1.542 
(epoch: 34, iters: 7584, time: 0.149, data: 0.000) loss: 1.340 
(epoch: 34, iters: 7664, time: 0.150, data: 0.000) loss: 0.850 
(epoch: 34, iters: 7744, time: 0.149, data: 0.020) loss: 1.093 
(epoch: 34, iters: 7824, time: 0.147, data: 0.000) loss: 1.514 
(epoch: 34, iters: 7904, time: 0.152, data: 0.005) loss: 1.009 
(epoch: 34, iters: 7984, time: 0.149, data: 0.019) loss: 0.956 
saving the latest model (epoch 34, total_steps 344352)
(epoch: 34, iters: 8064, time: 0.149, data: 0.005) loss: 1.473 
(epoch: 34, iters: 8144, time: 0.150, data: 0.014) loss: 1.430 
(epoch: 34, iters: 8224, time: 0.151, data: 0.000) loss: 0.859 
(epoch: 34, iters: 8304, time: 0.149, data: 0.011) loss: 1.527 
(epoch: 34, iters: 8384, time: 0.147, data: 0.005) loss: 1.551 
(epoch: 34, iters: 8464, time: 0.149, data: 0.005) loss: 0.741 
(epoch: 34, iters: 8544, time: 0.150, data: 0.005) loss: 1.553 
(epoch: 34, iters: 8624, time: 0.150, data: 0.000) loss: 1.213 
(epoch: 34, iters: 8704, time: 0.151, data: 0.000) loss: 1.613 
(epoch: 34, iters: 8784, time: 0.148, data: 0.000) loss: 0.973 
(epoch: 34, iters: 8864, time: 0.151, data: 0.005) loss: 1.161 
(epoch: 34, iters: 8944, time: 0.153, data: 0.000) loss: 0.599 
(epoch: 34, iters: 9024, time: 0.150, data: 0.015) loss: 1.067 
(epoch: 34, iters: 9104, time: 0.148, data: 0.000) loss: 1.026 
(epoch: 34, iters: 9184, time: 0.149, data: 0.005) loss: 1.264 
(epoch: 34, iters: 9264, time: 0.149, data: 0.024) loss: 0.965 
(epoch: 34, iters: 9344, time: 0.149, data: 0.000) loss: 1.377 
(epoch: 34, iters: 9424, time: 0.150, data: 0.000) loss: 1.192 
(epoch: 34, iters: 9504, time: 0.150, data: 0.000) loss: 0.742 
(epoch: 34, iters: 9584, time: 0.149, data: 0.000) loss: 0.720 
(epoch: 34, iters: 9664, time: 0.147, data: 0.000) loss: 0.743 
(epoch: 34, iters: 9744, time: 0.151, data: 0.000) loss: 1.186 
(epoch: 34, iters: 9824, time: 0.147, data: 0.000) loss: 0.762 
(epoch: 34, iters: 9904, time: 0.148, data: 0.015) loss: 0.842 
(epoch: 34, iters: 9984, time: 0.148, data: 0.023) loss: 0.721 
(epoch: 34, iters: 10064, time: 0.147, data: 0.000) loss: 1.826 
(epoch: 34, iters: 10144, time: 0.147, data: 0.000) loss: 0.926 
saving the model at the end of epoch 34, iters 346528
End of epoch 34 / 200 	 Time Taken: 1529 sec
learning rate = 0.0002000
saving the latest model (epoch 35, total_steps 346544)
(epoch: 35, iters: 32, time: 0.158, data: 0.000) loss: 1.411 
(epoch: 35, iters: 112, time: 0.151, data: 0.000) loss: 0.563 
(epoch: 35, iters: 192, time: 0.151, data: 0.013) loss: 1.041 
(epoch: 35, iters: 272, time: 0.150, data: 0.009) loss: 1.698 
(epoch: 35, iters: 352, time: 0.151, data: 0.000) loss: 1.213 
(epoch: 35, iters: 432, time: 0.149, data: 0.014) loss: 0.842 
(epoch: 35, iters: 512, time: 0.151, data: 0.005) loss: 0.955 
(epoch: 35, iters: 592, time: 0.150, data: 0.000) loss: 0.702 
(epoch: 35, iters: 672, time: 0.149, data: 0.000) loss: 0.751 
(epoch: 35, iters: 752, time: 0.149, data: 0.008) loss: 1.055 
(epoch: 35, iters: 832, time: 0.149, data: 0.005) loss: 1.075 
(epoch: 35, iters: 912, time: 0.150, data: 0.000) loss: 0.535 
(epoch: 35, iters: 992, time: 0.148, data: 0.027) loss: 1.104 
(epoch: 35, iters: 1072, time: 0.147, data: 0.000) loss: 0.818 
(epoch: 35, iters: 1152, time: 0.149, data: 0.010) loss: 0.593 
(epoch: 35, iters: 1232, time: 0.151, data: 0.000) loss: 1.555 
(epoch: 35, iters: 1312, time: 0.149, data: 0.000) loss: 0.761 
(epoch: 35, iters: 1392, time: 0.149, data: 0.009) loss: 0.643 
(epoch: 35, iters: 1472, time: 0.149, data: 0.000) loss: 1.530 
(epoch: 35, iters: 1552, time: 0.150, data: 0.000) loss: 0.826 
(epoch: 35, iters: 1632, time: 0.149, data: 0.019) loss: 1.119 
(epoch: 35, iters: 1712, time: 0.149, data: 0.023) loss: 0.716 
(epoch: 35, iters: 1792, time: 0.150, data: 0.000) loss: 0.968 
(epoch: 35, iters: 1872, time: 0.150, data: 0.017) loss: 0.952 
(epoch: 35, iters: 1952, time: 0.147, data: 0.005) loss: 0.959 
(epoch: 35, iters: 2032, time: 0.153, data: 0.000) loss: 0.537 
(epoch: 35, iters: 2112, time: 0.153, data: 0.031) loss: 0.604 
(epoch: 35, iters: 2192, time: 0.152, data: 0.000) loss: 0.647 
(epoch: 35, iters: 2272, time: 0.152, data: 0.010) loss: 1.153 
(epoch: 35, iters: 2352, time: 0.149, data: 0.005) loss: 1.268 
(epoch: 35, iters: 2432, time: 0.151, data: 0.000) loss: 1.445 
(epoch: 35, iters: 2512, time: 0.149, data: 0.000) loss: 1.709 
(epoch: 35, iters: 2592, time: 0.153, data: 0.021) loss: 0.913 
(epoch: 35, iters: 2672, time: 0.152, data: 0.005) loss: 1.257 
(epoch: 35, iters: 2752, time: 0.151, data: 0.006) loss: 1.284 
(epoch: 35, iters: 2832, time: 0.150, data: 0.014) loss: 1.685 
(epoch: 35, iters: 2912, time: 0.150, data: 0.032) loss: 0.981 
(epoch: 35, iters: 2992, time: 0.152, data: 0.000) loss: 0.791 
(epoch: 35, iters: 3072, time: 0.150, data: 0.000) loss: 0.950 
(epoch: 35, iters: 3152, time: 0.150, data: 0.000) loss: 1.152 
(epoch: 35, iters: 3232, time: 0.148, data: 0.024) loss: 0.781 
(epoch: 35, iters: 3312, time: 0.149, data: 0.009) loss: 0.691 
(epoch: 35, iters: 3392, time: 0.149, data: 0.013) loss: 1.533 
(epoch: 35, iters: 3472, time: 0.149, data: 0.000) loss: 1.025 
(epoch: 35, iters: 3552, time: 0.148, data: 0.000) loss: 0.758 
(epoch: 35, iters: 3632, time: 0.151, data: 0.005) loss: 0.818 
(epoch: 35, iters: 3712, time: 0.152, data: 0.000) loss: 0.807 
(epoch: 35, iters: 3792, time: 0.152, data: 0.005) loss: 1.225 
(epoch: 35, iters: 3872, time: 0.152, data: 0.005) loss: 0.702 
(epoch: 35, iters: 3952, time: 0.152, data: 0.000) loss: 1.189 
saving the latest model (epoch 35, total_steps 350544)
(epoch: 35, iters: 4032, time: 0.152, data: 0.000) loss: 1.254 
(epoch: 35, iters: 4112, time: 0.153, data: 0.000) loss: 1.075 
(epoch: 35, iters: 4192, time: 0.152, data: 0.006) loss: 0.794 
(epoch: 35, iters: 4272, time: 0.151, data: 0.000) loss: 1.109 
(epoch: 35, iters: 4352, time: 0.151, data: 0.016) loss: 0.560 
(epoch: 35, iters: 4432, time: 0.151, data: 0.000) loss: 1.011 
(epoch: 35, iters: 4512, time: 0.151, data: 0.000) loss: 0.899 
(epoch: 35, iters: 4592, time: 0.153, data: 0.030) loss: 0.679 
(epoch: 35, iters: 4672, time: 0.151, data: 0.023) loss: 0.980 
(epoch: 35, iters: 4752, time: 0.153, data: 0.029) loss: 0.926 
(epoch: 35, iters: 4832, time: 0.151, data: 0.000) loss: 1.535 
(epoch: 35, iters: 4912, time: 0.149, data: 0.000) loss: 0.995 
(epoch: 35, iters: 4992, time: 0.156, data: 0.008) loss: 1.175 
(epoch: 35, iters: 5072, time: 0.150, data: 0.005) loss: 1.936 
(epoch: 35, iters: 5152, time: 0.149, data: 0.017) loss: 0.990 
(epoch: 35, iters: 5232, time: 0.151, data: 0.000) loss: 0.863 
(epoch: 35, iters: 5312, time: 0.153, data: 0.014) loss: 0.676 
(epoch: 35, iters: 5392, time: 0.152, data: 0.005) loss: 1.544 
(epoch: 35, iters: 5472, time: 0.150, data: 0.000) loss: 0.887 
(epoch: 35, iters: 5552, time: 0.151, data: 0.033) loss: 0.909 
(epoch: 35, iters: 5632, time: 0.152, data: 0.000) loss: 1.261 
(epoch: 35, iters: 5712, time: 0.150, data: 0.022) loss: 0.629 
(epoch: 35, iters: 5792, time: 0.154, data: 0.000) loss: 0.724 
(epoch: 35, iters: 5872, time: 0.149, data: 0.016) loss: 0.363 
(epoch: 35, iters: 5952, time: 0.150, data: 0.000) loss: 0.613 
(epoch: 35, iters: 6032, time: 0.152, data: 0.008) loss: 1.512 
(epoch: 35, iters: 6112, time: 0.154, data: 0.000) loss: 1.164 
(epoch: 35, iters: 6192, time: 0.153, data: 0.014) loss: 0.764 
(epoch: 35, iters: 6272, time: 0.155, data: 0.008) loss: 1.384 
(epoch: 35, iters: 6352, time: 0.153, data: 0.000) loss: 1.064 
(epoch: 35, iters: 6432, time: 0.152, data: 0.021) loss: 0.495 
(epoch: 35, iters: 6512, time: 0.155, data: 0.005) loss: 1.082 
(epoch: 35, iters: 6592, time: 0.152, data: 0.009) loss: 0.819 
(epoch: 35, iters: 6672, time: 0.152, data: 0.000) loss: 1.156 
(epoch: 35, iters: 6752, time: 0.153, data: 0.023) loss: 1.271 
(epoch: 35, iters: 6832, time: 0.153, data: 0.006) loss: 0.864 
(epoch: 35, iters: 6912, time: 0.153, data: 0.018) loss: 0.648 
(epoch: 35, iters: 6992, time: 0.154, data: 0.000) loss: 1.153 
(epoch: 35, iters: 7072, time: 0.153, data: 0.020) loss: 1.272 
(epoch: 35, iters: 7152, time: 0.152, data: 0.000) loss: 0.616 
(epoch: 35, iters: 7232, time: 0.151, data: 0.020) loss: 1.038 
(epoch: 35, iters: 7312, time: 0.152, data: 0.008) loss: 1.120 
(epoch: 35, iters: 7392, time: 0.149, data: 0.000) loss: 1.104 
(epoch: 35, iters: 7472, time: 0.149, data: 0.020) loss: 1.331 
(epoch: 35, iters: 7552, time: 0.150, data: 0.006) loss: 1.026 
(epoch: 35, iters: 7632, time: 0.149, data: 0.024) loss: 0.899 
(epoch: 35, iters: 7712, time: 0.150, data: 0.000) loss: 0.671 
(epoch: 35, iters: 7792, time: 0.153, data: 0.005) loss: 0.820 
(epoch: 35, iters: 7872, time: 0.152, data: 0.000) loss: 0.734 
(epoch: 35, iters: 7952, time: 0.150, data: 0.000) loss: 1.196 
saving the latest model (epoch 35, total_steps 354544)
(epoch: 35, iters: 8032, time: 0.153, data: 0.009) loss: 1.088 
(epoch: 35, iters: 8112, time: 0.152, data: 0.013) loss: 0.738 
(epoch: 35, iters: 8192, time: 0.150, data: 0.016) loss: 1.145 
(epoch: 35, iters: 8272, time: 0.150, data: 0.000) loss: 1.330 
(epoch: 35, iters: 8352, time: 0.151, data: 0.005) loss: 2.063 
(epoch: 35, iters: 8432, time: 0.150, data: 0.000) loss: 0.619 
(epoch: 35, iters: 8512, time: 0.149, data: 0.017) loss: 1.131 
(epoch: 35, iters: 8592, time: 0.147, data: 0.000) loss: 1.476 
(epoch: 35, iters: 8672, time: 0.152, data: 0.028) loss: 1.162 
(epoch: 35, iters: 8752, time: 0.148, data: 0.000) loss: 0.693 
(epoch: 35, iters: 8832, time: 0.149, data: 0.031) loss: 0.946 
(epoch: 35, iters: 8912, time: 0.146, data: 0.000) loss: 1.226 
(epoch: 35, iters: 8992, time: 0.152, data: 0.000) loss: 0.801 
(epoch: 35, iters: 9072, time: 0.153, data: 0.000) loss: 1.443 
(epoch: 35, iters: 9152, time: 0.150, data: 0.000) loss: 0.862 
(epoch: 35, iters: 9232, time: 0.149, data: 0.000) loss: 0.699 
(epoch: 35, iters: 9312, time: 0.148, data: 0.000) loss: 1.528 
(epoch: 35, iters: 9392, time: 0.151, data: 0.015) loss: 0.863 
(epoch: 35, iters: 9472, time: 0.149, data: 0.014) loss: 0.883 
(epoch: 35, iters: 9552, time: 0.149, data: 0.005) loss: 0.941 
(epoch: 35, iters: 9632, time: 0.149, data: 0.000) loss: 1.659 
(epoch: 35, iters: 9712, time: 0.153, data: 0.005) loss: 0.792 
(epoch: 35, iters: 9792, time: 0.149, data: 0.000) loss: 0.690 
(epoch: 35, iters: 9872, time: 0.149, data: 0.014) loss: 0.647 
(epoch: 35, iters: 9952, time: 0.151, data: 0.000) loss: 0.966 
(epoch: 35, iters: 10032, time: 0.149, data: 0.005) loss: 0.694 
(epoch: 35, iters: 10112, time: 0.150, data: 0.010) loss: 0.883 
(epoch: 35, iters: 10192, time: 0.089, data: 0.009) loss: 1.393 
saving the model at the end of epoch 35, iters 356720
End of epoch 35 / 200 	 Time Taken: 1540 sec
learning rate = 0.0002000
saving the latest model (epoch 36, total_steps 356736)
(epoch: 36, iters: 80, time: 0.154, data: 0.294) loss: 0.859 
(epoch: 36, iters: 160, time: 0.149, data: 0.000) loss: 0.661 
(epoch: 36, iters: 240, time: 0.149, data: 0.000) loss: 0.965 
(epoch: 36, iters: 320, time: 0.150, data: 0.000) loss: 0.406 
(epoch: 36, iters: 400, time: 0.150, data: 0.020) loss: 0.525 
(epoch: 36, iters: 480, time: 0.149, data: 0.000) loss: 0.964 
(epoch: 36, iters: 560, time: 0.150, data: 0.013) loss: 0.997 
(epoch: 36, iters: 640, time: 0.146, data: 0.000) loss: 1.371 
(epoch: 36, iters: 720, time: 0.146, data: 0.005) loss: 1.241 
(epoch: 36, iters: 800, time: 0.147, data: 0.000) loss: 0.900 
(epoch: 36, iters: 880, time: 0.148, data: 0.027) loss: 0.601 
(epoch: 36, iters: 960, time: 0.147, data: 0.010) loss: 1.341 
(epoch: 36, iters: 1040, time: 0.151, data: 0.000) loss: 0.868 
(epoch: 36, iters: 1120, time: 0.149, data: 0.026) loss: 1.142 
(epoch: 36, iters: 1200, time: 0.153, data: 0.000) loss: 1.076 
(epoch: 36, iters: 1280, time: 0.149, data: 0.025) loss: 1.208 
(epoch: 36, iters: 1360, time: 0.150, data: 0.000) loss: 0.992 
(epoch: 36, iters: 1440, time: 0.149, data: 0.008) loss: 0.559 
(epoch: 36, iters: 1520, time: 0.150, data: 0.000) loss: 1.077 
(epoch: 36, iters: 1600, time: 0.150, data: 0.030) loss: 0.399 
(epoch: 36, iters: 1680, time: 0.149, data: 0.000) loss: 1.385 
(epoch: 36, iters: 1760, time: 0.150, data: 0.000) loss: 1.223 
(epoch: 36, iters: 1840, time: 0.150, data: 0.005) loss: 0.716 
(epoch: 36, iters: 1920, time: 0.151, data: 0.000) loss: 0.855 
(epoch: 36, iters: 2000, time: 0.146, data: 0.017) loss: 0.957 
(epoch: 36, iters: 2080, time: 0.152, data: 0.000) loss: 1.414 
(epoch: 36, iters: 2160, time: 0.149, data: 0.010) loss: 1.071 
(epoch: 36, iters: 2240, time: 0.152, data: 0.000) loss: 0.896 
(epoch: 36, iters: 2320, time: 0.146, data: 0.005) loss: 1.002 
(epoch: 36, iters: 2400, time: 0.151, data: 0.031) loss: 0.921 
(epoch: 36, iters: 2480, time: 0.151, data: 0.000) loss: 1.107 
(epoch: 36, iters: 2560, time: 0.150, data: 0.024) loss: 0.891 
(epoch: 36, iters: 2640, time: 0.148, data: 0.000) loss: 1.086 
(epoch: 36, iters: 2720, time: 0.149, data: 0.000) loss: 2.008 
(epoch: 36, iters: 2800, time: 0.150, data: 0.000) loss: 0.635 
(epoch: 36, iters: 2880, time: 0.150, data: 0.023) loss: 0.823 
(epoch: 36, iters: 2960, time: 0.151, data: 0.023) loss: 1.695 
(epoch: 36, iters: 3040, time: 0.151, data: 0.000) loss: 1.138 
(epoch: 36, iters: 3120, time: 0.153, data: 0.000) loss: 0.772 
(epoch: 36, iters: 3200, time: 0.150, data: 0.018) loss: 1.008 
(epoch: 36, iters: 3280, time: 0.150, data: 0.000) loss: 1.332 
(epoch: 36, iters: 3360, time: 0.151, data: 0.000) loss: 0.834 
(epoch: 36, iters: 3440, time: 0.149, data: 0.000) loss: 0.890 
(epoch: 36, iters: 3520, time: 0.154, data: 0.000) loss: 1.391 
(epoch: 36, iters: 3600, time: 0.149, data: 0.000) loss: 0.562 
(epoch: 36, iters: 3680, time: 0.148, data: 0.028) loss: 1.404 
(epoch: 36, iters: 3760, time: 0.150, data: 0.000) loss: 1.249 
(epoch: 36, iters: 3840, time: 0.151, data: 0.011) loss: 0.849 
(epoch: 36, iters: 3920, time: 0.153, data: 0.000) loss: 0.930 
(epoch: 36, iters: 4000, time: 0.150, data: 0.024) loss: 0.877 
saving the latest model (epoch 36, total_steps 360736)
(epoch: 36, iters: 4080, time: 0.154, data: 0.000) loss: 1.424 
(epoch: 36, iters: 4160, time: 0.156, data: 0.010) loss: 1.071 
(epoch: 36, iters: 4240, time: 0.153, data: 0.000) loss: 1.384 
(epoch: 36, iters: 4320, time: 0.154, data: 0.000) loss: 1.208 
(epoch: 36, iters: 4400, time: 0.151, data: 0.005) loss: 0.924 
(epoch: 36, iters: 4480, time: 0.152, data: 0.000) loss: 0.449 
(epoch: 36, iters: 4560, time: 0.153, data: 0.000) loss: 0.763 
(epoch: 36, iters: 4640, time: 0.150, data: 0.000) loss: 0.905 
(epoch: 36, iters: 4720, time: 0.154, data: 0.000) loss: 1.487 
(epoch: 36, iters: 4800, time: 0.155, data: 0.000) loss: 1.115 
(epoch: 36, iters: 4880, time: 0.154, data: 0.005) loss: 0.803 
(epoch: 36, iters: 4960, time: 0.150, data: 0.000) loss: 0.879 
(epoch: 36, iters: 5040, time: 0.151, data: 0.000) loss: 0.904 
(epoch: 36, iters: 5120, time: 0.155, data: 0.021) loss: 1.195 
(epoch: 36, iters: 5200, time: 0.151, data: 0.013) loss: 0.917 
(epoch: 36, iters: 5280, time: 0.149, data: 0.000) loss: 0.734 
(epoch: 36, iters: 5360, time: 0.152, data: 0.013) loss: 0.916 
(epoch: 36, iters: 5440, time: 0.151, data: 0.000) loss: 1.729 
(epoch: 36, iters: 5520, time: 0.155, data: 0.000) loss: 1.188 
(epoch: 36, iters: 5600, time: 0.153, data: 0.009) loss: 0.944 
(epoch: 36, iters: 5680, time: 0.150, data: 0.022) loss: 1.116 
(epoch: 36, iters: 5760, time: 0.150, data: 0.000) loss: 1.277 
(epoch: 36, iters: 5840, time: 0.155, data: 0.000) loss: 0.920 
(epoch: 36, iters: 5920, time: 0.150, data: 0.000) loss: 1.048 
(epoch: 36, iters: 6000, time: 0.152, data: 0.005) loss: 1.677 
(epoch: 36, iters: 6080, time: 0.150, data: 0.016) loss: 0.608 
(epoch: 36, iters: 6160, time: 0.151, data: 0.000) loss: 0.910 
(epoch: 36, iters: 6240, time: 0.153, data: 0.005) loss: 0.726 
(epoch: 36, iters: 6320, time: 0.154, data: 0.018) loss: 0.998 
(epoch: 36, iters: 6400, time: 0.151, data: 0.000) loss: 0.600 
(epoch: 36, iters: 6480, time: 0.150, data: 0.000) loss: 0.758 
(epoch: 36, iters: 6560, time: 0.152, data: 0.000) loss: 0.572 
(epoch: 36, iters: 6640, time: 0.149, data: 0.000) loss: 1.095 
(epoch: 36, iters: 6720, time: 0.151, data: 0.000) loss: 0.525 
(epoch: 36, iters: 6800, time: 0.150, data: 0.010) loss: 1.040 
(epoch: 36, iters: 6880, time: 0.149, data: 0.000) loss: 1.319 
(epoch: 36, iters: 6960, time: 0.150, data: 0.005) loss: 1.610 
(epoch: 36, iters: 7040, time: 0.152, data: 0.000) loss: 1.736 
(epoch: 36, iters: 7120, time: 0.153, data: 0.000) loss: 0.673 
(epoch: 36, iters: 7200, time: 0.151, data: 0.015) loss: 1.202 
(epoch: 36, iters: 7280, time: 0.153, data: 0.004) loss: 0.826 
(epoch: 36, iters: 7360, time: 0.154, data: 0.009) loss: 0.844 
(epoch: 36, iters: 7440, time: 0.152, data: 0.005) loss: 1.044 
(epoch: 36, iters: 7520, time: 0.154, data: 0.005) loss: 0.841 
(epoch: 36, iters: 7600, time: 0.153, data: 0.024) loss: 1.051 
(epoch: 36, iters: 7680, time: 0.148, data: 0.000) loss: 1.391 
(epoch: 36, iters: 7760, time: 0.149, data: 0.000) loss: 1.124 
(epoch: 36, iters: 7840, time: 0.151, data: 0.000) loss: 1.530 
(epoch: 36, iters: 7920, time: 0.153, data: 0.006) loss: 1.270 
(epoch: 36, iters: 8000, time: 0.151, data: 0.006) loss: 0.679 
saving the latest model (epoch 36, total_steps 364736)
(epoch: 36, iters: 8080, time: 0.150, data: 0.005) loss: 1.150 
(epoch: 36, iters: 8160, time: 0.150, data: 0.000) loss: 0.799 
(epoch: 36, iters: 8240, time: 0.149, data: 0.014) loss: 1.706 
(epoch: 36, iters: 8320, time: 0.148, data: 0.000) loss: 0.765 
(epoch: 36, iters: 8400, time: 0.150, data: 0.000) loss: 0.943 
(epoch: 36, iters: 8480, time: 0.150, data: 0.005) loss: 1.306 
(epoch: 36, iters: 8560, time: 0.148, data: 0.000) loss: 0.967 
(epoch: 36, iters: 8640, time: 0.152, data: 0.000) loss: 0.932 
(epoch: 36, iters: 8720, time: 0.156, data: 0.005) loss: 0.831 
(epoch: 36, iters: 8800, time: 0.153, data: 0.000) loss: 1.543 
(epoch: 36, iters: 8880, time: 0.151, data: 0.005) loss: 1.400 
(epoch: 36, iters: 8960, time: 0.152, data: 0.000) loss: 0.970 
(epoch: 36, iters: 9040, time: 0.152, data: 0.000) loss: 0.618 
(epoch: 36, iters: 9120, time: 0.152, data: 0.000) loss: 0.506 
(epoch: 36, iters: 9200, time: 0.152, data: 0.024) loss: 1.018 
(epoch: 36, iters: 9280, time: 0.151, data: 0.000) loss: 1.038 
(epoch: 36, iters: 9360, time: 0.150, data: 0.000) loss: 1.441 
(epoch: 36, iters: 9440, time: 0.150, data: 0.000) loss: 1.066 
(epoch: 36, iters: 9520, time: 0.150, data: 0.005) loss: 0.829 
(epoch: 36, iters: 9600, time: 0.148, data: 0.005) loss: 0.598 
(epoch: 36, iters: 9680, time: 0.150, data: 0.009) loss: 0.668 
(epoch: 36, iters: 9760, time: 0.147, data: 0.000) loss: 1.024 
(epoch: 36, iters: 9840, time: 0.151, data: 0.011) loss: 1.673 
(epoch: 36, iters: 9920, time: 0.150, data: 0.000) loss: 1.210 
(epoch: 36, iters: 10000, time: 0.147, data: 0.000) loss: 0.710 
(epoch: 36, iters: 10080, time: 0.150, data: 0.026) loss: 0.903 
(epoch: 36, iters: 10160, time: 0.146, data: 0.000) loss: 0.973 
saving the model at the end of epoch 36, iters 366912
End of epoch 36 / 200 	 Time Taken: 1540 sec
learning rate = 0.0002000
saving the latest model (epoch 37, total_steps 366928)
(epoch: 37, iters: 48, time: 0.153, data: 0.000) loss: 0.526 
(epoch: 37, iters: 128, time: 0.151, data: 0.011) loss: 0.738 
(epoch: 37, iters: 208, time: 0.150, data: 0.000) loss: 1.203 
(epoch: 37, iters: 288, time: 0.150, data: 0.017) loss: 1.034 
(epoch: 37, iters: 368, time: 0.150, data: 0.005) loss: 0.836 
(epoch: 37, iters: 448, time: 0.149, data: 0.000) loss: 1.099 
(epoch: 37, iters: 528, time: 0.154, data: 0.006) loss: 1.084 
(epoch: 37, iters: 608, time: 0.153, data: 0.016) loss: 1.090 
(epoch: 37, iters: 688, time: 0.151, data: 0.005) loss: 1.049 
(epoch: 37, iters: 768, time: 0.149, data: 0.005) loss: 1.032 
(epoch: 37, iters: 848, time: 0.147, data: 0.005) loss: 1.064 
(epoch: 37, iters: 928, time: 0.146, data: 0.000) loss: 2.009 
(epoch: 37, iters: 1008, time: 0.149, data: 0.009) loss: 0.639 
(epoch: 37, iters: 1088, time: 0.149, data: 0.000) loss: 1.333 
(epoch: 37, iters: 1168, time: 0.150, data: 0.000) loss: 1.260 
(epoch: 37, iters: 1248, time: 0.151, data: 0.005) loss: 0.727 
(epoch: 37, iters: 1328, time: 0.153, data: 0.000) loss: 1.775 
(epoch: 37, iters: 1408, time: 0.149, data: 0.000) loss: 1.345 
(epoch: 37, iters: 1488, time: 0.147, data: 0.014) loss: 1.718 
(epoch: 37, iters: 1568, time: 0.147, data: 0.000) loss: 0.944 
(epoch: 37, iters: 1648, time: 0.147, data: 0.000) loss: 0.797 
(epoch: 37, iters: 1728, time: 0.148, data: 0.005) loss: 2.098 
(epoch: 37, iters: 1808, time: 0.150, data: 0.006) loss: 0.776 
(epoch: 37, iters: 1888, time: 0.148, data: 0.015) loss: 0.888 
(epoch: 37, iters: 1968, time: 0.148, data: 0.009) loss: 0.782 
(epoch: 37, iters: 2048, time: 0.150, data: 0.000) loss: 0.834 
(epoch: 37, iters: 2128, time: 0.153, data: 0.000) loss: 0.758 
(epoch: 37, iters: 2208, time: 0.148, data: 0.005) loss: 1.210 
(epoch: 37, iters: 2288, time: 0.148, data: 0.000) loss: 0.823 
(epoch: 37, iters: 2368, time: 0.151, data: 0.009) loss: 0.919 
(epoch: 37, iters: 2448, time: 0.154, data: 0.010) loss: 0.322 
(epoch: 37, iters: 2528, time: 0.150, data: 0.021) loss: 1.799 
(epoch: 37, iters: 2608, time: 0.154, data: 0.005) loss: 0.857 
(epoch: 37, iters: 2688, time: 0.150, data: 0.013) loss: 1.674 
(epoch: 37, iters: 2768, time: 0.148, data: 0.000) loss: 0.915 
(epoch: 37, iters: 2848, time: 0.147, data: 0.000) loss: 1.258 
(epoch: 37, iters: 2928, time: 0.149, data: 0.015) loss: 1.314 
(epoch: 37, iters: 3008, time: 0.148, data: 0.000) loss: 1.476 
(epoch: 37, iters: 3088, time: 0.150, data: 0.034) loss: 1.117 
(epoch: 37, iters: 3168, time: 0.150, data: 0.000) loss: 1.421 
(epoch: 37, iters: 3248, time: 0.151, data: 0.011) loss: 0.891 
(epoch: 37, iters: 3328, time: 0.150, data: 0.005) loss: 1.265 
(epoch: 37, iters: 3408, time: 0.152, data: 0.040) loss: 0.993 
(epoch: 37, iters: 3488, time: 0.152, data: 0.000) loss: 1.293 
(epoch: 37, iters: 3568, time: 0.151, data: 0.024) loss: 1.594 
(epoch: 37, iters: 3648, time: 0.151, data: 0.000) loss: 0.939 
(epoch: 37, iters: 3728, time: 0.154, data: 0.000) loss: 0.841 
(epoch: 37, iters: 3808, time: 0.151, data: 0.000) loss: 1.123 
(epoch: 37, iters: 3888, time: 0.155, data: 0.000) loss: 0.964 
(epoch: 37, iters: 3968, time: 0.152, data: 0.027) loss: 0.884 
saving the latest model (epoch 37, total_steps 370928)
(epoch: 37, iters: 4048, time: 0.151, data: 0.000) loss: 1.861 
(epoch: 37, iters: 4128, time: 0.151, data: 0.032) loss: 0.559 
(epoch: 37, iters: 4208, time: 0.152, data: 0.000) loss: 0.986 
(epoch: 37, iters: 4288, time: 0.150, data: 0.013) loss: 1.095 
(epoch: 37, iters: 4368, time: 0.151, data: 0.000) loss: 1.468 
(epoch: 37, iters: 4448, time: 0.154, data: 0.000) loss: 1.320 
(epoch: 37, iters: 4528, time: 0.152, data: 0.005) loss: 1.261 
(epoch: 37, iters: 4608, time: 0.153, data: 0.018) loss: 0.853 
(epoch: 37, iters: 4688, time: 0.148, data: 0.000) loss: 1.086 
(epoch: 37, iters: 4768, time: 0.149, data: 0.023) loss: 0.947 
(epoch: 37, iters: 4848, time: 0.149, data: 0.000) loss: 1.057 
(epoch: 37, iters: 4928, time: 0.149, data: 0.000) loss: 0.945 
(epoch: 37, iters: 5008, time: 0.149, data: 0.016) loss: 1.159 
(epoch: 37, iters: 5088, time: 0.150, data: 0.000) loss: 0.944 
(epoch: 37, iters: 5168, time: 0.153, data: 0.005) loss: 0.764 
(epoch: 37, iters: 5248, time: 0.151, data: 0.000) loss: 0.829 
(epoch: 37, iters: 5328, time: 0.152, data: 0.008) loss: 0.764 
(epoch: 37, iters: 5408, time: 0.150, data: 0.022) loss: 0.752 
(epoch: 37, iters: 5488, time: 0.148, data: 0.000) loss: 1.234 
(epoch: 37, iters: 5568, time: 0.150, data: 0.000) loss: 1.071 
(epoch: 37, iters: 5648, time: 0.153, data: 0.018) loss: 0.867 
(epoch: 37, iters: 5728, time: 0.150, data: 0.000) loss: 0.747 
(epoch: 37, iters: 5808, time: 0.151, data: 0.000) loss: 0.702 
(epoch: 37, iters: 5888, time: 0.149, data: 0.000) loss: 0.703 
(epoch: 37, iters: 5968, time: 0.149, data: 0.000) loss: 0.460 
(epoch: 37, iters: 6048, time: 0.150, data: 0.023) loss: 1.562 
(epoch: 37, iters: 6128, time: 0.152, data: 0.000) loss: 0.627 
(epoch: 37, iters: 6208, time: 0.149, data: 0.023) loss: 0.751 
(epoch: 37, iters: 6288, time: 0.153, data: 0.000) loss: 0.645 
(epoch: 37, iters: 6368, time: 0.148, data: 0.005) loss: 0.971 
(epoch: 37, iters: 6448, time: 0.148, data: 0.000) loss: 1.301 
(epoch: 37, iters: 6528, time: 0.148, data: 0.000) loss: 1.368 
(epoch: 37, iters: 6608, time: 0.150, data: 0.020) loss: 1.086 
(epoch: 37, iters: 6688, time: 0.151, data: 0.000) loss: 1.434 
(epoch: 37, iters: 6768, time: 0.149, data: 0.024) loss: 0.744 
(epoch: 37, iters: 6848, time: 0.148, data: 0.000) loss: 1.119 
(epoch: 37, iters: 6928, time: 0.150, data: 0.005) loss: 0.817 
(epoch: 37, iters: 7008, time: 0.150, data: 0.033) loss: 1.055 
(epoch: 37, iters: 7088, time: 0.149, data: 0.000) loss: 1.009 
(epoch: 37, iters: 7168, time: 0.148, data: 0.013) loss: 1.013 
(epoch: 37, iters: 7248, time: 0.149, data: 0.004) loss: 0.610 
(epoch: 37, iters: 7328, time: 0.149, data: 0.000) loss: 0.860 
(epoch: 37, iters: 7408, time: 0.148, data: 0.005) loss: 1.200 
(epoch: 37, iters: 7488, time: 0.147, data: 0.025) loss: 1.032 
(epoch: 37, iters: 7568, time: 0.148, data: 0.000) loss: 0.969 
(epoch: 37, iters: 7648, time: 0.150, data: 0.000) loss: 0.764 
(epoch: 37, iters: 7728, time: 0.152, data: 0.000) loss: 1.117 
(epoch: 37, iters: 7808, time: 0.153, data: 0.000) loss: 0.921 
(epoch: 37, iters: 7888, time: 0.152, data: 0.024) loss: 0.748 
(epoch: 37, iters: 7968, time: 0.150, data: 0.000) loss: 1.478 
saving the latest model (epoch 37, total_steps 374928)
(epoch: 37, iters: 8048, time: 0.151, data: 0.005) loss: 1.212 
(epoch: 37, iters: 8128, time: 0.150, data: 0.000) loss: 1.567 
(epoch: 37, iters: 8208, time: 0.151, data: 0.000) loss: 0.621 
(epoch: 37, iters: 8288, time: 0.150, data: 0.000) loss: 0.863 
(epoch: 37, iters: 8368, time: 0.152, data: 0.021) loss: 0.691 
(epoch: 37, iters: 8448, time: 0.148, data: 0.006) loss: 0.380 
(epoch: 37, iters: 8528, time: 0.149, data: 0.009) loss: 0.836 
(epoch: 37, iters: 8608, time: 0.150, data: 0.005) loss: 1.389 
(epoch: 37, iters: 8688, time: 0.146, data: 0.000) loss: 0.996 
(epoch: 37, iters: 8768, time: 0.152, data: 0.017) loss: 1.159 
(epoch: 37, iters: 8848, time: 0.149, data: 0.000) loss: 1.236 
(epoch: 37, iters: 8928, time: 0.148, data: 0.021) loss: 1.074 
(epoch: 37, iters: 9008, time: 0.150, data: 0.005) loss: 0.747 
(epoch: 37, iters: 9088, time: 0.148, data: 0.033) loss: 1.426 
(epoch: 37, iters: 9168, time: 0.149, data: 0.000) loss: 0.519 
(epoch: 37, iters: 9248, time: 0.151, data: 0.017) loss: 1.707 
(epoch: 37, iters: 9328, time: 0.150, data: 0.025) loss: 1.361 
(epoch: 37, iters: 9408, time: 0.151, data: 0.000) loss: 0.675 
(epoch: 37, iters: 9488, time: 0.149, data: 0.000) loss: 0.842 
(epoch: 37, iters: 9568, time: 0.151, data: 0.015) loss: 0.680 
(epoch: 37, iters: 9648, time: 0.148, data: 0.000) loss: 1.602 
(epoch: 37, iters: 9728, time: 0.151, data: 0.015) loss: 1.623 
(epoch: 37, iters: 9808, time: 0.150, data: 0.005) loss: 0.571 
(epoch: 37, iters: 9888, time: 0.153, data: 0.000) loss: 1.280 
(epoch: 37, iters: 9968, time: 0.147, data: 0.000) loss: 0.960 
(epoch: 37, iters: 10048, time: 0.148, data: 0.005) loss: 0.813 
(epoch: 37, iters: 10128, time: 0.148, data: 0.008) loss: 0.955 
saving the model at the end of epoch 37, iters 377104
End of epoch 37 / 200 	 Time Taken: 1534 sec
learning rate = 0.0002000
(epoch: 38, iters: 16, time: 0.171, data: 0.000) loss: 1.170 
saving the latest model (epoch 38, total_steps 377120)
(epoch: 38, iters: 96, time: 0.147, data: 0.000) loss: 0.892 
(epoch: 38, iters: 176, time: 0.147, data: 0.012) loss: 1.121 
(epoch: 38, iters: 256, time: 0.155, data: 0.000) loss: 0.732 
(epoch: 38, iters: 336, time: 0.152, data: 0.025) loss: 1.134 
(epoch: 38, iters: 416, time: 0.150, data: 0.000) loss: 0.645 
(epoch: 38, iters: 496, time: 0.150, data: 0.000) loss: 0.660 
(epoch: 38, iters: 576, time: 0.153, data: 0.000) loss: 0.928 
(epoch: 38, iters: 656, time: 0.152, data: 0.013) loss: 0.890 
(epoch: 38, iters: 736, time: 0.151, data: 0.000) loss: 1.235 
(epoch: 38, iters: 816, time: 0.153, data: 0.017) loss: 0.619 
(epoch: 38, iters: 896, time: 0.153, data: 0.000) loss: 1.459 
(epoch: 38, iters: 976, time: 0.154, data: 0.027) loss: 0.640 
(epoch: 38, iters: 1056, time: 0.154, data: 0.000) loss: 1.007 
(epoch: 38, iters: 1136, time: 0.152, data: 0.010) loss: 0.939 
(epoch: 38, iters: 1216, time: 0.155, data: 0.000) loss: 0.823 
(epoch: 38, iters: 1296, time: 0.155, data: 0.015) loss: 1.149 
(epoch: 38, iters: 1376, time: 0.151, data: 0.000) loss: 1.032 
(epoch: 38, iters: 1456, time: 0.153, data: 0.031) loss: 1.013 
(epoch: 38, iters: 1536, time: 0.151, data: 0.000) loss: 0.877 
(epoch: 38, iters: 1616, time: 0.153, data: 0.025) loss: 1.201 
(epoch: 38, iters: 1696, time: 0.152, data: 0.000) loss: 0.505 
(epoch: 38, iters: 1776, time: 0.154, data: 0.000) loss: 0.638 
(epoch: 38, iters: 1856, time: 0.153, data: 0.025) loss: 1.045 
(epoch: 38, iters: 1936, time: 0.153, data: 0.000) loss: 0.379 
(epoch: 38, iters: 2016, time: 0.153, data: 0.000) loss: 1.031 
(epoch: 38, iters: 2096, time: 0.156, data: 0.006) loss: 1.051 
(epoch: 38, iters: 2176, time: 0.153, data: 0.000) loss: 0.761 
(epoch: 38, iters: 2256, time: 0.156, data: 0.018) loss: 1.198 
(epoch: 38, iters: 2336, time: 0.155, data: 0.000) loss: 1.168 
(epoch: 38, iters: 2416, time: 0.152, data: 0.000) loss: 1.493 
(epoch: 38, iters: 2496, time: 0.151, data: 0.008) loss: 1.736 
(epoch: 38, iters: 2576, time: 0.152, data: 0.000) loss: 1.193 
(epoch: 38, iters: 2656, time: 0.153, data: 0.005) loss: 2.026 
(epoch: 38, iters: 2736, time: 0.155, data: 0.005) loss: 0.614 
(epoch: 38, iters: 2816, time: 0.154, data: 0.011) loss: 1.095 
(epoch: 38, iters: 2896, time: 0.151, data: 0.000) loss: 0.971 
(epoch: 38, iters: 2976, time: 0.153, data: 0.008) loss: 0.869 
(epoch: 38, iters: 3056, time: 0.155, data: 0.000) loss: 1.185 
(epoch: 38, iters: 3136, time: 0.152, data: 0.009) loss: 0.637 
(epoch: 38, iters: 3216, time: 0.149, data: 0.011) loss: 1.065 
(epoch: 38, iters: 3296, time: 0.147, data: 0.000) loss: 1.307 
(epoch: 38, iters: 3376, time: 0.151, data: 0.012) loss: 0.722 
(epoch: 38, iters: 3456, time: 0.151, data: 0.014) loss: 0.333 
(epoch: 38, iters: 3536, time: 0.148, data: 0.021) loss: 0.938 
(epoch: 38, iters: 3616, time: 0.149, data: 0.000) loss: 0.966 
(epoch: 38, iters: 3696, time: 0.151, data: 0.012) loss: 1.227 
(epoch: 38, iters: 3776, time: 0.152, data: 0.005) loss: 1.361 
(epoch: 38, iters: 3856, time: 0.150, data: 0.000) loss: 0.525 
(epoch: 38, iters: 3936, time: 0.150, data: 0.021) loss: 0.983 
(epoch: 38, iters: 4016, time: 0.151, data: 0.005) loss: 0.844 
saving the latest model (epoch 38, total_steps 381120)
(epoch: 38, iters: 4096, time: 0.155, data: 0.005) loss: 0.843 
(epoch: 38, iters: 4176, time: 0.154, data: 0.009) loss: 1.563 
(epoch: 38, iters: 4256, time: 0.155, data: 0.008) loss: 1.474 
(epoch: 38, iters: 4336, time: 0.154, data: 0.008) loss: 0.690 
(epoch: 38, iters: 4416, time: 0.151, data: 0.000) loss: 0.730 
(epoch: 38, iters: 4496, time: 0.152, data: 0.011) loss: 0.782 
(epoch: 38, iters: 4576, time: 0.154, data: 0.015) loss: 1.006 
(epoch: 38, iters: 4656, time: 0.149, data: 0.000) loss: 1.090 
(epoch: 38, iters: 4736, time: 0.155, data: 0.017) loss: 1.155 
(epoch: 38, iters: 4816, time: 0.151, data: 0.000) loss: 0.981 
(epoch: 38, iters: 4896, time: 0.152, data: 0.000) loss: 0.873 
(epoch: 38, iters: 4976, time: 0.151, data: 0.000) loss: 1.020 
(epoch: 38, iters: 5056, time: 0.150, data: 0.008) loss: 0.522 
(epoch: 38, iters: 5136, time: 0.154, data: 0.021) loss: 1.246 
(epoch: 38, iters: 5216, time: 0.152, data: 0.000) loss: 0.589 
(epoch: 38, iters: 5296, time: 0.156, data: 0.010) loss: 1.125 
(epoch: 38, iters: 5376, time: 0.154, data: 0.000) loss: 1.760 
(epoch: 38, iters: 5456, time: 0.155, data: 0.022) loss: 1.895 
(epoch: 38, iters: 5536, time: 0.152, data: 0.000) loss: 0.895 
(epoch: 38, iters: 5616, time: 0.150, data: 0.024) loss: 1.130 
(epoch: 38, iters: 5696, time: 0.153, data: 0.005) loss: 0.683 
(epoch: 38, iters: 5776, time: 0.152, data: 0.000) loss: 1.457 
(epoch: 38, iters: 5856, time: 0.151, data: 0.000) loss: 0.824 
(epoch: 38, iters: 5936, time: 0.149, data: 0.014) loss: 1.223 
(epoch: 38, iters: 6016, time: 0.151, data: 0.005) loss: 0.985 
(epoch: 38, iters: 6096, time: 0.155, data: 0.000) loss: 1.512 
(epoch: 38, iters: 6176, time: 0.154, data: 0.000) loss: 1.102 
(epoch: 38, iters: 6256, time: 0.151, data: 0.005) loss: 0.717 
(epoch: 38, iters: 6336, time: 0.154, data: 0.025) loss: 0.515 
(epoch: 38, iters: 6416, time: 0.154, data: 0.000) loss: 0.606 
(epoch: 38, iters: 6496, time: 0.152, data: 0.024) loss: 1.251 
(epoch: 38, iters: 6576, time: 0.153, data: 0.000) loss: 0.873 
(epoch: 38, iters: 6656, time: 0.151, data: 0.000) loss: 0.988 
(epoch: 38, iters: 6736, time: 0.151, data: 0.018) loss: 0.712 
(epoch: 38, iters: 6816, time: 0.153, data: 0.000) loss: 0.868 
(epoch: 38, iters: 6896, time: 0.151, data: 0.000) loss: 0.764 
(epoch: 38, iters: 6976, time: 0.148, data: 0.000) loss: 0.763 
(epoch: 38, iters: 7056, time: 0.152, data: 0.000) loss: 0.924 
(epoch: 38, iters: 7136, time: 0.152, data: 0.024) loss: 0.723 
(epoch: 38, iters: 7216, time: 0.152, data: 0.000) loss: 0.825 
(epoch: 38, iters: 7296, time: 0.154, data: 0.025) loss: 1.089 
(epoch: 38, iters: 7376, time: 0.152, data: 0.000) loss: 0.812 
(epoch: 38, iters: 7456, time: 0.151, data: 0.000) loss: 0.968 
(epoch: 38, iters: 7536, time: 0.149, data: 0.022) loss: 1.270 
(epoch: 38, iters: 7616, time: 0.149, data: 0.000) loss: 1.127 
(epoch: 38, iters: 7696, time: 0.153, data: 0.023) loss: 0.907 
(epoch: 38, iters: 7776, time: 0.152, data: 0.024) loss: 0.734 
(epoch: 38, iters: 7856, time: 0.152, data: 0.000) loss: 1.423 
(epoch: 38, iters: 7936, time: 0.151, data: 0.000) loss: 0.810 
(epoch: 38, iters: 8016, time: 0.154, data: 0.000) loss: 0.971 
saving the latest model (epoch 38, total_steps 385120)
(epoch: 38, iters: 8096, time: 0.150, data: 0.014) loss: 0.552 
(epoch: 38, iters: 8176, time: 0.147, data: 0.025) loss: 1.075 
(epoch: 38, iters: 8256, time: 0.151, data: 0.000) loss: 0.971 
(epoch: 38, iters: 8336, time: 0.146, data: 0.005) loss: 0.687 
(epoch: 38, iters: 8416, time: 0.146, data: 0.000) loss: 0.822 
(epoch: 38, iters: 8496, time: 0.150, data: 0.000) loss: 1.525 
(epoch: 38, iters: 8576, time: 0.150, data: 0.014) loss: 0.747 
(epoch: 38, iters: 8656, time: 0.146, data: 0.000) loss: 1.493 
(epoch: 38, iters: 8736, time: 0.149, data: 0.000) loss: 1.469 
(epoch: 38, iters: 8816, time: 0.148, data: 0.015) loss: 0.552 
(epoch: 38, iters: 8896, time: 0.147, data: 0.010) loss: 0.877 
(epoch: 38, iters: 8976, time: 0.147, data: 0.000) loss: 0.851 
(epoch: 38, iters: 9056, time: 0.150, data: 0.000) loss: 1.659 
(epoch: 38, iters: 9136, time: 0.149, data: 0.000) loss: 1.100 
(epoch: 38, iters: 9216, time: 0.148, data: 0.009) loss: 0.454 
(epoch: 38, iters: 9296, time: 0.149, data: 0.000) loss: 0.567 
(epoch: 38, iters: 9376, time: 0.149, data: 0.005) loss: 1.156 
(epoch: 38, iters: 9456, time: 0.147, data: 0.000) loss: 1.096 
(epoch: 38, iters: 9536, time: 0.149, data: 0.019) loss: 0.871 
(epoch: 38, iters: 9616, time: 0.148, data: 0.032) loss: 1.306 
(epoch: 38, iters: 9696, time: 0.149, data: 0.000) loss: 0.886 
(epoch: 38, iters: 9776, time: 0.149, data: 0.000) loss: 0.701 
(epoch: 38, iters: 9856, time: 0.151, data: 0.008) loss: 1.711 
(epoch: 38, iters: 9936, time: 0.150, data: 0.000) loss: 0.759 
(epoch: 38, iters: 10016, time: 0.148, data: 0.005) loss: 0.825 
(epoch: 38, iters: 10096, time: 0.148, data: 0.010) loss: 1.351 
(epoch: 38, iters: 10176, time: 0.145, data: 0.000) loss: 1.039 
saving the model at the end of epoch 38, iters 387296
End of epoch 38 / 200 	 Time Taken: 1547 sec
learning rate = 0.0002000
saving the latest model (epoch 39, total_steps 387312)
(epoch: 39, iters: 64, time: 0.153, data: 0.000) loss: 0.712 
(epoch: 39, iters: 144, time: 0.151, data: 0.014) loss: 0.761 
(epoch: 39, iters: 224, time: 0.151, data: 0.011) loss: 0.586 
(epoch: 39, iters: 304, time: 0.148, data: 0.008) loss: 0.751 
(epoch: 39, iters: 384, time: 0.149, data: 0.000) loss: 1.417 
(epoch: 39, iters: 464, time: 0.151, data: 0.020) loss: 1.222 
(epoch: 39, iters: 544, time: 0.150, data: 0.000) loss: 0.904 
(epoch: 39, iters: 624, time: 0.153, data: 0.009) loss: 0.619 
(epoch: 39, iters: 704, time: 0.151, data: 0.000) loss: 1.278 
(epoch: 39, iters: 784, time: 0.154, data: 0.019) loss: 1.110 
(epoch: 39, iters: 864, time: 0.153, data: 0.024) loss: 0.890 
(epoch: 39, iters: 944, time: 0.152, data: 0.000) loss: 1.088 
(epoch: 39, iters: 1024, time: 0.154, data: 0.005) loss: 0.872 
(epoch: 39, iters: 1104, time: 0.150, data: 0.010) loss: 1.283 
(epoch: 39, iters: 1184, time: 0.151, data: 0.005) loss: 0.835 
(epoch: 39, iters: 1264, time: 0.154, data: 0.009) loss: 1.436 
(epoch: 39, iters: 1344, time: 0.151, data: 0.000) loss: 0.995 
(epoch: 39, iters: 1424, time: 0.152, data: 0.000) loss: 0.970 
(epoch: 39, iters: 1504, time: 0.153, data: 0.000) loss: 0.646 
(epoch: 39, iters: 1584, time: 0.152, data: 0.031) loss: 0.614 
(epoch: 39, iters: 1664, time: 0.152, data: 0.000) loss: 0.885 
(epoch: 39, iters: 1744, time: 0.155, data: 0.015) loss: 0.864 
(epoch: 39, iters: 1824, time: 0.153, data: 0.009) loss: 0.510 
(epoch: 39, iters: 1904, time: 0.153, data: 0.008) loss: 1.159 
(epoch: 39, iters: 1984, time: 0.153, data: 0.006) loss: 1.424 
(epoch: 39, iters: 2064, time: 0.152, data: 0.005) loss: 0.850 
(epoch: 39, iters: 2144, time: 0.152, data: 0.017) loss: 0.941 
(epoch: 39, iters: 2224, time: 0.152, data: 0.000) loss: 0.796 
(epoch: 39, iters: 2304, time: 0.155, data: 0.011) loss: 1.223 
(epoch: 39, iters: 2384, time: 0.157, data: 0.000) loss: 0.920 
(epoch: 39, iters: 2464, time: 0.149, data: 0.005) loss: 0.528 
(epoch: 39, iters: 2544, time: 0.150, data: 0.000) loss: 1.186 
(epoch: 39, iters: 2624, time: 0.153, data: 0.000) loss: 0.778 
(epoch: 39, iters: 2704, time: 0.153, data: 0.000) loss: 0.782 
(epoch: 39, iters: 2784, time: 0.154, data: 0.023) loss: 1.024 
(epoch: 39, iters: 2864, time: 0.150, data: 0.000) loss: 0.752 
(epoch: 39, iters: 2944, time: 0.148, data: 0.000) loss: 0.872 
(epoch: 39, iters: 3024, time: 0.151, data: 0.024) loss: 1.136 
(epoch: 39, iters: 3104, time: 0.149, data: 0.000) loss: 1.186 
(epoch: 39, iters: 3184, time: 0.148, data: 0.000) loss: 0.943 
(epoch: 39, iters: 3264, time: 0.153, data: 0.000) loss: 0.759 
(epoch: 39, iters: 3344, time: 0.150, data: 0.000) loss: 0.595 
(epoch: 39, iters: 3424, time: 0.152, data: 0.000) loss: 0.984 
(epoch: 39, iters: 3504, time: 0.152, data: 0.005) loss: 1.004 
(epoch: 39, iters: 3584, time: 0.151, data: 0.000) loss: 1.236 
(epoch: 39, iters: 3664, time: 0.149, data: 0.000) loss: 1.077 
(epoch: 39, iters: 3744, time: 0.154, data: 0.026) loss: 0.784 
(epoch: 39, iters: 3824, time: 0.153, data: 0.000) loss: 0.949 
(epoch: 39, iters: 3904, time: 0.153, data: 0.000) loss: 1.080 
(epoch: 39, iters: 3984, time: 0.154, data: 0.011) loss: 1.536 
saving the latest model (epoch 39, total_steps 391312)
(epoch: 39, iters: 4064, time: 0.151, data: 0.000) loss: 0.778 
(epoch: 39, iters: 4144, time: 0.150, data: 0.000) loss: 1.323 
(epoch: 39, iters: 4224, time: 0.150, data: 0.000) loss: 0.976 
(epoch: 39, iters: 4304, time: 0.151, data: 0.005) loss: 0.661 
(epoch: 39, iters: 4384, time: 0.153, data: 0.005) loss: 0.985 
(epoch: 39, iters: 4464, time: 0.153, data: 0.008) loss: 1.685 
(epoch: 39, iters: 4544, time: 0.150, data: 0.013) loss: 0.878 
(epoch: 39, iters: 4624, time: 0.152, data: 0.012) loss: 1.440 
(epoch: 39, iters: 4704, time: 0.150, data: 0.000) loss: 0.575 
(epoch: 39, iters: 4784, time: 0.148, data: 0.000) loss: 1.632 
(epoch: 39, iters: 4864, time: 0.148, data: 0.009) loss: 0.937 
(epoch: 39, iters: 4944, time: 0.149, data: 0.000) loss: 0.305 
(epoch: 39, iters: 5024, time: 0.146, data: 0.000) loss: 0.491 
(epoch: 39, iters: 5104, time: 0.153, data: 0.016) loss: 1.064 
(epoch: 39, iters: 5184, time: 0.151, data: 0.005) loss: 0.585 
(epoch: 39, iters: 5264, time: 0.151, data: 0.000) loss: 0.562 
(epoch: 39, iters: 5344, time: 0.152, data: 0.014) loss: 1.468 
(epoch: 39, iters: 5424, time: 0.150, data: 0.000) loss: 1.659 
(epoch: 39, iters: 5504, time: 0.154, data: 0.032) loss: 0.934 
(epoch: 39, iters: 5584, time: 0.150, data: 0.000) loss: 1.914 
(epoch: 39, iters: 5664, time: 0.151, data: 0.005) loss: 1.222 
(epoch: 39, iters: 5744, time: 0.152, data: 0.000) loss: 1.342 
(epoch: 39, iters: 5824, time: 0.150, data: 0.018) loss: 1.432 
(epoch: 39, iters: 5904, time: 0.152, data: 0.024) loss: 0.788 
(epoch: 39, iters: 5984, time: 0.152, data: 0.000) loss: 1.116 
(epoch: 39, iters: 6064, time: 0.151, data: 0.010) loss: 1.244 
(epoch: 39, iters: 6144, time: 0.151, data: 0.000) loss: 0.857 
(epoch: 39, iters: 6224, time: 0.152, data: 0.000) loss: 1.224 
(epoch: 39, iters: 6304, time: 0.151, data: 0.000) loss: 0.832 
(epoch: 39, iters: 6384, time: 0.154, data: 0.009) loss: 0.806 
(epoch: 39, iters: 6464, time: 0.150, data: 0.000) loss: 0.760 
(epoch: 39, iters: 6544, time: 0.151, data: 0.000) loss: 0.807 
(epoch: 39, iters: 6624, time: 0.151, data: 0.033) loss: 0.631 
(epoch: 39, iters: 6704, time: 0.152, data: 0.000) loss: 0.814 
(epoch: 39, iters: 6784, time: 0.155, data: 0.000) loss: 0.823 
(epoch: 39, iters: 6864, time: 0.149, data: 0.016) loss: 1.448 
(epoch: 39, iters: 6944, time: 0.150, data: 0.005) loss: 1.095 
(epoch: 39, iters: 7024, time: 0.153, data: 0.005) loss: 0.961 
(epoch: 39, iters: 7104, time: 0.151, data: 0.005) loss: 0.584 
(epoch: 39, iters: 7184, time: 0.151, data: 0.000) loss: 1.536 
(epoch: 39, iters: 7264, time: 0.152, data: 0.028) loss: 2.023 
(epoch: 39, iters: 7344, time: 0.150, data: 0.000) loss: 0.786 
(epoch: 39, iters: 7424, time: 0.154, data: 0.000) loss: 1.458 
(epoch: 39, iters: 7504, time: 0.150, data: 0.020) loss: 1.121 
(epoch: 39, iters: 7584, time: 0.151, data: 0.000) loss: 1.384 
(epoch: 39, iters: 7664, time: 0.150, data: 0.025) loss: 1.034 
(epoch: 39, iters: 7744, time: 0.154, data: 0.000) loss: 1.223 
(epoch: 39, iters: 7824, time: 0.152, data: 0.000) loss: 0.607 
(epoch: 39, iters: 7904, time: 0.150, data: 0.000) loss: 0.811 
(epoch: 39, iters: 7984, time: 0.148, data: 0.009) loss: 0.403 
saving the latest model (epoch 39, total_steps 395312)
(epoch: 39, iters: 8064, time: 0.151, data: 0.005) loss: 0.688 
(epoch: 39, iters: 8144, time: 0.154, data: 0.023) loss: 1.779 
(epoch: 39, iters: 8224, time: 0.152, data: 0.005) loss: 0.682 
(epoch: 39, iters: 8304, time: 0.151, data: 0.008) loss: 0.947 
(epoch: 39, iters: 8384, time: 0.153, data: 0.020) loss: 0.556 
(epoch: 39, iters: 8464, time: 0.150, data: 0.000) loss: 1.590 
(epoch: 39, iters: 8544, time: 0.155, data: 0.024) loss: 0.593 
(epoch: 39, iters: 8624, time: 0.153, data: 0.000) loss: 1.049 
(epoch: 39, iters: 8704, time: 0.151, data: 0.010) loss: 0.684 
(epoch: 39, iters: 8784, time: 0.154, data: 0.005) loss: 1.039 
(epoch: 39, iters: 8864, time: 0.147, data: 0.000) loss: 0.897 
(epoch: 39, iters: 8944, time: 0.148, data: 0.005) loss: 0.627 
(epoch: 39, iters: 9024, time: 0.150, data: 0.014) loss: 0.938 
(epoch: 39, iters: 9104, time: 0.149, data: 0.024) loss: 0.850 
(epoch: 39, iters: 9184, time: 0.152, data: 0.000) loss: 0.847 
(epoch: 39, iters: 9264, time: 0.150, data: 0.020) loss: 0.731 
(epoch: 39, iters: 9344, time: 0.152, data: 0.005) loss: 0.482 
(epoch: 39, iters: 9424, time: 0.149, data: 0.028) loss: 0.653 
(epoch: 39, iters: 9504, time: 0.148, data: 0.000) loss: 1.457 
(epoch: 39, iters: 9584, time: 0.152, data: 0.000) loss: 0.779 
(epoch: 39, iters: 9664, time: 0.150, data: 0.016) loss: 1.044 
(epoch: 39, iters: 9744, time: 0.151, data: 0.013) loss: 0.944 
(epoch: 39, iters: 9824, time: 0.153, data: 0.000) loss: 1.154 
(epoch: 39, iters: 9904, time: 0.151, data: 0.008) loss: 1.300 
(epoch: 39, iters: 9984, time: 0.152, data: 0.000) loss: 0.359 
(epoch: 39, iters: 10064, time: 0.150, data: 0.024) loss: 0.847 
(epoch: 39, iters: 10144, time: 0.151, data: 0.000) loss: 1.178 
saving the model at the end of epoch 39, iters 397488
End of epoch 39 / 200 	 Time Taken: 1546 sec
learning rate = 0.0002000
saving the latest model (epoch 40, total_steps 397504)
(epoch: 40, iters: 32, time: 0.159, data: 0.007) loss: 0.596 
(epoch: 40, iters: 112, time: 0.150, data: 0.019) loss: 0.937 
(epoch: 40, iters: 192, time: 0.148, data: 0.000) loss: 1.273 
(epoch: 40, iters: 272, time: 0.149, data: 0.000) loss: 1.436 
(epoch: 40, iters: 352, time: 0.148, data: 0.000) loss: 1.429 
(epoch: 40, iters: 432, time: 0.148, data: 0.008) loss: 1.008 
(epoch: 40, iters: 512, time: 0.149, data: 0.005) loss: 0.878 
(epoch: 40, iters: 592, time: 0.151, data: 0.025) loss: 0.779 
(epoch: 40, iters: 672, time: 0.149, data: 0.000) loss: 0.645 
(epoch: 40, iters: 752, time: 0.149, data: 0.000) loss: 1.442 
(epoch: 40, iters: 832, time: 0.153, data: 0.005) loss: 0.868 
(epoch: 40, iters: 912, time: 0.151, data: 0.005) loss: 0.986 
(epoch: 40, iters: 992, time: 0.152, data: 0.018) loss: 0.674 
(epoch: 40, iters: 1072, time: 0.150, data: 0.000) loss: 0.985 
(epoch: 40, iters: 1152, time: 0.153, data: 0.000) loss: 1.216 
(epoch: 40, iters: 1232, time: 0.152, data: 0.000) loss: 0.698 
(epoch: 40, iters: 1312, time: 0.149, data: 0.000) loss: 2.829 
(epoch: 40, iters: 1392, time: 0.152, data: 0.000) loss: 0.823 
(epoch: 40, iters: 1472, time: 0.151, data: 0.014) loss: 0.899 
(epoch: 40, iters: 1552, time: 0.149, data: 0.000) loss: 1.046 
(epoch: 40, iters: 1632, time: 0.149, data: 0.008) loss: 1.111 
(epoch: 40, iters: 1712, time: 0.149, data: 0.008) loss: 1.008 
(epoch: 40, iters: 1792, time: 0.148, data: 0.000) loss: 1.209 
(epoch: 40, iters: 1872, time: 0.150, data: 0.000) loss: 0.414 
(epoch: 40, iters: 1952, time: 0.152, data: 0.025) loss: 0.859 
(epoch: 40, iters: 2032, time: 0.151, data: 0.029) loss: 0.662 
(epoch: 40, iters: 2112, time: 0.147, data: 0.000) loss: 1.162 
(epoch: 40, iters: 2192, time: 0.152, data: 0.011) loss: 0.859 
(epoch: 40, iters: 2272, time: 0.147, data: 0.006) loss: 0.579 
(epoch: 40, iters: 2352, time: 0.149, data: 0.023) loss: 1.524 
(epoch: 40, iters: 2432, time: 0.147, data: 0.000) loss: 0.753 
(epoch: 40, iters: 2512, time: 0.150, data: 0.000) loss: 0.797 
(epoch: 40, iters: 2592, time: 0.146, data: 0.014) loss: 0.728 
(epoch: 40, iters: 2672, time: 0.146, data: 0.009) loss: 0.817 
(epoch: 40, iters: 2752, time: 0.150, data: 0.000) loss: 0.879 
(epoch: 40, iters: 2832, time: 0.150, data: 0.005) loss: 0.800 
(epoch: 40, iters: 2912, time: 0.149, data: 0.000) loss: 0.986 
(epoch: 40, iters: 2992, time: 0.153, data: 0.000) loss: 0.895 
(epoch: 40, iters: 3072, time: 0.149, data: 0.000) loss: 0.578 
(epoch: 40, iters: 3152, time: 0.149, data: 0.000) loss: 1.183 
(epoch: 40, iters: 3232, time: 0.151, data: 0.006) loss: 0.909 
(epoch: 40, iters: 3312, time: 0.151, data: 0.000) loss: 0.845 
(epoch: 40, iters: 3392, time: 0.151, data: 0.006) loss: 1.254 
(epoch: 40, iters: 3472, time: 0.150, data: 0.006) loss: 0.936 
(epoch: 40, iters: 3552, time: 0.149, data: 0.033) loss: 1.460 
(epoch: 40, iters: 3632, time: 0.148, data: 0.000) loss: 0.936 
(epoch: 40, iters: 3712, time: 0.151, data: 0.013) loss: 1.265 
(epoch: 40, iters: 3792, time: 0.150, data: 0.000) loss: 0.648 
(epoch: 40, iters: 3872, time: 0.150, data: 0.000) loss: 1.055 
(epoch: 40, iters: 3952, time: 0.146, data: 0.000) loss: 1.109 
saving the latest model (epoch 40, total_steps 401504)
(epoch: 40, iters: 4032, time: 0.147, data: 0.024) loss: 0.518 
(epoch: 40, iters: 4112, time: 0.154, data: 0.020) loss: 0.415 
(epoch: 40, iters: 4192, time: 0.152, data: 0.000) loss: 1.593 
(epoch: 40, iters: 4272, time: 0.150, data: 0.000) loss: 1.440 
(epoch: 40, iters: 4352, time: 0.150, data: 0.000) loss: 0.962 
(epoch: 40, iters: 4432, time: 0.149, data: 0.005) loss: 1.189 
(epoch: 40, iters: 4512, time: 0.146, data: 0.024) loss: 1.153 
(epoch: 40, iters: 4592, time: 0.148, data: 0.000) loss: 0.780 
(epoch: 40, iters: 4672, time: 0.149, data: 0.000) loss: 0.861 
(epoch: 40, iters: 4752, time: 0.149, data: 0.015) loss: 1.008 
(epoch: 40, iters: 4832, time: 0.147, data: 0.000) loss: 0.419 
(epoch: 40, iters: 4912, time: 0.153, data: 0.000) loss: 0.684 
(epoch: 40, iters: 4992, time: 0.151, data: 0.005) loss: 0.806 
(epoch: 40, iters: 5072, time: 0.151, data: 0.000) loss: 0.384 
(epoch: 40, iters: 5152, time: 0.150, data: 0.008) loss: 0.990 
(epoch: 40, iters: 5232, time: 0.149, data: 0.000) loss: 1.281 
(epoch: 40, iters: 5312, time: 0.150, data: 0.005) loss: 1.277 
(epoch: 40, iters: 5392, time: 0.148, data: 0.000) loss: 0.965 
(epoch: 40, iters: 5472, time: 0.145, data: 0.005) loss: 1.321 
(epoch: 40, iters: 5552, time: 0.147, data: 0.012) loss: 0.731 
(epoch: 40, iters: 5632, time: 0.148, data: 0.009) loss: 1.389 
(epoch: 40, iters: 5712, time: 0.145, data: 0.021) loss: 0.432 
(epoch: 40, iters: 5792, time: 0.151, data: 0.000) loss: 0.449 
(epoch: 40, iters: 5872, time: 0.151, data: 0.000) loss: 0.899 
(epoch: 40, iters: 5952, time: 0.150, data: 0.000) loss: 1.261 
(epoch: 40, iters: 6032, time: 0.150, data: 0.000) loss: 0.503 
(epoch: 40, iters: 6112, time: 0.149, data: 0.000) loss: 0.720 
(epoch: 40, iters: 6192, time: 0.152, data: 0.000) loss: 0.848 
(epoch: 40, iters: 6272, time: 0.153, data: 0.006) loss: 0.760 
(epoch: 40, iters: 6352, time: 0.151, data: 0.000) loss: 0.776 
(epoch: 40, iters: 6432, time: 0.150, data: 0.014) loss: 0.568 
(epoch: 40, iters: 6512, time: 0.153, data: 0.008) loss: 1.263 
(epoch: 40, iters: 6592, time: 0.148, data: 0.000) loss: 1.176 
(epoch: 40, iters: 6672, time: 0.153, data: 0.005) loss: 0.560 
(epoch: 40, iters: 6752, time: 0.149, data: 0.000) loss: 0.644 
(epoch: 40, iters: 6832, time: 0.149, data: 0.008) loss: 0.800 
(epoch: 40, iters: 6912, time: 0.152, data: 0.013) loss: 0.959 
(epoch: 40, iters: 6992, time: 0.150, data: 0.000) loss: 0.824 
(epoch: 40, iters: 7072, time: 0.150, data: 0.000) loss: 0.680 
(epoch: 40, iters: 7152, time: 0.152, data: 0.000) loss: 0.480 
(epoch: 40, iters: 7232, time: 0.152, data: 0.008) loss: 1.208 
(epoch: 40, iters: 7312, time: 0.152, data: 0.000) loss: 0.615 
(epoch: 40, iters: 7392, time: 0.150, data: 0.000) loss: 0.305 
(epoch: 40, iters: 7472, time: 0.156, data: 0.005) loss: 1.193 
(epoch: 40, iters: 7552, time: 0.150, data: 0.016) loss: 0.604 
(epoch: 40, iters: 7632, time: 0.150, data: 0.000) loss: 1.038 
(epoch: 40, iters: 7712, time: 0.155, data: 0.000) loss: 0.849 
(epoch: 40, iters: 7792, time: 0.154, data: 0.010) loss: 0.921 
(epoch: 40, iters: 7872, time: 0.153, data: 0.005) loss: 1.294 
(epoch: 40, iters: 7952, time: 0.150, data: 0.000) loss: 1.195 
saving the latest model (epoch 40, total_steps 405504)
(epoch: 40, iters: 8032, time: 0.152, data: 0.013) loss: 0.728 
(epoch: 40, iters: 8112, time: 0.152, data: 0.005) loss: 1.637 
(epoch: 40, iters: 8192, time: 0.155, data: 0.000) loss: 0.700 
(epoch: 40, iters: 8272, time: 0.154, data: 0.031) loss: 0.450 
(epoch: 40, iters: 8352, time: 0.150, data: 0.000) loss: 1.433 
(epoch: 40, iters: 8432, time: 0.150, data: 0.000) loss: 0.434 
(epoch: 40, iters: 8512, time: 0.152, data: 0.000) loss: 0.778 
(epoch: 40, iters: 8592, time: 0.147, data: 0.025) loss: 1.300 
(epoch: 40, iters: 8672, time: 0.147, data: 0.000) loss: 1.337 
(epoch: 40, iters: 8752, time: 0.149, data: 0.000) loss: 1.397 
(epoch: 40, iters: 8832, time: 0.147, data: 0.000) loss: 0.685 
(epoch: 40, iters: 8912, time: 0.149, data: 0.005) loss: 1.068 
(epoch: 40, iters: 8992, time: 0.152, data: 0.000) loss: 0.946 
(epoch: 40, iters: 9072, time: 0.151, data: 0.006) loss: 1.433 
(epoch: 40, iters: 9152, time: 0.151, data: 0.008) loss: 1.557 
(epoch: 40, iters: 9232, time: 0.149, data: 0.000) loss: 0.906 
(epoch: 40, iters: 9312, time: 0.150, data: 0.000) loss: 0.774 
(epoch: 40, iters: 9392, time: 0.152, data: 0.015) loss: 0.298 
(epoch: 40, iters: 9472, time: 0.152, data: 0.000) loss: 1.211 
(epoch: 40, iters: 9552, time: 0.149, data: 0.010) loss: 0.733 
(epoch: 40, iters: 9632, time: 0.148, data: 0.008) loss: 0.780 
(epoch: 40, iters: 9712, time: 0.149, data: 0.000) loss: 1.422 
(epoch: 40, iters: 9792, time: 0.150, data: 0.005) loss: 0.832 
(epoch: 40, iters: 9872, time: 0.151, data: 0.000) loss: 1.182 
(epoch: 40, iters: 9952, time: 0.150, data: 0.000) loss: 1.152 
(epoch: 40, iters: 10032, time: 0.150, data: 0.016) loss: 0.828 
(epoch: 40, iters: 10112, time: 0.150, data: 0.005) loss: 0.930 
(epoch: 40, iters: 10192, time: 0.091, data: 0.000) loss: 0.869 
saving the model at the end of epoch 40, iters 407680
End of epoch 40 / 200 	 Time Taken: 1533 sec
learning rate = 0.0002000
saving the latest model (epoch 41, total_steps 407696)
(epoch: 41, iters: 80, time: 0.156, data: 0.387) loss: 0.799 
(epoch: 41, iters: 160, time: 0.154, data: 0.000) loss: 1.123 
(epoch: 41, iters: 240, time: 0.151, data: 0.000) loss: 0.912 
(epoch: 41, iters: 320, time: 0.151, data: 0.000) loss: 0.867 
(epoch: 41, iters: 400, time: 0.150, data: 0.000) loss: 1.344 
(epoch: 41, iters: 480, time: 0.149, data: 0.000) loss: 0.955 
(epoch: 41, iters: 560, time: 0.148, data: 0.018) loss: 0.650 
(epoch: 41, iters: 640, time: 0.149, data: 0.000) loss: 0.242 
(epoch: 41, iters: 720, time: 0.147, data: 0.000) loss: 1.007 
(epoch: 41, iters: 800, time: 0.148, data: 0.008) loss: 1.279 
(epoch: 41, iters: 880, time: 0.149, data: 0.000) loss: 1.091 
(epoch: 41, iters: 960, time: 0.152, data: 0.005) loss: 1.445 
(epoch: 41, iters: 1040, time: 0.151, data: 0.024) loss: 0.789 
(epoch: 41, iters: 1120, time: 0.148, data: 0.000) loss: 1.203 
(epoch: 41, iters: 1200, time: 0.148, data: 0.005) loss: 0.886 
(epoch: 41, iters: 1280, time: 0.150, data: 0.017) loss: 1.264 
(epoch: 41, iters: 1360, time: 0.148, data: 0.008) loss: 1.458 
(epoch: 41, iters: 1440, time: 0.150, data: 0.032) loss: 1.972 
(epoch: 41, iters: 1520, time: 0.150, data: 0.000) loss: 0.668 
(epoch: 41, iters: 1600, time: 0.150, data: 0.000) loss: 0.661 
(epoch: 41, iters: 1680, time: 0.151, data: 0.009) loss: 0.956 
(epoch: 41, iters: 1760, time: 0.150, data: 0.020) loss: 1.283 
(epoch: 41, iters: 1840, time: 0.152, data: 0.005) loss: 0.747 
(epoch: 41, iters: 1920, time: 0.150, data: 0.017) loss: 1.004 
(epoch: 41, iters: 2000, time: 0.152, data: 0.000) loss: 1.131 
(epoch: 41, iters: 2080, time: 0.149, data: 0.000) loss: 0.728 
(epoch: 41, iters: 2160, time: 0.150, data: 0.005) loss: 0.885 
(epoch: 41, iters: 2240, time: 0.151, data: 0.000) loss: 0.436 
(epoch: 41, iters: 2320, time: 0.150, data: 0.014) loss: 0.774 
(epoch: 41, iters: 2400, time: 0.151, data: 0.000) loss: 0.593 
(epoch: 41, iters: 2480, time: 0.149, data: 0.000) loss: 1.203 
(epoch: 41, iters: 2560, time: 0.149, data: 0.000) loss: 0.449 
(epoch: 41, iters: 2640, time: 0.151, data: 0.000) loss: 0.734 
(epoch: 41, iters: 2720, time: 0.153, data: 0.000) loss: 1.095 
(epoch: 41, iters: 2800, time: 0.151, data: 0.000) loss: 1.302 
(epoch: 41, iters: 2880, time: 0.150, data: 0.000) loss: 1.333 
(epoch: 41, iters: 2960, time: 0.149, data: 0.000) loss: 1.040 
(epoch: 41, iters: 3040, time: 0.152, data: 0.005) loss: 0.998 
(epoch: 41, iters: 3120, time: 0.150, data: 0.005) loss: 0.682 
(epoch: 41, iters: 3200, time: 0.149, data: 0.010) loss: 1.329 
(epoch: 41, iters: 3280, time: 0.151, data: 0.000) loss: 0.647 
(epoch: 41, iters: 3360, time: 0.149, data: 0.010) loss: 1.843 
(epoch: 41, iters: 3440, time: 0.149, data: 0.000) loss: 1.086 
(epoch: 41, iters: 3520, time: 0.150, data: 0.000) loss: 0.834 
(epoch: 41, iters: 3600, time: 0.151, data: 0.005) loss: 1.355 
(epoch: 41, iters: 3680, time: 0.148, data: 0.000) loss: 1.445 
(epoch: 41, iters: 3760, time: 0.148, data: 0.018) loss: 0.698 
(epoch: 41, iters: 3840, time: 0.152, data: 0.005) loss: 0.814 
(epoch: 41, iters: 3920, time: 0.150, data: 0.000) loss: 0.303 
(epoch: 41, iters: 4000, time: 0.150, data: 0.000) loss: 1.025 
saving the latest model (epoch 41, total_steps 411696)
(epoch: 41, iters: 4080, time: 0.150, data: 0.000) loss: 0.885 
(epoch: 41, iters: 4160, time: 0.150, data: 0.000) loss: 1.377 
(epoch: 41, iters: 4240, time: 0.150, data: 0.015) loss: 0.731 
(epoch: 41, iters: 4320, time: 0.152, data: 0.000) loss: 1.054 
(epoch: 41, iters: 4400, time: 0.150, data: 0.000) loss: 1.344 
(epoch: 41, iters: 4480, time: 0.151, data: 0.019) loss: 1.303 
(epoch: 41, iters: 4560, time: 0.152, data: 0.000) loss: 1.252 
(epoch: 41, iters: 4640, time: 0.152, data: 0.000) loss: 1.465 
(epoch: 41, iters: 4720, time: 0.152, data: 0.000) loss: 0.681 
(epoch: 41, iters: 4800, time: 0.151, data: 0.008) loss: 1.534 
(epoch: 41, iters: 4880, time: 0.153, data: 0.000) loss: 0.329 
(epoch: 41, iters: 4960, time: 0.150, data: 0.031) loss: 0.576 
(epoch: 41, iters: 5040, time: 0.150, data: 0.000) loss: 0.574 
(epoch: 41, iters: 5120, time: 0.150, data: 0.006) loss: 1.054 
(epoch: 41, iters: 5200, time: 0.150, data: 0.017) loss: 1.007 
(epoch: 41, iters: 5280, time: 0.149, data: 0.000) loss: 0.980 
(epoch: 41, iters: 5360, time: 0.150, data: 0.000) loss: 1.121 
(epoch: 41, iters: 5440, time: 0.147, data: 0.020) loss: 1.103 
(epoch: 41, iters: 5520, time: 0.148, data: 0.005) loss: 1.313 
(epoch: 41, iters: 5600, time: 0.150, data: 0.000) loss: 1.120 
(epoch: 41, iters: 5680, time: 0.150, data: 0.000) loss: 1.095 
(epoch: 41, iters: 5760, time: 0.147, data: 0.005) loss: 0.931 
(epoch: 41, iters: 5840, time: 0.149, data: 0.009) loss: 0.590 
(epoch: 41, iters: 5920, time: 0.147, data: 0.000) loss: 1.446 
(epoch: 41, iters: 6000, time: 0.149, data: 0.026) loss: 1.503 
(epoch: 41, iters: 6080, time: 0.149, data: 0.000) loss: 1.490 
(epoch: 41, iters: 6160, time: 0.148, data: 0.014) loss: 1.075 
(epoch: 41, iters: 6240, time: 0.151, data: 0.008) loss: 0.952 
(epoch: 41, iters: 6320, time: 0.147, data: 0.000) loss: 0.955 
(epoch: 41, iters: 6400, time: 0.148, data: 0.009) loss: 0.432 
(epoch: 41, iters: 6480, time: 0.147, data: 0.000) loss: 1.144 
(epoch: 41, iters: 6560, time: 0.150, data: 0.000) loss: 0.510 
(epoch: 41, iters: 6640, time: 0.151, data: 0.017) loss: 1.292 
(epoch: 41, iters: 6720, time: 0.149, data: 0.005) loss: 1.008 
(epoch: 41, iters: 6800, time: 0.151, data: 0.000) loss: 0.708 
(epoch: 41, iters: 6880, time: 0.149, data: 0.013) loss: 1.047 
(epoch: 41, iters: 6960, time: 0.149, data: 0.008) loss: 1.121 
(epoch: 41, iters: 7040, time: 0.149, data: 0.000) loss: 0.896 
(epoch: 41, iters: 7120, time: 0.153, data: 0.000) loss: 0.653 
(epoch: 41, iters: 7200, time: 0.151, data: 0.008) loss: 0.443 
(epoch: 41, iters: 7280, time: 0.150, data: 0.008) loss: 1.253 
(epoch: 41, iters: 7360, time: 0.147, data: 0.000) loss: 0.971 
(epoch: 41, iters: 7440, time: 0.149, data: 0.006) loss: 0.716 
(epoch: 41, iters: 7520, time: 0.150, data: 0.000) loss: 1.415 
(epoch: 41, iters: 7600, time: 0.151, data: 0.005) loss: 0.781 
(epoch: 41, iters: 7680, time: 0.153, data: 0.000) loss: 0.698 
(epoch: 41, iters: 7760, time: 0.151, data: 0.008) loss: 1.112 
(epoch: 41, iters: 7840, time: 0.151, data: 0.000) loss: 0.924 
(epoch: 41, iters: 7920, time: 0.149, data: 0.020) loss: 0.348 
(epoch: 41, iters: 8000, time: 0.152, data: 0.017) loss: 0.840 
saving the latest model (epoch 41, total_steps 415696)
(epoch: 41, iters: 8080, time: 0.150, data: 0.008) loss: 1.067 
(epoch: 41, iters: 8160, time: 0.151, data: 0.000) loss: 0.931 
(epoch: 41, iters: 8240, time: 0.152, data: 0.006) loss: 0.823 
(epoch: 41, iters: 8320, time: 0.151, data: 0.000) loss: 1.094 
(epoch: 41, iters: 8400, time: 0.152, data: 0.000) loss: 0.846 
(epoch: 41, iters: 8480, time: 0.151, data: 0.009) loss: 0.886 
(epoch: 41, iters: 8560, time: 0.149, data: 0.000) loss: 0.773 
(epoch: 41, iters: 8640, time: 0.149, data: 0.005) loss: 0.566 
(epoch: 41, iters: 8720, time: 0.147, data: 0.018) loss: 1.594 
(epoch: 41, iters: 8800, time: 0.148, data: 0.000) loss: 1.308 
(epoch: 41, iters: 8880, time: 0.149, data: 0.016) loss: 0.747 
(epoch: 41, iters: 8960, time: 0.150, data: 0.000) loss: 0.690 
(epoch: 41, iters: 9040, time: 0.151, data: 0.000) loss: 1.326 
(epoch: 41, iters: 9120, time: 0.155, data: 0.017) loss: 0.946 
(epoch: 41, iters: 9200, time: 0.149, data: 0.000) loss: 0.806 
(epoch: 41, iters: 9280, time: 0.151, data: 0.000) loss: 1.617 
(epoch: 41, iters: 9360, time: 0.149, data: 0.005) loss: 0.888 
(epoch: 41, iters: 9440, time: 0.148, data: 0.000) loss: 0.361 
(epoch: 41, iters: 9520, time: 0.149, data: 0.005) loss: 0.666 
(epoch: 41, iters: 9600, time: 0.151, data: 0.006) loss: 1.432 
(epoch: 41, iters: 9680, time: 0.149, data: 0.000) loss: 0.701 
(epoch: 41, iters: 9760, time: 0.148, data: 0.012) loss: 1.101 
(epoch: 41, iters: 9840, time: 0.149, data: 0.005) loss: 1.252 
(epoch: 41, iters: 9920, time: 0.152, data: 0.019) loss: 0.796 
(epoch: 41, iters: 10000, time: 0.149, data: 0.000) loss: 1.691 
(epoch: 41, iters: 10080, time: 0.152, data: 0.000) loss: 0.774 
(epoch: 41, iters: 10160, time: 0.151, data: 0.004) loss: 1.294 
saving the model at the end of epoch 41, iters 417872
End of epoch 41 / 200 	 Time Taken: 1533 sec
learning rate = 0.0002000
saving the latest model (epoch 42, total_steps 417888)
(epoch: 42, iters: 48, time: 0.156, data: 0.005) loss: 1.128 
(epoch: 42, iters: 128, time: 0.152, data: 0.014) loss: 0.907 
(epoch: 42, iters: 208, time: 0.149, data: 0.035) loss: 0.998 
(epoch: 42, iters: 288, time: 0.150, data: 0.000) loss: 0.799 
(epoch: 42, iters: 368, time: 0.149, data: 0.029) loss: 0.674 
(epoch: 42, iters: 448, time: 0.148, data: 0.000) loss: 1.415 
(epoch: 42, iters: 528, time: 0.151, data: 0.000) loss: 0.837 
(epoch: 42, iters: 608, time: 0.150, data: 0.008) loss: 0.729 
(epoch: 42, iters: 688, time: 0.149, data: 0.008) loss: 1.066 
(epoch: 42, iters: 768, time: 0.148, data: 0.000) loss: 1.157 
(epoch: 42, iters: 848, time: 0.147, data: 0.029) loss: 0.827 
(epoch: 42, iters: 928, time: 0.148, data: 0.000) loss: 1.029 
(epoch: 42, iters: 1008, time: 0.151, data: 0.022) loss: 1.147 
(epoch: 42, iters: 1088, time: 0.150, data: 0.000) loss: 0.658 
(epoch: 42, iters: 1168, time: 0.150, data: 0.008) loss: 0.749 
(epoch: 42, iters: 1248, time: 0.147, data: 0.005) loss: 0.747 
(epoch: 42, iters: 1328, time: 0.152, data: 0.000) loss: 1.973 
(epoch: 42, iters: 1408, time: 0.149, data: 0.000) loss: 1.043 
(epoch: 42, iters: 1488, time: 0.150, data: 0.005) loss: 1.243 
(epoch: 42, iters: 1568, time: 0.148, data: 0.005) loss: 1.223 
(epoch: 42, iters: 1648, time: 0.149, data: 0.000) loss: 0.429 
(epoch: 42, iters: 1728, time: 0.150, data: 0.000) loss: 1.413 
(epoch: 42, iters: 1808, time: 0.151, data: 0.030) loss: 1.386 
(epoch: 42, iters: 1888, time: 0.150, data: 0.000) loss: 0.803 
(epoch: 42, iters: 1968, time: 0.151, data: 0.030) loss: 0.258 
(epoch: 42, iters: 2048, time: 0.150, data: 0.000) loss: 1.116 
(epoch: 42, iters: 2128, time: 0.152, data: 0.000) loss: 1.729 
(epoch: 42, iters: 2208, time: 0.152, data: 0.011) loss: 0.964 
(epoch: 42, iters: 2288, time: 0.156, data: 0.000) loss: 0.502 
(epoch: 42, iters: 2368, time: 0.150, data: 0.000) loss: 0.736 
(epoch: 42, iters: 2448, time: 0.151, data: 0.000) loss: 1.480 
(epoch: 42, iters: 2528, time: 0.150, data: 0.024) loss: 0.969 
(epoch: 42, iters: 2608, time: 0.153, data: 0.000) loss: 0.764 
(epoch: 42, iters: 2688, time: 0.150, data: 0.000) loss: 0.574 
(epoch: 42, iters: 2768, time: 0.152, data: 0.000) loss: 0.869 
(epoch: 42, iters: 2848, time: 0.151, data: 0.014) loss: 1.517 
(epoch: 42, iters: 2928, time: 0.153, data: 0.024) loss: 0.694 
(epoch: 42, iters: 3008, time: 0.152, data: 0.000) loss: 1.200 
(epoch: 42, iters: 3088, time: 0.152, data: 0.010) loss: 0.375 
(epoch: 42, iters: 3168, time: 0.150, data: 0.000) loss: 1.681 
(epoch: 42, iters: 3248, time: 0.152, data: 0.005) loss: 0.865 
(epoch: 42, iters: 3328, time: 0.151, data: 0.008) loss: 0.871 
(epoch: 42, iters: 3408, time: 0.150, data: 0.000) loss: 1.167 
(epoch: 42, iters: 3488, time: 0.150, data: 0.005) loss: 0.893 
(epoch: 42, iters: 3568, time: 0.148, data: 0.013) loss: 0.858 
(epoch: 42, iters: 3648, time: 0.149, data: 0.000) loss: 0.751 
(epoch: 42, iters: 3728, time: 0.148, data: 0.033) loss: 1.125 
(epoch: 42, iters: 3808, time: 0.155, data: 0.000) loss: 0.769 
(epoch: 42, iters: 3888, time: 0.151, data: 0.000) loss: 0.734 
(epoch: 42, iters: 3968, time: 0.148, data: 0.000) loss: 1.210 
saving the latest model (epoch 42, total_steps 421888)
(epoch: 42, iters: 4048, time: 0.151, data: 0.005) loss: 0.319 
(epoch: 42, iters: 4128, time: 0.150, data: 0.020) loss: 0.371 
(epoch: 42, iters: 4208, time: 0.153, data: 0.000) loss: 0.867 
(epoch: 42, iters: 4288, time: 0.151, data: 0.009) loss: 2.061 
(epoch: 42, iters: 4368, time: 0.153, data: 0.020) loss: 0.882 
(epoch: 42, iters: 4448, time: 0.149, data: 0.000) loss: 1.195 
(epoch: 42, iters: 4528, time: 0.150, data: 0.008) loss: 0.819 
(epoch: 42, iters: 4608, time: 0.152, data: 0.008) loss: 0.830 
(epoch: 42, iters: 4688, time: 0.152, data: 0.000) loss: 0.337 
(epoch: 42, iters: 4768, time: 0.152, data: 0.000) loss: 0.723 
(epoch: 42, iters: 4848, time: 0.153, data: 0.024) loss: 0.960 
(epoch: 42, iters: 4928, time: 0.146, data: 0.000) loss: 1.650 
(epoch: 42, iters: 5008, time: 0.150, data: 0.000) loss: 0.992 
(epoch: 42, iters: 5088, time: 0.149, data: 0.000) loss: 1.498 
(epoch: 42, iters: 5168, time: 0.153, data: 0.005) loss: 0.906 
(epoch: 42, iters: 5248, time: 0.150, data: 0.005) loss: 1.077 
(epoch: 42, iters: 5328, time: 0.151, data: 0.000) loss: 1.067 
(epoch: 42, iters: 5408, time: 0.154, data: 0.020) loss: 0.834 
(epoch: 42, iters: 5488, time: 0.152, data: 0.005) loss: 0.598 
(epoch: 42, iters: 5568, time: 0.152, data: 0.000) loss: 0.746 
(epoch: 42, iters: 5648, time: 0.150, data: 0.005) loss: 0.715 
(epoch: 42, iters: 5728, time: 0.151, data: 0.000) loss: 0.941 
(epoch: 42, iters: 5808, time: 0.149, data: 0.000) loss: 1.049 
(epoch: 42, iters: 5888, time: 0.153, data: 0.011) loss: 1.062 
(epoch: 42, iters: 5968, time: 0.150, data: 0.009) loss: 1.410 
(epoch: 42, iters: 6048, time: 0.150, data: 0.011) loss: 0.843 
(epoch: 42, iters: 6128, time: 0.151, data: 0.000) loss: 0.798 
(epoch: 42, iters: 6208, time: 0.152, data: 0.028) loss: 0.518 
(epoch: 42, iters: 6288, time: 0.151, data: 0.000) loss: 0.825 
(epoch: 42, iters: 6368, time: 0.152, data: 0.008) loss: 0.531 
(epoch: 42, iters: 6448, time: 0.151, data: 0.000) loss: 1.025 
(epoch: 42, iters: 6528, time: 0.151, data: 0.005) loss: 1.331 
(epoch: 42, iters: 6608, time: 0.149, data: 0.006) loss: 0.655 
(epoch: 42, iters: 6688, time: 0.148, data: 0.006) loss: 0.670 
(epoch: 42, iters: 6768, time: 0.150, data: 0.000) loss: 0.932 
(epoch: 42, iters: 6848, time: 0.148, data: 0.005) loss: 1.127 
(epoch: 42, iters: 6928, time: 0.149, data: 0.000) loss: 0.880 
(epoch: 42, iters: 7008, time: 0.150, data: 0.000) loss: 1.198 
(epoch: 42, iters: 7088, time: 0.150, data: 0.000) loss: 0.597 
(epoch: 42, iters: 7168, time: 0.149, data: 0.000) loss: 0.745 
(epoch: 42, iters: 7248, time: 0.150, data: 0.010) loss: 0.757 
(epoch: 42, iters: 7328, time: 0.149, data: 0.024) loss: 0.571 
(epoch: 42, iters: 7408, time: 0.150, data: 0.000) loss: 1.183 
(epoch: 42, iters: 7488, time: 0.150, data: 0.019) loss: 0.687 
(epoch: 42, iters: 7568, time: 0.150, data: 0.000) loss: 0.914 
(epoch: 42, iters: 7648, time: 0.153, data: 0.000) loss: 0.627 
(epoch: 42, iters: 7728, time: 0.148, data: 0.019) loss: 1.206 
(epoch: 42, iters: 7808, time: 0.149, data: 0.012) loss: 1.030 
(epoch: 42, iters: 7888, time: 0.150, data: 0.005) loss: 1.047 
(epoch: 42, iters: 7968, time: 0.150, data: 0.033) loss: 1.292 
saving the latest model (epoch 42, total_steps 425888)
(epoch: 42, iters: 8048, time: 0.151, data: 0.000) loss: 1.030 
(epoch: 42, iters: 8128, time: 0.150, data: 0.000) loss: 0.765 
(epoch: 42, iters: 8208, time: 0.149, data: 0.008) loss: 1.513 
(epoch: 42, iters: 8288, time: 0.150, data: 0.005) loss: 0.942 
(epoch: 42, iters: 8368, time: 0.151, data: 0.000) loss: 1.012 
(epoch: 42, iters: 8448, time: 0.151, data: 0.005) loss: 0.600 
(epoch: 42, iters: 8528, time: 0.152, data: 0.000) loss: 1.029 
(epoch: 42, iters: 8608, time: 0.152, data: 0.000) loss: 1.372 
(epoch: 42, iters: 8688, time: 0.150, data: 0.015) loss: 0.811 
(epoch: 42, iters: 8768, time: 0.150, data: 0.000) loss: 0.922 
(epoch: 42, iters: 8848, time: 0.149, data: 0.021) loss: 1.008 
(epoch: 42, iters: 8928, time: 0.151, data: 0.000) loss: 1.330 
(epoch: 42, iters: 9008, time: 0.147, data: 0.014) loss: 1.233 
(epoch: 42, iters: 9088, time: 0.149, data: 0.009) loss: 0.529 
(epoch: 42, iters: 9168, time: 0.150, data: 0.000) loss: 1.756 
(epoch: 42, iters: 9248, time: 0.148, data: 0.000) loss: 1.004 
(epoch: 42, iters: 9328, time: 0.151, data: 0.006) loss: 0.989 
(epoch: 42, iters: 9408, time: 0.151, data: 0.000) loss: 1.034 
(epoch: 42, iters: 9488, time: 0.149, data: 0.000) loss: 1.518 
(epoch: 42, iters: 9568, time: 0.153, data: 0.000) loss: 0.986 
(epoch: 42, iters: 9648, time: 0.152, data: 0.009) loss: 0.905 
(epoch: 42, iters: 9728, time: 0.150, data: 0.000) loss: 1.491 
(epoch: 42, iters: 9808, time: 0.150, data: 0.000) loss: 0.533 
(epoch: 42, iters: 9888, time: 0.151, data: 0.000) loss: 1.047 
(epoch: 42, iters: 9968, time: 0.150, data: 0.000) loss: 0.970 
(epoch: 42, iters: 10048, time: 0.150, data: 0.029) loss: 0.581 
(epoch: 42, iters: 10128, time: 0.149, data: 0.008) loss: 0.647 
saving the model at the end of epoch 42, iters 428064
End of epoch 42 / 200 	 Time Taken: 1537 sec
learning rate = 0.0002000
(epoch: 43, iters: 16, time: 0.179, data: 0.013) loss: 0.809 
saving the latest model (epoch 43, total_steps 428080)
(epoch: 43, iters: 96, time: 0.151, data: 0.025) loss: 0.805 
(epoch: 43, iters: 176, time: 0.150, data: 0.018) loss: 1.500 
(epoch: 43, iters: 256, time: 0.154, data: 0.000) loss: 0.379 
(epoch: 43, iters: 336, time: 0.153, data: 0.000) loss: 0.818 
(epoch: 43, iters: 416, time: 0.150, data: 0.000) loss: 1.294 
(epoch: 43, iters: 496, time: 0.154, data: 0.019) loss: 0.910 
(epoch: 43, iters: 576, time: 0.156, data: 0.000) loss: 1.239 
(epoch: 43, iters: 656, time: 0.153, data: 0.031) loss: 1.300 
(epoch: 43, iters: 736, time: 0.155, data: 0.000) loss: 0.991 
(epoch: 43, iters: 816, time: 0.149, data: 0.013) loss: 1.224 
(epoch: 43, iters: 896, time: 0.150, data: 0.000) loss: 0.900 
(epoch: 43, iters: 976, time: 0.146, data: 0.005) loss: 0.787 
(epoch: 43, iters: 1056, time: 0.148, data: 0.000) loss: 1.053 
(epoch: 43, iters: 1136, time: 0.148, data: 0.023) loss: 1.217 
(epoch: 43, iters: 1216, time: 0.147, data: 0.000) loss: 1.094 
(epoch: 43, iters: 1296, time: 0.148, data: 0.000) loss: 0.654 
(epoch: 43, iters: 1376, time: 0.152, data: 0.009) loss: 1.690 
(epoch: 43, iters: 1456, time: 0.152, data: 0.000) loss: 1.172 
(epoch: 43, iters: 1536, time: 0.150, data: 0.008) loss: 1.271 
(epoch: 43, iters: 1616, time: 0.150, data: 0.018) loss: 0.657 
(epoch: 43, iters: 1696, time: 0.155, data: 0.000) loss: 0.937 
(epoch: 43, iters: 1776, time: 0.151, data: 0.000) loss: 0.596 
(epoch: 43, iters: 1856, time: 0.153, data: 0.008) loss: 0.769 
(epoch: 43, iters: 1936, time: 0.151, data: 0.000) loss: 1.171 
(epoch: 43, iters: 2016, time: 0.153, data: 0.008) loss: 0.970 
(epoch: 43, iters: 2096, time: 0.151, data: 0.000) loss: 1.167 
(epoch: 43, iters: 2176, time: 0.149, data: 0.000) loss: 0.810 
(epoch: 43, iters: 2256, time: 0.154, data: 0.021) loss: 0.919 
(epoch: 43, iters: 2336, time: 0.153, data: 0.000) loss: 0.784 
(epoch: 43, iters: 2416, time: 0.152, data: 0.005) loss: 0.613 
(epoch: 43, iters: 2496, time: 0.153, data: 0.015) loss: 0.448 
(epoch: 43, iters: 2576, time: 0.152, data: 0.000) loss: 1.406 
(epoch: 43, iters: 2656, time: 0.154, data: 0.000) loss: 1.052 
(epoch: 43, iters: 2736, time: 0.151, data: 0.000) loss: 1.030 
(epoch: 43, iters: 2816, time: 0.153, data: 0.000) loss: 0.695 
(epoch: 43, iters: 2896, time: 0.152, data: 0.000) loss: 1.406 
(epoch: 43, iters: 2976, time: 0.154, data: 0.000) loss: 0.954 
(epoch: 43, iters: 3056, time: 0.151, data: 0.000) loss: 0.709 
(epoch: 43, iters: 3136, time: 0.151, data: 0.026) loss: 0.875 
(epoch: 43, iters: 3216, time: 0.148, data: 0.000) loss: 0.981 
(epoch: 43, iters: 3296, time: 0.151, data: 0.031) loss: 1.234 
(epoch: 43, iters: 3376, time: 0.150, data: 0.000) loss: 1.099 
(epoch: 43, iters: 3456, time: 0.148, data: 0.013) loss: 1.103 
(epoch: 43, iters: 3536, time: 0.152, data: 0.008) loss: 1.184 
(epoch: 43, iters: 3616, time: 0.154, data: 0.005) loss: 1.405 
(epoch: 43, iters: 3696, time: 0.149, data: 0.006) loss: 0.720 
(epoch: 43, iters: 3776, time: 0.150, data: 0.010) loss: 0.505 
(epoch: 43, iters: 3856, time: 0.148, data: 0.009) loss: 0.926 
(epoch: 43, iters: 3936, time: 0.150, data: 0.000) loss: 0.638 
(epoch: 43, iters: 4016, time: 0.150, data: 0.006) loss: 0.914 
saving the latest model (epoch 43, total_steps 432080)
(epoch: 43, iters: 4096, time: 0.152, data: 0.000) loss: 0.379 
(epoch: 43, iters: 4176, time: 0.150, data: 0.008) loss: 0.888 
(epoch: 43, iters: 4256, time: 0.153, data: 0.005) loss: 1.045 
(epoch: 43, iters: 4336, time: 0.152, data: 0.000) loss: 0.757 
(epoch: 43, iters: 4416, time: 0.156, data: 0.000) loss: 0.912 
(epoch: 43, iters: 4496, time: 0.153, data: 0.000) loss: 0.984 
(epoch: 43, iters: 4576, time: 0.153, data: 0.000) loss: 1.247 
(epoch: 43, iters: 4656, time: 0.152, data: 0.014) loss: 1.106 
(epoch: 43, iters: 4736, time: 0.153, data: 0.005) loss: 0.421 
(epoch: 43, iters: 4816, time: 0.152, data: 0.000) loss: 0.967 
(epoch: 43, iters: 4896, time: 0.150, data: 0.011) loss: 1.104 
(epoch: 43, iters: 4976, time: 0.151, data: 0.000) loss: 0.770 
(epoch: 43, iters: 5056, time: 0.154, data: 0.006) loss: 0.549 
(epoch: 43, iters: 5136, time: 0.149, data: 0.000) loss: 0.596 
(epoch: 43, iters: 5216, time: 0.148, data: 0.000) loss: 0.888 
(epoch: 43, iters: 5296, time: 0.151, data: 0.005) loss: 0.806 
(epoch: 43, iters: 5376, time: 0.152, data: 0.000) loss: 0.546 
(epoch: 43, iters: 5456, time: 0.154, data: 0.017) loss: 0.759 
(epoch: 43, iters: 5536, time: 0.149, data: 0.009) loss: 0.879 
(epoch: 43, iters: 5616, time: 0.146, data: 0.000) loss: 0.675 
(epoch: 43, iters: 5696, time: 0.147, data: 0.014) loss: 1.561 
(epoch: 43, iters: 5776, time: 0.149, data: 0.000) loss: 1.439 
(epoch: 43, iters: 5856, time: 0.146, data: 0.000) loss: 0.741 
(epoch: 43, iters: 5936, time: 0.146, data: 0.013) loss: 0.861 
(epoch: 43, iters: 6016, time: 0.149, data: 0.000) loss: 0.700 
(epoch: 43, iters: 6096, time: 0.147, data: 0.018) loss: 0.735 
(epoch: 43, iters: 6176, time: 0.148, data: 0.013) loss: 1.514 
(epoch: 43, iters: 6256, time: 0.147, data: 0.000) loss: 1.091 
(epoch: 43, iters: 6336, time: 0.151, data: 0.015) loss: 1.135 
(epoch: 43, iters: 6416, time: 0.151, data: 0.000) loss: 0.706 
(epoch: 43, iters: 6496, time: 0.153, data: 0.014) loss: 0.856 
(epoch: 43, iters: 6576, time: 0.148, data: 0.005) loss: 0.448 
(epoch: 43, iters: 6656, time: 0.149, data: 0.008) loss: 0.966 
(epoch: 43, iters: 6736, time: 0.148, data: 0.000) loss: 0.603 
(epoch: 43, iters: 6816, time: 0.150, data: 0.000) loss: 1.366 
(epoch: 43, iters: 6896, time: 0.149, data: 0.005) loss: 0.569 
(epoch: 43, iters: 6976, time: 0.151, data: 0.000) loss: 2.080 
(epoch: 43, iters: 7056, time: 0.152, data: 0.000) loss: 0.719 
(epoch: 43, iters: 7136, time: 0.152, data: 0.005) loss: 0.965 
(epoch: 43, iters: 7216, time: 0.147, data: 0.022) loss: 0.902 
(epoch: 43, iters: 7296, time: 0.149, data: 0.000) loss: 0.536 
(epoch: 43, iters: 7376, time: 0.148, data: 0.005) loss: 0.967 
(epoch: 43, iters: 7456, time: 0.153, data: 0.005) loss: 0.699 
(epoch: 43, iters: 7536, time: 0.151, data: 0.000) loss: 0.919 
(epoch: 43, iters: 7616, time: 0.153, data: 0.016) loss: 0.702 
(epoch: 43, iters: 7696, time: 0.151, data: 0.000) loss: 1.192 
(epoch: 43, iters: 7776, time: 0.151, data: 0.008) loss: 1.177 
(epoch: 43, iters: 7856, time: 0.155, data: 0.000) loss: 0.790 
(epoch: 43, iters: 7936, time: 0.154, data: 0.000) loss: 0.842 
(epoch: 43, iters: 8016, time: 0.156, data: 0.000) loss: 1.174 
saving the latest model (epoch 43, total_steps 436080)
(epoch: 43, iters: 8096, time: 0.152, data: 0.000) loss: 0.687 
(epoch: 43, iters: 8176, time: 0.152, data: 0.000) loss: 1.308 
(epoch: 43, iters: 8256, time: 0.149, data: 0.000) loss: 0.996 
(epoch: 43, iters: 8336, time: 0.149, data: 0.000) loss: 1.147 
(epoch: 43, iters: 8416, time: 0.149, data: 0.008) loss: 0.469 
(epoch: 43, iters: 8496, time: 0.152, data: 0.000) loss: 0.762 
(epoch: 43, iters: 8576, time: 0.153, data: 0.015) loss: 1.751 
(epoch: 43, iters: 8656, time: 0.153, data: 0.000) loss: 0.576 
(epoch: 43, iters: 8736, time: 0.151, data: 0.011) loss: 1.057 
(epoch: 43, iters: 8816, time: 0.153, data: 0.000) loss: 1.105 
(epoch: 43, iters: 8896, time: 0.150, data: 0.005) loss: 1.107 
(epoch: 43, iters: 8976, time: 0.153, data: 0.015) loss: 0.701 
(epoch: 43, iters: 9056, time: 0.148, data: 0.005) loss: 1.026 
(epoch: 43, iters: 9136, time: 0.149, data: 0.000) loss: 0.865 
(epoch: 43, iters: 9216, time: 0.151, data: 0.010) loss: 1.599 
(epoch: 43, iters: 9296, time: 0.152, data: 0.000) loss: 1.387 
(epoch: 43, iters: 9376, time: 0.150, data: 0.000) loss: 0.296 
(epoch: 43, iters: 9456, time: 0.150, data: 0.014) loss: 0.628 
(epoch: 43, iters: 9536, time: 0.150, data: 0.000) loss: 1.001 
(epoch: 43, iters: 9616, time: 0.149, data: 0.000) loss: 0.347 
(epoch: 43, iters: 9696, time: 0.150, data: 0.005) loss: 1.038 
(epoch: 43, iters: 9776, time: 0.151, data: 0.005) loss: 0.649 
(epoch: 43, iters: 9856, time: 0.151, data: 0.000) loss: 0.657 
(epoch: 43, iters: 9936, time: 0.147, data: 0.011) loss: 0.714 
(epoch: 43, iters: 10016, time: 0.149, data: 0.008) loss: 0.866 
(epoch: 43, iters: 10096, time: 0.151, data: 0.016) loss: 1.147 
(epoch: 43, iters: 10176, time: 0.152, data: 0.000) loss: 0.956 
saving the model at the end of epoch 43, iters 438256
End of epoch 43 / 200 	 Time Taken: 1540 sec
learning rate = 0.0002000
saving the latest model (epoch 44, total_steps 438272)
(epoch: 44, iters: 64, time: 0.153, data: 0.000) loss: 0.651 
(epoch: 44, iters: 144, time: 0.155, data: 0.000) loss: 0.673 
(epoch: 44, iters: 224, time: 0.151, data: 0.005) loss: 0.470 
(epoch: 44, iters: 304, time: 0.150, data: 0.006) loss: 0.718 
(epoch: 44, iters: 384, time: 0.151, data: 0.000) loss: 0.686 
(epoch: 44, iters: 464, time: 0.150, data: 0.005) loss: 0.788 
(epoch: 44, iters: 544, time: 0.147, data: 0.000) loss: 0.633 
(epoch: 44, iters: 624, time: 0.151, data: 0.008) loss: 1.001 
(epoch: 44, iters: 704, time: 0.152, data: 0.000) loss: 1.344 
(epoch: 44, iters: 784, time: 0.150, data: 0.006) loss: 1.670 
(epoch: 44, iters: 864, time: 0.150, data: 0.000) loss: 0.448 
(epoch: 44, iters: 944, time: 0.152, data: 0.031) loss: 0.629 
(epoch: 44, iters: 1024, time: 0.149, data: 0.000) loss: 0.488 
(epoch: 44, iters: 1104, time: 0.149, data: 0.000) loss: 0.714 
(epoch: 44, iters: 1184, time: 0.148, data: 0.000) loss: 0.873 
(epoch: 44, iters: 1264, time: 0.149, data: 0.000) loss: 1.002 
(epoch: 44, iters: 1344, time: 0.150, data: 0.000) loss: 0.514 
(epoch: 44, iters: 1424, time: 0.153, data: 0.000) loss: 0.655 
(epoch: 44, iters: 1504, time: 0.149, data: 0.014) loss: 1.043 
(epoch: 44, iters: 1584, time: 0.153, data: 0.018) loss: 1.173 
(epoch: 44, iters: 1664, time: 0.150, data: 0.005) loss: 0.994 
(epoch: 44, iters: 1744, time: 0.151, data: 0.016) loss: 1.047 
(epoch: 44, iters: 1824, time: 0.152, data: 0.025) loss: 1.026 
(epoch: 44, iters: 1904, time: 0.149, data: 0.000) loss: 0.562 
(epoch: 44, iters: 1984, time: 0.150, data: 0.000) loss: 1.084 
(epoch: 44, iters: 2064, time: 0.150, data: 0.005) loss: 0.633 
(epoch: 44, iters: 2144, time: 0.152, data: 0.009) loss: 0.431 
(epoch: 44, iters: 2224, time: 0.150, data: 0.000) loss: 1.503 
(epoch: 44, iters: 2304, time: 0.150, data: 0.005) loss: 0.885 
(epoch: 44, iters: 2384, time: 0.150, data: 0.017) loss: 1.001 
(epoch: 44, iters: 2464, time: 0.149, data: 0.000) loss: 1.155 
(epoch: 44, iters: 2544, time: 0.149, data: 0.005) loss: 1.237 
(epoch: 44, iters: 2624, time: 0.151, data: 0.032) loss: 1.098 
(epoch: 44, iters: 2704, time: 0.151, data: 0.000) loss: 0.753 
(epoch: 44, iters: 2784, time: 0.151, data: 0.000) loss: 0.861 
(epoch: 44, iters: 2864, time: 0.154, data: 0.005) loss: 0.994 
(epoch: 44, iters: 2944, time: 0.147, data: 0.000) loss: 0.783 
(epoch: 44, iters: 3024, time: 0.147, data: 0.000) loss: 1.234 
(epoch: 44, iters: 3104, time: 0.150, data: 0.022) loss: 0.949 
(epoch: 44, iters: 3184, time: 0.147, data: 0.014) loss: 0.750 
(epoch: 44, iters: 3264, time: 0.148, data: 0.026) loss: 0.627 
(epoch: 44, iters: 3344, time: 0.150, data: 0.000) loss: 0.845 
(epoch: 44, iters: 3424, time: 0.152, data: 0.005) loss: 0.523 
(epoch: 44, iters: 3504, time: 0.153, data: 0.009) loss: 0.789 
(epoch: 44, iters: 3584, time: 0.151, data: 0.009) loss: 0.840 
(epoch: 44, iters: 3664, time: 0.150, data: 0.024) loss: 0.639 
(epoch: 44, iters: 3744, time: 0.153, data: 0.000) loss: 0.694 
(epoch: 44, iters: 3824, time: 0.149, data: 0.025) loss: 1.407 
(epoch: 44, iters: 3904, time: 0.149, data: 0.000) loss: 1.093 
(epoch: 44, iters: 3984, time: 0.151, data: 0.000) loss: 0.380 
saving the latest model (epoch 44, total_steps 442272)
(epoch: 44, iters: 4064, time: 0.152, data: 0.000) loss: 0.758 
(epoch: 44, iters: 4144, time: 0.153, data: 0.009) loss: 0.902 
(epoch: 44, iters: 4224, time: 0.150, data: 0.000) loss: 0.794 
(epoch: 44, iters: 4304, time: 0.151, data: 0.029) loss: 0.950 
(epoch: 44, iters: 4384, time: 0.148, data: 0.000) loss: 1.647 
(epoch: 44, iters: 4464, time: 0.150, data: 0.035) loss: 0.717 
(epoch: 44, iters: 4544, time: 0.149, data: 0.039) loss: 1.516 
(epoch: 44, iters: 4624, time: 0.148, data: 0.000) loss: 1.225 
(epoch: 44, iters: 4704, time: 0.150, data: 0.023) loss: 1.224 
(epoch: 44, iters: 4784, time: 0.151, data: 0.000) loss: 0.818 
(epoch: 44, iters: 4864, time: 0.150, data: 0.000) loss: 1.070 
(epoch: 44, iters: 4944, time: 0.149, data: 0.005) loss: 1.113 
(epoch: 44, iters: 5024, time: 0.150, data: 0.008) loss: 0.564 
(epoch: 44, iters: 5104, time: 0.151, data: 0.005) loss: 1.732 
(epoch: 44, iters: 5184, time: 0.150, data: 0.000) loss: 0.736 
(epoch: 44, iters: 5264, time: 0.148, data: 0.000) loss: 0.809 
(epoch: 44, iters: 5344, time: 0.149, data: 0.005) loss: 1.143 
(epoch: 44, iters: 5424, time: 0.152, data: 0.011) loss: 1.061 
(epoch: 44, iters: 5504, time: 0.148, data: 0.000) loss: 0.781 
(epoch: 44, iters: 5584, time: 0.147, data: 0.010) loss: 1.173 
(epoch: 44, iters: 5664, time: 0.150, data: 0.000) loss: 0.946 
(epoch: 44, iters: 5744, time: 0.150, data: 0.033) loss: 0.708 
(epoch: 44, iters: 5824, time: 0.150, data: 0.000) loss: 0.983 
(epoch: 44, iters: 5904, time: 0.151, data: 0.016) loss: 0.962 
(epoch: 44, iters: 5984, time: 0.147, data: 0.000) loss: 0.363 
(epoch: 44, iters: 6064, time: 0.150, data: 0.034) loss: 1.212 
(epoch: 44, iters: 6144, time: 0.151, data: 0.000) loss: 0.615 
(epoch: 44, iters: 6224, time: 0.152, data: 0.000) loss: 0.827 
(epoch: 44, iters: 6304, time: 0.152, data: 0.005) loss: 0.788 
(epoch: 44, iters: 6384, time: 0.152, data: 0.000) loss: 0.622 
(epoch: 44, iters: 6464, time: 0.150, data: 0.031) loss: 0.860 
(epoch: 44, iters: 6544, time: 0.151, data: 0.000) loss: 0.907 
(epoch: 44, iters: 6624, time: 0.151, data: 0.000) loss: 0.615 
(epoch: 44, iters: 6704, time: 0.152, data: 0.005) loss: 0.849 
(epoch: 44, iters: 6784, time: 0.152, data: 0.000) loss: 1.176 
(epoch: 44, iters: 6864, time: 0.153, data: 0.005) loss: 0.493 
(epoch: 44, iters: 6944, time: 0.150, data: 0.000) loss: 0.647 
(epoch: 44, iters: 7024, time: 0.150, data: 0.000) loss: 1.268 
(epoch: 44, iters: 7104, time: 0.148, data: 0.000) loss: 0.721 
(epoch: 44, iters: 7184, time: 0.147, data: 0.005) loss: 0.854 
(epoch: 44, iters: 7264, time: 0.146, data: 0.000) loss: 0.730 
(epoch: 44, iters: 7344, time: 0.150, data: 0.018) loss: 0.878 
(epoch: 44, iters: 7424, time: 0.149, data: 0.000) loss: 1.527 
(epoch: 44, iters: 7504, time: 0.148, data: 0.000) loss: 0.875 
(epoch: 44, iters: 7584, time: 0.149, data: 0.000) loss: 0.975 
(epoch: 44, iters: 7664, time: 0.150, data: 0.000) loss: 0.889 
(epoch: 44, iters: 7744, time: 0.154, data: 0.024) loss: 0.481 
(epoch: 44, iters: 7824, time: 0.151, data: 0.009) loss: 0.426 
(epoch: 44, iters: 7904, time: 0.151, data: 0.006) loss: 1.107 
(epoch: 44, iters: 7984, time: 0.148, data: 0.005) loss: 1.087 
saving the latest model (epoch 44, total_steps 446272)
(epoch: 44, iters: 8064, time: 0.148, data: 0.000) loss: 0.954 
(epoch: 44, iters: 8144, time: 0.152, data: 0.014) loss: 0.493 
(epoch: 44, iters: 8224, time: 0.149, data: 0.000) loss: 0.584 
(epoch: 44, iters: 8304, time: 0.151, data: 0.018) loss: 1.173 
(epoch: 44, iters: 8384, time: 0.148, data: 0.000) loss: 1.041 
(epoch: 44, iters: 8464, time: 0.149, data: 0.000) loss: 0.900 
(epoch: 44, iters: 8544, time: 0.148, data: 0.005) loss: 1.341 
(epoch: 44, iters: 8624, time: 0.148, data: 0.000) loss: 0.934 
(epoch: 44, iters: 8704, time: 0.149, data: 0.000) loss: 0.809 
(epoch: 44, iters: 8784, time: 0.148, data: 0.000) loss: 0.604 
(epoch: 44, iters: 8864, time: 0.148, data: 0.018) loss: 1.089 
(epoch: 44, iters: 8944, time: 0.149, data: 0.024) loss: 1.165 
(epoch: 44, iters: 9024, time: 0.151, data: 0.000) loss: 0.879 
(epoch: 44, iters: 9104, time: 0.150, data: 0.032) loss: 0.955 
(epoch: 44, iters: 9184, time: 0.149, data: 0.000) loss: 0.611 
(epoch: 44, iters: 9264, time: 0.148, data: 0.000) loss: 0.974 
(epoch: 44, iters: 9344, time: 0.148, data: 0.015) loss: 0.491 
(epoch: 44, iters: 9424, time: 0.150, data: 0.013) loss: 1.165 
(epoch: 44, iters: 9504, time: 0.148, data: 0.009) loss: 1.121 
(epoch: 44, iters: 9584, time: 0.149, data: 0.014) loss: 0.822 
(epoch: 44, iters: 9664, time: 0.149, data: 0.000) loss: 1.350 
(epoch: 44, iters: 9744, time: 0.152, data: 0.020) loss: 1.279 
(epoch: 44, iters: 9824, time: 0.149, data: 0.000) loss: 0.307 
(epoch: 44, iters: 9904, time: 0.151, data: 0.000) loss: 1.052 
(epoch: 44, iters: 9984, time: 0.150, data: 0.006) loss: 0.949 
(epoch: 44, iters: 10064, time: 0.152, data: 0.000) loss: 0.675 
(epoch: 44, iters: 10144, time: 0.148, data: 0.017) loss: 1.098 
saving the model at the end of epoch 44, iters 448448
End of epoch 44 / 200 	 Time Taken: 1533 sec
learning rate = 0.0002000
saving the latest model (epoch 45, total_steps 448464)
(epoch: 45, iters: 32, time: 0.159, data: 0.017) loss: 1.304 
(epoch: 45, iters: 112, time: 0.152, data: 0.015) loss: 0.695 
(epoch: 45, iters: 192, time: 0.152, data: 0.000) loss: 0.812 
(epoch: 45, iters: 272, time: 0.149, data: 0.025) loss: 0.818 
(epoch: 45, iters: 352, time: 0.153, data: 0.000) loss: 0.730 
(epoch: 45, iters: 432, time: 0.152, data: 0.013) loss: 1.261 
(epoch: 45, iters: 512, time: 0.148, data: 0.005) loss: 0.590 
(epoch: 45, iters: 592, time: 0.150, data: 0.005) loss: 1.412 
(epoch: 45, iters: 672, time: 0.150, data: 0.000) loss: 0.846 
(epoch: 45, iters: 752, time: 0.148, data: 0.010) loss: 1.075 
(epoch: 45, iters: 832, time: 0.151, data: 0.000) loss: 0.840 
(epoch: 45, iters: 912, time: 0.151, data: 0.005) loss: 0.530 
(epoch: 45, iters: 992, time: 0.149, data: 0.023) loss: 0.872 
(epoch: 45, iters: 1072, time: 0.153, data: 0.000) loss: 0.835 
(epoch: 45, iters: 1152, time: 0.149, data: 0.000) loss: 0.998 
(epoch: 45, iters: 1232, time: 0.152, data: 0.008) loss: 1.088 
(epoch: 45, iters: 1312, time: 0.150, data: 0.005) loss: 1.045 
(epoch: 45, iters: 1392, time: 0.150, data: 0.008) loss: 0.911 
(epoch: 45, iters: 1472, time: 0.151, data: 0.000) loss: 0.508 
(epoch: 45, iters: 1552, time: 0.153, data: 0.010) loss: 0.745 
(epoch: 45, iters: 1632, time: 0.156, data: 0.000) loss: 0.275 
(epoch: 45, iters: 1712, time: 0.149, data: 0.024) loss: 0.846 
(epoch: 45, iters: 1792, time: 0.149, data: 0.000) loss: 1.890 
(epoch: 45, iters: 1872, time: 0.150, data: 0.000) loss: 0.619 
(epoch: 45, iters: 1952, time: 0.153, data: 0.000) loss: 0.725 
(epoch: 45, iters: 2032, time: 0.151, data: 0.005) loss: 0.893 
(epoch: 45, iters: 2112, time: 0.151, data: 0.000) loss: 0.474 
(epoch: 45, iters: 2192, time: 0.149, data: 0.011) loss: 1.604 
(epoch: 45, iters: 2272, time: 0.147, data: 0.000) loss: 0.995 
(epoch: 45, iters: 2352, time: 0.152, data: 0.039) loss: 0.947 
(epoch: 45, iters: 2432, time: 0.151, data: 0.000) loss: 1.407 
(epoch: 45, iters: 2512, time: 0.153, data: 0.024) loss: 1.265 
(epoch: 45, iters: 2592, time: 0.154, data: 0.000) loss: 0.636 
(epoch: 45, iters: 2672, time: 0.154, data: 0.000) loss: 1.050 
(epoch: 45, iters: 2752, time: 0.152, data: 0.018) loss: 0.919 
(epoch: 45, iters: 2832, time: 0.151, data: 0.000) loss: 1.675 
(epoch: 45, iters: 2912, time: 0.152, data: 0.024) loss: 0.644 
(epoch: 45, iters: 2992, time: 0.152, data: 0.000) loss: 0.713 
(epoch: 45, iters: 3072, time: 0.150, data: 0.008) loss: 1.566 
(epoch: 45, iters: 3152, time: 0.150, data: 0.000) loss: 0.944 
(epoch: 45, iters: 3232, time: 0.151, data: 0.005) loss: 0.638 
(epoch: 45, iters: 3312, time: 0.150, data: 0.000) loss: 1.015 
(epoch: 45, iters: 3392, time: 0.149, data: 0.000) loss: 0.564 
(epoch: 45, iters: 3472, time: 0.152, data: 0.014) loss: 0.702 
(epoch: 45, iters: 3552, time: 0.151, data: 0.017) loss: 0.731 
(epoch: 45, iters: 3632, time: 0.150, data: 0.000) loss: 0.997 
(epoch: 45, iters: 3712, time: 0.150, data: 0.016) loss: 1.055 
(epoch: 45, iters: 3792, time: 0.152, data: 0.015) loss: 1.238 
(epoch: 45, iters: 3872, time: 0.150, data: 0.005) loss: 0.867 
(epoch: 45, iters: 3952, time: 0.151, data: 0.000) loss: 0.930 
saving the latest model (epoch 45, total_steps 452464)
(epoch: 45, iters: 4032, time: 0.149, data: 0.000) loss: 1.232 
(epoch: 45, iters: 4112, time: 0.150, data: 0.008) loss: 1.110 
(epoch: 45, iters: 4192, time: 0.152, data: 0.005) loss: 1.300 
(epoch: 45, iters: 4272, time: 0.150, data: 0.000) loss: 1.220 
(epoch: 45, iters: 4352, time: 0.155, data: 0.000) loss: 1.003 
(epoch: 45, iters: 4432, time: 0.150, data: 0.000) loss: 1.270 
(epoch: 45, iters: 4512, time: 0.152, data: 0.000) loss: 0.856 
(epoch: 45, iters: 4592, time: 0.150, data: 0.000) loss: 0.646 
(epoch: 45, iters: 4672, time: 0.151, data: 0.000) loss: 1.558 
(epoch: 45, iters: 4752, time: 0.150, data: 0.023) loss: 1.795 
(epoch: 45, iters: 4832, time: 0.151, data: 0.000) loss: 0.788 
(epoch: 45, iters: 4912, time: 0.148, data: 0.000) loss: 0.993 
(epoch: 45, iters: 4992, time: 0.150, data: 0.006) loss: 1.091 
(epoch: 45, iters: 5072, time: 0.149, data: 0.017) loss: 0.714 
(epoch: 45, iters: 5152, time: 0.151, data: 0.000) loss: 1.403 
(epoch: 45, iters: 5232, time: 0.147, data: 0.000) loss: 0.645 
(epoch: 45, iters: 5312, time: 0.150, data: 0.005) loss: 0.687 
(epoch: 45, iters: 5392, time: 0.148, data: 0.000) loss: 1.307 
(epoch: 45, iters: 5472, time: 0.150, data: 0.006) loss: 1.433 
(epoch: 45, iters: 5552, time: 0.149, data: 0.000) loss: 1.155 
(epoch: 45, iters: 5632, time: 0.148, data: 0.009) loss: 0.524 
(epoch: 45, iters: 5712, time: 0.152, data: 0.006) loss: 1.449 
(epoch: 45, iters: 5792, time: 0.151, data: 0.010) loss: 1.206 
(epoch: 45, iters: 5872, time: 0.152, data: 0.005) loss: 0.954 
(epoch: 45, iters: 5952, time: 0.151, data: 0.028) loss: 1.303 
(epoch: 45, iters: 6032, time: 0.150, data: 0.000) loss: 1.613 
(epoch: 45, iters: 6112, time: 0.153, data: 0.010) loss: 1.341 
(epoch: 45, iters: 6192, time: 0.150, data: 0.000) loss: 1.245 
(epoch: 45, iters: 6272, time: 0.155, data: 0.031) loss: 1.368 
(epoch: 45, iters: 6352, time: 0.150, data: 0.000) loss: 1.632 
(epoch: 45, iters: 6432, time: 0.153, data: 0.000) loss: 0.932 
(epoch: 45, iters: 6512, time: 0.152, data: 0.005) loss: 1.167 
(epoch: 45, iters: 6592, time: 0.152, data: 0.000) loss: 0.954 
(epoch: 45, iters: 6672, time: 0.155, data: 0.000) loss: 1.425 
(epoch: 45, iters: 6752, time: 0.152, data: 0.000) loss: 0.482 
(epoch: 45, iters: 6832, time: 0.155, data: 0.006) loss: 0.588 
(epoch: 45, iters: 6912, time: 0.157, data: 0.000) loss: 0.909 
(epoch: 45, iters: 6992, time: 0.154, data: 0.010) loss: 0.817 
(epoch: 45, iters: 7072, time: 0.152, data: 0.000) loss: 1.409 
(epoch: 45, iters: 7152, time: 0.153, data: 0.014) loss: 0.885 
(epoch: 45, iters: 7232, time: 0.154, data: 0.005) loss: 1.007 
(epoch: 45, iters: 7312, time: 0.152, data: 0.005) loss: 0.654 
(epoch: 45, iters: 7392, time: 0.153, data: 0.005) loss: 0.516 
(epoch: 45, iters: 7472, time: 0.150, data: 0.008) loss: 1.166 
(epoch: 45, iters: 7552, time: 0.150, data: 0.000) loss: 0.858 
(epoch: 45, iters: 7632, time: 0.154, data: 0.005) loss: 1.284 
(epoch: 45, iters: 7712, time: 0.152, data: 0.000) loss: 1.107 
(epoch: 45, iters: 7792, time: 0.153, data: 0.000) loss: 0.595 
(epoch: 45, iters: 7872, time: 0.149, data: 0.000) loss: 0.733 
(epoch: 45, iters: 7952, time: 0.150, data: 0.011) loss: 1.806 
saving the latest model (epoch 45, total_steps 456464)
(epoch: 45, iters: 8032, time: 0.151, data: 0.000) loss: 0.517 
(epoch: 45, iters: 8112, time: 0.157, data: 0.000) loss: 0.818 
(epoch: 45, iters: 8192, time: 0.150, data: 0.000) loss: 1.129 
(epoch: 45, iters: 8272, time: 0.149, data: 0.000) loss: 1.306 
(epoch: 45, iters: 8352, time: 0.154, data: 0.000) loss: 0.727 
(epoch: 45, iters: 8432, time: 0.149, data: 0.000) loss: 0.747 
(epoch: 45, iters: 8512, time: 0.150, data: 0.000) loss: 0.844 
(epoch: 45, iters: 8592, time: 0.151, data: 0.008) loss: 0.901 
(epoch: 45, iters: 8672, time: 0.150, data: 0.000) loss: 0.956 
(epoch: 45, iters: 8752, time: 0.151, data: 0.000) loss: 0.816 
(epoch: 45, iters: 8832, time: 0.150, data: 0.000) loss: 0.728 
(epoch: 45, iters: 8912, time: 0.152, data: 0.000) loss: 0.793 
(epoch: 45, iters: 8992, time: 0.155, data: 0.015) loss: 0.640 
(epoch: 45, iters: 9072, time: 0.151, data: 0.016) loss: 0.472 
(epoch: 45, iters: 9152, time: 0.151, data: 0.000) loss: 1.051 
(epoch: 45, iters: 9232, time: 0.152, data: 0.000) loss: 0.710 
(epoch: 45, iters: 9312, time: 0.152, data: 0.014) loss: 0.851 
(epoch: 45, iters: 9392, time: 0.151, data: 0.000) loss: 0.695 
(epoch: 45, iters: 9472, time: 0.151, data: 0.013) loss: 1.251 
(epoch: 45, iters: 9552, time: 0.149, data: 0.000) loss: 0.420 
(epoch: 45, iters: 9632, time: 0.155, data: 0.024) loss: 1.075 
(epoch: 45, iters: 9712, time: 0.154, data: 0.005) loss: 1.083 
(epoch: 45, iters: 9792, time: 0.151, data: 0.009) loss: 1.258 
(epoch: 45, iters: 9872, time: 0.152, data: 0.000) loss: 0.512 
(epoch: 45, iters: 9952, time: 0.152, data: 0.025) loss: 0.464 
(epoch: 45, iters: 10032, time: 0.153, data: 0.000) loss: 0.949 
(epoch: 45, iters: 10112, time: 0.151, data: 0.017) loss: 0.790 
(epoch: 45, iters: 10192, time: 0.091, data: 0.000) loss: 0.483 
saving the model at the end of epoch 45, iters 458640
End of epoch 45 / 200 	 Time Taken: 1544 sec
learning rate = 0.0002000
saving the latest model (epoch 46, total_steps 458656)
(epoch: 46, iters: 80, time: 0.154, data: 0.185) loss: 1.199 
(epoch: 46, iters: 160, time: 0.151, data: 0.019) loss: 1.329 
(epoch: 46, iters: 240, time: 0.152, data: 0.000) loss: 0.809 
(epoch: 46, iters: 320, time: 0.153, data: 0.023) loss: 0.725 
(epoch: 46, iters: 400, time: 0.152, data: 0.000) loss: 0.579 
(epoch: 46, iters: 480, time: 0.151, data: 0.000) loss: 1.039 
(epoch: 46, iters: 560, time: 0.150, data: 0.031) loss: 1.022 
(epoch: 46, iters: 640, time: 0.151, data: 0.000) loss: 0.486 
(epoch: 46, iters: 720, time: 0.153, data: 0.000) loss: 1.322 
(epoch: 46, iters: 800, time: 0.151, data: 0.000) loss: 1.062 
(epoch: 46, iters: 880, time: 0.151, data: 0.011) loss: 0.476 
(epoch: 46, iters: 960, time: 0.150, data: 0.000) loss: 0.702 
(epoch: 46, iters: 1040, time: 0.152, data: 0.000) loss: 0.984 
(epoch: 46, iters: 1120, time: 0.150, data: 0.014) loss: 0.934 
(epoch: 46, iters: 1200, time: 0.148, data: 0.022) loss: 1.088 
(epoch: 46, iters: 1280, time: 0.150, data: 0.000) loss: 1.576 
(epoch: 46, iters: 1360, time: 0.149, data: 0.008) loss: 0.982 
(epoch: 46, iters: 1440, time: 0.149, data: 0.000) loss: 1.178 
(epoch: 46, iters: 1520, time: 0.150, data: 0.017) loss: 1.108 
(epoch: 46, iters: 1600, time: 0.150, data: 0.000) loss: 0.842 
(epoch: 46, iters: 1680, time: 0.152, data: 0.008) loss: 0.599 
(epoch: 46, iters: 1760, time: 0.151, data: 0.005) loss: 0.728 
(epoch: 46, iters: 1840, time: 0.150, data: 0.008) loss: 1.542 
(epoch: 46, iters: 1920, time: 0.152, data: 0.013) loss: 0.820 
(epoch: 46, iters: 2000, time: 0.150, data: 0.000) loss: 0.932 
(epoch: 46, iters: 2080, time: 0.151, data: 0.005) loss: 1.366 
(epoch: 46, iters: 2160, time: 0.150, data: 0.034) loss: 0.790 
(epoch: 46, iters: 2240, time: 0.150, data: 0.000) loss: 0.488 
(epoch: 46, iters: 2320, time: 0.149, data: 0.032) loss: 0.512 
(epoch: 46, iters: 2400, time: 0.150, data: 0.000) loss: 1.028 
(epoch: 46, iters: 2480, time: 0.152, data: 0.000) loss: 0.536 
(epoch: 46, iters: 2560, time: 0.152, data: 0.005) loss: 0.516 
(epoch: 46, iters: 2640, time: 0.150, data: 0.005) loss: 0.438 
(epoch: 46, iters: 2720, time: 0.149, data: 0.000) loss: 0.862 
(epoch: 46, iters: 2800, time: 0.150, data: 0.022) loss: 1.320 
(epoch: 46, iters: 2880, time: 0.150, data: 0.000) loss: 1.176 
(epoch: 46, iters: 2960, time: 0.151, data: 0.005) loss: 0.816 
(epoch: 46, iters: 3040, time: 0.151, data: 0.013) loss: 1.756 
(epoch: 46, iters: 3120, time: 0.152, data: 0.000) loss: 0.539 
(epoch: 46, iters: 3200, time: 0.151, data: 0.000) loss: 1.187 
(epoch: 46, iters: 3280, time: 0.151, data: 0.015) loss: 0.361 
(epoch: 46, iters: 3360, time: 0.150, data: 0.000) loss: 0.311 
(epoch: 46, iters: 3440, time: 0.149, data: 0.000) loss: 1.358 
(epoch: 46, iters: 3520, time: 0.150, data: 0.019) loss: 0.711 
(epoch: 46, iters: 3600, time: 0.148, data: 0.000) loss: 1.175 
(epoch: 46, iters: 3680, time: 0.152, data: 0.000) loss: 1.327 
(epoch: 46, iters: 3760, time: 0.152, data: 0.000) loss: 0.660 
(epoch: 46, iters: 3840, time: 0.148, data: 0.000) loss: 1.356 
(epoch: 46, iters: 3920, time: 0.149, data: 0.000) loss: 1.149 
(epoch: 46, iters: 4000, time: 0.150, data: 0.000) loss: 0.611 
saving the latest model (epoch 46, total_steps 462656)
(epoch: 46, iters: 4080, time: 0.150, data: 0.012) loss: 1.075 
(epoch: 46, iters: 4160, time: 0.150, data: 0.000) loss: 0.651 
(epoch: 46, iters: 4240, time: 0.151, data: 0.000) loss: 1.416 
(epoch: 46, iters: 4320, time: 0.151, data: 0.005) loss: 0.755 
(epoch: 46, iters: 4400, time: 0.153, data: 0.017) loss: 0.604 
(epoch: 46, iters: 4480, time: 0.152, data: 0.000) loss: 0.566 
(epoch: 46, iters: 4560, time: 0.149, data: 0.014) loss: 0.648 
(epoch: 46, iters: 4640, time: 0.151, data: 0.000) loss: 0.730 
(epoch: 46, iters: 4720, time: 0.151, data: 0.014) loss: 1.418 
(epoch: 46, iters: 4800, time: 0.151, data: 0.000) loss: 0.619 
(epoch: 46, iters: 4880, time: 0.151, data: 0.009) loss: 1.407 
(epoch: 46, iters: 4960, time: 0.150, data: 0.005) loss: 0.600 
(epoch: 46, iters: 5040, time: 0.153, data: 0.000) loss: 0.643 
(epoch: 46, iters: 5120, time: 0.149, data: 0.022) loss: 0.988 
(epoch: 46, iters: 5200, time: 0.150, data: 0.000) loss: 0.972 
(epoch: 46, iters: 5280, time: 0.151, data: 0.010) loss: 0.844 
(epoch: 46, iters: 5360, time: 0.149, data: 0.005) loss: 0.656 
(epoch: 46, iters: 5440, time: 0.150, data: 0.000) loss: 1.239 
(epoch: 46, iters: 5520, time: 0.151, data: 0.008) loss: 0.596 
(epoch: 46, iters: 5600, time: 0.149, data: 0.000) loss: 0.887 
(epoch: 46, iters: 5680, time: 0.153, data: 0.000) loss: 1.042 
(epoch: 46, iters: 5760, time: 0.153, data: 0.021) loss: 0.975 
(epoch: 46, iters: 5840, time: 0.149, data: 0.000) loss: 1.011 
(epoch: 46, iters: 5920, time: 0.150, data: 0.000) loss: 0.914 
(epoch: 46, iters: 6000, time: 0.149, data: 0.000) loss: 0.916 
(epoch: 46, iters: 6080, time: 0.148, data: 0.000) loss: 1.201 
(epoch: 46, iters: 6160, time: 0.150, data: 0.005) loss: 0.775 
(epoch: 46, iters: 6240, time: 0.153, data: 0.000) loss: 0.410 
(epoch: 46, iters: 6320, time: 0.151, data: 0.006) loss: 0.967 
(epoch: 46, iters: 6400, time: 0.151, data: 0.000) loss: 0.624 
(epoch: 46, iters: 6480, time: 0.152, data: 0.013) loss: 0.676 
(epoch: 46, iters: 6560, time: 0.150, data: 0.000) loss: 0.476 
(epoch: 46, iters: 6640, time: 0.152, data: 0.005) loss: 1.447 
(epoch: 46, iters: 6720, time: 0.151, data: 0.000) loss: 1.104 
(epoch: 46, iters: 6800, time: 0.150, data: 0.021) loss: 1.191 
(epoch: 46, iters: 6880, time: 0.150, data: 0.000) loss: 0.639 
(epoch: 46, iters: 6960, time: 0.151, data: 0.013) loss: 1.030 
(epoch: 46, iters: 7040, time: 0.151, data: 0.000) loss: 0.916 
(epoch: 46, iters: 7120, time: 0.150, data: 0.000) loss: 1.199 
(epoch: 46, iters: 7200, time: 0.150, data: 0.000) loss: 1.096 
(epoch: 46, iters: 7280, time: 0.152, data: 0.000) loss: 0.870 
(epoch: 46, iters: 7360, time: 0.153, data: 0.005) loss: 0.882 
(epoch: 46, iters: 7440, time: 0.150, data: 0.021) loss: 0.691 
(epoch: 46, iters: 7520, time: 0.149, data: 0.005) loss: 1.093 
(epoch: 46, iters: 7600, time: 0.153, data: 0.005) loss: 0.690 
(epoch: 46, iters: 7680, time: 0.151, data: 0.009) loss: 1.072 
(epoch: 46, iters: 7760, time: 0.205, data: 0.021) loss: 0.500 
(epoch: 46, iters: 7840, time: 0.153, data: 0.000) loss: 1.300 
(epoch: 46, iters: 7920, time: 0.156, data: 0.000) loss: 0.753 
(epoch: 46, iters: 8000, time: 0.152, data: 0.005) loss: 0.474 
saving the latest model (epoch 46, total_steps 466656)
(epoch: 46, iters: 8080, time: 0.151, data: 0.000) loss: 1.240 
(epoch: 46, iters: 8160, time: 0.150, data: 0.000) loss: 0.594 
(epoch: 46, iters: 8240, time: 0.152, data: 0.000) loss: 0.675 
(epoch: 46, iters: 8320, time: 0.155, data: 0.000) loss: 0.816 
(epoch: 46, iters: 8400, time: 0.156, data: 0.000) loss: 1.036 
(epoch: 46, iters: 8480, time: 0.151, data: 0.013) loss: 0.999 
(epoch: 46, iters: 8560, time: 0.180, data: 0.000) loss: 0.829 
(epoch: 46, iters: 8640, time: 0.164, data: 0.011) loss: 0.971 
(epoch: 46, iters: 8720, time: 0.164, data: 0.000) loss: 0.781 
(epoch: 46, iters: 8800, time: 0.163, data: 0.000) loss: 0.726 
(epoch: 46, iters: 8880, time: 0.164, data: 0.000) loss: 0.666 
(epoch: 46, iters: 8960, time: 0.165, data: 0.014) loss: 0.972 
(epoch: 46, iters: 9040, time: 0.163, data: 0.000) loss: 0.978 
(epoch: 46, iters: 9120, time: 0.169, data: 0.010) loss: 1.215 
(epoch: 46, iters: 9200, time: 0.165, data: 0.020) loss: 0.578 
(epoch: 46, iters: 9280, time: 0.164, data: 0.008) loss: 1.211 
(epoch: 46, iters: 9360, time: 0.168, data: 0.005) loss: 0.720 
(epoch: 46, iters: 9440, time: 0.222, data: 0.020) loss: 0.836 
(epoch: 46, iters: 9520, time: 0.197, data: 0.009) loss: 1.178 
(epoch: 46, iters: 9600, time: 0.224, data: 0.000) loss: 1.168 
(epoch: 46, iters: 9680, time: 0.222, data: 0.036) loss: 0.873 
(epoch: 46, iters: 9760, time: 0.250, data: 0.000) loss: 0.690 
(epoch: 46, iters: 9840, time: 0.378, data: 0.019) loss: 0.440 
(epoch: 46, iters: 9920, time: 0.495, data: 0.000) loss: 1.223 
(epoch: 46, iters: 10000, time: 0.473, data: 0.000) loss: 0.671 
(epoch: 46, iters: 10080, time: 0.595, data: 0.000) loss: 0.658 
(epoch: 46, iters: 10160, time: 0.541, data: 0.000) loss: 0.921 
saving the model at the end of epoch 46, iters 468832
End of epoch 46 / 200 	 Time Taken: 1719 sec
learning rate = 0.0002000
saving the latest model (epoch 47, total_steps 468848)
(epoch: 47, iters: 48, time: 0.531, data: 0.011) loss: 0.836 
(epoch: 47, iters: 128, time: 0.481, data: 0.095) loss: 0.836 
(epoch: 47, iters: 208, time: 0.521, data: 0.081) loss: 1.327 
(epoch: 47, iters: 288, time: 0.495, data: 0.000) loss: 0.394 
(epoch: 47, iters: 368, time: 0.454, data: 0.000) loss: 0.662 
(epoch: 47, iters: 448, time: 0.480, data: 0.000) loss: 0.982 
(epoch: 47, iters: 528, time: 0.519, data: 0.000) loss: 0.228 
(epoch: 47, iters: 608, time: 0.621, data: 0.049) loss: 0.545 
(epoch: 47, iters: 688, time: 0.517, data: 0.000) loss: 0.771 
(epoch: 47, iters: 768, time: 0.517, data: 0.000) loss: 0.714 
(epoch: 47, iters: 848, time: 0.480, data: 0.024) loss: 0.684 
(epoch: 47, iters: 928, time: 0.383, data: 0.045) loss: 1.379 
(epoch: 47, iters: 1008, time: 0.400, data: 0.000) loss: 1.434 
(epoch: 47, iters: 1088, time: 0.484, data: 0.000) loss: 0.513 
(epoch: 47, iters: 1168, time: 0.541, data: 0.009) loss: 0.705 
(epoch: 47, iters: 1248, time: 0.464, data: 0.017) loss: 0.680 
(epoch: 47, iters: 1328, time: 0.532, data: 0.000) loss: 0.587 
(epoch: 47, iters: 1408, time: 0.457, data: 0.011) loss: 0.698 
(epoch: 47, iters: 1488, time: 0.432, data: 0.024) loss: 0.399 
(epoch: 47, iters: 1568, time: 0.477, data: 0.000) loss: 1.033 
(epoch: 47, iters: 1648, time: 0.492, data: 0.017) loss: 0.843 
(epoch: 47, iters: 1728, time: 0.501, data: 0.035) loss: 1.672 
(epoch: 47, iters: 1808, time: 0.417, data: 0.031) loss: 0.926 
(epoch: 47, iters: 1888, time: 0.530, data: 0.000) loss: 0.503 
(epoch: 47, iters: 1968, time: 0.526, data: 0.031) loss: 1.143 
(epoch: 47, iters: 2048, time: 0.474, data: 0.000) loss: 1.558 
(epoch: 47, iters: 2128, time: 0.519, data: 0.006) loss: 0.912 
(epoch: 47, iters: 2208, time: 0.483, data: 0.000) loss: 0.760 
(epoch: 47, iters: 2288, time: 0.452, data: 0.000) loss: 0.951 
(epoch: 47, iters: 2368, time: 0.516, data: 0.059) loss: 0.570 
(epoch: 47, iters: 2448, time: 0.482, data: 0.000) loss: 0.753 
(epoch: 47, iters: 2528, time: 0.487, data: 0.036) loss: 0.715 
(epoch: 47, iters: 2608, time: 0.454, data: 0.000) loss: 1.145 
(epoch: 47, iters: 2688, time: 0.527, data: 0.000) loss: 1.157 
(epoch: 47, iters: 2768, time: 0.482, data: 0.000) loss: 0.465 
(epoch: 47, iters: 2848, time: 0.522, data: 0.040) loss: 0.523 
(epoch: 47, iters: 2928, time: 0.529, data: 0.000) loss: 1.348 
(epoch: 47, iters: 3008, time: 0.486, data: 0.000) loss: 0.782 
(epoch: 47, iters: 3088, time: 0.437, data: 0.000) loss: 1.143 
(epoch: 47, iters: 3168, time: 0.500, data: 0.024) loss: 0.935 
(epoch: 47, iters: 3248, time: 0.486, data: 0.000) loss: 0.457 
(epoch: 47, iters: 3328, time: 0.526, data: 0.000) loss: 0.935 
(epoch: 47, iters: 3408, time: 0.511, data: 0.000) loss: 0.958 
(epoch: 47, iters: 3488, time: 0.513, data: 0.000) loss: 0.789 
(epoch: 47, iters: 3568, time: 0.501, data: 0.008) loss: 0.642 
(epoch: 47, iters: 3648, time: 0.480, data: 0.000) loss: 0.998 
(epoch: 47, iters: 3728, time: 0.444, data: 0.000) loss: 0.754 
(epoch: 47, iters: 3808, time: 0.440, data: 0.033) loss: 0.897 
(epoch: 47, iters: 3888, time: 0.505, data: 0.007) loss: 1.078 
(epoch: 47, iters: 3968, time: 0.531, data: 0.000) loss: 1.121 
saving the latest model (epoch 47, total_steps 472848)
(epoch: 47, iters: 4048, time: 0.526, data: 0.000) loss: 0.830 
(epoch: 47, iters: 4128, time: 0.530, data: 0.073) loss: 0.576 
(epoch: 47, iters: 4208, time: 0.497, data: 0.099) loss: 1.041 
(epoch: 47, iters: 4288, time: 0.428, data: 0.000) loss: 0.683 
(epoch: 47, iters: 4368, time: 0.513, data: 0.000) loss: 0.949 
(epoch: 47, iters: 4448, time: 0.483, data: 0.008) loss: 0.476 
(epoch: 47, iters: 4528, time: 0.516, data: 0.038) loss: 0.636 
(epoch: 47, iters: 4608, time: 0.526, data: 0.035) loss: 0.804 
(epoch: 47, iters: 4688, time: 0.511, data: 0.006) loss: 1.068 
(epoch: 47, iters: 4768, time: 0.440, data: 0.000) loss: 1.098 
(epoch: 47, iters: 4848, time: 0.476, data: 0.023) loss: 0.991 
(epoch: 47, iters: 4928, time: 0.503, data: 0.000) loss: 1.114 
(epoch: 47, iters: 5008, time: 0.484, data: 0.011) loss: 1.001 
(epoch: 47, iters: 5088, time: 0.467, data: 0.008) loss: 0.756 
(epoch: 47, iters: 5168, time: 0.472, data: 0.000) loss: 1.074 
(epoch: 47, iters: 5248, time: 0.363, data: 0.073) loss: 0.846 
(epoch: 47, iters: 5328, time: 0.498, data: 0.000) loss: 0.549 
(epoch: 47, iters: 5408, time: 0.493, data: 0.054) loss: 0.949 
(epoch: 47, iters: 5488, time: 0.486, data: 0.036) loss: 1.412 
(epoch: 47, iters: 5568, time: 0.492, data: 0.000) loss: 0.794 
(epoch: 47, iters: 5648, time: 0.449, data: 0.000) loss: 0.800 
(epoch: 47, iters: 5728, time: 0.464, data: 0.000) loss: 0.655 
(epoch: 47, iters: 5808, time: 0.430, data: 0.010) loss: 1.512 
(epoch: 47, iters: 5888, time: 0.401, data: 0.008) loss: 1.280 
(epoch: 47, iters: 5968, time: 0.382, data: 0.000) loss: 0.581 
(epoch: 47, iters: 6048, time: 0.509, data: 0.048) loss: 0.708 
(epoch: 47, iters: 6128, time: 0.518, data: 0.000) loss: 0.719 
(epoch: 47, iters: 6208, time: 0.454, data: 0.007) loss: 0.760 
(epoch: 47, iters: 6288, time: 0.497, data: 0.000) loss: 0.846 
(epoch: 47, iters: 6368, time: 0.470, data: 0.000) loss: 1.316 
(epoch: 47, iters: 6448, time: 0.481, data: 0.025) loss: 0.480 
(epoch: 47, iters: 6528, time: 0.520, data: 0.013) loss: 1.038 
(epoch: 47, iters: 6608, time: 0.380, data: 0.006) loss: 0.774 
(epoch: 47, iters: 6688, time: 0.367, data: 0.014) loss: 1.113 
(epoch: 47, iters: 6768, time: 0.502, data: 0.059) loss: 1.217 
(epoch: 47, iters: 6848, time: 0.537, data: 0.009) loss: 0.523 
(epoch: 47, iters: 6928, time: 0.550, data: 0.006) loss: 0.909 
(epoch: 47, iters: 7008, time: 0.567, data: 0.011) loss: 1.318 
(epoch: 47, iters: 7088, time: 0.542, data: 0.000) loss: 0.763 
(epoch: 47, iters: 7168, time: 0.485, data: 0.000) loss: 0.593 
(epoch: 47, iters: 7248, time: 0.507, data: 0.000) loss: 0.277 
(epoch: 47, iters: 7328, time: 0.508, data: 0.023) loss: 1.582 
(epoch: 47, iters: 7408, time: 0.474, data: 0.000) loss: 0.953 
(epoch: 47, iters: 7488, time: 0.545, data: 0.022) loss: 0.669 
(epoch: 47, iters: 7568, time: 0.511, data: 0.000) loss: 1.011 
(epoch: 47, iters: 7648, time: 0.523, data: 0.000) loss: 0.923 
(epoch: 47, iters: 7728, time: 0.497, data: 0.000) loss: 0.738 
(epoch: 47, iters: 7808, time: 0.502, data: 0.010) loss: 0.954 
(epoch: 47, iters: 7888, time: 0.430, data: 0.100) loss: 0.875 
(epoch: 47, iters: 7968, time: 0.516, data: 0.000) loss: 0.315 
saving the latest model (epoch 47, total_steps 476848)
(epoch: 47, iters: 8048, time: 0.512, data: 0.082) loss: 0.619 
(epoch: 47, iters: 8128, time: 0.484, data: 0.051) loss: 1.029 
(epoch: 47, iters: 8208, time: 0.535, data: 0.070) loss: 0.846 
(epoch: 47, iters: 8288, time: 0.552, data: 0.000) loss: 0.609 
(epoch: 47, iters: 8368, time: 0.504, data: 0.048) loss: 1.253 
(epoch: 47, iters: 8448, time: 0.502, data: 0.010) loss: 0.589 
(epoch: 47, iters: 8528, time: 0.518, data: 0.000) loss: 1.265 
(epoch: 47, iters: 8608, time: 0.450, data: 0.000) loss: 0.609 
(epoch: 47, iters: 8688, time: 0.507, data: 0.000) loss: 0.849 
(epoch: 47, iters: 8768, time: 0.473, data: 0.000) loss: 1.296 
(epoch: 47, iters: 8848, time: 0.495, data: 0.043) loss: 0.772 
(epoch: 47, iters: 8928, time: 0.533, data: 0.000) loss: 0.617 
(epoch: 47, iters: 9008, time: 0.483, data: 0.011) loss: 1.085 
(epoch: 47, iters: 9088, time: 0.466, data: 0.011) loss: 0.663 
(epoch: 47, iters: 9168, time: 0.445, data: 0.000) loss: 0.870 
(epoch: 47, iters: 9248, time: 0.460, data: 0.000) loss: 1.587 
(epoch: 47, iters: 9328, time: 0.421, data: 0.010) loss: 0.459 
(epoch: 47, iters: 9408, time: 0.488, data: 0.000) loss: 0.930 
(epoch: 47, iters: 9488, time: 0.545, data: 0.067) loss: 0.925 
(epoch: 47, iters: 9568, time: 0.462, data: 0.000) loss: 0.405 
(epoch: 47, iters: 9648, time: 0.510, data: 0.000) loss: 0.740 
(epoch: 47, iters: 9728, time: 0.490, data: 0.000) loss: 0.793 
(epoch: 47, iters: 9808, time: 0.531, data: 0.000) loss: 0.762 
(epoch: 47, iters: 9888, time: 0.391, data: 0.013) loss: 0.957 
(epoch: 47, iters: 9968, time: 0.507, data: 0.000) loss: 0.726 
(epoch: 47, iters: 10048, time: 0.386, data: 0.024) loss: 1.468 
(epoch: 47, iters: 10128, time: 0.482, data: 0.000) loss: 0.819 
saving the model at the end of epoch 47, iters 479024
End of epoch 47 / 200 	 Time Taken: 4953 sec
learning rate = 0.0002000
(epoch: 48, iters: 16, time: 0.583, data: 0.000) loss: 0.324 
saving the latest model (epoch 48, total_steps 479040)
(epoch: 48, iters: 96, time: 0.531, data: 0.000) loss: 0.746 
(epoch: 48, iters: 176, time: 0.509, data: 0.045) loss: 0.961 
(epoch: 48, iters: 256, time: 0.429, data: 0.007) loss: 0.550 
(epoch: 48, iters: 336, time: 0.528, data: 0.022) loss: 0.457 
(epoch: 48, iters: 416, time: 0.502, data: 0.010) loss: 0.779 
(epoch: 48, iters: 496, time: 0.456, data: 0.010) loss: 0.738 
(epoch: 48, iters: 576, time: 0.435, data: 0.034) loss: 1.189 
(epoch: 48, iters: 656, time: 0.472, data: 0.000) loss: 0.491 
(epoch: 48, iters: 736, time: 0.490, data: 0.000) loss: 0.652 
(epoch: 48, iters: 816, time: 0.534, data: 0.010) loss: 0.751 
(epoch: 48, iters: 896, time: 0.471, data: 0.007) loss: 0.817 
(epoch: 48, iters: 976, time: 0.523, data: 0.000) loss: 1.388 
(epoch: 48, iters: 1056, time: 0.558, data: 0.049) loss: 0.417 
(epoch: 48, iters: 1136, time: 0.427, data: 0.003) loss: 0.816 
(epoch: 48, iters: 1216, time: 0.490, data: 0.000) loss: 0.750 
(epoch: 48, iters: 1296, time: 0.443, data: 0.000) loss: 1.588 
(epoch: 48, iters: 1376, time: 0.441, data: 0.000) loss: 0.676 
(epoch: 48, iters: 1456, time: 0.479, data: 0.000) loss: 1.021 
(epoch: 48, iters: 1536, time: 0.482, data: 0.053) loss: 1.182 
(epoch: 48, iters: 1616, time: 0.457, data: 0.000) loss: 0.710 
(epoch: 48, iters: 1696, time: 0.518, data: 0.000) loss: 0.934 
(epoch: 48, iters: 1776, time: 0.536, data: 0.007) loss: 0.699 
(epoch: 48, iters: 1856, time: 0.497, data: 0.030) loss: 0.677 
(epoch: 48, iters: 1936, time: 0.372, data: 0.010) loss: 0.769 
(epoch: 48, iters: 2016, time: 0.501, data: 0.000) loss: 0.836 
(epoch: 48, iters: 2096, time: 0.427, data: 0.000) loss: 0.706 
(epoch: 48, iters: 2176, time: 0.503, data: 0.106) loss: 0.717 
(epoch: 48, iters: 2256, time: 0.564, data: 0.000) loss: 0.578 
(epoch: 48, iters: 2336, time: 0.516, data: 0.045) loss: 0.502 
(epoch: 48, iters: 2416, time: 0.568, data: 0.011) loss: 0.629 
(epoch: 48, iters: 2496, time: 0.529, data: 0.000) loss: 0.541 
(epoch: 48, iters: 2576, time: 0.482, data: 0.000) loss: 0.802 
(epoch: 48, iters: 2656, time: 0.433, data: 0.011) loss: 0.685 
(epoch: 48, iters: 2736, time: 0.547, data: 0.017) loss: 0.761 
(epoch: 48, iters: 2816, time: 0.452, data: 0.029) loss: 1.149 
(epoch: 48, iters: 2896, time: 0.532, data: 0.000) loss: 0.721 
(epoch: 48, iters: 2976, time: 0.547, data: 0.000) loss: 0.712 
(epoch: 48, iters: 3056, time: 0.470, data: 0.000) loss: 0.820 
(epoch: 48, iters: 3136, time: 0.465, data: 0.010) loss: 0.730 
(epoch: 48, iters: 3216, time: 0.499, data: 0.000) loss: 1.118 
(epoch: 48, iters: 3296, time: 0.476, data: 0.000) loss: 0.722 
(epoch: 48, iters: 3376, time: 0.466, data: 0.046) loss: 0.498 
(epoch: 48, iters: 3456, time: 0.506, data: 0.000) loss: 1.200 
(epoch: 48, iters: 3536, time: 0.496, data: 0.033) loss: 0.706 
(epoch: 48, iters: 3616, time: 0.484, data: 0.010) loss: 0.349 
(epoch: 48, iters: 3696, time: 0.508, data: 0.000) loss: 1.253 
(epoch: 48, iters: 3776, time: 0.502, data: 0.000) loss: 0.878 
(epoch: 48, iters: 3856, time: 0.523, data: 0.010) loss: 1.038 
(epoch: 48, iters: 3936, time: 0.470, data: 0.000) loss: 0.804 
(epoch: 48, iters: 4016, time: 0.438, data: 0.000) loss: 0.701 
saving the latest model (epoch 48, total_steps 483040)
(epoch: 48, iters: 4096, time: 0.361, data: 0.000) loss: 0.406 
(epoch: 48, iters: 4176, time: 0.356, data: 0.000) loss: 0.473 
(epoch: 48, iters: 4256, time: 0.486, data: 0.011) loss: 0.880 
(epoch: 48, iters: 4336, time: 0.555, data: 0.020) loss: 1.317 
(epoch: 48, iters: 4416, time: 0.529, data: 0.000) loss: 0.968 
(epoch: 48, iters: 4496, time: 0.432, data: 0.076) loss: 0.824 
(epoch: 48, iters: 4576, time: 0.501, data: 0.000) loss: 0.854 
(epoch: 48, iters: 4656, time: 0.507, data: 0.106) loss: 1.880 
(epoch: 48, iters: 4736, time: 0.466, data: 0.000) loss: 1.110 
(epoch: 48, iters: 4816, time: 0.422, data: 0.000) loss: 0.888 
(epoch: 48, iters: 4896, time: 0.519, data: 0.000) loss: 0.394 
(epoch: 48, iters: 4976, time: 0.480, data: 0.037) loss: 0.869 
(epoch: 48, iters: 5056, time: 0.495, data: 0.015) loss: 1.130 
(epoch: 48, iters: 5136, time: 0.508, data: 0.011) loss: 0.565 
(epoch: 48, iters: 5216, time: 0.527, data: 0.007) loss: 0.955 
(epoch: 48, iters: 5296, time: 0.541, data: 0.000) loss: 0.941 
(epoch: 48, iters: 5376, time: 0.466, data: 0.029) loss: 1.322 
(epoch: 48, iters: 5456, time: 0.460, data: 0.000) loss: 0.951 
(epoch: 48, iters: 5536, time: 0.516, data: 0.000) loss: 0.757 
(epoch: 48, iters: 5616, time: 0.484, data: 0.051) loss: 0.798 
(epoch: 48, iters: 5696, time: 0.544, data: 0.000) loss: 0.946 
(epoch: 48, iters: 5776, time: 0.454, data: 0.010) loss: 0.961 
(epoch: 48, iters: 5856, time: 0.452, data: 0.000) loss: 0.669 
(epoch: 48, iters: 5936, time: 0.475, data: 0.045) loss: 0.878 
(epoch: 48, iters: 6016, time: 0.498, data: 0.000) loss: 0.661 
(epoch: 48, iters: 6096, time: 0.502, data: 0.000) loss: 0.796 
(epoch: 48, iters: 6176, time: 0.381, data: 0.011) loss: 0.652 
(epoch: 48, iters: 6256, time: 0.368, data: 0.000) loss: 0.794 
(epoch: 48, iters: 6336, time: 0.521, data: 0.020) loss: 0.730 
(epoch: 48, iters: 6416, time: 0.495, data: 0.000) loss: 1.349 
(epoch: 48, iters: 6496, time: 0.517, data: 0.000) loss: 0.795 
(epoch: 48, iters: 6576, time: 0.543, data: 0.006) loss: 0.695 
(epoch: 48, iters: 6656, time: 0.486, data: 0.064) loss: 0.525 
(epoch: 48, iters: 6736, time: 0.473, data: 0.000) loss: 1.044 
(epoch: 48, iters: 6816, time: 0.495, data: 0.017) loss: 0.371 
(epoch: 48, iters: 6896, time: 0.332, data: 0.025) loss: 1.083 
(epoch: 48, iters: 6976, time: 0.501, data: 0.000) loss: 0.708 
(epoch: 48, iters: 7056, time: 0.506, data: 0.015) loss: 0.568 
(epoch: 48, iters: 7136, time: 0.508, data: 0.000) loss: 0.979 
(epoch: 48, iters: 7216, time: 0.494, data: 0.000) loss: 0.579 
(epoch: 48, iters: 7296, time: 0.485, data: 0.000) loss: 0.778 
(epoch: 48, iters: 7376, time: 0.534, data: 0.000) loss: 0.378 
(epoch: 48, iters: 7456, time: 0.510, data: 0.012) loss: 1.485 
(epoch: 48, iters: 7536, time: 0.460, data: 0.000) loss: 0.831 
(epoch: 48, iters: 7616, time: 0.497, data: 0.000) loss: 0.290 
(epoch: 48, iters: 7696, time: 0.508, data: 0.000) loss: 0.574 
(epoch: 48, iters: 7776, time: 0.499, data: 0.000) loss: 0.935 
(epoch: 48, iters: 7856, time: 0.550, data: 0.016) loss: 1.253 
(epoch: 48, iters: 7936, time: 0.481, data: 0.005) loss: 0.731 
(epoch: 48, iters: 8016, time: 0.464, data: 0.000) loss: 0.855 
saving the latest model (epoch 48, total_steps 487040)
(epoch: 48, iters: 8096, time: 0.500, data: 0.066) loss: 1.295 
(epoch: 48, iters: 8176, time: 0.513, data: 0.000) loss: 1.186 
(epoch: 48, iters: 8256, time: 0.468, data: 0.000) loss: 0.561 
(epoch: 48, iters: 8336, time: 0.506, data: 0.006) loss: 0.900 
(epoch: 48, iters: 8416, time: 0.454, data: 0.009) loss: 0.655 
(epoch: 48, iters: 8496, time: 0.541, data: 0.047) loss: 1.010 
(epoch: 48, iters: 8576, time: 0.542, data: 0.000) loss: 1.349 
(epoch: 48, iters: 8656, time: 0.507, data: 0.000) loss: 1.089 
(epoch: 48, iters: 8736, time: 0.493, data: 0.000) loss: 0.561 
(epoch: 48, iters: 8816, time: 0.458, data: 0.000) loss: 0.469 
(epoch: 48, iters: 8896, time: 0.530, data: 0.009) loss: 1.420 
(epoch: 48, iters: 8976, time: 0.471, data: 0.000) loss: 1.243 
(epoch: 48, iters: 9056, time: 0.519, data: 0.018) loss: 0.517 
(epoch: 48, iters: 9136, time: 0.517, data: 0.000) loss: 0.535 
(epoch: 48, iters: 9216, time: 0.485, data: 0.019) loss: 0.633 
(epoch: 48, iters: 9296, time: 0.476, data: 0.000) loss: 1.072 
(epoch: 48, iters: 9376, time: 0.510, data: 0.011) loss: 0.890 
(epoch: 48, iters: 9456, time: 0.459, data: 0.019) loss: 0.829 
(epoch: 48, iters: 9536, time: 0.537, data: 0.000) loss: 1.432 
(epoch: 48, iters: 9616, time: 0.534, data: 0.010) loss: 0.623 
(epoch: 48, iters: 9696, time: 0.473, data: 0.000) loss: 1.241 
(epoch: 48, iters: 9776, time: 0.530, data: 0.010) loss: 0.355 
(epoch: 48, iters: 9856, time: 0.428, data: 0.005) loss: 1.250 
(epoch: 48, iters: 9936, time: 0.440, data: 0.029) loss: 0.480 
(epoch: 48, iters: 10016, time: 0.549, data: 0.000) loss: 0.951 
(epoch: 48, iters: 10096, time: 0.477, data: 0.000) loss: 0.252 
(epoch: 48, iters: 10176, time: 0.487, data: 0.006) loss: 0.777 
saving the model at the end of epoch 48, iters 489216
End of epoch 48 / 200 	 Time Taken: 4943 sec
learning rate = 0.0002000
saving the latest model (epoch 49, total_steps 489232)
(epoch: 49, iters: 64, time: 0.464, data: 0.004) loss: 1.220 
(epoch: 49, iters: 144, time: 0.464, data: 0.030) loss: 1.004 
(epoch: 49, iters: 224, time: 0.406, data: 0.050) loss: 0.589 
(epoch: 49, iters: 304, time: 0.481, data: 0.001) loss: 0.445 
(epoch: 49, iters: 384, time: 0.521, data: 0.000) loss: 1.022 
(epoch: 49, iters: 464, time: 0.506, data: 0.010) loss: 0.929 
(epoch: 49, iters: 544, time: 0.498, data: 0.000) loss: 0.530 
(epoch: 49, iters: 624, time: 0.511, data: 0.000) loss: 0.621 
(epoch: 49, iters: 704, time: 0.493, data: 0.000) loss: 0.637 
(epoch: 49, iters: 784, time: 0.576, data: 0.010) loss: 0.646 
(epoch: 49, iters: 864, time: 0.508, data: 0.000) loss: 0.594 
(epoch: 49, iters: 944, time: 0.389, data: 0.021) loss: 0.531 
(epoch: 49, iters: 1024, time: 0.372, data: 0.000) loss: 1.006 
(epoch: 49, iters: 1104, time: 0.494, data: 0.021) loss: 0.605 
(epoch: 49, iters: 1184, time: 0.544, data: 0.077) loss: 0.565 
(epoch: 49, iters: 1264, time: 0.497, data: 0.000) loss: 1.048 
(epoch: 49, iters: 1344, time: 0.531, data: 0.000) loss: 0.412 
(epoch: 49, iters: 1424, time: 0.506, data: 0.000) loss: 0.729 
(epoch: 49, iters: 1504, time: 0.526, data: 0.000) loss: 1.065 
(epoch: 49, iters: 1584, time: 0.516, data: 0.017) loss: 1.479 
(epoch: 49, iters: 1664, time: 0.498, data: 0.000) loss: 0.857 
(epoch: 49, iters: 1744, time: 0.430, data: 0.052) loss: 1.251 
(epoch: 49, iters: 1824, time: 0.516, data: 0.000) loss: 0.248 
(epoch: 49, iters: 1904, time: 0.500, data: 0.000) loss: 1.181 
(epoch: 49, iters: 1984, time: 0.460, data: 0.000) loss: 0.647 
(epoch: 49, iters: 2064, time: 0.402, data: 0.000) loss: 1.844 
(epoch: 49, iters: 2144, time: 0.445, data: 0.000) loss: 0.559 
(epoch: 49, iters: 2224, time: 0.492, data: 0.011) loss: 1.264 
(epoch: 49, iters: 2304, time: 0.454, data: 0.000) loss: 1.235 
(epoch: 49, iters: 2384, time: 0.540, data: 0.010) loss: 0.692 
(epoch: 49, iters: 2464, time: 0.469, data: 0.011) loss: 0.708 
(epoch: 49, iters: 2544, time: 0.574, data: 0.000) loss: 1.362 
(epoch: 49, iters: 2624, time: 0.484, data: 0.009) loss: 1.141 
(epoch: 49, iters: 2704, time: 0.500, data: 0.000) loss: 0.637 
(epoch: 49, iters: 2784, time: 0.522, data: 0.011) loss: 0.775 
(epoch: 49, iters: 2864, time: 0.525, data: 0.000) loss: 0.534 
(epoch: 49, iters: 2944, time: 0.455, data: 0.091) loss: 1.703 
(epoch: 49, iters: 3024, time: 0.476, data: 0.000) loss: 1.076 
(epoch: 49, iters: 3104, time: 0.389, data: 0.000) loss: 0.942 
(epoch: 49, iters: 3184, time: 0.477, data: 0.000) loss: 0.898 
(epoch: 49, iters: 3264, time: 0.487, data: 0.000) loss: 0.789 
(epoch: 49, iters: 3344, time: 0.541, data: 0.045) loss: 0.668 
(epoch: 49, iters: 3424, time: 0.473, data: 0.000) loss: 0.459 
(epoch: 49, iters: 3504, time: 0.497, data: 0.000) loss: 1.072 
(epoch: 49, iters: 3584, time: 0.504, data: 0.011) loss: 0.788 
(epoch: 49, iters: 3664, time: 0.458, data: 0.000) loss: 0.910 
(epoch: 49, iters: 3744, time: 0.447, data: 0.050) loss: 0.730 
(epoch: 49, iters: 3824, time: 0.350, data: 0.000) loss: 1.184 
(epoch: 49, iters: 3904, time: 0.497, data: 0.013) loss: 0.734 
(epoch: 49, iters: 3984, time: 0.474, data: 0.007) loss: 0.806 
saving the latest model (epoch 49, total_steps 493232)
(epoch: 49, iters: 4064, time: 0.473, data: 0.000) loss: 0.923 
(epoch: 49, iters: 4144, time: 0.531, data: 0.000) loss: 0.212 
(epoch: 49, iters: 4224, time: 0.473, data: 0.000) loss: 0.812 
(epoch: 49, iters: 4304, time: 0.483, data: 0.010) loss: 1.060 
(epoch: 49, iters: 4384, time: 0.539, data: 0.020) loss: 0.820 
(epoch: 49, iters: 4464, time: 0.513, data: 0.000) loss: 0.791 
(epoch: 49, iters: 4544, time: 0.418, data: 0.000) loss: 0.765 
(epoch: 49, iters: 4624, time: 0.476, data: 0.007) loss: 1.756 
(epoch: 49, iters: 4704, time: 0.515, data: 0.000) loss: 0.704 
(epoch: 49, iters: 4784, time: 0.498, data: 0.009) loss: 0.782 
(epoch: 49, iters: 4864, time: 0.506, data: 0.033) loss: 0.976 
(epoch: 49, iters: 4944, time: 0.493, data: 0.000) loss: 1.331 
(epoch: 49, iters: 5024, time: 0.517, data: 0.000) loss: 0.561 
(epoch: 49, iters: 5104, time: 0.447, data: 0.000) loss: 0.602 
(epoch: 49, iters: 5184, time: 0.385, data: 0.000) loss: 1.030 
(epoch: 49, iters: 5264, time: 0.439, data: 0.000) loss: 0.636 
(epoch: 49, iters: 5344, time: 0.437, data: 0.012) loss: 0.434 
(epoch: 49, iters: 5424, time: 0.523, data: 0.000) loss: 1.385 
(epoch: 49, iters: 5504, time: 0.515, data: 0.000) loss: 1.227 
(epoch: 49, iters: 5584, time: 0.424, data: 0.040) loss: 0.773 
(epoch: 49, iters: 5664, time: 0.455, data: 0.000) loss: 0.627 
(epoch: 49, iters: 5744, time: 0.488, data: 0.000) loss: 0.558 
(epoch: 49, iters: 5824, time: 0.442, data: 0.011) loss: 0.981 
(epoch: 49, iters: 5904, time: 0.412, data: 0.000) loss: 0.813 
(epoch: 49, iters: 5984, time: 0.483, data: 0.000) loss: 0.560 
(epoch: 49, iters: 6064, time: 0.499, data: 0.000) loss: 1.234 
(epoch: 49, iters: 6144, time: 0.509, data: 0.026) loss: 0.626 
(epoch: 49, iters: 6224, time: 0.467, data: 0.010) loss: 0.911 
(epoch: 49, iters: 6304, time: 0.492, data: 0.000) loss: 1.602 
(epoch: 49, iters: 6384, time: 0.459, data: 0.000) loss: 0.648 
(epoch: 49, iters: 6464, time: 0.462, data: 0.010) loss: 1.479 
(epoch: 49, iters: 6544, time: 0.419, data: 0.000) loss: 0.447 
(epoch: 49, iters: 6624, time: 0.445, data: 0.000) loss: 0.463 
(epoch: 49, iters: 6704, time: 0.458, data: 0.040) loss: 0.392 
(epoch: 49, iters: 6784, time: 0.523, data: 0.000) loss: 1.345 
(epoch: 49, iters: 6864, time: 0.456, data: 0.011) loss: 1.199 
(epoch: 49, iters: 6944, time: 0.493, data: 0.000) loss: 0.387 
(epoch: 49, iters: 7024, time: 0.525, data: 0.000) loss: 0.598 
(epoch: 49, iters: 7104, time: 0.519, data: 0.000) loss: 0.337 
(epoch: 49, iters: 7184, time: 0.471, data: 0.000) loss: 0.529 
(epoch: 49, iters: 7264, time: 0.447, data: 0.010) loss: 0.925 
(epoch: 49, iters: 7344, time: 0.437, data: 0.020) loss: 0.692 
(epoch: 49, iters: 7424, time: 0.551, data: 0.000) loss: 0.867 
(epoch: 49, iters: 7504, time: 0.485, data: 0.031) loss: 1.711 
(epoch: 49, iters: 7584, time: 0.470, data: 0.000) loss: 0.802 
(epoch: 49, iters: 7664, time: 0.482, data: 0.011) loss: 0.369 
(epoch: 49, iters: 7744, time: 0.544, data: 0.000) loss: 0.297 
(epoch: 49, iters: 7824, time: 0.493, data: 0.010) loss: 0.676 
(epoch: 49, iters: 7904, time: 0.513, data: 0.005) loss: 1.144 
(epoch: 49, iters: 7984, time: 0.448, data: 0.056) loss: 1.115 
saving the latest model (epoch 49, total_steps 497232)
(epoch: 49, iters: 8064, time: 0.490, data: 0.000) loss: 1.858 
(epoch: 49, iters: 8144, time: 0.461, data: 0.000) loss: 0.936 
(epoch: 49, iters: 8224, time: 0.485, data: 0.000) loss: 0.272 
(epoch: 49, iters: 8304, time: 0.504, data: 0.044) loss: 1.014 
(epoch: 49, iters: 8384, time: 0.497, data: 0.000) loss: 0.730 
(epoch: 49, iters: 8464, time: 0.501, data: 0.021) loss: 1.331 
(epoch: 49, iters: 8544, time: 0.568, data: 0.016) loss: 0.960 
(epoch: 49, iters: 8624, time: 0.495, data: 0.000) loss: 0.411 
(epoch: 49, iters: 8704, time: 0.490, data: 0.062) loss: 0.443 
(epoch: 49, iters: 8784, time: 0.482, data: 0.000) loss: 0.670 
(epoch: 49, iters: 8864, time: 0.503, data: 0.006) loss: 0.416 
(epoch: 49, iters: 8944, time: 0.483, data: 0.006) loss: 0.778 
(epoch: 49, iters: 9024, time: 0.477, data: 0.006) loss: 0.570 
(epoch: 49, iters: 9104, time: 0.551, data: 0.010) loss: 0.815 
(epoch: 49, iters: 9184, time: 0.534, data: 0.000) loss: 0.445 
(epoch: 49, iters: 9264, time: 0.552, data: 0.027) loss: 0.915 
(epoch: 49, iters: 9344, time: 0.462, data: 0.006) loss: 1.786 
(epoch: 49, iters: 9424, time: 0.388, data: 0.005) loss: 0.792 
(epoch: 49, iters: 9504, time: 0.459, data: 0.000) loss: 0.455 
(epoch: 49, iters: 9584, time: 0.514, data: 0.016) loss: 1.071 
(epoch: 49, iters: 9664, time: 0.491, data: 0.009) loss: 0.091 
(epoch: 49, iters: 9744, time: 0.501, data: 0.009) loss: 0.353 
(epoch: 49, iters: 9824, time: 0.474, data: 0.061) loss: 1.246 
(epoch: 49, iters: 9904, time: 0.497, data: 0.000) loss: 0.717 
(epoch: 49, iters: 9984, time: 0.535, data: 0.020) loss: 1.138 
(epoch: 49, iters: 10064, time: 0.482, data: 0.040) loss: 0.250 
(epoch: 49, iters: 10144, time: 0.484, data: 0.000) loss: 0.667 
saving the model at the end of epoch 49, iters 499408
End of epoch 49 / 200 	 Time Taken: 4914 sec
learning rate = 0.0002000
saving the latest model (epoch 50, total_steps 499424)
(epoch: 50, iters: 32, time: 0.365, data: 0.000) loss: 0.954 
(epoch: 50, iters: 112, time: 0.503, data: 0.000) loss: 2.131 
(epoch: 50, iters: 192, time: 0.482, data: 0.000) loss: 1.357 
(epoch: 50, iters: 272, time: 0.484, data: 0.056) loss: 0.991 
(epoch: 50, iters: 352, time: 0.410, data: 0.000) loss: 0.356 
(epoch: 50, iters: 432, time: 0.485, data: 0.000) loss: 0.787 
(epoch: 50, iters: 512, time: 0.577, data: 0.000) loss: 0.571 
(epoch: 50, iters: 592, time: 0.465, data: 0.012) loss: 0.624 
(epoch: 50, iters: 672, time: 0.454, data: 0.000) loss: 0.937 
(epoch: 50, iters: 752, time: 0.385, data: 0.064) loss: 0.529 
(epoch: 50, iters: 832, time: 0.531, data: 0.000) loss: 0.759 
(epoch: 50, iters: 912, time: 0.484, data: 0.000) loss: 0.792 
(epoch: 50, iters: 992, time: 0.556, data: 0.000) loss: 0.547 
(epoch: 50, iters: 1072, time: 0.512, data: 0.013) loss: 0.908 
(epoch: 50, iters: 1152, time: 0.491, data: 0.006) loss: 1.459 
(epoch: 50, iters: 1232, time: 0.481, data: 0.000) loss: 0.852 
(epoch: 50, iters: 1312, time: 0.507, data: 0.000) loss: 1.157 
(epoch: 50, iters: 1392, time: 0.507, data: 0.000) loss: 0.780 
(epoch: 50, iters: 1472, time: 0.395, data: 0.017) loss: 0.512 
(epoch: 50, iters: 1552, time: 0.496, data: 0.009) loss: 1.111 
(epoch: 50, iters: 1632, time: 0.437, data: 0.000) loss: 0.909 
(epoch: 50, iters: 1712, time: 0.506, data: 0.000) loss: 0.767 
(epoch: 50, iters: 1792, time: 0.525, data: 0.000) loss: 0.823 
(epoch: 50, iters: 1872, time: 0.502, data: 0.000) loss: 0.314 
(epoch: 50, iters: 1952, time: 0.447, data: 0.000) loss: 0.956 
(epoch: 50, iters: 2032, time: 0.506, data: 0.082) loss: 0.483 
(epoch: 50, iters: 2112, time: 0.491, data: 0.033) loss: 0.992 
(epoch: 50, iters: 2192, time: 0.434, data: 0.000) loss: 0.600 
(epoch: 50, iters: 2272, time: 0.491, data: 0.000) loss: 1.005 
(epoch: 50, iters: 2352, time: 0.485, data: 0.011) loss: 0.808 
(epoch: 50, iters: 2432, time: 0.531, data: 0.000) loss: 0.859 
(epoch: 50, iters: 2512, time: 0.442, data: 0.000) loss: 0.901 
(epoch: 50, iters: 2592, time: 0.499, data: 0.000) loss: 0.445 
(epoch: 50, iters: 2672, time: 0.525, data: 0.023) loss: 0.753 
(epoch: 50, iters: 2752, time: 0.469, data: 0.000) loss: 0.433 
(epoch: 50, iters: 2832, time: 0.486, data: 0.000) loss: 0.734 
(epoch: 50, iters: 2912, time: 0.370, data: 0.000) loss: 0.441 
(epoch: 50, iters: 2992, time: 0.500, data: 0.054) loss: 0.993 
(epoch: 50, iters: 3072, time: 0.570, data: 0.000) loss: 1.065 
(epoch: 50, iters: 3152, time: 0.477, data: 0.000) loss: 1.081 
(epoch: 50, iters: 3232, time: 0.503, data: 0.028) loss: 0.671 
(epoch: 50, iters: 3312, time: 0.496, data: 0.043) loss: 1.131 
(epoch: 50, iters: 3392, time: 0.552, data: 0.038) loss: 0.805 
(epoch: 50, iters: 3472, time: 0.449, data: 0.014) loss: 0.944 
(epoch: 50, iters: 3552, time: 0.460, data: 0.007) loss: 0.322 
(epoch: 50, iters: 3632, time: 0.446, data: 0.000) loss: 1.059 
(epoch: 50, iters: 3712, time: 0.493, data: 0.019) loss: 1.715 
(epoch: 50, iters: 3792, time: 0.490, data: 0.000) loss: 0.855 
(epoch: 50, iters: 3872, time: 0.502, data: 0.019) loss: 0.457 
(epoch: 50, iters: 3952, time: 0.474, data: 0.000) loss: 0.914 
saving the latest model (epoch 50, total_steps 503424)
(epoch: 50, iters: 4032, time: 0.505, data: 0.021) loss: 1.009 
(epoch: 50, iters: 4112, time: 0.529, data: 0.000) loss: 0.595 
(epoch: 50, iters: 4192, time: 0.488, data: 0.009) loss: 0.881 
(epoch: 50, iters: 4272, time: 0.362, data: 0.015) loss: 0.862 
(epoch: 50, iters: 4352, time: 0.339, data: 0.000) loss: 1.106 
(epoch: 50, iters: 4432, time: 0.534, data: 0.000) loss: 0.583 
(epoch: 50, iters: 4512, time: 0.501, data: 0.007) loss: 1.237 
(epoch: 50, iters: 4592, time: 0.486, data: 0.000) loss: 0.703 
(epoch: 50, iters: 4672, time: 0.502, data: 0.065) loss: 0.714 
(epoch: 50, iters: 4752, time: 0.469, data: 0.000) loss: 0.767 
(epoch: 50, iters: 4832, time: 0.523, data: 0.000) loss: 1.143 
(epoch: 50, iters: 4912, time: 0.383, data: 0.000) loss: 1.024 
(epoch: 50, iters: 4992, time: 0.476, data: 0.062) loss: 0.526 
(epoch: 50, iters: 5072, time: 0.492, data: 0.000) loss: 0.807 
(epoch: 50, iters: 5152, time: 0.423, data: 0.056) loss: 0.711 
(epoch: 50, iters: 5232, time: 0.454, data: 0.038) loss: 0.546 
(epoch: 50, iters: 5312, time: 0.441, data: 0.000) loss: 0.731 
(epoch: 50, iters: 5392, time: 0.474, data: 0.006) loss: 0.504 
(epoch: 50, iters: 5472, time: 0.523, data: 0.000) loss: 1.221 
(epoch: 50, iters: 5552, time: 0.489, data: 0.031) loss: 0.649 
(epoch: 50, iters: 5632, time: 0.368, data: 0.007) loss: 0.209 
(epoch: 50, iters: 5712, time: 0.478, data: 0.000) loss: 0.604 
(epoch: 50, iters: 5792, time: 0.502, data: 0.000) loss: 0.608 
(epoch: 50, iters: 5872, time: 0.485, data: 0.000) loss: 1.061 
(epoch: 50, iters: 5952, time: 0.434, data: 0.021) loss: 1.034 
(epoch: 50, iters: 6032, time: 0.521, data: 0.011) loss: 0.878 
(epoch: 50, iters: 6112, time: 0.499, data: 0.005) loss: 0.934 
(epoch: 50, iters: 6192, time: 0.499, data: 0.011) loss: 0.475 
(epoch: 50, iters: 6272, time: 0.494, data: 0.036) loss: 0.947 
(epoch: 50, iters: 6352, time: 0.477, data: 0.000) loss: 1.067 
(epoch: 50, iters: 6432, time: 0.437, data: 0.026) loss: 0.590 
(epoch: 50, iters: 6512, time: 0.477, data: 0.022) loss: 0.940 
(epoch: 50, iters: 6592, time: 0.516, data: 0.000) loss: 1.364 
(epoch: 50, iters: 6672, time: 0.490, data: 0.022) loss: 0.429 
(epoch: 50, iters: 6752, time: 0.517, data: 0.000) loss: 0.826 
(epoch: 50, iters: 6832, time: 0.533, data: 0.000) loss: 0.516 
(epoch: 50, iters: 6912, time: 0.475, data: 0.173) loss: 0.868 
(epoch: 50, iters: 6992, time: 0.535, data: 0.000) loss: 0.657 
(epoch: 50, iters: 7072, time: 0.496, data: 0.029) loss: 1.235 
(epoch: 50, iters: 7152, time: 0.520, data: 0.000) loss: 0.906 
(epoch: 50, iters: 7232, time: 0.469, data: 0.065) loss: 0.498 
(epoch: 50, iters: 7312, time: 0.522, data: 0.011) loss: 0.659 
(epoch: 50, iters: 7392, time: 0.496, data: 0.000) loss: 0.702 
(epoch: 50, iters: 7472, time: 0.533, data: 0.036) loss: 0.973 
(epoch: 50, iters: 7552, time: 0.512, data: 0.000) loss: 0.405 
(epoch: 50, iters: 7632, time: 0.503, data: 0.006) loss: 0.431 
(epoch: 50, iters: 7712, time: 0.453, data: 0.000) loss: 0.992 
(epoch: 50, iters: 7792, time: 0.446, data: 0.043) loss: 0.633 
(epoch: 50, iters: 7872, time: 0.494, data: 0.000) loss: 0.693 
(epoch: 50, iters: 7952, time: 0.473, data: 0.000) loss: 0.736 
saving the latest model (epoch 50, total_steps 507424)
(epoch: 50, iters: 8032, time: 0.538, data: 0.010) loss: 0.471 
(epoch: 50, iters: 8112, time: 0.484, data: 0.025) loss: 0.707 
(epoch: 50, iters: 8192, time: 0.535, data: 0.011) loss: 0.712 
(epoch: 50, iters: 8272, time: 0.491, data: 0.000) loss: 0.627 
(epoch: 50, iters: 8352, time: 0.507, data: 0.000) loss: 0.384 
(epoch: 50, iters: 8432, time: 0.373, data: 0.000) loss: 0.726 
(epoch: 50, iters: 8512, time: 0.527, data: 0.072) loss: 0.461 
(epoch: 50, iters: 8592, time: 0.460, data: 0.000) loss: 0.679 
(epoch: 50, iters: 8672, time: 0.419, data: 0.000) loss: 0.920 
(epoch: 50, iters: 8752, time: 0.507, data: 0.000) loss: 1.325 
(epoch: 50, iters: 8832, time: 0.587, data: 0.000) loss: 1.110 
(epoch: 50, iters: 8912, time: 0.745, data: 0.010) loss: 0.388 
(epoch: 50, iters: 8992, time: 0.470, data: 0.000) loss: 0.742 
(epoch: 50, iters: 9072, time: 0.529, data: 0.000) loss: 1.506 
(epoch: 50, iters: 9152, time: 0.406, data: 0.000) loss: 0.469 
(epoch: 50, iters: 9232, time: 0.497, data: 0.009) loss: 0.600 
(epoch: 50, iters: 9312, time: 0.495, data: 0.000) loss: 1.466 
(epoch: 50, iters: 9392, time: 0.483, data: 0.010) loss: 1.002 
(epoch: 50, iters: 9472, time: 0.500, data: 0.000) loss: 1.406 
(epoch: 50, iters: 9552, time: 0.516, data: 0.033) loss: 0.946 
(epoch: 50, iters: 9632, time: 0.430, data: 0.010) loss: 0.580 
(epoch: 50, iters: 9712, time: 0.492, data: 0.000) loss: 0.659 
(epoch: 50, iters: 9792, time: 0.523, data: 0.000) loss: 0.829 
(epoch: 50, iters: 9872, time: 0.531, data: 0.025) loss: 0.969 
(epoch: 50, iters: 9952, time: 0.490, data: 0.022) loss: 0.505 
(epoch: 50, iters: 10032, time: 0.468, data: 0.000) loss: 1.278 
(epoch: 50, iters: 10112, time: 0.403, data: 0.020) loss: 0.250 
(epoch: 50, iters: 10192, time: 0.335, data: 0.010) loss: 0.403 
saving the model at the end of epoch 50, iters 509600
End of epoch 50 / 200 	 Time Taken: 4931 sec
learning rate = 0.0002000
saving the latest model (epoch 51, total_steps 509616)
(epoch: 51, iters: 80, time: 0.484, data: 0.405) loss: 0.783 
(epoch: 51, iters: 160, time: 0.415, data: 0.000) loss: 1.139 
(epoch: 51, iters: 240, time: 0.438, data: 0.000) loss: 0.481 
(epoch: 51, iters: 320, time: 0.522, data: 0.100) loss: 0.935 
(epoch: 51, iters: 400, time: 0.532, data: 0.000) loss: 0.822 
(epoch: 51, iters: 480, time: 0.392, data: 0.000) loss: 1.437 
(epoch: 51, iters: 560, time: 0.503, data: 0.010) loss: 0.843 
(epoch: 51, iters: 640, time: 0.429, data: 0.000) loss: 0.694 
(epoch: 51, iters: 720, time: 0.537, data: 0.000) loss: 1.404 
(epoch: 51, iters: 800, time: 0.465, data: 0.006) loss: 0.736 
(epoch: 51, iters: 880, time: 0.506, data: 0.000) loss: 0.717 
(epoch: 51, iters: 960, time: 0.438, data: 0.006) loss: 1.482 
(epoch: 51, iters: 1040, time: 0.461, data: 0.000) loss: 0.697 
(epoch: 51, iters: 1120, time: 0.471, data: 0.000) loss: 1.092 
(epoch: 51, iters: 1200, time: 0.466, data: 0.026) loss: 0.825 
(epoch: 51, iters: 1280, time: 0.504, data: 0.023) loss: 1.275 
(epoch: 51, iters: 1360, time: 0.496, data: 0.000) loss: 0.628 
(epoch: 51, iters: 1440, time: 0.531, data: 0.010) loss: 0.816 
(epoch: 51, iters: 1520, time: 0.507, data: 0.000) loss: 1.194 
(epoch: 51, iters: 1600, time: 0.467, data: 0.000) loss: 0.694 
(epoch: 51, iters: 1680, time: 0.463, data: 0.022) loss: 0.966 
(epoch: 51, iters: 1760, time: 0.511, data: 0.000) loss: 0.827 
(epoch: 51, iters: 1840, time: 0.624, data: 0.000) loss: 1.070 
(epoch: 51, iters: 1920, time: 0.615, data: 0.038) loss: 0.361 
(epoch: 51, iters: 2000, time: 0.664, data: 0.000) loss: 1.340 
(epoch: 51, iters: 2080, time: 0.550, data: 0.010) loss: 0.272 
(epoch: 51, iters: 2160, time: 0.647, data: 0.000) loss: 0.329 
(epoch: 51, iters: 2240, time: 0.542, data: 0.010) loss: 0.317 
(epoch: 51, iters: 2320, time: 0.713, data: 0.009) loss: 0.667 
(epoch: 51, iters: 2400, time: 0.555, data: 0.000) loss: 0.569 
(epoch: 51, iters: 2480, time: 0.552, data: 0.000) loss: 0.593 
(epoch: 51, iters: 2560, time: 0.601, data: 0.083) loss: 0.603 
(epoch: 51, iters: 2640, time: 0.619, data: 0.000) loss: 1.361 
(epoch: 51, iters: 2720, time: 0.658, data: 0.002) loss: 0.845 
(epoch: 51, iters: 2800, time: 0.499, data: 0.000) loss: 1.196 
(epoch: 51, iters: 2880, time: 0.658, data: 0.000) loss: 1.870 
(epoch: 51, iters: 2960, time: 0.559, data: 0.009) loss: 0.794 
(epoch: 51, iters: 3040, time: 0.598, data: 0.000) loss: 0.984 
(epoch: 51, iters: 3120, time: 0.607, data: 0.000) loss: 0.506 
(epoch: 51, iters: 3200, time: 0.543, data: 0.000) loss: 0.655 
(epoch: 51, iters: 3280, time: 0.593, data: 0.052) loss: 0.856 
(epoch: 51, iters: 3360, time: 0.492, data: 0.000) loss: 1.244 
(epoch: 51, iters: 3440, time: 0.480, data: 0.042) loss: 0.482 
(epoch: 51, iters: 3520, time: 0.494, data: 0.000) loss: 0.393 
(epoch: 51, iters: 3600, time: 0.547, data: 0.000) loss: 1.624 
(epoch: 51, iters: 3680, time: 0.498, data: 0.006) loss: 0.917 
(epoch: 51, iters: 3760, time: 0.453, data: 0.011) loss: 0.506 
(epoch: 51, iters: 3840, time: 0.492, data: 0.006) loss: 1.275 
(epoch: 51, iters: 3920, time: 0.549, data: 0.012) loss: 0.969 
(epoch: 51, iters: 4000, time: 0.504, data: 0.000) loss: 0.931 
saving the latest model (epoch 51, total_steps 513616)
(epoch: 51, iters: 4080, time: 0.511, data: 0.010) loss: 0.744 
(epoch: 51, iters: 4160, time: 0.467, data: 0.000) loss: 0.605 
(epoch: 51, iters: 4240, time: 0.489, data: 0.052) loss: 0.834 
(epoch: 51, iters: 4320, time: 0.474, data: 0.000) loss: 0.497 
(epoch: 51, iters: 4400, time: 0.503, data: 0.008) loss: 0.462 
(epoch: 51, iters: 4480, time: 0.525, data: 0.000) loss: 0.888 
(epoch: 51, iters: 4560, time: 0.375, data: 0.013) loss: 0.976 
(epoch: 51, iters: 4640, time: 0.462, data: 0.000) loss: 0.944 
(epoch: 51, iters: 4720, time: 0.483, data: 0.010) loss: 1.016 
(epoch: 51, iters: 4800, time: 0.515, data: 0.011) loss: 1.076 
(epoch: 51, iters: 4880, time: 0.432, data: 0.058) loss: 1.327 
(epoch: 51, iters: 4960, time: 0.526, data: 0.000) loss: 1.437 
(epoch: 51, iters: 5040, time: 0.457, data: 0.000) loss: 0.857 
(epoch: 51, iters: 5120, time: 0.460, data: 0.000) loss: 1.043 
(epoch: 51, iters: 5200, time: 0.482, data: 0.000) loss: 0.421 
(epoch: 51, iters: 5280, time: 0.500, data: 0.010) loss: 1.353 
(epoch: 51, iters: 5360, time: 0.507, data: 0.000) loss: 0.617 
(epoch: 51, iters: 5440, time: 0.496, data: 0.000) loss: 0.950 
(epoch: 51, iters: 5520, time: 0.464, data: 0.000) loss: 0.574 
(epoch: 51, iters: 5600, time: 0.402, data: 0.062) loss: 0.866 
(epoch: 51, iters: 5680, time: 0.427, data: 0.000) loss: 0.819 
(epoch: 51, iters: 5760, time: 0.503, data: 0.000) loss: 0.676 
(epoch: 51, iters: 5840, time: 0.443, data: 0.001) loss: 1.461 
(epoch: 51, iters: 5920, time: 0.510, data: 0.000) loss: 0.669 
(epoch: 51, iters: 6000, time: 0.471, data: 0.000) loss: 0.426 
(epoch: 51, iters: 6080, time: 0.482, data: 0.000) loss: 1.276 
(epoch: 51, iters: 6160, time: 0.517, data: 0.000) loss: 0.372 
(epoch: 51, iters: 6240, time: 0.449, data: 0.010) loss: 0.878 
(epoch: 51, iters: 6320, time: 0.409, data: 0.000) loss: 1.147 
(epoch: 51, iters: 6400, time: 0.523, data: 0.011) loss: 0.719 
(epoch: 51, iters: 6480, time: 0.511, data: 0.000) loss: 0.601 
(epoch: 51, iters: 6560, time: 0.526, data: 0.000) loss: 0.804 
(epoch: 51, iters: 6640, time: 0.506, data: 0.012) loss: 0.852 
(epoch: 51, iters: 6720, time: 0.481, data: 0.021) loss: 0.794 
(epoch: 51, iters: 6800, time: 0.442, data: 0.000) loss: 0.851 
(epoch: 51, iters: 6880, time: 0.492, data: 0.028) loss: 0.606 
(epoch: 51, iters: 6960, time: 0.540, data: 0.012) loss: 0.841 
(epoch: 51, iters: 7040, time: 0.415, data: 0.019) loss: 1.019 
(epoch: 51, iters: 7120, time: 0.486, data: 0.010) loss: 0.943 
(epoch: 51, iters: 7200, time: 0.499, data: 0.026) loss: 0.887 
(epoch: 51, iters: 7280, time: 0.508, data: 0.000) loss: 0.440 
(epoch: 51, iters: 7360, time: 0.473, data: 0.000) loss: 0.739 
(epoch: 51, iters: 7440, time: 0.480, data: 0.023) loss: 0.790 
(epoch: 51, iters: 7520, time: 0.470, data: 0.000) loss: 0.621 
(epoch: 51, iters: 7600, time: 0.472, data: 0.011) loss: 1.339 
(epoch: 51, iters: 7680, time: 0.463, data: 0.000) loss: 1.207 
(epoch: 51, iters: 7760, time: 0.452, data: 0.011) loss: 0.714 
(epoch: 51, iters: 7840, time: 0.456, data: 0.000) loss: 0.747 
(epoch: 51, iters: 7920, time: 0.486, data: 0.000) loss: 1.488 
(epoch: 51, iters: 8000, time: 0.444, data: 0.000) loss: 0.637 
saving the latest model (epoch 51, total_steps 517616)
(epoch: 51, iters: 8080, time: 0.478, data: 0.038) loss: 0.768 
(epoch: 51, iters: 8160, time: 0.502, data: 0.037) loss: 0.860 
(epoch: 51, iters: 8240, time: 0.431, data: 0.000) loss: 0.911 
(epoch: 51, iters: 8320, time: 0.561, data: 0.049) loss: 0.487 
(epoch: 51, iters: 8400, time: 0.492, data: 0.010) loss: 0.697 
(epoch: 51, iters: 8480, time: 0.325, data: 0.000) loss: 0.670 
(epoch: 51, iters: 8560, time: 0.490, data: 0.000) loss: 1.040 
(epoch: 51, iters: 8640, time: 0.564, data: 0.000) loss: 0.716 
(epoch: 51, iters: 8720, time: 0.459, data: 0.000) loss: 0.669 
(epoch: 51, iters: 8800, time: 0.428, data: 0.011) loss: 0.522 
(epoch: 51, iters: 8880, time: 0.463, data: 0.000) loss: 0.941 
(epoch: 51, iters: 8960, time: 0.498, data: 0.000) loss: 0.868 
(epoch: 51, iters: 9040, time: 0.472, data: 0.000) loss: 0.521 
(epoch: 51, iters: 9120, time: 0.491, data: 0.000) loss: 0.648 
(epoch: 51, iters: 9200, time: 0.419, data: 0.049) loss: 1.181 
(epoch: 51, iters: 9280, time: 0.470, data: 0.000) loss: 1.325 
(epoch: 51, iters: 9360, time: 0.476, data: 0.043) loss: 0.569 
(epoch: 51, iters: 9440, time: 0.431, data: 0.000) loss: 0.461 
(epoch: 51, iters: 9520, time: 0.393, data: 0.000) loss: 0.547 
(epoch: 51, iters: 9600, time: 0.538, data: 0.012) loss: 0.939 
(epoch: 51, iters: 9680, time: 0.549, data: 0.043) loss: 0.895 
(epoch: 51, iters: 9760, time: 0.470, data: 0.000) loss: 0.627 
(epoch: 51, iters: 9840, time: 0.458, data: 0.000) loss: 0.615 
(epoch: 51, iters: 9920, time: 0.451, data: 0.000) loss: 0.651 
(epoch: 51, iters: 10000, time: 0.472, data: 0.010) loss: 1.090 
(epoch: 51, iters: 10080, time: 0.496, data: 0.011) loss: 0.822 
(epoch: 51, iters: 10160, time: 0.517, data: 0.011) loss: 0.824 
saving the model at the end of epoch 51, iters 519792
End of epoch 51 / 200 	 Time Taken: 5104 sec
learning rate = 0.0002000
saving the latest model (epoch 52, total_steps 519808)
(epoch: 52, iters: 48, time: 0.434, data: 0.000) loss: 0.796 
(epoch: 52, iters: 128, time: 0.474, data: 0.068) loss: 0.904 
(epoch: 52, iters: 208, time: 0.471, data: 0.000) loss: 0.464 
(epoch: 52, iters: 288, time: 0.464, data: 0.000) loss: 0.726 
(epoch: 52, iters: 368, time: 0.470, data: 0.008) loss: 0.759 
(epoch: 52, iters: 448, time: 0.504, data: 0.000) loss: 0.733 
(epoch: 52, iters: 528, time: 0.480, data: 0.011) loss: 0.588 
(epoch: 52, iters: 608, time: 0.482, data: 0.000) loss: 0.800 
(epoch: 52, iters: 688, time: 0.504, data: 0.000) loss: 0.242 
(epoch: 52, iters: 768, time: 0.465, data: 0.065) loss: 1.154 
(epoch: 52, iters: 848, time: 0.533, data: 0.000) loss: 1.018 
(epoch: 52, iters: 928, time: 0.461, data: 0.000) loss: 1.261 
(epoch: 52, iters: 1008, time: 0.443, data: 0.039) loss: 0.772 
(epoch: 52, iters: 1088, time: 0.482, data: 0.035) loss: 0.972 
(epoch: 52, iters: 1168, time: 0.524, data: 0.029) loss: 0.814 
(epoch: 52, iters: 1248, time: 0.510, data: 0.000) loss: 0.675 
(epoch: 52, iters: 1328, time: 0.452, data: 0.074) loss: 1.187 
(epoch: 52, iters: 1408, time: 0.478, data: 0.000) loss: 1.478 
(epoch: 52, iters: 1488, time: 0.503, data: 0.000) loss: 1.151 
(epoch: 52, iters: 1568, time: 0.458, data: 0.000) loss: 0.809 
(epoch: 52, iters: 1648, time: 0.505, data: 0.000) loss: 1.093 
(epoch: 52, iters: 1728, time: 0.454, data: 0.018) loss: 1.656 
(epoch: 52, iters: 1808, time: 0.451, data: 0.000) loss: 0.838 
(epoch: 52, iters: 1888, time: 0.476, data: 0.000) loss: 0.589 
(epoch: 52, iters: 1968, time: 0.487, data: 0.011) loss: 0.578 
(epoch: 52, iters: 2048, time: 0.507, data: 0.000) loss: 0.982 
(epoch: 52, iters: 2128, time: 0.442, data: 0.000) loss: 0.991 
(epoch: 52, iters: 2208, time: 0.377, data: 0.075) loss: 0.947 
(epoch: 52, iters: 2288, time: 0.514, data: 0.000) loss: 0.915 
(epoch: 52, iters: 2368, time: 0.481, data: 0.000) loss: 1.381 
(epoch: 52, iters: 2448, time: 0.471, data: 0.000) loss: 0.656 
(epoch: 52, iters: 2528, time: 0.450, data: 0.033) loss: 0.498 
(epoch: 52, iters: 2608, time: 0.489, data: 0.020) loss: 0.818 
(epoch: 52, iters: 2688, time: 0.492, data: 0.000) loss: 0.857 
(epoch: 52, iters: 2768, time: 0.487, data: 0.000) loss: 0.963 
(epoch: 52, iters: 2848, time: 0.431, data: 0.000) loss: 1.301 
(epoch: 52, iters: 2928, time: 0.542, data: 0.015) loss: 0.973 
(epoch: 52, iters: 3008, time: 0.468, data: 0.000) loss: 1.516 
(epoch: 52, iters: 3088, time: 0.516, data: 0.013) loss: 0.587 
(epoch: 52, iters: 3168, time: 0.450, data: 0.000) loss: 1.200 
(epoch: 52, iters: 3248, time: 0.531, data: 0.000) loss: 0.786 
(epoch: 52, iters: 3328, time: 0.494, data: 0.014) loss: 0.855 
(epoch: 52, iters: 3408, time: 0.487, data: 0.006) loss: 1.165 
(epoch: 52, iters: 3488, time: 0.501, data: 0.000) loss: 0.623 
(epoch: 52, iters: 3568, time: 0.344, data: 0.000) loss: 0.407 
(epoch: 52, iters: 3648, time: 0.516, data: 0.000) loss: 0.936 
(epoch: 52, iters: 3728, time: 0.405, data: 0.000) loss: 0.794 
(epoch: 52, iters: 3808, time: 0.522, data: 0.000) loss: 0.170 
(epoch: 52, iters: 3888, time: 0.442, data: 0.000) loss: 0.830 
(epoch: 52, iters: 3968, time: 0.492, data: 0.000) loss: 0.430 
saving the latest model (epoch 52, total_steps 523808)
(epoch: 52, iters: 4048, time: 0.533, data: 0.015) loss: 0.475 
(epoch: 52, iters: 4128, time: 0.475, data: 0.000) loss: 0.613 
(epoch: 52, iters: 4208, time: 0.490, data: 0.012) loss: 0.591 
(epoch: 52, iters: 4288, time: 0.462, data: 0.045) loss: 0.490 
(epoch: 52, iters: 4368, time: 0.503, data: 0.027) loss: 0.587 
(epoch: 52, iters: 4448, time: 0.386, data: 0.000) loss: 0.406 
(epoch: 52, iters: 4528, time: 0.537, data: 0.000) loss: 1.312 
(epoch: 52, iters: 4608, time: 0.457, data: 0.000) loss: 0.563 
(epoch: 52, iters: 4688, time: 0.515, data: 0.000) loss: 0.819 
(epoch: 52, iters: 4768, time: 0.514, data: 0.000) loss: 1.029 
(epoch: 52, iters: 4848, time: 0.495, data: 0.000) loss: 1.293 
(epoch: 52, iters: 4928, time: 0.444, data: 0.007) loss: 0.822 
(epoch: 52, iters: 5008, time: 0.437, data: 0.000) loss: 1.794 
(epoch: 52, iters: 5088, time: 0.531, data: 0.045) loss: 0.765 
(epoch: 52, iters: 5168, time: 0.406, data: 0.011) loss: 1.249 
(epoch: 52, iters: 5248, time: 0.553, data: 0.107) loss: 1.071 
(epoch: 52, iters: 5328, time: 0.468, data: 0.061) loss: 0.847 
(epoch: 52, iters: 5408, time: 0.482, data: 0.000) loss: 0.856 
(epoch: 52, iters: 5488, time: 0.468, data: 0.012) loss: 1.351 
(epoch: 52, iters: 5568, time: 0.474, data: 0.010) loss: 1.009 
(epoch: 52, iters: 5648, time: 0.471, data: 0.033) loss: 0.881 
(epoch: 52, iters: 5728, time: 0.486, data: 0.000) loss: 1.034 
(epoch: 52, iters: 5808, time: 0.527, data: 0.000) loss: 0.146 
(epoch: 52, iters: 5888, time: 0.456, data: 0.000) loss: 0.512 
(epoch: 52, iters: 5968, time: 0.457, data: 0.026) loss: 0.705 
(epoch: 52, iters: 6048, time: 0.466, data: 0.000) loss: 0.925 
(epoch: 52, iters: 6128, time: 0.449, data: 0.031) loss: 2.156 
(epoch: 52, iters: 6208, time: 0.464, data: 0.037) loss: 1.266 
(epoch: 52, iters: 6288, time: 0.459, data: 0.000) loss: 0.654 
(epoch: 52, iters: 6368, time: 0.405, data: 0.024) loss: 0.414 
(epoch: 52, iters: 6448, time: 0.476, data: 0.000) loss: 0.457 
(epoch: 52, iters: 6528, time: 0.474, data: 0.048) loss: 0.521 
(epoch: 52, iters: 6608, time: 0.442, data: 0.000) loss: 0.704 
(epoch: 52, iters: 6688, time: 0.495, data: 0.000) loss: 0.821 
(epoch: 52, iters: 6768, time: 0.534, data: 0.010) loss: 0.615 
(epoch: 52, iters: 6848, time: 0.528, data: 0.006) loss: 1.136 
(epoch: 52, iters: 6928, time: 0.509, data: 0.000) loss: 0.867 
(epoch: 52, iters: 7008, time: 0.489, data: 0.005) loss: 1.030 
(epoch: 52, iters: 7088, time: 0.496, data: 0.000) loss: 1.056 
(epoch: 52, iters: 7168, time: 0.479, data: 0.031) loss: 0.981 
(epoch: 52, iters: 7248, time: 0.453, data: 0.037) loss: 0.762 
(epoch: 52, iters: 7328, time: 0.508, data: 0.000) loss: 1.042 
(epoch: 52, iters: 7408, time: 0.519, data: 0.000) loss: 0.990 
(epoch: 52, iters: 7488, time: 0.526, data: 0.010) loss: 0.665 
(epoch: 52, iters: 7568, time: 0.449, data: 0.000) loss: 1.116 
(epoch: 52, iters: 7648, time: 0.426, data: 0.008) loss: 1.101 
(epoch: 52, iters: 7728, time: 0.435, data: 0.010) loss: 1.542 
(epoch: 52, iters: 7808, time: 0.429, data: 0.000) loss: 0.410 
(epoch: 52, iters: 7888, time: 0.425, data: 0.000) loss: 0.626 
(epoch: 52, iters: 7968, time: 0.479, data: 0.011) loss: 0.961 
saving the latest model (epoch 52, total_steps 527808)
(epoch: 52, iters: 8048, time: 0.428, data: 0.000) loss: 0.716 
(epoch: 52, iters: 8128, time: 0.483, data: 0.011) loss: 0.734 
(epoch: 52, iters: 8208, time: 0.473, data: 0.000) loss: 1.014 
(epoch: 52, iters: 8288, time: 0.456, data: 0.000) loss: 0.960 
(epoch: 52, iters: 8368, time: 0.535, data: 0.000) loss: 0.590 
(epoch: 52, iters: 8448, time: 0.483, data: 0.007) loss: 0.660 
(epoch: 52, iters: 8528, time: 0.420, data: 0.005) loss: 1.746 
(epoch: 52, iters: 8608, time: 0.463, data: 0.012) loss: 0.552 
(epoch: 52, iters: 8688, time: 0.518, data: 0.022) loss: 0.647 
(epoch: 52, iters: 8768, time: 0.460, data: 0.042) loss: 0.575 
(epoch: 52, iters: 8848, time: 0.452, data: 0.007) loss: 1.272 
(epoch: 52, iters: 8928, time: 0.481, data: 0.000) loss: 1.327 
(epoch: 52, iters: 9008, time: 0.441, data: 0.005) loss: 0.786 
(epoch: 52, iters: 9088, time: 0.468, data: 0.009) loss: 0.517 
(epoch: 52, iters: 9168, time: 0.465, data: 0.000) loss: 0.851 
(epoch: 52, iters: 9248, time: 0.373, data: 0.000) loss: 0.764 
(epoch: 52, iters: 9328, time: 0.470, data: 0.074) loss: 0.574 
(epoch: 52, iters: 9408, time: 0.415, data: 0.000) loss: 1.205 
(epoch: 52, iters: 9488, time: 0.495, data: 0.000) loss: 0.650 
(epoch: 52, iters: 9568, time: 0.472, data: 0.000) loss: 0.442 
(epoch: 52, iters: 9648, time: 0.499, data: 0.012) loss: 0.634 
(epoch: 52, iters: 9728, time: 0.366, data: 0.010) loss: 0.787 
(epoch: 52, iters: 9808, time: 0.453, data: 0.000) loss: 0.825 
(epoch: 52, iters: 9888, time: 0.481, data: 0.006) loss: 0.311 
(epoch: 52, iters: 9968, time: 0.509, data: 0.011) loss: 1.047 
(epoch: 52, iters: 10048, time: 0.512, data: 0.087) loss: 0.570 
(epoch: 52, iters: 10128, time: 0.395, data: 0.000) loss: 1.065 
saving the model at the end of epoch 52, iters 529984
End of epoch 52 / 200 	 Time Taken: 4857 sec
learning rate = 0.0002000
(epoch: 53, iters: 16, time: 0.566, data: 0.000) loss: 0.848 
saving the latest model (epoch 53, total_steps 530000)
(epoch: 53, iters: 96, time: 0.473, data: 0.000) loss: 0.464 
(epoch: 53, iters: 176, time: 0.475, data: 0.006) loss: 0.654 
(epoch: 53, iters: 256, time: 0.432, data: 0.000) loss: 1.471 
(epoch: 53, iters: 336, time: 0.408, data: 0.000) loss: 0.787 
(epoch: 53, iters: 416, time: 0.452, data: 0.000) loss: 0.695 
(epoch: 53, iters: 496, time: 0.503, data: 0.017) loss: 0.616 
(epoch: 53, iters: 576, time: 0.503, data: 0.009) loss: 0.521 
(epoch: 53, iters: 656, time: 0.363, data: 0.012) loss: 0.314 
(epoch: 53, iters: 736, time: 0.472, data: 0.011) loss: 0.471 
(epoch: 53, iters: 816, time: 0.535, data: 0.010) loss: 0.313 
(epoch: 53, iters: 896, time: 0.536, data: 0.000) loss: 1.510 
(epoch: 53, iters: 976, time: 0.387, data: 0.027) loss: 1.175 
(epoch: 53, iters: 1056, time: 0.480, data: 0.090) loss: 0.619 
(epoch: 53, iters: 1136, time: 0.440, data: 0.000) loss: 0.725 
(epoch: 53, iters: 1216, time: 0.481, data: 0.000) loss: 0.529 
(epoch: 53, iters: 1296, time: 0.518, data: 0.000) loss: 0.784 
(epoch: 53, iters: 1376, time: 0.408, data: 0.012) loss: 0.863 
(epoch: 53, iters: 1456, time: 0.471, data: 0.000) loss: 0.758 
(epoch: 53, iters: 1536, time: 0.506, data: 0.014) loss: 0.429 
(epoch: 53, iters: 1616, time: 0.539, data: 0.043) loss: 0.545 
(epoch: 53, iters: 1696, time: 0.444, data: 0.000) loss: 0.777 
(epoch: 53, iters: 1776, time: 0.475, data: 0.000) loss: 0.938 
(epoch: 53, iters: 1856, time: 0.420, data: 0.010) loss: 1.464 
(epoch: 53, iters: 1936, time: 0.452, data: 0.000) loss: 0.956 
(epoch: 53, iters: 2016, time: 0.493, data: 0.016) loss: 0.440 
(epoch: 53, iters: 2096, time: 0.507, data: 0.000) loss: 0.624 
(epoch: 53, iters: 2176, time: 0.527, data: 0.011) loss: 0.506 
(epoch: 53, iters: 2256, time: 0.503, data: 0.000) loss: 0.594 
(epoch: 53, iters: 2336, time: 0.523, data: 0.016) loss: 0.720 
(epoch: 53, iters: 2416, time: 0.482, data: 0.000) loss: 0.685 
(epoch: 53, iters: 2496, time: 0.453, data: 0.063) loss: 1.765 
(epoch: 53, iters: 2576, time: 0.485, data: 0.000) loss: 0.674 
(epoch: 53, iters: 2656, time: 0.487, data: 0.000) loss: 0.681 
(epoch: 53, iters: 2736, time: 0.491, data: 0.060) loss: 0.838 
(epoch: 53, iters: 2816, time: 0.527, data: 0.000) loss: 0.638 
(epoch: 53, iters: 2896, time: 0.488, data: 0.020) loss: 1.357 
(epoch: 53, iters: 2976, time: 0.475, data: 0.000) loss: 1.151 
(epoch: 53, iters: 3056, time: 0.457, data: 0.000) loss: 0.726 
(epoch: 53, iters: 3136, time: 0.506, data: 0.000) loss: 0.451 
(epoch: 53, iters: 3216, time: 0.503, data: 0.012) loss: 0.642 
(epoch: 53, iters: 3296, time: 0.459, data: 0.000) loss: 0.638 
(epoch: 53, iters: 3376, time: 0.419, data: 0.000) loss: 0.506 
(epoch: 53, iters: 3456, time: 0.440, data: 0.015) loss: 0.646 
(epoch: 53, iters: 3536, time: 0.517, data: 0.000) loss: 1.087 
(epoch: 53, iters: 3616, time: 0.497, data: 0.008) loss: 0.435 
(epoch: 53, iters: 3696, time: 0.484, data: 0.000) loss: 1.280 
(epoch: 53, iters: 3776, time: 0.449, data: 0.000) loss: 0.660 
(epoch: 53, iters: 3856, time: 0.451, data: 0.012) loss: 0.769 
(epoch: 53, iters: 3936, time: 0.498, data: 0.000) loss: 0.448 
(epoch: 53, iters: 4016, time: 0.446, data: 0.000) loss: 0.869 
saving the latest model (epoch 53, total_steps 534000)
(epoch: 53, iters: 4096, time: 0.441, data: 0.018) loss: 0.913 
(epoch: 53, iters: 4176, time: 0.431, data: 0.017) loss: 0.774 
(epoch: 53, iters: 4256, time: 0.435, data: 0.010) loss: 0.957 
(epoch: 53, iters: 4336, time: 0.511, data: 0.028) loss: 1.205 
(epoch: 53, iters: 4416, time: 0.523, data: 0.010) loss: 0.601 
(epoch: 53, iters: 4496, time: 0.465, data: 0.000) loss: 0.468 
(epoch: 53, iters: 4576, time: 0.453, data: 0.011) loss: 1.345 
(epoch: 53, iters: 4656, time: 0.465, data: 0.012) loss: 0.377 
(epoch: 53, iters: 4736, time: 0.449, data: 0.000) loss: 1.301 
(epoch: 53, iters: 4816, time: 0.461, data: 0.002) loss: 0.486 
(epoch: 53, iters: 4896, time: 0.491, data: 0.000) loss: 0.707 
(epoch: 53, iters: 4976, time: 0.496, data: 0.000) loss: 0.595 
(epoch: 53, iters: 5056, time: 0.489, data: 0.010) loss: 0.899 
(epoch: 53, iters: 5136, time: 0.464, data: 0.000) loss: 1.182 
(epoch: 53, iters: 5216, time: 0.455, data: 0.078) loss: 0.399 
(epoch: 53, iters: 5296, time: 0.455, data: 0.070) loss: 1.083 
(epoch: 53, iters: 5376, time: 0.488, data: 0.025) loss: 0.924 
(epoch: 53, iters: 5456, time: 0.508, data: 0.000) loss: 0.746 
(epoch: 53, iters: 5536, time: 0.482, data: 0.000) loss: 0.481 
(epoch: 53, iters: 5616, time: 0.482, data: 0.000) loss: 0.573 
(epoch: 53, iters: 5696, time: 0.547, data: 0.000) loss: 1.193 
(epoch: 53, iters: 5776, time: 0.496, data: 0.006) loss: 0.649 
(epoch: 53, iters: 5856, time: 0.504, data: 0.011) loss: 0.213 
(epoch: 53, iters: 5936, time: 0.441, data: 0.000) loss: 0.355 
(epoch: 53, iters: 6016, time: 0.465, data: 0.010) loss: 0.834 
(epoch: 53, iters: 6096, time: 0.448, data: 0.000) loss: 0.470 
(epoch: 53, iters: 6176, time: 0.473, data: 0.032) loss: 0.497 
(epoch: 53, iters: 6256, time: 0.491, data: 0.043) loss: 0.837 
(epoch: 53, iters: 6336, time: 0.483, data: 0.033) loss: 0.757 
(epoch: 53, iters: 6416, time: 0.520, data: 0.000) loss: 0.869 
(epoch: 53, iters: 6496, time: 0.492, data: 0.016) loss: 0.912 
(epoch: 53, iters: 6576, time: 0.452, data: 0.009) loss: 1.213 
(epoch: 53, iters: 6656, time: 0.477, data: 0.000) loss: 0.599 
(epoch: 53, iters: 6736, time: 0.501, data: 0.010) loss: 0.747 
(epoch: 53, iters: 6816, time: 0.420, data: 0.034) loss: 2.049 
(epoch: 53, iters: 6896, time: 0.494, data: 0.000) loss: 1.096 
(epoch: 53, iters: 6976, time: 0.470, data: 0.018) loss: 0.462 
(epoch: 53, iters: 7056, time: 0.420, data: 0.000) loss: 0.755 
(epoch: 53, iters: 7136, time: 0.507, data: 0.000) loss: 0.594 
(epoch: 53, iters: 7216, time: 0.543, data: 0.039) loss: 0.698 
(epoch: 53, iters: 7296, time: 0.417, data: 0.095) loss: 0.905 
(epoch: 53, iters: 7376, time: 0.495, data: 0.000) loss: 0.825 
(epoch: 53, iters: 7456, time: 0.509, data: 0.020) loss: 1.270 
(epoch: 53, iters: 7536, time: 0.339, data: 0.000) loss: 0.449 
(epoch: 53, iters: 7616, time: 0.461, data: 0.013) loss: 0.718 
(epoch: 53, iters: 7696, time: 0.440, data: 0.000) loss: 1.054 
(epoch: 53, iters: 7776, time: 0.449, data: 0.000) loss: 0.767 
(epoch: 53, iters: 7856, time: 0.508, data: 0.010) loss: 0.731 
(epoch: 53, iters: 7936, time: 0.514, data: 0.041) loss: 1.323 
(epoch: 53, iters: 8016, time: 0.456, data: 0.000) loss: 0.647 
saving the latest model (epoch 53, total_steps 538000)
(epoch: 53, iters: 8096, time: 0.426, data: 0.028) loss: 0.361 
(epoch: 53, iters: 8176, time: 0.472, data: 0.000) loss: 0.639 
(epoch: 53, iters: 8256, time: 0.409, data: 0.043) loss: 1.448 
(epoch: 53, iters: 8336, time: 0.519, data: 0.000) loss: 0.330 
(epoch: 53, iters: 8416, time: 0.531, data: 0.025) loss: 0.773 
(epoch: 53, iters: 8496, time: 0.401, data: 0.011) loss: 1.403 
(epoch: 53, iters: 8576, time: 0.501, data: 0.025) loss: 0.501 
(epoch: 53, iters: 8656, time: 0.483, data: 0.000) loss: 0.590 
(epoch: 53, iters: 8736, time: 0.480, data: 0.007) loss: 1.070 
(epoch: 53, iters: 8816, time: 0.466, data: 0.000) loss: 1.044 
(epoch: 53, iters: 8896, time: 0.435, data: 0.000) loss: 0.451 
(epoch: 53, iters: 8976, time: 0.355, data: 0.010) loss: 0.860 
(epoch: 53, iters: 9056, time: 0.487, data: 0.000) loss: 0.971 
(epoch: 53, iters: 9136, time: 0.522, data: 0.005) loss: 0.883 
(epoch: 53, iters: 9216, time: 0.363, data: 0.094) loss: 0.817 
(epoch: 53, iters: 9296, time: 0.484, data: 0.000) loss: 0.774 
(epoch: 53, iters: 9376, time: 0.493, data: 0.101) loss: 0.862 
(epoch: 53, iters: 9456, time: 0.512, data: 0.000) loss: 1.366 
(epoch: 53, iters: 9536, time: 0.484, data: 0.052) loss: 0.533 
(epoch: 53, iters: 9616, time: 0.477, data: 0.000) loss: 0.684 
(epoch: 53, iters: 9696, time: 0.403, data: 0.024) loss: 0.730 
(epoch: 53, iters: 9776, time: 0.539, data: 0.000) loss: 1.357 
(epoch: 53, iters: 9856, time: 0.466, data: 0.010) loss: 1.106 
(epoch: 53, iters: 9936, time: 0.397, data: 0.000) loss: 1.177 
(epoch: 53, iters: 10016, time: 0.515, data: 0.030) loss: 0.789 
(epoch: 53, iters: 10096, time: 0.517, data: 0.032) loss: 0.453 
(epoch: 53, iters: 10176, time: 0.513, data: 0.000) loss: 0.921 
saving the model at the end of epoch 53, iters 540176
End of epoch 53 / 200 	 Time Taken: 4833 sec
learning rate = 0.0002000
saving the latest model (epoch 54, total_steps 540192)
(epoch: 54, iters: 64, time: 0.507, data: 0.000) loss: 1.094 
(epoch: 54, iters: 144, time: 0.302, data: 0.063) loss: 0.557 
(epoch: 54, iters: 224, time: 0.433, data: 0.000) loss: 0.636 
(epoch: 54, iters: 304, time: 0.412, data: 0.052) loss: 0.808 
(epoch: 54, iters: 384, time: 0.500, data: 0.000) loss: 0.643 
(epoch: 54, iters: 464, time: 0.396, data: 0.000) loss: 0.568 
(epoch: 54, iters: 544, time: 0.517, data: 0.024) loss: 1.390 
(epoch: 54, iters: 624, time: 0.485, data: 0.000) loss: 1.131 
(epoch: 54, iters: 704, time: 0.462, data: 0.000) loss: 0.819 
(epoch: 54, iters: 784, time: 0.482, data: 0.000) loss: 0.855 
(epoch: 54, iters: 864, time: 0.456, data: 0.058) loss: 0.806 
(epoch: 54, iters: 944, time: 0.417, data: 0.011) loss: 1.215 
(epoch: 54, iters: 1024, time: 0.488, data: 0.000) loss: 0.405 
(epoch: 54, iters: 1104, time: 0.474, data: 0.012) loss: 0.940 
(epoch: 54, iters: 1184, time: 0.489, data: 0.000) loss: 0.484 
(epoch: 54, iters: 1264, time: 0.484, data: 0.000) loss: 0.504 
(epoch: 54, iters: 1344, time: 0.550, data: 0.096) loss: 0.495 
(epoch: 54, iters: 1424, time: 0.477, data: 0.000) loss: 0.489 
(epoch: 54, iters: 1504, time: 0.495, data: 0.000) loss: 0.672 
(epoch: 54, iters: 1584, time: 0.447, data: 0.009) loss: 0.478 
(epoch: 54, iters: 1664, time: 0.373, data: 0.000) loss: 0.840 
(epoch: 54, iters: 1744, time: 0.443, data: 0.000) loss: 0.751 
(epoch: 54, iters: 1824, time: 0.475, data: 0.001) loss: 1.028 
(epoch: 54, iters: 1904, time: 0.446, data: 0.032) loss: 0.538 
(epoch: 54, iters: 1984, time: 0.499, data: 0.000) loss: 0.839 
(epoch: 54, iters: 2064, time: 0.472, data: 0.000) loss: 0.899 
(epoch: 54, iters: 2144, time: 0.491, data: 0.000) loss: 0.569 
(epoch: 54, iters: 2224, time: 0.484, data: 0.010) loss: 0.856 
(epoch: 54, iters: 2304, time: 0.461, data: 0.000) loss: 0.762 
(epoch: 54, iters: 2384, time: 0.559, data: 0.037) loss: 0.737 
(epoch: 54, iters: 2464, time: 0.557, data: 0.000) loss: 0.659 
(epoch: 54, iters: 2544, time: 0.505, data: 0.000) loss: 0.886 
(epoch: 54, iters: 2624, time: 0.493, data: 0.000) loss: 1.041 
(epoch: 54, iters: 2704, time: 0.522, data: 0.040) loss: 0.591 
(epoch: 54, iters: 2784, time: 0.502, data: 0.035) loss: 0.529 
(epoch: 54, iters: 2864, time: 0.510, data: 0.000) loss: 0.994 
(epoch: 54, iters: 2944, time: 0.513, data: 0.011) loss: 0.628 
(epoch: 54, iters: 3024, time: 0.397, data: 0.000) loss: 0.787 
(epoch: 54, iters: 3104, time: 0.474, data: 0.000) loss: 1.123 
(epoch: 54, iters: 3184, time: 0.410, data: 0.022) loss: 1.072 
(epoch: 54, iters: 3264, time: 0.494, data: 0.010) loss: 0.631 
(epoch: 54, iters: 3344, time: 0.535, data: 0.000) loss: 1.083 
(epoch: 54, iters: 3424, time: 0.550, data: 0.023) loss: 1.089 
(epoch: 54, iters: 3504, time: 0.530, data: 0.011) loss: 0.726 
(epoch: 54, iters: 3584, time: 0.527, data: 0.028) loss: 1.133 
(epoch: 54, iters: 3664, time: 0.456, data: 0.000) loss: 1.008 
(epoch: 54, iters: 3744, time: 0.444, data: 0.038) loss: 0.716 
(epoch: 54, iters: 3824, time: 0.500, data: 0.000) loss: 0.891 
(epoch: 54, iters: 3904, time: 0.439, data: 0.038) loss: 1.460 
(epoch: 54, iters: 3984, time: 0.487, data: 0.026) loss: 1.065 
saving the latest model (epoch 54, total_steps 544192)
(epoch: 54, iters: 4064, time: 0.501, data: 0.006) loss: 0.484 
(epoch: 54, iters: 4144, time: 0.482, data: 0.000) loss: 0.470 
(epoch: 54, iters: 4224, time: 0.500, data: 0.000) loss: 0.770 
(epoch: 54, iters: 4304, time: 0.458, data: 0.000) loss: 0.685 
(epoch: 54, iters: 4384, time: 0.471, data: 0.005) loss: 0.548 
(epoch: 54, iters: 4464, time: 0.367, data: 0.000) loss: 0.718 
(epoch: 54, iters: 4544, time: 0.510, data: 0.000) loss: 0.417 
(epoch: 54, iters: 4624, time: 0.431, data: 0.005) loss: 1.323 
(epoch: 54, iters: 4704, time: 0.420, data: 0.021) loss: 0.573 
(epoch: 54, iters: 4784, time: 0.471, data: 0.000) loss: 0.601 
(epoch: 54, iters: 4864, time: 0.494, data: 0.000) loss: 1.317 
(epoch: 54, iters: 4944, time: 0.484, data: 0.016) loss: 0.762 
(epoch: 54, iters: 5024, time: 0.411, data: 0.072) loss: 0.579 
(epoch: 54, iters: 5104, time: 0.510, data: 0.000) loss: 0.355 
(epoch: 54, iters: 5184, time: 0.476, data: 0.000) loss: 0.413 
(epoch: 54, iters: 5264, time: 0.468, data: 0.000) loss: 0.600 
(epoch: 54, iters: 5344, time: 0.497, data: 0.000) loss: 0.794 
(epoch: 54, iters: 5424, time: 0.542, data: 0.050) loss: 0.485 
(epoch: 54, iters: 5504, time: 0.468, data: 0.041) loss: 0.560 
(epoch: 54, iters: 5584, time: 0.558, data: 0.000) loss: 0.368 
(epoch: 54, iters: 5664, time: 0.474, data: 0.004) loss: 0.674 
(epoch: 54, iters: 5744, time: 0.512, data: 0.015) loss: 0.536 
(epoch: 54, iters: 5824, time: 0.525, data: 0.000) loss: 0.538 
(epoch: 54, iters: 5904, time: 0.536, data: 0.000) loss: 0.759 
(epoch: 54, iters: 5984, time: 0.450, data: 0.046) loss: 1.046 
(epoch: 54, iters: 6064, time: 0.445, data: 0.000) loss: 0.332 
(epoch: 54, iters: 6144, time: 0.450, data: 0.011) loss: 1.038 
(epoch: 54, iters: 6224, time: 0.563, data: 0.016) loss: 0.627 
(epoch: 54, iters: 6304, time: 0.536, data: 0.013) loss: 0.472 
(epoch: 54, iters: 6384, time: 0.512, data: 0.046) loss: 0.764 
(epoch: 54, iters: 6464, time: 0.512, data: 0.000) loss: 0.554 
(epoch: 54, iters: 6544, time: 0.509, data: 0.000) loss: 0.369 
(epoch: 54, iters: 6624, time: 0.418, data: 0.000) loss: 0.744 
(epoch: 54, iters: 6704, time: 0.452, data: 0.011) loss: 0.823 
(epoch: 54, iters: 6784, time: 0.454, data: 0.037) loss: 0.774 
(epoch: 54, iters: 6864, time: 0.345, data: 0.000) loss: 1.438 
(epoch: 54, iters: 6944, time: 0.497, data: 0.019) loss: 0.704 
(epoch: 54, iters: 7024, time: 0.502, data: 0.000) loss: 0.662 
(epoch: 54, iters: 7104, time: 0.540, data: 0.000) loss: 0.829 
(epoch: 54, iters: 7184, time: 0.448, data: 0.023) loss: 1.023 
(epoch: 54, iters: 7264, time: 0.454, data: 0.000) loss: 0.851 
(epoch: 54, iters: 7344, time: 0.491, data: 0.000) loss: 0.578 
(epoch: 54, iters: 7424, time: 0.515, data: 0.000) loss: 1.077 
(epoch: 54, iters: 7504, time: 0.527, data: 0.000) loss: 0.496 
(epoch: 54, iters: 7584, time: 0.396, data: 0.017) loss: 1.262 
(epoch: 54, iters: 7664, time: 0.467, data: 0.041) loss: 1.053 
(epoch: 54, iters: 7744, time: 0.456, data: 0.053) loss: 0.939 
(epoch: 54, iters: 7824, time: 0.442, data: 0.000) loss: 0.639 
(epoch: 54, iters: 7904, time: 0.535, data: 0.007) loss: 0.810 
(epoch: 54, iters: 7984, time: 0.367, data: 0.000) loss: 1.141 
saving the latest model (epoch 54, total_steps 548192)
(epoch: 54, iters: 8064, time: 0.459, data: 0.034) loss: 0.409 
(epoch: 54, iters: 8144, time: 0.497, data: 0.008) loss: 0.728 
(epoch: 54, iters: 8224, time: 0.468, data: 0.011) loss: 0.545 
(epoch: 54, iters: 8304, time: 0.362, data: 0.009) loss: 0.408 
(epoch: 54, iters: 8384, time: 0.493, data: 0.000) loss: 0.906 
(epoch: 54, iters: 8464, time: 0.463, data: 0.010) loss: 0.821 
(epoch: 54, iters: 8544, time: 0.541, data: 0.000) loss: 0.600 
(epoch: 54, iters: 8624, time: 0.546, data: 0.000) loss: 1.653 
(epoch: 54, iters: 8704, time: 0.345, data: 0.015) loss: 0.211 
(epoch: 54, iters: 8784, time: 0.530, data: 0.000) loss: 1.079 
(epoch: 54, iters: 8864, time: 0.501, data: 0.040) loss: 0.663 
(epoch: 54, iters: 8944, time: 0.491, data: 0.022) loss: 0.567 
(epoch: 54, iters: 9024, time: 0.445, data: 0.151) loss: 1.237 
(epoch: 54, iters: 9104, time: 0.522, data: 0.000) loss: 0.424 
(epoch: 54, iters: 9184, time: 0.454, data: 0.011) loss: 0.547 
(epoch: 54, iters: 9264, time: 0.502, data: 0.010) loss: 0.714 
(epoch: 54, iters: 9344, time: 0.488, data: 0.000) loss: 0.578 
(epoch: 54, iters: 9424, time: 0.507, data: 0.079) loss: 1.138 
(epoch: 54, iters: 9504, time: 0.538, data: 0.017) loss: 1.395 
(epoch: 54, iters: 9584, time: 0.457, data: 0.000) loss: 1.455 
(epoch: 54, iters: 9664, time: 0.497, data: 0.000) loss: 0.847 
(epoch: 54, iters: 9744, time: 0.468, data: 0.028) loss: 0.660 
(epoch: 54, iters: 9824, time: 0.513, data: 0.069) loss: 0.488 
(epoch: 54, iters: 9904, time: 0.482, data: 0.000) loss: 0.869 
(epoch: 54, iters: 9984, time: 0.517, data: 0.064) loss: 0.310 
(epoch: 54, iters: 10064, time: 0.484, data: 0.000) loss: 0.538 
(epoch: 54, iters: 10144, time: 0.381, data: 0.000) loss: 0.903 
saving the model at the end of epoch 54, iters 550368
End of epoch 54 / 200 	 Time Taken: 4863 sec
learning rate = 0.0002000
saving the latest model (epoch 55, total_steps 550384)
(epoch: 55, iters: 32, time: 0.551, data: 0.007) loss: 1.234 
(epoch: 55, iters: 112, time: 0.429, data: 0.060) loss: 0.596 
(epoch: 55, iters: 192, time: 0.505, data: 0.007) loss: 1.001 
(epoch: 55, iters: 272, time: 0.484, data: 0.000) loss: 0.711 
(epoch: 55, iters: 352, time: 0.476, data: 0.035) loss: 1.089 
(epoch: 55, iters: 432, time: 0.508, data: 0.000) loss: 0.444 
(epoch: 55, iters: 512, time: 0.500, data: 0.011) loss: 1.198 
(epoch: 55, iters: 592, time: 0.469, data: 0.000) loss: 1.212 
(epoch: 55, iters: 672, time: 0.422, data: 0.000) loss: 1.073 
(epoch: 55, iters: 752, time: 0.496, data: 0.000) loss: 0.633 
(epoch: 55, iters: 832, time: 0.500, data: 0.032) loss: 0.578 
(epoch: 55, iters: 912, time: 0.521, data: 0.000) loss: 0.279 
(epoch: 55, iters: 992, time: 0.453, data: 0.013) loss: 0.919 
(epoch: 55, iters: 1072, time: 0.498, data: 0.000) loss: 0.824 
(epoch: 55, iters: 1152, time: 0.515, data: 0.000) loss: 1.404 
(epoch: 55, iters: 1232, time: 0.500, data: 0.003) loss: 0.835 
(epoch: 55, iters: 1312, time: 0.378, data: 0.000) loss: 0.694 
(epoch: 55, iters: 1392, time: 0.450, data: 0.035) loss: 0.222 
(epoch: 55, iters: 1472, time: 0.452, data: 0.000) loss: 0.257 
(epoch: 55, iters: 1552, time: 0.426, data: 0.055) loss: 0.772 
(epoch: 55, iters: 1632, time: 0.381, data: 0.011) loss: 1.098 
(epoch: 55, iters: 1712, time: 0.484, data: 0.000) loss: 0.906 
(epoch: 55, iters: 1792, time: 0.529, data: 0.011) loss: 0.962 
(epoch: 55, iters: 1872, time: 0.469, data: 0.034) loss: 0.523 
(epoch: 55, iters: 1952, time: 0.474, data: 0.042) loss: 0.849 
(epoch: 55, iters: 2032, time: 0.409, data: 0.026) loss: 1.321 
(epoch: 55, iters: 2112, time: 0.444, data: 0.000) loss: 1.067 
(epoch: 55, iters: 2192, time: 0.517, data: 0.000) loss: 0.841 
(epoch: 55, iters: 2272, time: 0.497, data: 0.012) loss: 0.867 
(epoch: 55, iters: 2352, time: 0.529, data: 0.010) loss: 0.558 
(epoch: 55, iters: 2432, time: 0.475, data: 0.000) loss: 0.555 
(epoch: 55, iters: 2512, time: 0.489, data: 0.030) loss: 1.028 
(epoch: 55, iters: 2592, time: 0.540, data: 0.000) loss: 0.885 
(epoch: 55, iters: 2672, time: 0.501, data: 0.000) loss: 0.444 
(epoch: 55, iters: 2752, time: 0.417, data: 0.000) loss: 0.457 
(epoch: 55, iters: 2832, time: 0.354, data: 0.000) loss: 0.613 
(epoch: 55, iters: 2912, time: 0.508, data: 0.022) loss: 1.767 
(epoch: 55, iters: 2992, time: 0.462, data: 0.010) loss: 0.875 
(epoch: 55, iters: 3072, time: 0.519, data: 0.011) loss: 1.207 
(epoch: 55, iters: 3152, time: 0.502, data: 0.000) loss: 0.729 
(epoch: 55, iters: 3232, time: 0.447, data: 0.000) loss: 0.954 
(epoch: 55, iters: 3312, time: 0.490, data: 0.010) loss: 0.803 
(epoch: 55, iters: 3392, time: 0.477, data: 0.000) loss: 0.578 
(epoch: 55, iters: 3472, time: 0.397, data: 0.000) loss: 0.866 
(epoch: 55, iters: 3552, time: 0.439, data: 0.073) loss: 0.546 
(epoch: 55, iters: 3632, time: 0.459, data: 0.012) loss: 0.346 
(epoch: 55, iters: 3712, time: 0.454, data: 0.000) loss: 1.022 
(epoch: 55, iters: 3792, time: 0.458, data: 0.000) loss: 0.191 
(epoch: 55, iters: 3872, time: 0.485, data: 0.029) loss: 0.474 
(epoch: 55, iters: 3952, time: 0.469, data: 0.000) loss: 0.818 
saving the latest model (epoch 55, total_steps 554384)
(epoch: 55, iters: 4032, time: 0.518, data: 0.011) loss: 0.685 
(epoch: 55, iters: 4112, time: 0.473, data: 0.000) loss: 0.548 
(epoch: 55, iters: 4192, time: 0.408, data: 0.000) loss: 0.346 
(epoch: 55, iters: 4272, time: 0.452, data: 0.031) loss: 0.678 
(epoch: 55, iters: 4352, time: 0.537, data: 0.000) loss: 0.701 
(epoch: 55, iters: 4432, time: 0.485, data: 0.050) loss: 0.652 
(epoch: 55, iters: 4512, time: 0.363, data: 0.006) loss: 0.373 
(epoch: 55, iters: 4592, time: 0.474, data: 0.000) loss: 0.851 
(epoch: 55, iters: 4672, time: 0.478, data: 0.000) loss: 1.070 
(epoch: 55, iters: 4752, time: 0.493, data: 0.045) loss: 0.829 
(epoch: 55, iters: 4832, time: 0.502, data: 0.000) loss: 0.617 
(epoch: 55, iters: 4912, time: 0.533, data: 0.000) loss: 0.411 
(epoch: 55, iters: 4992, time: 0.390, data: 0.049) loss: 1.252 
(epoch: 55, iters: 5072, time: 0.458, data: 0.000) loss: 0.751 
(epoch: 55, iters: 5152, time: 0.504, data: 0.025) loss: 0.919 
(epoch: 55, iters: 5232, time: 0.515, data: 0.010) loss: 1.016 
(epoch: 55, iters: 5312, time: 0.538, data: 0.000) loss: 0.379 
(epoch: 55, iters: 5392, time: 0.498, data: 0.025) loss: 0.742 
(epoch: 55, iters: 5472, time: 0.524, data: 0.010) loss: 0.789 
(epoch: 55, iters: 5552, time: 0.446, data: 0.000) loss: 1.139 
(epoch: 55, iters: 5632, time: 0.487, data: 0.000) loss: 0.627 
(epoch: 55, iters: 5712, time: 0.509, data: 0.012) loss: 0.794 
(epoch: 55, iters: 5792, time: 0.491, data: 0.000) loss: 0.358 
(epoch: 55, iters: 5872, time: 0.458, data: 0.011) loss: 0.971 
(epoch: 55, iters: 5952, time: 0.497, data: 0.006) loss: 0.635 
(epoch: 55, iters: 6032, time: 0.459, data: 0.021) loss: 0.890 
(epoch: 55, iters: 6112, time: 0.497, data: 0.000) loss: 1.125 
(epoch: 55, iters: 6192, time: 0.506, data: 0.000) loss: 0.787 
(epoch: 55, iters: 6272, time: 0.429, data: 0.010) loss: 0.784 
(epoch: 55, iters: 6352, time: 0.486, data: 0.000) loss: 0.640 
(epoch: 55, iters: 6432, time: 0.529, data: 0.000) loss: 1.338 
(epoch: 55, iters: 6512, time: 0.477, data: 0.040) loss: 0.639 
(epoch: 55, iters: 6592, time: 0.372, data: 0.065) loss: 1.460 
(epoch: 55, iters: 6672, time: 0.460, data: 0.000) loss: 0.951 
(epoch: 55, iters: 6752, time: 0.466, data: 0.023) loss: 0.858 
(epoch: 55, iters: 6832, time: 0.523, data: 0.012) loss: 0.758 
(epoch: 55, iters: 6912, time: 0.441, data: 0.000) loss: 1.161 
(epoch: 55, iters: 6992, time: 0.450, data: 0.000) loss: 1.153 
(epoch: 55, iters: 7072, time: 0.455, data: 0.000) loss: 1.423 
(epoch: 55, iters: 7152, time: 0.514, data: 0.000) loss: 0.621 
(epoch: 55, iters: 7232, time: 0.478, data: 0.040) loss: 0.638 
(epoch: 55, iters: 7312, time: 0.405, data: 0.000) loss: 1.353 
(epoch: 55, iters: 7392, time: 0.471, data: 0.074) loss: 1.215 
(epoch: 55, iters: 7472, time: 0.494, data: 0.000) loss: 0.866 
(epoch: 55, iters: 7552, time: 0.409, data: 0.098) loss: 1.048 
(epoch: 55, iters: 7632, time: 0.439, data: 0.000) loss: 0.516 
(epoch: 55, iters: 7712, time: 0.458, data: 0.000) loss: 0.447 
(epoch: 55, iters: 7792, time: 0.464, data: 0.032) loss: 0.481 
(epoch: 55, iters: 7872, time: 0.511, data: 0.000) loss: 0.547 
(epoch: 55, iters: 7952, time: 0.500, data: 0.000) loss: 0.304 
saving the latest model (epoch 55, total_steps 558384)
(epoch: 55, iters: 8032, time: 0.417, data: 0.000) loss: 0.872 
(epoch: 55, iters: 8112, time: 0.541, data: 0.029) loss: 1.069 
(epoch: 55, iters: 8192, time: 0.532, data: 0.000) loss: 0.901 
(epoch: 55, iters: 8272, time: 0.473, data: 0.000) loss: 0.957 
(epoch: 55, iters: 8352, time: 0.465, data: 0.024) loss: 0.342 
(epoch: 55, iters: 8432, time: 0.507, data: 0.000) loss: 0.728 
(epoch: 55, iters: 8512, time: 0.444, data: 0.000) loss: 1.014 
(epoch: 55, iters: 8592, time: 0.549, data: 0.035) loss: 1.201 
(epoch: 55, iters: 8672, time: 0.448, data: 0.045) loss: 1.101 
(epoch: 55, iters: 8752, time: 0.492, data: 0.000) loss: 0.481 
(epoch: 55, iters: 8832, time: 0.491, data: 0.000) loss: 0.767 
(epoch: 55, iters: 8912, time: 0.520, data: 0.000) loss: 0.782 
(epoch: 55, iters: 8992, time: 0.487, data: 0.036) loss: 0.688 
(epoch: 55, iters: 9072, time: 0.539, data: 0.037) loss: 0.593 
(epoch: 55, iters: 9152, time: 0.500, data: 0.006) loss: 0.536 
(epoch: 55, iters: 9232, time: 0.410, data: 0.041) loss: 0.900 
(epoch: 55, iters: 9312, time: 0.431, data: 0.000) loss: 0.685 
(epoch: 55, iters: 9392, time: 0.449, data: 0.010) loss: 0.732 
(epoch: 55, iters: 9472, time: 0.586, data: 0.000) loss: 0.851 
(epoch: 55, iters: 9552, time: 0.478, data: 0.000) loss: 1.962 
(epoch: 55, iters: 9632, time: 0.522, data: 0.000) loss: 0.697 
(epoch: 55, iters: 9712, time: 0.433, data: 0.000) loss: 0.885 
(epoch: 55, iters: 9792, time: 0.476, data: 0.030) loss: 0.756 
(epoch: 55, iters: 9872, time: 0.526, data: 0.011) loss: 0.798 
(epoch: 55, iters: 9952, time: 0.497, data: 0.000) loss: 0.538 
(epoch: 55, iters: 10032, time: 0.452, data: 0.000) loss: 0.702 
(epoch: 55, iters: 10112, time: 0.362, data: 0.011) loss: 1.532 
(epoch: 55, iters: 10192, time: 0.324, data: 0.000) loss: 0.806 
saving the model at the end of epoch 55, iters 560560
End of epoch 55 / 200 	 Time Taken: 4909 sec
learning rate = 0.0002000
saving the latest model (epoch 56, total_steps 560576)
(epoch: 56, iters: 80, time: 0.462, data: 0.275) loss: 0.906 
(epoch: 56, iters: 160, time: 0.484, data: 0.053) loss: 1.279 
(epoch: 56, iters: 240, time: 0.499, data: 0.010) loss: 0.492 
(epoch: 56, iters: 320, time: 0.372, data: 0.009) loss: 1.223 
(epoch: 56, iters: 400, time: 0.482, data: 0.000) loss: 0.434 
(epoch: 56, iters: 480, time: 0.516, data: 0.000) loss: 1.002 
(epoch: 56, iters: 560, time: 0.439, data: 0.104) loss: 0.638 
(epoch: 56, iters: 640, time: 0.403, data: 0.000) loss: 0.478 
(epoch: 56, iters: 720, time: 0.499, data: 0.059) loss: 0.539 
(epoch: 56, iters: 800, time: 0.543, data: 0.000) loss: 0.498 
(epoch: 56, iters: 880, time: 0.438, data: 0.080) loss: 0.916 
(epoch: 56, iters: 960, time: 0.477, data: 0.000) loss: 0.558 
(epoch: 56, iters: 1040, time: 0.444, data: 0.000) loss: 0.566 
(epoch: 56, iters: 1120, time: 0.502, data: 0.015) loss: 0.931 
(epoch: 56, iters: 1200, time: 0.504, data: 0.010) loss: 0.499 
(epoch: 56, iters: 1280, time: 0.526, data: 0.000) loss: 0.966 
(epoch: 56, iters: 1360, time: 0.567, data: 0.000) loss: 0.450 
(epoch: 56, iters: 1440, time: 0.480, data: 0.000) loss: 0.719 
(epoch: 56, iters: 1520, time: 0.522, data: 0.000) loss: 1.641 
(epoch: 56, iters: 1600, time: 0.470, data: 0.067) loss: 0.767 
(epoch: 56, iters: 1680, time: 0.459, data: 0.000) loss: 1.034 
(epoch: 56, iters: 1760, time: 0.516, data: 0.011) loss: 0.824 
(epoch: 56, iters: 1840, time: 0.456, data: 0.000) loss: 0.461 
(epoch: 56, iters: 1920, time: 0.429, data: 0.000) loss: 0.785 
(epoch: 56, iters: 2000, time: 0.542, data: 0.010) loss: 0.831 
(epoch: 56, iters: 2080, time: 0.502, data: 0.010) loss: 0.471 
(epoch: 56, iters: 2160, time: 0.510, data: 0.062) loss: 0.765 
(epoch: 56, iters: 2240, time: 0.502, data: 0.000) loss: 0.872 
(epoch: 56, iters: 2320, time: 0.533, data: 0.000) loss: 0.592 
(epoch: 56, iters: 2400, time: 0.471, data: 0.008) loss: 0.594 
(epoch: 56, iters: 2480, time: 0.511, data: 0.000) loss: 0.324 
(epoch: 56, iters: 2560, time: 0.524, data: 0.054) loss: 1.566 
(epoch: 56, iters: 2640, time: 0.450, data: 0.000) loss: 0.934 
(epoch: 56, iters: 2720, time: 0.490, data: 0.000) loss: 0.824 
(epoch: 56, iters: 2800, time: 0.549, data: 0.000) loss: 0.850 
(epoch: 56, iters: 2880, time: 0.519, data: 0.000) loss: 0.525 
(epoch: 56, iters: 2960, time: 0.463, data: 0.007) loss: 0.795 
(epoch: 56, iters: 3040, time: 0.507, data: 0.006) loss: 0.713 
(epoch: 56, iters: 3120, time: 0.487, data: 0.011) loss: 0.738 
(epoch: 56, iters: 3200, time: 0.500, data: 0.000) loss: 0.546 
(epoch: 56, iters: 3280, time: 0.429, data: 0.000) loss: 0.574 
(epoch: 56, iters: 3360, time: 0.485, data: 0.054) loss: 0.943 
(epoch: 56, iters: 3440, time: 0.477, data: 0.000) loss: 1.428 
(epoch: 56, iters: 3520, time: 0.533, data: 0.007) loss: 0.531 
(epoch: 56, iters: 3600, time: 0.563, data: 0.012) loss: 0.508 
(epoch: 56, iters: 3680, time: 0.518, data: 0.013) loss: 0.537 
(epoch: 56, iters: 3760, time: 0.435, data: 0.000) loss: 0.470 
(epoch: 56, iters: 3840, time: 0.414, data: 0.030) loss: 0.719 
(epoch: 56, iters: 3920, time: 0.483, data: 0.000) loss: 0.892 
(epoch: 56, iters: 4000, time: 0.474, data: 0.000) loss: 0.158 
saving the latest model (epoch 56, total_steps 564576)
(epoch: 56, iters: 4080, time: 0.484, data: 0.000) loss: 1.134 
(epoch: 56, iters: 4160, time: 0.351, data: 0.035) loss: 0.584 
(epoch: 56, iters: 4240, time: 0.554, data: 0.015) loss: 1.162 
(epoch: 56, iters: 4320, time: 0.480, data: 0.000) loss: 0.722 
(epoch: 56, iters: 4400, time: 0.514, data: 0.048) loss: 0.782 
(epoch: 56, iters: 4480, time: 0.462, data: 0.000) loss: 0.906 
(epoch: 56, iters: 4560, time: 0.451, data: 0.056) loss: 0.543 
(epoch: 56, iters: 4640, time: 0.462, data: 0.000) loss: 0.510 
(epoch: 56, iters: 4720, time: 0.377, data: 0.000) loss: 1.138 
(epoch: 56, iters: 4800, time: 0.507, data: 0.061) loss: 1.068 
(epoch: 56, iters: 4880, time: 0.497, data: 0.035) loss: 0.442 
(epoch: 56, iters: 4960, time: 0.481, data: 0.079) loss: 1.041 
(epoch: 56, iters: 5040, time: 0.490, data: 0.000) loss: 0.279 
(epoch: 56, iters: 5120, time: 0.434, data: 0.000) loss: 0.980 
(epoch: 56, iters: 5200, time: 0.490, data: 0.000) loss: 0.635 
(epoch: 56, iters: 5280, time: 0.472, data: 0.000) loss: 0.921 
(epoch: 56, iters: 5360, time: 0.467, data: 0.044) loss: 0.596 
(epoch: 56, iters: 5440, time: 0.379, data: 0.000) loss: 1.131 
(epoch: 56, iters: 5520, time: 0.470, data: 0.000) loss: 1.067 
(epoch: 56, iters: 5600, time: 0.446, data: 0.010) loss: 1.488 
(epoch: 56, iters: 5680, time: 0.544, data: 0.000) loss: 0.665 
(epoch: 56, iters: 5760, time: 0.494, data: 0.058) loss: 1.308 
(epoch: 56, iters: 5840, time: 0.430, data: 0.000) loss: 0.585 
(epoch: 56, iters: 5920, time: 0.498, data: 0.000) loss: 0.623 
(epoch: 56, iters: 6000, time: 0.556, data: 0.036) loss: 1.088 
(epoch: 56, iters: 6080, time: 0.447, data: 0.034) loss: 0.687 
(epoch: 56, iters: 6160, time: 0.413, data: 0.000) loss: 0.503 
(epoch: 56, iters: 6240, time: 0.459, data: 0.011) loss: 0.778 
(epoch: 56, iters: 6320, time: 0.488, data: 0.046) loss: 1.530 
(epoch: 56, iters: 6400, time: 0.469, data: 0.000) loss: 0.478 
(epoch: 56, iters: 6480, time: 0.502, data: 0.011) loss: 1.057 
(epoch: 56, iters: 6560, time: 0.444, data: 0.000) loss: 0.543 
(epoch: 56, iters: 6640, time: 0.479, data: 0.000) loss: 0.422 
(epoch: 56, iters: 6720, time: 0.427, data: 0.000) loss: 0.414 
(epoch: 56, iters: 6800, time: 0.448, data: 0.011) loss: 0.446 
(epoch: 56, iters: 6880, time: 0.398, data: 0.006) loss: 0.431 
(epoch: 56, iters: 6960, time: 0.468, data: 0.000) loss: 0.776 
(epoch: 56, iters: 7040, time: 0.504, data: 0.000) loss: 0.747 
(epoch: 56, iters: 7120, time: 0.441, data: 0.000) loss: 0.325 
(epoch: 56, iters: 7200, time: 0.509, data: 0.000) loss: 1.018 
(epoch: 56, iters: 7280, time: 0.485, data: 0.091) loss: 0.804 
(epoch: 56, iters: 7360, time: 0.501, data: 0.000) loss: 0.433 
(epoch: 56, iters: 7440, time: 0.501, data: 0.000) loss: 1.153 
(epoch: 56, iters: 7520, time: 0.489, data: 0.036) loss: 0.351 
(epoch: 56, iters: 7600, time: 0.465, data: 0.000) loss: 0.939 
(epoch: 56, iters: 7680, time: 0.509, data: 0.000) loss: 0.796 
(epoch: 56, iters: 7760, time: 0.481, data: 0.000) loss: 0.693 
(epoch: 56, iters: 7840, time: 0.479, data: 0.026) loss: 1.126 
(epoch: 56, iters: 7920, time: 0.498, data: 0.000) loss: 0.670 
(epoch: 56, iters: 8000, time: 0.489, data: 0.000) loss: 0.382 
saving the latest model (epoch 56, total_steps 568576)
(epoch: 56, iters: 8080, time: 0.412, data: 0.005) loss: 0.891 
(epoch: 56, iters: 8160, time: 0.467, data: 0.000) loss: 0.580 
(epoch: 56, iters: 8240, time: 0.546, data: 0.022) loss: 0.430 
(epoch: 56, iters: 8320, time: 0.483, data: 0.006) loss: 0.942 
(epoch: 56, iters: 8400, time: 0.528, data: 0.000) loss: 0.264 
(epoch: 56, iters: 8480, time: 0.506, data: 0.000) loss: 0.693 
(epoch: 56, iters: 8560, time: 0.489, data: 0.000) loss: 0.749 
(epoch: 56, iters: 8640, time: 0.460, data: 0.000) loss: 0.559 
(epoch: 56, iters: 8720, time: 0.493, data: 0.006) loss: 0.967 
(epoch: 56, iters: 8800, time: 0.502, data: 0.032) loss: 0.410 
(epoch: 56, iters: 8880, time: 0.471, data: 0.014) loss: 0.682 
(epoch: 56, iters: 8960, time: 0.434, data: 0.000) loss: 0.536 
(epoch: 56, iters: 9040, time: 0.392, data: 0.057) loss: 1.198 
(epoch: 56, iters: 9120, time: 0.458, data: 0.000) loss: 0.976 
(epoch: 56, iters: 9200, time: 0.567, data: 0.000) loss: 0.528 
(epoch: 56, iters: 9280, time: 0.512, data: 0.000) loss: 0.905 
(epoch: 56, iters: 9360, time: 0.486, data: 0.041) loss: 0.683 
(epoch: 56, iters: 9440, time: 0.518, data: 0.008) loss: 0.944 
(epoch: 56, iters: 9520, time: 0.489, data: 0.000) loss: 0.523 
(epoch: 56, iters: 9600, time: 0.439, data: 0.012) loss: 0.487 
(epoch: 56, iters: 9680, time: 0.484, data: 0.023) loss: 0.896 
(epoch: 56, iters: 9760, time: 0.507, data: 0.006) loss: 0.835 
(epoch: 56, iters: 9840, time: 0.408, data: 0.000) loss: 0.491 
(epoch: 56, iters: 9920, time: 0.526, data: 0.000) loss: 0.467 
(epoch: 56, iters: 10000, time: 0.538, data: 0.000) loss: 1.128 
(epoch: 56, iters: 10080, time: 0.520, data: 0.007) loss: 0.498 
(epoch: 56, iters: 10160, time: 0.491, data: 0.016) loss: 0.500 
saving the model at the end of epoch 56, iters 570752
End of epoch 56 / 200 	 Time Taken: 4897 sec
learning rate = 0.0002000
saving the latest model (epoch 57, total_steps 570768)
(epoch: 57, iters: 48, time: 0.458, data: 0.009) loss: 1.176 
(epoch: 57, iters: 128, time: 0.473, data: 0.000) loss: 0.387 
(epoch: 57, iters: 208, time: 0.426, data: 0.006) loss: 1.102 
(epoch: 57, iters: 288, time: 0.492, data: 0.011) loss: 0.873 
(epoch: 57, iters: 368, time: 0.578, data: 0.000) loss: 0.837 
(epoch: 57, iters: 448, time: 0.479, data: 0.000) loss: 0.467 
(epoch: 57, iters: 528, time: 0.486, data: 0.081) loss: 1.083 
(epoch: 57, iters: 608, time: 0.472, data: 0.010) loss: 1.029 
(epoch: 57, iters: 688, time: 0.421, data: 0.000) loss: 0.736 
(epoch: 57, iters: 768, time: 0.488, data: 0.000) loss: 0.920 
(epoch: 57, iters: 848, time: 0.455, data: 0.000) loss: 0.177 
(epoch: 57, iters: 928, time: 0.438, data: 0.017) loss: 1.413 
(epoch: 57, iters: 1008, time: 0.509, data: 0.020) loss: 0.471 
(epoch: 57, iters: 1088, time: 0.457, data: 0.011) loss: 0.502 
(epoch: 57, iters: 1168, time: 0.492, data: 0.046) loss: 1.154 
(epoch: 57, iters: 1248, time: 0.506, data: 0.009) loss: 1.274 
(epoch: 57, iters: 1328, time: 0.487, data: 0.000) loss: 0.396 
(epoch: 57, iters: 1408, time: 0.450, data: 0.067) loss: 0.979 
(epoch: 57, iters: 1488, time: 0.281, data: 0.007) loss: 1.884 
(epoch: 57, iters: 1568, time: 0.273, data: 0.000) loss: 0.606 
(epoch: 57, iters: 1648, time: 0.273, data: 0.016) loss: 0.290 
(epoch: 57, iters: 1728, time: 0.262, data: 0.000) loss: 1.013 
(epoch: 57, iters: 1808, time: 0.255, data: 0.010) loss: 1.331 
(epoch: 57, iters: 1888, time: 0.264, data: 0.000) loss: 0.660 
(epoch: 57, iters: 1968, time: 0.265, data: 0.040) loss: 0.794 
(epoch: 57, iters: 2048, time: 0.261, data: 0.000) loss: 0.672 
(epoch: 57, iters: 2128, time: 0.259, data: 0.018) loss: 0.893 
(epoch: 57, iters: 2208, time: 0.267, data: 0.000) loss: 1.285 
(epoch: 57, iters: 2288, time: 0.267, data: 0.000) loss: 0.630 
(epoch: 57, iters: 2368, time: 0.265, data: 0.000) loss: 1.119 
(epoch: 57, iters: 2448, time: 0.259, data: 0.000) loss: 0.778 
(epoch: 57, iters: 2528, time: 0.260, data: 0.012) loss: 0.928 
(epoch: 57, iters: 2608, time: 0.283, data: 0.000) loss: 1.017 
(epoch: 57, iters: 2688, time: 0.264, data: 0.000) loss: 1.188 
(epoch: 57, iters: 2768, time: 0.274, data: 0.029) loss: 1.236 
(epoch: 57, iters: 2848, time: 0.240, data: 0.006) loss: 0.846 
(epoch: 57, iters: 2928, time: 0.263, data: 0.006) loss: 0.954 
(epoch: 57, iters: 3008, time: 0.258, data: 0.037) loss: 1.566 
(epoch: 57, iters: 3088, time: 0.256, data: 0.005) loss: 1.084 
(epoch: 57, iters: 3168, time: 0.253, data: 0.010) loss: 1.223 
(epoch: 57, iters: 3248, time: 0.253, data: 0.000) loss: 1.075 
(epoch: 57, iters: 3328, time: 0.263, data: 0.038) loss: 0.560 
(epoch: 57, iters: 3408, time: 0.283, data: 0.006) loss: 0.682 
(epoch: 57, iters: 3488, time: 0.274, data: 0.011) loss: 0.627 
(epoch: 57, iters: 3568, time: 0.272, data: 0.000) loss: 0.596 
(epoch: 57, iters: 3648, time: 0.271, data: 0.000) loss: 0.832 
(epoch: 57, iters: 3728, time: 0.273, data: 0.030) loss: 1.722 
(epoch: 57, iters: 3808, time: 0.274, data: 0.000) loss: 1.049 
(epoch: 57, iters: 3888, time: 0.264, data: 0.000) loss: 0.946 
(epoch: 57, iters: 3968, time: 0.271, data: 0.010) loss: 0.565 
saving the latest model (epoch 57, total_steps 574768)
(epoch: 57, iters: 4048, time: 0.257, data: 0.000) loss: 0.708 
(epoch: 57, iters: 4128, time: 0.270, data: 0.020) loss: 0.332 
(epoch: 57, iters: 4208, time: 0.254, data: 0.006) loss: 0.838 
(epoch: 57, iters: 4288, time: 0.258, data: 0.000) loss: 0.888 
(epoch: 57, iters: 4368, time: 0.253, data: 0.000) loss: 0.644 
(epoch: 57, iters: 4448, time: 0.252, data: 0.005) loss: 0.643 
(epoch: 57, iters: 4528, time: 0.257, data: 0.015) loss: 0.392 
(epoch: 57, iters: 4608, time: 0.243, data: 0.007) loss: 1.005 
(epoch: 57, iters: 4688, time: 0.209, data: 0.000) loss: 1.013 
(epoch: 57, iters: 4768, time: 0.216, data: 0.028) loss: 0.820 
(epoch: 57, iters: 4848, time: 0.208, data: 0.000) loss: 0.484 
(epoch: 57, iters: 4928, time: 0.219, data: 0.000) loss: 0.562 
(epoch: 57, iters: 5008, time: 0.237, data: 0.007) loss: 0.554 
(epoch: 57, iters: 5088, time: 0.222, data: 0.000) loss: 0.422 
(epoch: 57, iters: 5168, time: 0.219, data: 0.000) loss: 0.912 
(epoch: 57, iters: 5248, time: 0.236, data: 0.024) loss: 0.992 
(epoch: 57, iters: 5328, time: 0.228, data: 0.000) loss: 1.246 
(epoch: 57, iters: 5408, time: 0.236, data: 0.043) loss: 0.770 
(epoch: 57, iters: 5488, time: 0.195, data: 0.000) loss: 0.813 
(epoch: 57, iters: 5568, time: 0.214, data: 0.008) loss: 0.968 
(epoch: 57, iters: 5648, time: 0.199, data: 0.009) loss: 1.280 
(epoch: 57, iters: 5728, time: 0.202, data: 0.018) loss: 0.741 
(epoch: 57, iters: 5808, time: 0.165, data: 0.000) loss: 0.913 
(epoch: 57, iters: 5888, time: 0.164, data: 0.023) loss: 1.018 
(epoch: 57, iters: 5968, time: 0.166, data: 0.000) loss: 0.473 
(epoch: 57, iters: 6048, time: 0.163, data: 0.000) loss: 0.985 
(epoch: 57, iters: 6128, time: 0.166, data: 0.000) loss: 0.955 
(epoch: 57, iters: 6208, time: 0.164, data: 0.000) loss: 0.716 
(epoch: 57, iters: 6288, time: 0.163, data: 0.000) loss: 0.736 
(epoch: 57, iters: 6368, time: 0.164, data: 0.006) loss: 0.509 
(epoch: 57, iters: 6448, time: 0.162, data: 0.000) loss: 0.440 
(epoch: 57, iters: 6528, time: 0.164, data: 0.000) loss: 0.714 
(epoch: 57, iters: 6608, time: 0.162, data: 0.023) loss: 0.554 
(epoch: 57, iters: 6688, time: 0.163, data: 0.000) loss: 0.607 
(epoch: 57, iters: 6768, time: 0.163, data: 0.000) loss: 0.930 
(epoch: 57, iters: 6848, time: 0.163, data: 0.005) loss: 0.668 
(epoch: 57, iters: 6928, time: 0.165, data: 0.000) loss: 0.813 
(epoch: 57, iters: 7008, time: 0.164, data: 0.012) loss: 0.434 
(epoch: 57, iters: 7088, time: 0.164, data: 0.000) loss: 0.647 
(epoch: 57, iters: 7168, time: 0.164, data: 0.000) loss: 0.597 
(epoch: 57, iters: 7248, time: 0.162, data: 0.008) loss: 0.828 
(epoch: 57, iters: 7328, time: 0.163, data: 0.000) loss: 0.834 
(epoch: 57, iters: 7408, time: 0.164, data: 0.000) loss: 1.106 
(epoch: 57, iters: 7488, time: 0.169, data: 0.023) loss: 0.696 
(epoch: 57, iters: 7568, time: 0.163, data: 0.000) loss: 0.930 
(epoch: 57, iters: 7648, time: 0.162, data: 0.018) loss: 0.655 
(epoch: 57, iters: 7728, time: 0.163, data: 0.016) loss: 0.621 
(epoch: 57, iters: 7808, time: 0.167, data: 0.000) loss: 0.896 
(epoch: 57, iters: 7888, time: 0.161, data: 0.000) loss: 0.465 
(epoch: 57, iters: 7968, time: 0.163, data: 0.000) loss: 0.488 
saving the latest model (epoch 57, total_steps 578768)
(epoch: 57, iters: 8048, time: 0.162, data: 0.005) loss: 0.613 
(epoch: 57, iters: 8128, time: 0.162, data: 0.000) loss: 0.774 
(epoch: 57, iters: 8208, time: 0.162, data: 0.000) loss: 0.887 
(epoch: 57, iters: 8288, time: 0.163, data: 0.000) loss: 0.595 
(epoch: 57, iters: 8368, time: 0.164, data: 0.009) loss: 0.717 
(epoch: 57, iters: 8448, time: 0.163, data: 0.000) loss: 0.940 
(epoch: 57, iters: 8528, time: 0.162, data: 0.030) loss: 1.313 
(epoch: 57, iters: 8608, time: 0.163, data: 0.000) loss: 0.760 
(epoch: 57, iters: 8688, time: 0.163, data: 0.000) loss: 0.311 
(epoch: 57, iters: 8768, time: 0.162, data: 0.013) loss: 0.769 
(epoch: 57, iters: 8848, time: 0.162, data: 0.000) loss: 0.574 
(epoch: 57, iters: 8928, time: 0.168, data: 0.010) loss: 0.453 
(epoch: 57, iters: 9008, time: 0.166, data: 0.007) loss: 1.055 
(epoch: 57, iters: 9088, time: 0.162, data: 0.016) loss: 0.623 
(epoch: 57, iters: 9168, time: 0.162, data: 0.010) loss: 1.115 
(epoch: 57, iters: 9248, time: 0.165, data: 0.021) loss: 1.157 
(epoch: 57, iters: 9328, time: 0.161, data: 0.000) loss: 0.911 
(epoch: 57, iters: 9408, time: 0.172, data: 0.013) loss: 0.975 
(epoch: 57, iters: 9488, time: 0.163, data: 0.000) loss: 0.475 
(epoch: 57, iters: 9568, time: 0.166, data: 0.018) loss: 0.653 
(epoch: 57, iters: 9648, time: 0.163, data: 0.013) loss: 0.583 
(epoch: 57, iters: 9728, time: 0.162, data: 0.000) loss: 1.321 
(epoch: 57, iters: 9808, time: 0.161, data: 0.005) loss: 0.704 
(epoch: 57, iters: 9888, time: 0.162, data: 0.022) loss: 0.229 
(epoch: 57, iters: 9968, time: 0.164, data: 0.000) loss: 1.516 
(epoch: 57, iters: 10048, time: 0.164, data: 0.005) loss: 0.706 
(epoch: 57, iters: 10128, time: 0.162, data: 0.000) loss: 0.921 
saving the model at the end of epoch 57, iters 580944
End of epoch 57 / 200 	 Time Taken: 2509 sec
learning rate = 0.0002000
(epoch: 58, iters: 16, time: 0.194, data: 0.000) loss: 0.678 
saving the latest model (epoch 58, total_steps 580960)
(epoch: 58, iters: 96, time: 0.166, data: 0.033) loss: 0.433 
(epoch: 58, iters: 176, time: 0.163, data: 0.000) loss: 0.652 
(epoch: 58, iters: 256, time: 0.161, data: 0.000) loss: 0.750 
(epoch: 58, iters: 336, time: 0.163, data: 0.013) loss: 0.638 
(epoch: 58, iters: 416, time: 0.163, data: 0.000) loss: 0.604 
(epoch: 58, iters: 496, time: 0.161, data: 0.011) loss: 0.916 
(epoch: 58, iters: 576, time: 0.165, data: 0.018) loss: 0.646 
(epoch: 58, iters: 656, time: 0.163, data: 0.000) loss: 0.432 
(epoch: 58, iters: 736, time: 0.167, data: 0.000) loss: 0.459 
(epoch: 58, iters: 816, time: 0.165, data: 0.000) loss: 0.718 
(epoch: 58, iters: 896, time: 0.163, data: 0.000) loss: 0.584 
(epoch: 58, iters: 976, time: 0.163, data: 0.008) loss: 1.036 
(epoch: 58, iters: 1056, time: 0.163, data: 0.000) loss: 0.493 
(epoch: 58, iters: 1136, time: 0.164, data: 0.006) loss: 0.491 
(epoch: 58, iters: 1216, time: 0.164, data: 0.000) loss: 0.909 
(epoch: 58, iters: 1296, time: 0.161, data: 0.021) loss: 1.843 
(epoch: 58, iters: 1376, time: 0.161, data: 0.013) loss: 0.650 
(epoch: 58, iters: 1456, time: 0.162, data: 0.000) loss: 0.769 
(epoch: 58, iters: 1536, time: 0.166, data: 0.040) loss: 0.584 
(epoch: 58, iters: 1616, time: 0.163, data: 0.000) loss: 0.627 
(epoch: 58, iters: 1696, time: 0.162, data: 0.010) loss: 0.579 
(epoch: 58, iters: 1776, time: 0.162, data: 0.000) loss: 0.360 
(epoch: 58, iters: 1856, time: 0.167, data: 0.005) loss: 1.009 
(epoch: 58, iters: 1936, time: 0.163, data: 0.024) loss: 0.744 
(epoch: 58, iters: 2016, time: 0.165, data: 0.000) loss: 0.609 
(epoch: 58, iters: 2096, time: 0.164, data: 0.000) loss: 0.646 
(epoch: 58, iters: 2176, time: 0.164, data: 0.005) loss: 0.785 
(epoch: 58, iters: 2256, time: 0.171, data: 0.000) loss: 0.807 
(epoch: 58, iters: 2336, time: 0.163, data: 0.006) loss: 0.930 
(epoch: 58, iters: 2416, time: 0.162, data: 0.009) loss: 1.011 
(epoch: 58, iters: 2496, time: 0.160, data: 0.000) loss: 0.952 
(epoch: 58, iters: 2576, time: 0.163, data: 0.011) loss: 1.111 
(epoch: 58, iters: 2656, time: 0.162, data: 0.000) loss: 0.394 
(epoch: 58, iters: 2736, time: 0.164, data: 0.000) loss: 1.079 
(epoch: 58, iters: 2816, time: 0.166, data: 0.005) loss: 0.814 
(epoch: 58, iters: 2896, time: 0.161, data: 0.025) loss: 0.910 
(epoch: 58, iters: 2976, time: 0.161, data: 0.000) loss: 0.607 
(epoch: 58, iters: 3056, time: 0.162, data: 0.000) loss: 0.303 
(epoch: 58, iters: 3136, time: 0.165, data: 0.016) loss: 0.800 
(epoch: 58, iters: 3216, time: 0.161, data: 0.000) loss: 0.752 
(epoch: 58, iters: 3296, time: 0.161, data: 0.016) loss: 0.800 
(epoch: 58, iters: 3376, time: 0.161, data: 0.020) loss: 1.105 
(epoch: 58, iters: 3456, time: 0.163, data: 0.000) loss: 0.441 
(epoch: 58, iters: 3536, time: 0.165, data: 0.000) loss: 0.909 
(epoch: 58, iters: 3616, time: 0.163, data: 0.013) loss: 0.546 
(epoch: 58, iters: 3696, time: 0.164, data: 0.000) loss: 0.791 
(epoch: 58, iters: 3776, time: 0.166, data: 0.005) loss: 0.597 
(epoch: 58, iters: 3856, time: 0.164, data: 0.000) loss: 0.791 
(epoch: 58, iters: 3936, time: 0.165, data: 0.000) loss: 0.577 
(epoch: 58, iters: 4016, time: 0.163, data: 0.011) loss: 0.661 
saving the latest model (epoch 58, total_steps 584960)
(epoch: 58, iters: 4096, time: 0.162, data: 0.000) loss: 0.695 
(epoch: 58, iters: 4176, time: 0.168, data: 0.022) loss: 0.318 
(epoch: 58, iters: 4256, time: 0.164, data: 0.000) loss: 0.268 
(epoch: 58, iters: 4336, time: 0.163, data: 0.000) loss: 0.721 
(epoch: 58, iters: 4416, time: 0.167, data: 0.000) loss: 0.819 
(epoch: 58, iters: 4496, time: 0.162, data: 0.000) loss: 1.128 
(epoch: 58, iters: 4576, time: 0.161, data: 0.008) loss: 0.384 
(epoch: 58, iters: 4656, time: 0.162, data: 0.006) loss: 0.857 
(epoch: 58, iters: 4736, time: 0.165, data: 0.032) loss: 0.643 
(epoch: 58, iters: 4816, time: 0.164, data: 0.000) loss: 1.493 
(epoch: 58, iters: 4896, time: 0.168, data: 0.000) loss: 0.787 
(epoch: 58, iters: 4976, time: 0.163, data: 0.000) loss: 0.633 
(epoch: 58, iters: 5056, time: 0.164, data: 0.000) loss: 1.011 
(epoch: 58, iters: 5136, time: 0.162, data: 0.025) loss: 0.791 
(epoch: 58, iters: 5216, time: 0.161, data: 0.000) loss: 0.402 
(epoch: 58, iters: 5296, time: 0.166, data: 0.011) loss: 0.758 
(epoch: 58, iters: 5376, time: 0.163, data: 0.000) loss: 0.566 
(epoch: 58, iters: 5456, time: 0.166, data: 0.000) loss: 0.875 
(epoch: 58, iters: 5536, time: 0.162, data: 0.000) loss: 0.487 
(epoch: 58, iters: 5616, time: 0.161, data: 0.022) loss: 1.677 
(epoch: 58, iters: 5696, time: 0.168, data: 0.039) loss: 0.577 
(epoch: 58, iters: 5776, time: 0.163, data: 0.000) loss: 0.493 
(epoch: 58, iters: 5856, time: 0.161, data: 0.005) loss: 0.503 
(epoch: 58, iters: 5936, time: 0.162, data: 0.005) loss: 1.179 
(epoch: 58, iters: 6016, time: 0.166, data: 0.008) loss: 0.566 
(epoch: 58, iters: 6096, time: 0.162, data: 0.000) loss: 0.956 
(epoch: 58, iters: 6176, time: 0.163, data: 0.020) loss: 0.444 
(epoch: 58, iters: 6256, time: 0.163, data: 0.005) loss: 0.913 
(epoch: 58, iters: 6336, time: 0.162, data: 0.011) loss: 0.826 
(epoch: 58, iters: 6416, time: 0.165, data: 0.015) loss: 0.421 
(epoch: 58, iters: 6496, time: 0.162, data: 0.000) loss: 0.870 
(epoch: 58, iters: 6576, time: 0.166, data: 0.015) loss: 0.963 
(epoch: 58, iters: 6656, time: 0.163, data: 0.000) loss: 0.574 
(epoch: 58, iters: 6736, time: 0.163, data: 0.000) loss: 0.993 
(epoch: 58, iters: 6816, time: 0.166, data: 0.005) loss: 0.728 
(epoch: 58, iters: 6896, time: 0.161, data: 0.000) loss: 0.963 
(epoch: 58, iters: 6976, time: 0.162, data: 0.008) loss: 0.696 
(epoch: 58, iters: 7056, time: 0.163, data: 0.006) loss: 0.863 
(epoch: 58, iters: 7136, time: 0.164, data: 0.005) loss: 0.518 
(epoch: 58, iters: 7216, time: 0.163, data: 0.008) loss: 0.617 
(epoch: 58, iters: 7296, time: 0.161, data: 0.000) loss: 0.555 
(epoch: 58, iters: 7376, time: 0.162, data: 0.018) loss: 0.942 
(epoch: 58, iters: 7456, time: 0.161, data: 0.000) loss: 0.500 
(epoch: 58, iters: 7536, time: 0.161, data: 0.000) loss: 0.682 
(epoch: 58, iters: 7616, time: 0.169, data: 0.011) loss: 1.396 
(epoch: 58, iters: 7696, time: 0.164, data: 0.000) loss: 0.934 
(epoch: 58, iters: 7776, time: 0.163, data: 0.000) loss: 0.722 
(epoch: 58, iters: 7856, time: 0.163, data: 0.012) loss: 0.337 
(epoch: 58, iters: 7936, time: 0.163, data: 0.000) loss: 1.238 
(epoch: 58, iters: 8016, time: 0.165, data: 0.011) loss: 0.678 
saving the latest model (epoch 58, total_steps 588960)
(epoch: 58, iters: 8096, time: 0.164, data: 0.000) loss: 0.653 
(epoch: 58, iters: 8176, time: 0.163, data: 0.000) loss: 0.698 
(epoch: 58, iters: 8256, time: 0.167, data: 0.018) loss: 0.493 
(epoch: 58, iters: 8336, time: 0.164, data: 0.000) loss: 0.510 
(epoch: 58, iters: 8416, time: 0.168, data: 0.000) loss: 0.797 
(epoch: 58, iters: 8496, time: 0.161, data: 0.015) loss: 0.344 
(epoch: 58, iters: 8576, time: 0.165, data: 0.000) loss: 0.341 
(epoch: 58, iters: 8656, time: 0.161, data: 0.020) loss: 0.320 
(epoch: 58, iters: 8736, time: 0.164, data: 0.000) loss: 1.014 
(epoch: 58, iters: 8816, time: 0.161, data: 0.017) loss: 0.656 
(epoch: 58, iters: 8896, time: 0.161, data: 0.000) loss: 0.491 
(epoch: 58, iters: 8976, time: 0.162, data: 0.017) loss: 0.504 
(epoch: 58, iters: 9056, time: 0.162, data: 0.011) loss: 0.442 
(epoch: 58, iters: 9136, time: 0.162, data: 0.000) loss: 0.715 
(epoch: 58, iters: 9216, time: 0.161, data: 0.000) loss: 0.674 
(epoch: 58, iters: 9296, time: 0.165, data: 0.000) loss: 0.402 
(epoch: 58, iters: 9376, time: 0.161, data: 0.000) loss: 1.191 
(epoch: 58, iters: 9456, time: 0.165, data: 0.000) loss: 0.179 
(epoch: 58, iters: 9536, time: 0.172, data: 0.000) loss: 0.718 
(epoch: 58, iters: 9616, time: 0.163, data: 0.030) loss: 0.824 
(epoch: 58, iters: 9696, time: 0.162, data: 0.008) loss: 0.973 
(epoch: 58, iters: 9776, time: 0.166, data: 0.022) loss: 0.934 
(epoch: 58, iters: 9856, time: 0.162, data: 0.000) loss: 0.854 
(epoch: 58, iters: 9936, time: 0.166, data: 0.013) loss: 0.933 
(epoch: 58, iters: 10016, time: 0.163, data: 0.021) loss: 0.246 
(epoch: 58, iters: 10096, time: 0.163, data: 0.010) loss: 0.841 
(epoch: 58, iters: 10176, time: 0.161, data: 0.000) loss: 0.791 
saving the model at the end of epoch 58, iters 591136
End of epoch 58 / 200 	 Time Taken: 1670 sec
learning rate = 0.0002000
saving the latest model (epoch 59, total_steps 591152)
(epoch: 59, iters: 64, time: 0.167, data: 0.004) loss: 0.710 
(epoch: 59, iters: 144, time: 0.160, data: 0.000) loss: 0.754 
(epoch: 59, iters: 224, time: 0.163, data: 0.000) loss: 0.860 
(epoch: 59, iters: 304, time: 0.162, data: 0.000) loss: 0.519 
(epoch: 59, iters: 384, time: 0.163, data: 0.000) loss: 0.764 
(epoch: 59, iters: 464, time: 0.162, data: 0.020) loss: 0.676 
(epoch: 59, iters: 544, time: 0.162, data: 0.000) loss: 0.326 
(epoch: 59, iters: 624, time: 0.162, data: 0.000) loss: 1.015 
(epoch: 59, iters: 704, time: 0.160, data: 0.016) loss: 0.585 
(epoch: 59, iters: 784, time: 0.161, data: 0.000) loss: 0.623 
(epoch: 59, iters: 864, time: 0.172, data: 0.007) loss: 0.407 
(epoch: 59, iters: 944, time: 0.162, data: 0.005) loss: 1.273 
(epoch: 59, iters: 1024, time: 0.163, data: 0.000) loss: 1.332 
(epoch: 59, iters: 1104, time: 0.161, data: 0.010) loss: 0.445 
(epoch: 59, iters: 1184, time: 0.162, data: 0.000) loss: 0.996 
(epoch: 59, iters: 1264, time: 0.160, data: 0.011) loss: 0.687 
(epoch: 59, iters: 1344, time: 0.163, data: 0.000) loss: 0.924 
(epoch: 59, iters: 1424, time: 0.164, data: 0.000) loss: 1.065 
(epoch: 59, iters: 1504, time: 0.163, data: 0.006) loss: 0.418 
(epoch: 59, iters: 1584, time: 0.163, data: 0.000) loss: 0.800 
(epoch: 59, iters: 1664, time: 0.161, data: 0.000) loss: 0.586 
(epoch: 59, iters: 1744, time: 0.163, data: 0.000) loss: 0.672 
(epoch: 59, iters: 1824, time: 0.162, data: 0.008) loss: 0.368 
(epoch: 59, iters: 1904, time: 0.161, data: 0.000) loss: 0.550 
(epoch: 59, iters: 1984, time: 0.161, data: 0.000) loss: 1.071 
(epoch: 59, iters: 2064, time: 0.159, data: 0.011) loss: 1.229 
(epoch: 59, iters: 2144, time: 0.161, data: 0.000) loss: 0.423 
(epoch: 59, iters: 2224, time: 0.163, data: 0.000) loss: 0.339 
(epoch: 59, iters: 2304, time: 0.162, data: 0.000) loss: 0.737 
(epoch: 59, iters: 2384, time: 0.162, data: 0.008) loss: 0.830 
(epoch: 59, iters: 2464, time: 0.159, data: 0.000) loss: 0.267 
(epoch: 59, iters: 2544, time: 0.161, data: 0.005) loss: 0.885 
(epoch: 59, iters: 2624, time: 0.160, data: 0.008) loss: 1.216 
(epoch: 59, iters: 2704, time: 0.159, data: 0.000) loss: 0.727 
(epoch: 59, iters: 2784, time: 0.159, data: 0.000) loss: 0.439 
(epoch: 59, iters: 2864, time: 0.162, data: 0.000) loss: 0.574 
(epoch: 59, iters: 2944, time: 0.161, data: 0.025) loss: 0.742 
(epoch: 59, iters: 3024, time: 0.163, data: 0.000) loss: 0.545 
(epoch: 59, iters: 3104, time: 0.162, data: 0.005) loss: 0.925 
(epoch: 59, iters: 3184, time: 0.170, data: 0.000) loss: 0.953 
(epoch: 59, iters: 3264, time: 0.161, data: 0.000) loss: 1.022 
(epoch: 59, iters: 3344, time: 0.162, data: 0.000) loss: 0.404 
(epoch: 59, iters: 3424, time: 0.164, data: 0.000) loss: 0.370 
(epoch: 59, iters: 3504, time: 0.161, data: 0.005) loss: 0.376 
(epoch: 59, iters: 3584, time: 0.160, data: 0.000) loss: 0.614 
(epoch: 59, iters: 3664, time: 0.161, data: 0.000) loss: 1.298 
(epoch: 59, iters: 3744, time: 0.160, data: 0.005) loss: 0.988 
(epoch: 59, iters: 3824, time: 0.162, data: 0.000) loss: 0.481 
(epoch: 59, iters: 3904, time: 0.161, data: 0.000) loss: 0.553 
(epoch: 59, iters: 3984, time: 0.160, data: 0.000) loss: 0.846 
saving the latest model (epoch 59, total_steps 595152)
(epoch: 59, iters: 4064, time: 0.161, data: 0.005) loss: 0.660 
(epoch: 59, iters: 4144, time: 0.160, data: 0.005) loss: 0.863 
(epoch: 59, iters: 4224, time: 0.163, data: 0.000) loss: 0.521 
(epoch: 59, iters: 4304, time: 0.162, data: 0.000) loss: 0.974 
(epoch: 59, iters: 4384, time: 0.172, data: 0.005) loss: 0.569 
(epoch: 59, iters: 4464, time: 0.162, data: 0.000) loss: 1.059 
(epoch: 59, iters: 4544, time: 0.159, data: 0.000) loss: 0.597 
(epoch: 59, iters: 4624, time: 0.160, data: 0.005) loss: 1.506 
(epoch: 59, iters: 4704, time: 0.160, data: 0.010) loss: 1.516 
(epoch: 59, iters: 4784, time: 0.161, data: 0.000) loss: 0.667 
(epoch: 59, iters: 4864, time: 0.161, data: 0.000) loss: 0.718 
(epoch: 59, iters: 4944, time: 0.159, data: 0.005) loss: 0.725 
(epoch: 59, iters: 5024, time: 0.162, data: 0.014) loss: 0.670 
(epoch: 59, iters: 5104, time: 0.164, data: 0.006) loss: 0.901 
(epoch: 59, iters: 5184, time: 0.161, data: 0.000) loss: 1.346 
(epoch: 59, iters: 5264, time: 0.162, data: 0.023) loss: 1.999 
(epoch: 59, iters: 5344, time: 0.159, data: 0.009) loss: 0.985 
(epoch: 59, iters: 5424, time: 0.163, data: 0.000) loss: 0.874 
(epoch: 59, iters: 5504, time: 0.167, data: 0.005) loss: 0.742 
(epoch: 59, iters: 5584, time: 0.159, data: 0.000) loss: 0.648 
(epoch: 59, iters: 5664, time: 0.159, data: 0.027) loss: 0.676 
(epoch: 59, iters: 5744, time: 0.161, data: 0.000) loss: 0.455 
(epoch: 59, iters: 5824, time: 0.162, data: 0.029) loss: 0.708 
(epoch: 59, iters: 5904, time: 0.163, data: 0.000) loss: 0.960 
(epoch: 59, iters: 5984, time: 0.160, data: 0.009) loss: 0.632 
(epoch: 59, iters: 6064, time: 0.159, data: 0.000) loss: 1.003 
(epoch: 59, iters: 6144, time: 0.161, data: 0.006) loss: 0.888 
(epoch: 59, iters: 6224, time: 0.163, data: 0.000) loss: 0.548 
(epoch: 59, iters: 6304, time: 0.160, data: 0.024) loss: 1.139 
(epoch: 59, iters: 6384, time: 0.159, data: 0.000) loss: 0.755 
(epoch: 59, iters: 6464, time: 0.162, data: 0.013) loss: 0.464 
(epoch: 59, iters: 6544, time: 0.162, data: 0.005) loss: 0.595 
(epoch: 59, iters: 6624, time: 0.160, data: 0.000) loss: 0.764 
(epoch: 59, iters: 6704, time: 0.162, data: 0.006) loss: 1.018 
(epoch: 59, iters: 6784, time: 0.161, data: 0.008) loss: 0.795 
(epoch: 59, iters: 6864, time: 0.159, data: 0.000) loss: 0.600 
(epoch: 59, iters: 6944, time: 0.159, data: 0.011) loss: 0.663 
(epoch: 59, iters: 7024, time: 0.160, data: 0.000) loss: 0.886 
(epoch: 59, iters: 7104, time: 0.161, data: 0.000) loss: 0.502 
(epoch: 59, iters: 7184, time: 0.159, data: 0.005) loss: 1.140 
(epoch: 59, iters: 7264, time: 0.160, data: 0.017) loss: 0.789 
(epoch: 59, iters: 7344, time: 0.161, data: 0.000) loss: 0.544 
(epoch: 59, iters: 7424, time: 0.160, data: 0.021) loss: 1.273 
(epoch: 59, iters: 7504, time: 0.162, data: 0.005) loss: 0.758 
(epoch: 59, iters: 7584, time: 0.159, data: 0.024) loss: 1.190 
(epoch: 59, iters: 7664, time: 0.161, data: 0.000) loss: 1.559 
(epoch: 59, iters: 7744, time: 0.159, data: 0.005) loss: 1.292 
(epoch: 59, iters: 7824, time: 0.163, data: 0.000) loss: 1.086 
(epoch: 59, iters: 7904, time: 0.161, data: 0.000) loss: 1.020 
(epoch: 59, iters: 7984, time: 0.161, data: 0.010) loss: 0.877 
saving the latest model (epoch 59, total_steps 599152)
(epoch: 59, iters: 8064, time: 0.161, data: 0.005) loss: 0.605 
(epoch: 59, iters: 8144, time: 0.164, data: 0.000) loss: 1.540 
(epoch: 59, iters: 8224, time: 0.167, data: 0.011) loss: 0.997 
(epoch: 59, iters: 8304, time: 0.159, data: 0.000) loss: 0.777 
(epoch: 59, iters: 8384, time: 0.157, data: 0.005) loss: 1.053 
(epoch: 59, iters: 8464, time: 0.156, data: 0.019) loss: 0.788 
(epoch: 59, iters: 8544, time: 0.160, data: 0.000) loss: 0.602 
(epoch: 59, iters: 8624, time: 0.160, data: 0.000) loss: 0.413 
(epoch: 59, iters: 8704, time: 0.161, data: 0.000) loss: 0.800 
(epoch: 59, iters: 8784, time: 0.160, data: 0.000) loss: 0.562 
(epoch: 59, iters: 8864, time: 0.160, data: 0.000) loss: 0.815 
(epoch: 59, iters: 8944, time: 0.158, data: 0.005) loss: 0.643 
(epoch: 59, iters: 9024, time: 0.160, data: 0.000) loss: 0.586 
(epoch: 59, iters: 9104, time: 0.158, data: 0.016) loss: 0.808 
(epoch: 59, iters: 9184, time: 0.157, data: 0.000) loss: 0.747 
(epoch: 59, iters: 9264, time: 0.161, data: 0.025) loss: 0.283 
(epoch: 59, iters: 9344, time: 0.161, data: 0.008) loss: 0.777 
(epoch: 59, iters: 9424, time: 0.160, data: 0.017) loss: 0.467 
(epoch: 59, iters: 9504, time: 0.158, data: 0.006) loss: 1.065 
(epoch: 59, iters: 9584, time: 0.158, data: 0.000) loss: 0.795 
(epoch: 59, iters: 9664, time: 0.161, data: 0.013) loss: 0.986 
(epoch: 59, iters: 9744, time: 0.162, data: 0.026) loss: 0.400 
(epoch: 59, iters: 9824, time: 0.162, data: 0.000) loss: 0.893 
(epoch: 59, iters: 9904, time: 0.161, data: 0.009) loss: 1.338 
(epoch: 59, iters: 9984, time: 0.157, data: 0.000) loss: 1.200 
(epoch: 59, iters: 10064, time: 0.162, data: 0.005) loss: 0.627 
(epoch: 59, iters: 10144, time: 0.160, data: 0.000) loss: 0.513 
saving the model at the end of epoch 59, iters 601328
End of epoch 59 / 200 	 Time Taken: 1646 sec
learning rate = 0.0002000
saving the latest model (epoch 60, total_steps 601344)
(epoch: 60, iters: 32, time: 0.167, data: 0.005) loss: 0.612 
(epoch: 60, iters: 112, time: 0.164, data: 0.000) loss: 0.455 
(epoch: 60, iters: 192, time: 0.161, data: 0.006) loss: 0.880 
(epoch: 60, iters: 272, time: 0.161, data: 0.000) loss: 0.511 
(epoch: 60, iters: 352, time: 0.161, data: 0.000) loss: 1.032 
(epoch: 60, iters: 432, time: 0.165, data: 0.005) loss: 0.936 
(epoch: 60, iters: 512, time: 0.162, data: 0.000) loss: 0.393 
(epoch: 60, iters: 592, time: 0.160, data: 0.000) loss: 0.377 
(epoch: 60, iters: 672, time: 0.161, data: 0.005) loss: 0.814 
(epoch: 60, iters: 752, time: 0.162, data: 0.000) loss: 1.078 
(epoch: 60, iters: 832, time: 0.162, data: 0.000) loss: 0.801 
(epoch: 60, iters: 912, time: 0.162, data: 0.000) loss: 0.466 
(epoch: 60, iters: 992, time: 0.160, data: 0.000) loss: 0.811 
(epoch: 60, iters: 1072, time: 0.161, data: 0.018) loss: 0.523 
(epoch: 60, iters: 1152, time: 0.163, data: 0.000) loss: 0.580 
(epoch: 60, iters: 1232, time: 0.161, data: 0.005) loss: 1.606 
(epoch: 60, iters: 1312, time: 0.159, data: 0.024) loss: 0.837 
(epoch: 60, iters: 1392, time: 0.162, data: 0.000) loss: 0.848 
(epoch: 60, iters: 1472, time: 0.165, data: 0.040) loss: 0.964 
(epoch: 60, iters: 1552, time: 0.163, data: 0.000) loss: 0.334 
(epoch: 60, iters: 1632, time: 0.161, data: 0.000) loss: 0.923 
(epoch: 60, iters: 1712, time: 0.159, data: 0.005) loss: 0.828 
(epoch: 60, iters: 1792, time: 0.159, data: 0.015) loss: 0.669 
(epoch: 60, iters: 1872, time: 0.160, data: 0.013) loss: 0.583 
(epoch: 60, iters: 1952, time: 0.159, data: 0.000) loss: 0.790 
(epoch: 60, iters: 2032, time: 0.162, data: 0.023) loss: 0.305 
(epoch: 60, iters: 2112, time: 0.161, data: 0.000) loss: 0.916 
(epoch: 60, iters: 2192, time: 0.161, data: 0.011) loss: 0.501 
(epoch: 60, iters: 2272, time: 0.162, data: 0.008) loss: 0.614 
(epoch: 60, iters: 2352, time: 0.164, data: 0.006) loss: 0.840 
(epoch: 60, iters: 2432, time: 0.160, data: 0.025) loss: 1.162 
(epoch: 60, iters: 2512, time: 0.159, data: 0.000) loss: 0.515 
(epoch: 60, iters: 2592, time: 0.161, data: 0.000) loss: 0.836 
(epoch: 60, iters: 2672, time: 0.160, data: 0.000) loss: 0.981 
(epoch: 60, iters: 2752, time: 0.160, data: 0.000) loss: 0.780 
(epoch: 60, iters: 2832, time: 0.161, data: 0.000) loss: 1.066 
(epoch: 60, iters: 2912, time: 0.165, data: 0.022) loss: 1.075 
(epoch: 60, iters: 2992, time: 0.160, data: 0.000) loss: 1.140 
(epoch: 60, iters: 3072, time: 0.164, data: 0.032) loss: 0.590 
(epoch: 60, iters: 3152, time: 0.162, data: 0.000) loss: 0.824 
(epoch: 60, iters: 3232, time: 0.161, data: 0.032) loss: 0.600 
(epoch: 60, iters: 3312, time: 0.161, data: 0.000) loss: 0.786 
(epoch: 60, iters: 3392, time: 0.161, data: 0.000) loss: 1.296 
(epoch: 60, iters: 3472, time: 0.167, data: 0.000) loss: 1.105 
(epoch: 60, iters: 3552, time: 0.161, data: 0.000) loss: 0.722 
(epoch: 60, iters: 3632, time: 0.161, data: 0.000) loss: 0.568 
(epoch: 60, iters: 3712, time: 0.161, data: 0.000) loss: 1.063 
(epoch: 60, iters: 3792, time: 0.164, data: 0.000) loss: 0.545 
(epoch: 60, iters: 3872, time: 0.161, data: 0.019) loss: 1.114 
(epoch: 60, iters: 3952, time: 0.164, data: 0.000) loss: 0.488 
saving the latest model (epoch 60, total_steps 605344)
(epoch: 60, iters: 4032, time: 0.159, data: 0.000) loss: 0.485 
(epoch: 60, iters: 4112, time: 0.162, data: 0.008) loss: 0.514 
(epoch: 60, iters: 4192, time: 0.160, data: 0.000) loss: 1.583 
(epoch: 60, iters: 4272, time: 0.161, data: 0.020) loss: 1.382 
(epoch: 60, iters: 4352, time: 0.161, data: 0.012) loss: 1.095 
(epoch: 60, iters: 4432, time: 0.159, data: 0.024) loss: 0.434 
(epoch: 60, iters: 4512, time: 0.160, data: 0.000) loss: 1.315 
(epoch: 60, iters: 4592, time: 0.159, data: 0.000) loss: 0.901 
(epoch: 60, iters: 4672, time: 0.161, data: 0.009) loss: 0.899 
(epoch: 60, iters: 4752, time: 0.162, data: 0.000) loss: 1.386 
(epoch: 60, iters: 4832, time: 0.160, data: 0.000) loss: 0.339 
(epoch: 60, iters: 4912, time: 0.163, data: 0.009) loss: 1.077 
(epoch: 60, iters: 4992, time: 0.161, data: 0.011) loss: 1.224 
(epoch: 60, iters: 5072, time: 0.160, data: 0.000) loss: 0.304 
(epoch: 60, iters: 5152, time: 0.160, data: 0.000) loss: 0.507 
(epoch: 60, iters: 5232, time: 0.160, data: 0.024) loss: 0.982 
(epoch: 60, iters: 5312, time: 0.163, data: 0.000) loss: 0.583 
(epoch: 60, iters: 5392, time: 0.160, data: 0.000) loss: 1.504 
(epoch: 60, iters: 5472, time: 0.159, data: 0.000) loss: 0.535 
(epoch: 60, iters: 5552, time: 0.160, data: 0.006) loss: 1.868 
(epoch: 60, iters: 5632, time: 0.165, data: 0.000) loss: 0.723 
(epoch: 60, iters: 5712, time: 0.160, data: 0.000) loss: 0.716 
(epoch: 60, iters: 5792, time: 0.163, data: 0.000) loss: 0.636 
(epoch: 60, iters: 5872, time: 0.164, data: 0.005) loss: 0.709 
(epoch: 60, iters: 5952, time: 0.161, data: 0.000) loss: 1.197 
(epoch: 60, iters: 6032, time: 0.162, data: 0.000) loss: 1.317 
(epoch: 60, iters: 6112, time: 0.166, data: 0.024) loss: 0.657 
(epoch: 60, iters: 6192, time: 0.163, data: 0.000) loss: 0.218 
(epoch: 60, iters: 6272, time: 0.161, data: 0.000) loss: 0.738 
(epoch: 60, iters: 6352, time: 0.160, data: 0.006) loss: 0.621 
(epoch: 60, iters: 6432, time: 0.161, data: 0.024) loss: 0.494 
(epoch: 60, iters: 6512, time: 0.160, data: 0.000) loss: 0.949 
(epoch: 60, iters: 6592, time: 0.164, data: 0.011) loss: 0.850 
(epoch: 60, iters: 6672, time: 0.159, data: 0.005) loss: 0.265 
(epoch: 60, iters: 6752, time: 0.163, data: 0.000) loss: 0.715 
(epoch: 60, iters: 6832, time: 0.164, data: 0.008) loss: 0.737 
(epoch: 60, iters: 6912, time: 0.161, data: 0.000) loss: 0.970 
(epoch: 60, iters: 6992, time: 0.161, data: 0.000) loss: 0.796 
(epoch: 60, iters: 7072, time: 0.162, data: 0.020) loss: 0.863 
(epoch: 60, iters: 7152, time: 0.161, data: 0.014) loss: 0.329 
(epoch: 60, iters: 7232, time: 0.161, data: 0.005) loss: 1.054 
(epoch: 60, iters: 7312, time: 0.160, data: 0.014) loss: 0.741 
(epoch: 60, iters: 7392, time: 0.161, data: 0.034) loss: 0.942 
(epoch: 60, iters: 7472, time: 0.160, data: 0.000) loss: 0.325 
(epoch: 60, iters: 7552, time: 0.162, data: 0.000) loss: 0.768 
(epoch: 60, iters: 7632, time: 0.160, data: 0.000) loss: 0.791 
(epoch: 60, iters: 7712, time: 0.160, data: 0.000) loss: 0.818 
(epoch: 60, iters: 7792, time: 0.163, data: 0.000) loss: 0.361 
(epoch: 60, iters: 7872, time: 0.159, data: 0.020) loss: 0.894 
(epoch: 60, iters: 7952, time: 0.161, data: 0.028) loss: 0.917 
saving the latest model (epoch 60, total_steps 609344)
(epoch: 60, iters: 8032, time: 0.158, data: 0.000) loss: 0.455 
(epoch: 60, iters: 8112, time: 0.165, data: 0.000) loss: 1.209 
(epoch: 60, iters: 8192, time: 0.162, data: 0.000) loss: 0.473 
(epoch: 60, iters: 8272, time: 0.159, data: 0.000) loss: 0.632 
(epoch: 60, iters: 8352, time: 0.160, data: 0.000) loss: 1.016 
(epoch: 60, iters: 8432, time: 0.157, data: 0.017) loss: 0.937 
(epoch: 60, iters: 8512, time: 0.168, data: 0.000) loss: 0.856 
(epoch: 60, iters: 8592, time: 0.157, data: 0.000) loss: 0.646 
(epoch: 60, iters: 8672, time: 0.157, data: 0.006) loss: 0.774 
(epoch: 60, iters: 8752, time: 0.161, data: 0.000) loss: 0.926 
(epoch: 60, iters: 8832, time: 0.165, data: 0.024) loss: 0.685 
(epoch: 60, iters: 8912, time: 0.164, data: 0.000) loss: 1.028 
(epoch: 60, iters: 8992, time: 0.162, data: 0.000) loss: 0.487 
(epoch: 60, iters: 9072, time: 0.161, data: 0.006) loss: 0.795 
(epoch: 60, iters: 9152, time: 0.161, data: 0.000) loss: 0.804 
(epoch: 60, iters: 9232, time: 0.161, data: 0.027) loss: 0.483 
(epoch: 60, iters: 9312, time: 0.160, data: 0.000) loss: 0.196 
(epoch: 60, iters: 9392, time: 0.163, data: 0.000) loss: 0.805 
(epoch: 60, iters: 9472, time: 0.160, data: 0.023) loss: 0.673 
(epoch: 60, iters: 9552, time: 0.164, data: 0.000) loss: 1.136 
(epoch: 60, iters: 9632, time: 0.158, data: 0.000) loss: 0.540 
(epoch: 60, iters: 9712, time: 0.160, data: 0.000) loss: 0.290 
(epoch: 60, iters: 9792, time: 0.159, data: 0.005) loss: 1.134 
(epoch: 60, iters: 9872, time: 0.160, data: 0.000) loss: 1.082 
(epoch: 60, iters: 9952, time: 0.158, data: 0.005) loss: 0.389 
(epoch: 60, iters: 10032, time: 0.160, data: 0.000) loss: 0.779 
(epoch: 60, iters: 10112, time: 0.158, data: 0.014) loss: 0.666 
(epoch: 60, iters: 10192, time: 0.097, data: 0.000) loss: 0.900 
saving the model at the end of epoch 60, iters 611520
End of epoch 60 / 200 	 Time Taken: 1647 sec
learning rate = 0.0002000
saving the latest model (epoch 61, total_steps 611536)
(epoch: 61, iters: 80, time: 0.163, data: 0.186) loss: 0.997 
(epoch: 61, iters: 160, time: 0.163, data: 0.000) loss: 1.113 
(epoch: 61, iters: 240, time: 0.159, data: 0.000) loss: 0.377 
(epoch: 61, iters: 320, time: 0.159, data: 0.006) loss: 0.987 
(epoch: 61, iters: 400, time: 0.159, data: 0.000) loss: 0.869 
(epoch: 61, iters: 480, time: 0.159, data: 0.019) loss: 1.458 
(epoch: 61, iters: 560, time: 0.158, data: 0.021) loss: 0.595 
(epoch: 61, iters: 640, time: 0.166, data: 0.000) loss: 0.777 
(epoch: 61, iters: 720, time: 0.158, data: 0.009) loss: 0.882 
(epoch: 61, iters: 800, time: 0.159, data: 0.000) loss: 0.636 
(epoch: 61, iters: 880, time: 0.158, data: 0.006) loss: 0.672 
(epoch: 61, iters: 960, time: 0.159, data: 0.000) loss: 0.468 
(epoch: 61, iters: 1040, time: 0.163, data: 0.000) loss: 1.126 
(epoch: 61, iters: 1120, time: 0.158, data: 0.000) loss: 0.508 
(epoch: 61, iters: 1200, time: 0.157, data: 0.000) loss: 1.040 
(epoch: 61, iters: 1280, time: 0.159, data: 0.024) loss: 0.530 
(epoch: 61, iters: 1360, time: 0.158, data: 0.000) loss: 0.410 
(epoch: 61, iters: 1440, time: 0.158, data: 0.000) loss: 0.580 
(epoch: 61, iters: 1520, time: 0.158, data: 0.022) loss: 0.286 
(epoch: 61, iters: 1600, time: 0.160, data: 0.000) loss: 0.707 
(epoch: 61, iters: 1680, time: 0.157, data: 0.000) loss: 0.891 
(epoch: 61, iters: 1760, time: 0.157, data: 0.000) loss: 1.224 
(epoch: 61, iters: 1840, time: 0.159, data: 0.014) loss: 1.046 
(epoch: 61, iters: 1920, time: 0.160, data: 0.008) loss: 1.831 
(epoch: 61, iters: 2000, time: 0.158, data: 0.000) loss: 0.690 
(epoch: 61, iters: 2080, time: 0.160, data: 0.000) loss: 1.016 
(epoch: 61, iters: 2160, time: 0.160, data: 0.000) loss: 0.419 
(epoch: 61, iters: 2240, time: 0.157, data: 0.006) loss: 0.496 
(epoch: 61, iters: 2320, time: 0.159, data: 0.000) loss: 0.614 
(epoch: 61, iters: 2400, time: 0.160, data: 0.025) loss: 0.676 
(epoch: 61, iters: 2480, time: 0.156, data: 0.000) loss: 1.367 
(epoch: 61, iters: 2560, time: 0.160, data: 0.011) loss: 1.248 
(epoch: 61, iters: 2640, time: 0.155, data: 0.000) loss: 0.431 
(epoch: 61, iters: 2720, time: 0.159, data: 0.000) loss: 0.558 
(epoch: 61, iters: 2800, time: 0.156, data: 0.000) loss: 0.614 
(epoch: 61, iters: 2880, time: 0.159, data: 0.030) loss: 0.389 
(epoch: 61, iters: 2960, time: 0.160, data: 0.000) loss: 0.406 
(epoch: 61, iters: 3040, time: 0.158, data: 0.000) loss: 1.186 
(epoch: 61, iters: 3120, time: 0.159, data: 0.000) loss: 0.982 
(epoch: 61, iters: 3200, time: 0.161, data: 0.012) loss: 0.689 
(epoch: 61, iters: 3280, time: 0.160, data: 0.000) loss: 0.646 
(epoch: 61, iters: 3360, time: 0.160, data: 0.033) loss: 0.671 
(epoch: 61, iters: 3440, time: 0.159, data: 0.000) loss: 0.701 
(epoch: 61, iters: 3520, time: 0.160, data: 0.025) loss: 0.945 
(epoch: 61, iters: 3600, time: 0.161, data: 0.000) loss: 0.316 
(epoch: 61, iters: 3680, time: 0.159, data: 0.000) loss: 1.227 
(epoch: 61, iters: 3760, time: 0.158, data: 0.034) loss: 0.640 
(epoch: 61, iters: 3840, time: 0.159, data: 0.000) loss: 0.466 
(epoch: 61, iters: 3920, time: 0.160, data: 0.008) loss: 0.545 
(epoch: 61, iters: 4000, time: 0.160, data: 0.005) loss: 1.153 
saving the latest model (epoch 61, total_steps 615536)
(epoch: 61, iters: 4080, time: 0.159, data: 0.000) loss: 0.289 
(epoch: 61, iters: 4160, time: 0.158, data: 0.008) loss: 0.686 
(epoch: 61, iters: 4240, time: 0.159, data: 0.000) loss: 0.485 
(epoch: 61, iters: 4320, time: 0.160, data: 0.005) loss: 0.378 
(epoch: 61, iters: 4400, time: 0.160, data: 0.000) loss: 0.940 
(epoch: 61, iters: 4480, time: 0.159, data: 0.010) loss: 0.451 
(epoch: 61, iters: 4560, time: 0.161, data: 0.000) loss: 0.583 
(epoch: 61, iters: 4640, time: 0.159, data: 0.016) loss: 0.672 
(epoch: 61, iters: 4720, time: 0.159, data: 0.018) loss: 0.209 
(epoch: 61, iters: 4800, time: 0.158, data: 0.000) loss: 0.703 
(epoch: 61, iters: 4880, time: 0.159, data: 0.000) loss: 0.803 
(epoch: 61, iters: 4960, time: 0.160, data: 0.000) loss: 1.041 
(epoch: 61, iters: 5040, time: 0.161, data: 0.027) loss: 0.673 
(epoch: 61, iters: 5120, time: 0.158, data: 0.000) loss: 0.346 
(epoch: 61, iters: 5200, time: 0.162, data: 0.011) loss: 0.598 
(epoch: 61, iters: 5280, time: 0.162, data: 0.000) loss: 1.040 
(epoch: 61, iters: 5360, time: 0.162, data: 0.006) loss: 0.583 
(epoch: 61, iters: 5440, time: 0.161, data: 0.006) loss: 0.990 
(epoch: 61, iters: 5520, time: 0.160, data: 0.000) loss: 0.630 
(epoch: 61, iters: 5600, time: 0.156, data: 0.005) loss: 1.252 
(epoch: 61, iters: 5680, time: 0.161, data: 0.000) loss: 0.436 
(epoch: 61, iters: 5760, time: 0.162, data: 0.000) loss: 0.421 
(epoch: 61, iters: 5840, time: 0.158, data: 0.000) loss: 0.981 
(epoch: 61, iters: 5920, time: 0.162, data: 0.009) loss: 0.978 
(epoch: 61, iters: 6000, time: 0.160, data: 0.000) loss: 0.491 
(epoch: 61, iters: 6080, time: 0.158, data: 0.014) loss: 0.768 
(epoch: 61, iters: 6160, time: 0.159, data: 0.000) loss: 0.837 
(epoch: 61, iters: 6240, time: 0.160, data: 0.008) loss: 0.667 
(epoch: 61, iters: 6320, time: 0.157, data: 0.005) loss: 1.378 
(epoch: 61, iters: 6400, time: 0.159, data: 0.000) loss: 0.621 
(epoch: 61, iters: 6480, time: 0.158, data: 0.000) loss: 0.948 
(epoch: 61, iters: 6560, time: 0.160, data: 0.024) loss: 1.229 
(epoch: 61, iters: 6640, time: 0.158, data: 0.006) loss: 0.546 
(epoch: 61, iters: 6720, time: 0.157, data: 0.011) loss: 0.490 
(epoch: 61, iters: 6800, time: 0.162, data: 0.000) loss: 0.846 
(epoch: 61, iters: 6880, time: 0.158, data: 0.008) loss: 0.506 
(epoch: 61, iters: 6960, time: 0.161, data: 0.000) loss: 0.853 
(epoch: 61, iters: 7040, time: 0.158, data: 0.000) loss: 0.737 
(epoch: 61, iters: 7120, time: 0.160, data: 0.005) loss: 0.395 
(epoch: 61, iters: 7200, time: 0.158, data: 0.000) loss: 0.568 
(epoch: 61, iters: 7280, time: 0.161, data: 0.000) loss: 0.702 
(epoch: 61, iters: 7360, time: 0.156, data: 0.024) loss: 0.787 
(epoch: 61, iters: 7440, time: 0.158, data: 0.000) loss: 0.921 
(epoch: 61, iters: 7520, time: 0.156, data: 0.000) loss: 0.266 
(epoch: 61, iters: 7600, time: 0.159, data: 0.009) loss: 0.791 
(epoch: 61, iters: 7680, time: 0.158, data: 0.000) loss: 0.349 
(epoch: 61, iters: 7760, time: 0.158, data: 0.012) loss: 0.752 
(epoch: 61, iters: 7840, time: 0.161, data: 0.000) loss: 0.618 
(epoch: 61, iters: 7920, time: 0.158, data: 0.023) loss: 0.691 
(epoch: 61, iters: 8000, time: 0.155, data: 0.000) loss: 1.043 
saving the latest model (epoch 61, total_steps 619536)
(epoch: 61, iters: 8080, time: 0.156, data: 0.005) loss: 0.561 
(epoch: 61, iters: 8160, time: 0.159, data: 0.000) loss: 0.589 
(epoch: 61, iters: 8240, time: 0.157, data: 0.020) loss: 0.542 
(epoch: 61, iters: 8320, time: 0.159, data: 0.006) loss: 1.005 
(epoch: 61, iters: 8400, time: 0.158, data: 0.008) loss: 1.154 
(epoch: 61, iters: 8480, time: 0.157, data: 0.000) loss: 0.354 
(epoch: 61, iters: 8560, time: 0.157, data: 0.006) loss: 0.425 
(epoch: 61, iters: 8640, time: 0.159, data: 0.009) loss: 0.435 
(epoch: 61, iters: 8720, time: 0.159, data: 0.005) loss: 1.546 
(epoch: 61, iters: 8800, time: 0.158, data: 0.000) loss: 0.718 
(epoch: 61, iters: 8880, time: 0.160, data: 0.020) loss: 0.755 
(epoch: 61, iters: 8960, time: 0.162, data: 0.033) loss: 0.363 
(epoch: 61, iters: 9040, time: 0.157, data: 0.000) loss: 0.460 
(epoch: 61, iters: 9120, time: 0.157, data: 0.000) loss: 0.628 
(epoch: 61, iters: 9200, time: 0.158, data: 0.000) loss: 1.391 
(epoch: 61, iters: 9280, time: 0.163, data: 0.000) loss: 0.152 
(epoch: 61, iters: 9360, time: 0.156, data: 0.000) loss: 0.627 
(epoch: 61, iters: 9440, time: 0.159, data: 0.016) loss: 1.214 
(epoch: 61, iters: 9520, time: 0.157, data: 0.006) loss: 0.269 
(epoch: 61, iters: 9600, time: 0.157, data: 0.008) loss: 0.753 
(epoch: 61, iters: 9680, time: 0.160, data: 0.000) loss: 1.017 
(epoch: 61, iters: 9760, time: 0.158, data: 0.008) loss: 0.585 
(epoch: 61, iters: 9840, time: 0.158, data: 0.033) loss: 0.751 
(epoch: 61, iters: 9920, time: 0.158, data: 0.000) loss: 0.460 
(epoch: 61, iters: 10000, time: 0.159, data: 0.011) loss: 1.087 
(epoch: 61, iters: 10080, time: 0.161, data: 0.005) loss: 0.746 
(epoch: 61, iters: 10160, time: 0.159, data: 0.000) loss: 0.467 
saving the model at the end of epoch 61, iters 621712
End of epoch 61 / 200 	 Time Taken: 1622 sec
learning rate = 0.0002000
saving the latest model (epoch 62, total_steps 621728)
(epoch: 62, iters: 48, time: 0.167, data: 0.007) loss: 0.357 
(epoch: 62, iters: 128, time: 0.159, data: 0.029) loss: 0.572 
(epoch: 62, iters: 208, time: 0.162, data: 0.000) loss: 0.379 
(epoch: 62, iters: 288, time: 0.160, data: 0.000) loss: 0.552 
(epoch: 62, iters: 368, time: 0.160, data: 0.011) loss: 0.910 
(epoch: 62, iters: 448, time: 0.159, data: 0.000) loss: 0.427 
(epoch: 62, iters: 528, time: 0.158, data: 0.000) loss: 0.373 
(epoch: 62, iters: 608, time: 0.159, data: 0.000) loss: 0.924 
(epoch: 62, iters: 688, time: 0.158, data: 0.000) loss: 0.704 
(epoch: 62, iters: 768, time: 0.157, data: 0.023) loss: 0.634 
(epoch: 62, iters: 848, time: 0.159, data: 0.000) loss: 0.440 
(epoch: 62, iters: 928, time: 0.159, data: 0.008) loss: 1.065 
(epoch: 62, iters: 1008, time: 0.162, data: 0.000) loss: 0.829 
(epoch: 62, iters: 1088, time: 0.162, data: 0.014) loss: 0.246 
(epoch: 62, iters: 1168, time: 0.159, data: 0.013) loss: 0.996 
(epoch: 62, iters: 1248, time: 0.158, data: 0.000) loss: 0.929 
(epoch: 62, iters: 1328, time: 0.160, data: 0.000) loss: 0.697 
(epoch: 62, iters: 1408, time: 0.157, data: 0.008) loss: 0.480 
(epoch: 62, iters: 1488, time: 0.162, data: 0.005) loss: 0.709 
(epoch: 62, iters: 1568, time: 0.158, data: 0.000) loss: 0.826 
(epoch: 62, iters: 1648, time: 0.159, data: 0.005) loss: 0.482 
(epoch: 62, iters: 1728, time: 0.160, data: 0.000) loss: 0.277 
(epoch: 62, iters: 1808, time: 0.166, data: 0.008) loss: 0.781 
(epoch: 62, iters: 1888, time: 0.158, data: 0.000) loss: 1.132 
(epoch: 62, iters: 1968, time: 0.158, data: 0.033) loss: 0.794 
(epoch: 62, iters: 2048, time: 0.160, data: 0.000) loss: 0.969 
(epoch: 62, iters: 2128, time: 0.159, data: 0.019) loss: 0.383 
(epoch: 62, iters: 2208, time: 0.162, data: 0.005) loss: 0.940 
(epoch: 62, iters: 2288, time: 0.160, data: 0.000) loss: 0.541 
(epoch: 62, iters: 2368, time: 0.159, data: 0.000) loss: 0.367 
(epoch: 62, iters: 2448, time: 0.162, data: 0.025) loss: 0.569 
(epoch: 62, iters: 2528, time: 0.159, data: 0.000) loss: 0.349 
(epoch: 62, iters: 2608, time: 0.158, data: 0.025) loss: 0.542 
(epoch: 62, iters: 2688, time: 0.157, data: 0.000) loss: 1.276 
(epoch: 62, iters: 2768, time: 0.157, data: 0.000) loss: 0.915 
(epoch: 62, iters: 2848, time: 0.159, data: 0.013) loss: 0.474 
(epoch: 62, iters: 2928, time: 0.159, data: 0.000) loss: 0.741 
(epoch: 62, iters: 3008, time: 0.158, data: 0.008) loss: 0.844 
(epoch: 62, iters: 3088, time: 0.158, data: 0.009) loss: 0.837 
(epoch: 62, iters: 3168, time: 0.158, data: 0.000) loss: 0.356 
(epoch: 62, iters: 3248, time: 0.160, data: 0.006) loss: 0.683 
(epoch: 62, iters: 3328, time: 0.157, data: 0.000) loss: 0.972 
(epoch: 62, iters: 3408, time: 0.160, data: 0.000) loss: 0.743 
(epoch: 62, iters: 3488, time: 0.160, data: 0.005) loss: 0.967 
(epoch: 62, iters: 3568, time: 0.159, data: 0.009) loss: 0.889 
(epoch: 62, iters: 3648, time: 0.162, data: 0.000) loss: 0.730 
(epoch: 62, iters: 3728, time: 0.160, data: 0.000) loss: 0.958 
(epoch: 62, iters: 3808, time: 0.162, data: 0.010) loss: 1.539 
(epoch: 62, iters: 3888, time: 0.160, data: 0.000) loss: 0.416 
(epoch: 62, iters: 3968, time: 0.160, data: 0.000) loss: 0.334 
saving the latest model (epoch 62, total_steps 625728)
(epoch: 62, iters: 4048, time: 0.160, data: 0.000) loss: 0.797 
(epoch: 62, iters: 4128, time: 0.167, data: 0.005) loss: 0.324 
(epoch: 62, iters: 4208, time: 0.160, data: 0.000) loss: 0.811 
(epoch: 62, iters: 4288, time: 0.159, data: 0.000) loss: 1.076 
(epoch: 62, iters: 4368, time: 0.163, data: 0.013) loss: 0.595 
(epoch: 62, iters: 4448, time: 0.163, data: 0.000) loss: 0.859 
(epoch: 62, iters: 4528, time: 0.167, data: 0.000) loss: 0.695 
(epoch: 62, iters: 4608, time: 0.162, data: 0.005) loss: 1.081 
(epoch: 62, iters: 4688, time: 0.159, data: 0.000) loss: 0.755 
(epoch: 62, iters: 4768, time: 0.160, data: 0.009) loss: 0.526 
(epoch: 62, iters: 4848, time: 0.161, data: 0.000) loss: 1.022 
(epoch: 62, iters: 4928, time: 0.160, data: 0.011) loss: 1.076 
(epoch: 62, iters: 5008, time: 0.161, data: 0.000) loss: 0.382 
(epoch: 62, iters: 5088, time: 0.159, data: 0.000) loss: 0.762 
(epoch: 62, iters: 5168, time: 0.159, data: 0.011) loss: 0.731 
(epoch: 62, iters: 5248, time: 0.158, data: 0.005) loss: 0.741 
(epoch: 62, iters: 5328, time: 0.159, data: 0.016) loss: 0.808 
(epoch: 62, iters: 5408, time: 0.162, data: 0.008) loss: 0.605 
(epoch: 62, iters: 5488, time: 0.159, data: 0.008) loss: 0.557 
(epoch: 62, iters: 5568, time: 0.161, data: 0.000) loss: 0.419 
(epoch: 62, iters: 5648, time: 0.159, data: 0.005) loss: 0.429 
(epoch: 62, iters: 5728, time: 0.161, data: 0.000) loss: 0.486 
(epoch: 62, iters: 5808, time: 0.158, data: 0.014) loss: 0.706 
(epoch: 62, iters: 5888, time: 0.159, data: 0.029) loss: 1.252 
(epoch: 62, iters: 5968, time: 0.161, data: 0.000) loss: 0.617 
(epoch: 62, iters: 6048, time: 0.159, data: 0.000) loss: 1.587 
(epoch: 62, iters: 6128, time: 0.163, data: 0.000) loss: 0.844 
(epoch: 62, iters: 6208, time: 0.159, data: 0.008) loss: 0.825 
(epoch: 62, iters: 6288, time: 0.161, data: 0.017) loss: 0.427 
(epoch: 62, iters: 6368, time: 0.161, data: 0.000) loss: 0.906 
(epoch: 62, iters: 6448, time: 0.166, data: 0.000) loss: 1.503 
(epoch: 62, iters: 6528, time: 0.159, data: 0.000) loss: 1.943 
(epoch: 62, iters: 6608, time: 0.161, data: 0.032) loss: 0.770 
(epoch: 62, iters: 6688, time: 0.159, data: 0.000) loss: 0.487 
(epoch: 62, iters: 6768, time: 0.160, data: 0.000) loss: 0.662 
(epoch: 62, iters: 6848, time: 0.162, data: 0.000) loss: 0.888 
(epoch: 62, iters: 6928, time: 0.161, data: 0.006) loss: 0.408 
(epoch: 62, iters: 7008, time: 0.160, data: 0.000) loss: 0.425 
(epoch: 62, iters: 7088, time: 0.159, data: 0.000) loss: 0.927 
(epoch: 62, iters: 7168, time: 0.162, data: 0.005) loss: 0.802 
(epoch: 62, iters: 7248, time: 0.159, data: 0.009) loss: 0.525 
(epoch: 62, iters: 7328, time: 0.160, data: 0.000) loss: 0.169 
(epoch: 62, iters: 7408, time: 0.159, data: 0.000) loss: 0.929 
(epoch: 62, iters: 7488, time: 0.161, data: 0.000) loss: 0.578 
(epoch: 62, iters: 7568, time: 0.162, data: 0.000) loss: 0.575 
(epoch: 62, iters: 7648, time: 0.162, data: 0.021) loss: 0.593 
(epoch: 62, iters: 7728, time: 0.160, data: 0.000) loss: 0.572 
(epoch: 62, iters: 7808, time: 0.162, data: 0.014) loss: 0.551 
(epoch: 62, iters: 7888, time: 0.160, data: 0.000) loss: 0.833 
(epoch: 62, iters: 7968, time: 0.161, data: 0.023) loss: 0.457 
saving the latest model (epoch 62, total_steps 629728)
(epoch: 62, iters: 8048, time: 0.158, data: 0.021) loss: 0.913 
(epoch: 62, iters: 8128, time: 0.162, data: 0.000) loss: 0.253 
(epoch: 62, iters: 8208, time: 0.158, data: 0.000) loss: 0.985 
(epoch: 62, iters: 8288, time: 0.159, data: 0.005) loss: 0.706 
(epoch: 62, iters: 8368, time: 0.163, data: 0.000) loss: 0.835 
(epoch: 62, iters: 8448, time: 0.160, data: 0.000) loss: 1.130 
(epoch: 62, iters: 8528, time: 0.164, data: 0.010) loss: 0.675 
(epoch: 62, iters: 8608, time: 0.162, data: 0.001) loss: 0.630 
(epoch: 62, iters: 8688, time: 0.162, data: 0.000) loss: 0.561 
(epoch: 62, iters: 8768, time: 0.166, data: 0.000) loss: 1.723 
(epoch: 62, iters: 8848, time: 0.160, data: 0.005) loss: 0.367 
(epoch: 62, iters: 8928, time: 0.160, data: 0.000) loss: 0.711 
(epoch: 62, iters: 9008, time: 0.159, data: 0.000) loss: 0.908 
(epoch: 62, iters: 9088, time: 0.164, data: 0.017) loss: 0.524 
(epoch: 62, iters: 9168, time: 0.160, data: 0.000) loss: 0.724 
(epoch: 62, iters: 9248, time: 0.162, data: 0.000) loss: 1.139 
(epoch: 62, iters: 9328, time: 0.159, data: 0.006) loss: 1.029 
(epoch: 62, iters: 9408, time: 0.162, data: 0.005) loss: 1.056 
(epoch: 62, iters: 9488, time: 0.160, data: 0.000) loss: 0.909 
(epoch: 62, iters: 9568, time: 0.161, data: 0.016) loss: 0.618 
(epoch: 62, iters: 9648, time: 0.161, data: 0.000) loss: 0.675 
(epoch: 62, iters: 9728, time: 0.163, data: 0.000) loss: 0.869 
(epoch: 62, iters: 9808, time: 0.164, data: 0.000) loss: 0.446 
(epoch: 62, iters: 9888, time: 0.162, data: 0.000) loss: 1.385 
(epoch: 62, iters: 9968, time: 0.162, data: 0.000) loss: 0.518 
(epoch: 62, iters: 10048, time: 0.158, data: 0.010) loss: 0.646 
(epoch: 62, iters: 10128, time: 0.159, data: 0.009) loss: 0.843 
saving the model at the end of epoch 62, iters 631904
End of epoch 62 / 200 	 Time Taken: 1638 sec
learning rate = 0.0002000
(epoch: 63, iters: 16, time: 0.178, data: 0.000) loss: 0.684 
saving the latest model (epoch 63, total_steps 631920)
(epoch: 63, iters: 96, time: 0.161, data: 0.000) loss: 1.017 
(epoch: 63, iters: 176, time: 0.156, data: 0.012) loss: 0.582 
(epoch: 63, iters: 256, time: 0.153, data: 0.000) loss: 1.022 
(epoch: 63, iters: 336, time: 0.157, data: 0.000) loss: 0.567 
(epoch: 63, iters: 416, time: 0.156, data: 0.000) loss: 0.661 
(epoch: 63, iters: 496, time: 0.162, data: 0.000) loss: 0.546 
(epoch: 63, iters: 576, time: 0.157, data: 0.000) loss: 0.289 
(epoch: 63, iters: 656, time: 0.161, data: 0.006) loss: 0.934 
(epoch: 63, iters: 736, time: 0.160, data: 0.000) loss: 0.400 
(epoch: 63, iters: 816, time: 0.160, data: 0.005) loss: 1.041 
(epoch: 63, iters: 896, time: 0.168, data: 0.008) loss: 0.693 
(epoch: 63, iters: 976, time: 0.160, data: 0.000) loss: 1.174 
(epoch: 63, iters: 1056, time: 0.160, data: 0.000) loss: 0.840 
(epoch: 63, iters: 1136, time: 0.159, data: 0.000) loss: 0.938 
(epoch: 63, iters: 1216, time: 0.158, data: 0.000) loss: 0.447 
(epoch: 63, iters: 1296, time: 0.159, data: 0.000) loss: 0.693 
(epoch: 63, iters: 1376, time: 0.159, data: 0.005) loss: 0.336 
(epoch: 63, iters: 1456, time: 0.159, data: 0.000) loss: 0.509 
(epoch: 63, iters: 1536, time: 0.159, data: 0.005) loss: 0.860 
(epoch: 63, iters: 1616, time: 0.160, data: 0.000) loss: 0.644 
(epoch: 63, iters: 1696, time: 0.160, data: 0.000) loss: 0.462 
(epoch: 63, iters: 1776, time: 0.159, data: 0.000) loss: 0.701 
(epoch: 63, iters: 1856, time: 0.158, data: 0.000) loss: 1.234 
(epoch: 63, iters: 1936, time: 0.160, data: 0.026) loss: 1.233 
(epoch: 63, iters: 2016, time: 0.159, data: 0.031) loss: 0.677 
(epoch: 63, iters: 2096, time: 0.159, data: 0.000) loss: 0.909 
(epoch: 63, iters: 2176, time: 0.160, data: 0.005) loss: 0.697 
(epoch: 63, iters: 2256, time: 0.161, data: 0.009) loss: 0.590 
(epoch: 63, iters: 2336, time: 0.160, data: 0.000) loss: 0.416 
(epoch: 63, iters: 2416, time: 0.161, data: 0.000) loss: 0.907 
(epoch: 63, iters: 2496, time: 0.161, data: 0.000) loss: 1.105 
(epoch: 63, iters: 2576, time: 0.160, data: 0.008) loss: 0.920 
(epoch: 63, iters: 2656, time: 0.160, data: 0.000) loss: 1.139 
(epoch: 63, iters: 2736, time: 0.160, data: 0.005) loss: 0.742 
(epoch: 63, iters: 2816, time: 0.162, data: 0.000) loss: 0.377 
(epoch: 63, iters: 2896, time: 0.159, data: 0.008) loss: 0.921 
(epoch: 63, iters: 2976, time: 0.160, data: 0.000) loss: 0.618 
(epoch: 63, iters: 3056, time: 0.158, data: 0.023) loss: 0.774 
(epoch: 63, iters: 3136, time: 0.160, data: 0.000) loss: 1.446 
(epoch: 63, iters: 3216, time: 0.165, data: 0.000) loss: 0.565 
(epoch: 63, iters: 3296, time: 0.158, data: 0.024) loss: 0.928 
(epoch: 63, iters: 3376, time: 0.160, data: 0.000) loss: 0.842 
(epoch: 63, iters: 3456, time: 0.160, data: 0.033) loss: 0.650 
(epoch: 63, iters: 3536, time: 0.163, data: 0.000) loss: 0.337 
(epoch: 63, iters: 3616, time: 0.160, data: 0.000) loss: 0.841 
(epoch: 63, iters: 3696, time: 0.160, data: 0.000) loss: 0.649 
(epoch: 63, iters: 3776, time: 0.161, data: 0.000) loss: 1.056 
(epoch: 63, iters: 3856, time: 0.159, data: 0.000) loss: 0.665 
(epoch: 63, iters: 3936, time: 0.163, data: 0.014) loss: 0.673 
(epoch: 63, iters: 4016, time: 0.159, data: 0.000) loss: 0.772 
saving the latest model (epoch 63, total_steps 635920)
(epoch: 63, iters: 4096, time: 0.159, data: 0.000) loss: 1.112 
(epoch: 63, iters: 4176, time: 0.161, data: 0.000) loss: 0.603 
(epoch: 63, iters: 4256, time: 0.159, data: 0.005) loss: 0.506 
(epoch: 63, iters: 4336, time: 0.163, data: 0.000) loss: 0.572 
(epoch: 63, iters: 4416, time: 0.160, data: 0.000) loss: 0.733 
(epoch: 63, iters: 4496, time: 0.164, data: 0.000) loss: 0.883 
(epoch: 63, iters: 4576, time: 0.161, data: 0.008) loss: 0.426 
(epoch: 63, iters: 4656, time: 0.160, data: 0.009) loss: 0.566 
(epoch: 63, iters: 4736, time: 0.162, data: 0.000) loss: 1.221 
(epoch: 63, iters: 4816, time: 0.162, data: 0.011) loss: 1.354 
(epoch: 63, iters: 4896, time: 0.160, data: 0.000) loss: 0.712 
(epoch: 63, iters: 4976, time: 0.158, data: 0.000) loss: 0.819 
(epoch: 63, iters: 5056, time: 0.160, data: 0.006) loss: 0.417 
(epoch: 63, iters: 5136, time: 0.167, data: 0.011) loss: 0.504 
(epoch: 63, iters: 5216, time: 0.159, data: 0.000) loss: 0.656 
(epoch: 63, iters: 5296, time: 0.160, data: 0.000) loss: 0.270 
(epoch: 63, iters: 5376, time: 0.160, data: 0.005) loss: 0.634 
(epoch: 63, iters: 5456, time: 0.162, data: 0.006) loss: 0.591 
(epoch: 63, iters: 5536, time: 0.164, data: 0.008) loss: 0.192 
(epoch: 63, iters: 5616, time: 0.160, data: 0.008) loss: 1.255 
(epoch: 63, iters: 5696, time: 0.159, data: 0.010) loss: 0.515 
(epoch: 63, iters: 5776, time: 0.160, data: 0.000) loss: 0.613 
(epoch: 63, iters: 5856, time: 0.161, data: 0.000) loss: 0.247 
(epoch: 63, iters: 5936, time: 0.162, data: 0.033) loss: 0.861 
(epoch: 63, iters: 6016, time: 0.161, data: 0.000) loss: 0.650 
(epoch: 63, iters: 6096, time: 0.162, data: 0.008) loss: 1.194 
(epoch: 63, iters: 6176, time: 0.161, data: 0.014) loss: 0.312 
(epoch: 63, iters: 6256, time: 0.161, data: 0.013) loss: 0.539 
(epoch: 63, iters: 6336, time: 0.162, data: 0.000) loss: 0.371 
(epoch: 63, iters: 6416, time: 0.159, data: 0.000) loss: 0.974 
(epoch: 63, iters: 6496, time: 0.164, data: 0.005) loss: 0.478 
(epoch: 63, iters: 6576, time: 0.161, data: 0.000) loss: 0.783 
(epoch: 63, iters: 6656, time: 0.162, data: 0.000) loss: 0.687 
(epoch: 63, iters: 6736, time: 0.161, data: 0.000) loss: 0.633 
(epoch: 63, iters: 6816, time: 0.161, data: 0.000) loss: 0.632 
(epoch: 63, iters: 6896, time: 0.160, data: 0.000) loss: 0.541 
(epoch: 63, iters: 6976, time: 0.160, data: 0.000) loss: 0.916 
(epoch: 63, iters: 7056, time: 0.170, data: 0.025) loss: 0.702 
(epoch: 63, iters: 7136, time: 0.162, data: 0.022) loss: 0.614 
(epoch: 63, iters: 7216, time: 0.160, data: 0.015) loss: 0.923 
(epoch: 63, iters: 7296, time: 0.163, data: 0.000) loss: 1.087 
(epoch: 63, iters: 7376, time: 0.160, data: 0.000) loss: 0.403 
(epoch: 63, iters: 7456, time: 0.161, data: 0.005) loss: 0.586 
(epoch: 63, iters: 7536, time: 0.160, data: 0.006) loss: 0.850 
(epoch: 63, iters: 7616, time: 0.159, data: 0.000) loss: 0.558 
(epoch: 63, iters: 7696, time: 0.163, data: 0.000) loss: 0.218 
(epoch: 63, iters: 7776, time: 0.162, data: 0.005) loss: 1.465 
(epoch: 63, iters: 7856, time: 0.162, data: 0.000) loss: 0.271 
(epoch: 63, iters: 7936, time: 0.160, data: 0.010) loss: 0.609 
(epoch: 63, iters: 8016, time: 0.160, data: 0.000) loss: 0.703 
saving the latest model (epoch 63, total_steps 639920)
(epoch: 63, iters: 8096, time: 0.160, data: 0.000) loss: 0.654 
(epoch: 63, iters: 8176, time: 0.162, data: 0.005) loss: 0.786 
(epoch: 63, iters: 8256, time: 0.160, data: 0.014) loss: 0.449 
(epoch: 63, iters: 8336, time: 0.160, data: 0.010) loss: 0.491 
(epoch: 63, iters: 8416, time: 0.160, data: 0.000) loss: 0.422 
(epoch: 63, iters: 8496, time: 0.161, data: 0.000) loss: 0.967 
(epoch: 63, iters: 8576, time: 0.160, data: 0.008) loss: 0.403 
(epoch: 63, iters: 8656, time: 0.164, data: 0.000) loss: 0.720 
(epoch: 63, iters: 8736, time: 0.160, data: 0.007) loss: 1.159 
(epoch: 63, iters: 8816, time: 0.160, data: 0.000) loss: 0.815 
(epoch: 63, iters: 8896, time: 0.163, data: 0.027) loss: 0.847 
(epoch: 63, iters: 8976, time: 0.163, data: 0.000) loss: 0.323 
(epoch: 63, iters: 9056, time: 0.162, data: 0.000) loss: 0.674 
(epoch: 63, iters: 9136, time: 0.158, data: 0.005) loss: 1.125 
(epoch: 63, iters: 9216, time: 0.160, data: 0.000) loss: 0.536 
(epoch: 63, iters: 9296, time: 0.162, data: 0.015) loss: 0.648 
(epoch: 63, iters: 9376, time: 0.164, data: 0.000) loss: 1.232 
(epoch: 63, iters: 9456, time: 0.162, data: 0.000) loss: 1.286 
(epoch: 63, iters: 9536, time: 0.161, data: 0.024) loss: 0.577 
(epoch: 63, iters: 9616, time: 0.160, data: 0.000) loss: 0.537 
(epoch: 63, iters: 9696, time: 0.159, data: 0.000) loss: 0.706 
(epoch: 63, iters: 9776, time: 0.163, data: 0.000) loss: 0.579 
(epoch: 63, iters: 9856, time: 0.160, data: 0.000) loss: 0.785 
(epoch: 63, iters: 9936, time: 0.160, data: 0.000) loss: 0.240 
(epoch: 63, iters: 10016, time: 0.160, data: 0.000) loss: 0.567 
(epoch: 63, iters: 10096, time: 0.161, data: 0.020) loss: 1.112 
(epoch: 63, iters: 10176, time: 0.159, data: 0.005) loss: 1.040 
saving the model at the end of epoch 63, iters 642096
End of epoch 63 / 200 	 Time Taken: 1639 sec
learning rate = 0.0002000
saving the latest model (epoch 64, total_steps 642112)
(epoch: 64, iters: 64, time: 0.167, data: 0.000) loss: 0.505 
(epoch: 64, iters: 144, time: 0.160, data: 0.042) loss: 0.831 
(epoch: 64, iters: 224, time: 0.160, data: 0.000) loss: 0.600 
(epoch: 64, iters: 304, time: 0.164, data: 0.015) loss: 0.976 
(epoch: 64, iters: 384, time: 0.160, data: 0.000) loss: 1.218 
(epoch: 64, iters: 464, time: 0.160, data: 0.000) loss: 0.471 
(epoch: 64, iters: 544, time: 0.162, data: 0.000) loss: 1.034 
(epoch: 64, iters: 624, time: 0.160, data: 0.025) loss: 0.366 
(epoch: 64, iters: 704, time: 0.161, data: 0.000) loss: 0.645 
(epoch: 64, iters: 784, time: 0.160, data: 0.026) loss: 1.055 
(epoch: 64, iters: 864, time: 0.163, data: 0.000) loss: 0.552 
(epoch: 64, iters: 944, time: 0.159, data: 0.008) loss: 0.514 
(epoch: 64, iters: 1024, time: 0.160, data: 0.009) loss: 0.544 
(epoch: 64, iters: 1104, time: 0.166, data: 0.000) loss: 0.535 
(epoch: 64, iters: 1184, time: 0.162, data: 0.019) loss: 0.682 
(epoch: 64, iters: 1264, time: 0.158, data: 0.000) loss: 0.410 
(epoch: 64, iters: 1344, time: 0.162, data: 0.011) loss: 0.806 
(epoch: 64, iters: 1424, time: 0.160, data: 0.000) loss: 0.394 
(epoch: 64, iters: 1504, time: 0.162, data: 0.023) loss: 0.665 
(epoch: 64, iters: 1584, time: 0.160, data: 0.000) loss: 0.463 
(epoch: 64, iters: 1664, time: 0.159, data: 0.000) loss: 0.496 
(epoch: 64, iters: 1744, time: 0.160, data: 0.023) loss: 0.468 
(epoch: 64, iters: 1824, time: 0.161, data: 0.000) loss: 0.914 
(epoch: 64, iters: 1904, time: 0.161, data: 0.005) loss: 0.946 
(epoch: 64, iters: 1984, time: 0.159, data: 0.000) loss: 0.296 
(epoch: 64, iters: 2064, time: 0.159, data: 0.005) loss: 0.423 
(epoch: 64, iters: 2144, time: 0.159, data: 0.028) loss: 0.579 
(epoch: 64, iters: 2224, time: 0.162, data: 0.005) loss: 0.785 
(epoch: 64, iters: 2304, time: 0.161, data: 0.008) loss: 0.374 
(epoch: 64, iters: 2384, time: 0.161, data: 0.000) loss: 0.648 
(epoch: 64, iters: 2464, time: 0.162, data: 0.000) loss: 1.941 
(epoch: 64, iters: 2544, time: 0.161, data: 0.005) loss: 1.049 
(epoch: 64, iters: 2624, time: 0.163, data: 0.032) loss: 0.730 
(epoch: 64, iters: 2704, time: 0.160, data: 0.000) loss: 0.978 
(epoch: 64, iters: 2784, time: 0.162, data: 0.000) loss: 0.455 
(epoch: 64, iters: 2864, time: 0.162, data: 0.009) loss: 0.604 
(epoch: 64, iters: 2944, time: 0.161, data: 0.005) loss: 0.816 
(epoch: 64, iters: 3024, time: 0.164, data: 0.005) loss: 0.702 
(epoch: 64, iters: 3104, time: 0.165, data: 0.012) loss: 0.406 
(epoch: 64, iters: 3184, time: 0.159, data: 0.016) loss: 2.139 
(epoch: 64, iters: 3264, time: 0.158, data: 0.020) loss: 1.009 
(epoch: 64, iters: 3344, time: 0.160, data: 0.021) loss: 0.430 
(epoch: 64, iters: 3424, time: 0.161, data: 0.017) loss: 0.762 
(epoch: 64, iters: 3504, time: 0.161, data: 0.000) loss: 0.774 
(epoch: 64, iters: 3584, time: 0.163, data: 0.009) loss: 0.319 
(epoch: 64, iters: 3664, time: 0.156, data: 0.000) loss: 1.028 
(epoch: 64, iters: 3744, time: 0.157, data: 0.025) loss: 0.437 
(epoch: 64, iters: 3824, time: 0.158, data: 0.000) loss: 0.656 
(epoch: 64, iters: 3904, time: 0.157, data: 0.036) loss: 0.702 
(epoch: 64, iters: 3984, time: 0.161, data: 0.000) loss: 0.401 
saving the latest model (epoch 64, total_steps 646112)
(epoch: 64, iters: 4064, time: 0.158, data: 0.040) loss: 0.855 
(epoch: 64, iters: 4144, time: 0.156, data: 0.000) loss: 0.710 
(epoch: 64, iters: 4224, time: 0.159, data: 0.037) loss: 0.753 
(epoch: 64, iters: 4304, time: 0.157, data: 0.000) loss: 0.959 
(epoch: 64, iters: 4384, time: 0.159, data: 0.000) loss: 0.910 
(epoch: 64, iters: 4464, time: 0.158, data: 0.005) loss: 0.377 
(epoch: 64, iters: 4544, time: 0.160, data: 0.008) loss: 0.937 
(epoch: 64, iters: 4624, time: 0.160, data: 0.000) loss: 0.396 
(epoch: 64, iters: 4704, time: 0.162, data: 0.000) loss: 0.402 
(epoch: 64, iters: 4784, time: 0.161, data: 0.000) loss: 0.718 
(epoch: 64, iters: 4864, time: 0.161, data: 0.011) loss: 0.630 
(epoch: 64, iters: 4944, time: 0.161, data: 0.000) loss: 0.899 
(epoch: 64, iters: 5024, time: 0.162, data: 0.008) loss: 0.352 
(epoch: 64, iters: 5104, time: 0.160, data: 0.000) loss: 0.611 
(epoch: 64, iters: 5184, time: 0.158, data: 0.025) loss: 1.124 
(epoch: 64, iters: 5264, time: 0.162, data: 0.000) loss: 1.073 
(epoch: 64, iters: 5344, time: 0.159, data: 0.007) loss: 0.643 
(epoch: 64, iters: 5424, time: 0.162, data: 0.008) loss: 0.635 
(epoch: 64, iters: 5504, time: 0.160, data: 0.012) loss: 0.825 
(epoch: 64, iters: 5584, time: 0.160, data: 0.000) loss: 0.568 
(epoch: 64, iters: 5664, time: 0.160, data: 0.000) loss: 0.707 
(epoch: 64, iters: 5744, time: 0.168, data: 0.008) loss: 0.596 
(epoch: 64, iters: 5824, time: 0.158, data: 0.000) loss: 0.655 
(epoch: 64, iters: 5904, time: 0.161, data: 0.032) loss: 0.728 
(epoch: 64, iters: 5984, time: 0.159, data: 0.000) loss: 0.831 
(epoch: 64, iters: 6064, time: 0.159, data: 0.005) loss: 0.707 
(epoch: 64, iters: 6144, time: 0.161, data: 0.000) loss: 0.923 
(epoch: 64, iters: 6224, time: 0.158, data: 0.000) loss: 0.865 
(epoch: 64, iters: 6304, time: 0.163, data: 0.028) loss: 0.754 
(epoch: 64, iters: 6384, time: 0.159, data: 0.008) loss: 0.177 
(epoch: 64, iters: 6464, time: 0.160, data: 0.000) loss: 0.327 
(epoch: 64, iters: 6544, time: 0.159, data: 0.010) loss: 0.711 
(epoch: 64, iters: 6624, time: 0.159, data: 0.000) loss: 0.579 
(epoch: 64, iters: 6704, time: 0.160, data: 0.000) loss: 0.911 
(epoch: 64, iters: 6784, time: 0.159, data: 0.005) loss: 2.485 
(epoch: 64, iters: 6864, time: 0.160, data: 0.000) loss: 0.757 
(epoch: 64, iters: 6944, time: 0.159, data: 0.000) loss: 0.501 
(epoch: 64, iters: 7024, time: 0.160, data: 0.000) loss: 0.577 
(epoch: 64, iters: 7104, time: 0.158, data: 0.000) loss: 0.327 
(epoch: 64, iters: 7184, time: 0.160, data: 0.008) loss: 1.994 
(epoch: 64, iters: 7264, time: 0.159, data: 0.000) loss: 1.723 
(epoch: 64, iters: 7344, time: 0.159, data: 0.005) loss: 0.616 
(epoch: 64, iters: 7424, time: 0.159, data: 0.005) loss: 0.368 
(epoch: 64, iters: 7504, time: 0.158, data: 0.000) loss: 0.521 
(epoch: 64, iters: 7584, time: 0.160, data: 0.010) loss: 0.759 
(epoch: 64, iters: 7664, time: 0.157, data: 0.030) loss: 0.859 
(epoch: 64, iters: 7744, time: 0.160, data: 0.000) loss: 0.507 
(epoch: 64, iters: 7824, time: 0.158, data: 0.000) loss: 1.104 
(epoch: 64, iters: 7904, time: 0.158, data: 0.022) loss: 1.171 
(epoch: 64, iters: 7984, time: 0.156, data: 0.008) loss: 0.836 
saving the latest model (epoch 64, total_steps 650112)
(epoch: 64, iters: 8064, time: 0.161, data: 0.017) loss: 0.742 
(epoch: 64, iters: 8144, time: 0.160, data: 0.010) loss: 0.217 
(epoch: 64, iters: 8224, time: 0.166, data: 0.034) loss: 0.406 
(epoch: 64, iters: 8304, time: 0.161, data: 0.000) loss: 1.040 
(epoch: 64, iters: 8384, time: 0.162, data: 0.000) loss: 0.539 
(epoch: 64, iters: 8464, time: 0.187, data: 0.000) loss: 0.837 
(epoch: 64, iters: 8544, time: 0.161, data: 0.015) loss: 1.264 
(epoch: 64, iters: 8624, time: 0.161, data: 0.014) loss: 1.021 
(epoch: 64, iters: 8704, time: 0.161, data: 0.008) loss: 1.536 
(epoch: 64, iters: 8784, time: 0.166, data: 0.000) loss: 0.438 
(epoch: 64, iters: 8864, time: 0.161, data: 0.006) loss: 0.858 
(epoch: 64, iters: 8944, time: 0.164, data: 0.008) loss: 1.023 
(epoch: 64, iters: 9024, time: 0.159, data: 0.005) loss: 0.660 
(epoch: 64, iters: 9104, time: 0.163, data: 0.005) loss: 0.670 
(epoch: 64, iters: 9184, time: 0.160, data: 0.008) loss: 0.624 
(epoch: 64, iters: 9264, time: 0.165, data: 0.021) loss: 0.309 
(epoch: 64, iters: 9344, time: 0.162, data: 0.000) loss: 0.385 
(epoch: 64, iters: 9424, time: 0.161, data: 0.000) loss: 1.188 
(epoch: 64, iters: 9504, time: 0.159, data: 0.009) loss: 0.511 
(epoch: 64, iters: 9584, time: 0.159, data: 0.005) loss: 0.420 
(epoch: 64, iters: 9664, time: 0.162, data: 0.005) loss: 0.885 
(epoch: 64, iters: 9744, time: 0.158, data: 0.000) loss: 0.539 
(epoch: 64, iters: 9824, time: 0.159, data: 0.024) loss: 0.637 
(epoch: 64, iters: 9904, time: 0.158, data: 0.009) loss: 0.875 
(epoch: 64, iters: 9984, time: 0.160, data: 0.000) loss: 1.029 
(epoch: 64, iters: 10064, time: 0.159, data: 0.000) loss: 0.473 
(epoch: 64, iters: 10144, time: 0.156, data: 0.000) loss: 1.317 
saving the model at the end of epoch 64, iters 652288
End of epoch 64 / 200 	 Time Taken: 1638 sec
learning rate = 0.0002000
saving the latest model (epoch 65, total_steps 652304)
(epoch: 65, iters: 32, time: 0.168, data: 0.012) loss: 0.802 
(epoch: 65, iters: 112, time: 0.157, data: 0.000) loss: 1.174 
(epoch: 65, iters: 192, time: 0.162, data: 0.000) loss: 0.293 
(epoch: 65, iters: 272, time: 0.159, data: 0.010) loss: 0.291 
(epoch: 65, iters: 352, time: 0.161, data: 0.017) loss: 0.702 
(epoch: 65, iters: 432, time: 0.160, data: 0.000) loss: 0.609 
(epoch: 65, iters: 512, time: 0.159, data: 0.023) loss: 0.665 
(epoch: 65, iters: 592, time: 0.157, data: 0.000) loss: 0.443 
(epoch: 65, iters: 672, time: 0.161, data: 0.000) loss: 0.260 
(epoch: 65, iters: 752, time: 0.158, data: 0.017) loss: 0.964 
(epoch: 65, iters: 832, time: 0.159, data: 0.016) loss: 1.102 
(epoch: 65, iters: 912, time: 0.156, data: 0.006) loss: 1.522 
(epoch: 65, iters: 992, time: 0.159, data: 0.000) loss: 1.283 
(epoch: 65, iters: 1072, time: 0.156, data: 0.006) loss: 0.545 
(epoch: 65, iters: 1152, time: 0.157, data: 0.000) loss: 0.623 
(epoch: 65, iters: 1232, time: 0.157, data: 0.000) loss: 1.005 
(epoch: 65, iters: 1312, time: 0.158, data: 0.005) loss: 0.750 
(epoch: 65, iters: 1392, time: 0.157, data: 0.009) loss: 0.650 
(epoch: 65, iters: 1472, time: 0.160, data: 0.008) loss: 0.688 
(epoch: 65, iters: 1552, time: 0.158, data: 0.009) loss: 0.559 
(epoch: 65, iters: 1632, time: 0.157, data: 0.024) loss: 0.601 
(epoch: 65, iters: 1712, time: 0.160, data: 0.000) loss: 0.402 
(epoch: 65, iters: 1792, time: 0.159, data: 0.005) loss: 0.731 
(epoch: 65, iters: 1872, time: 0.158, data: 0.000) loss: 1.070 
(epoch: 65, iters: 1952, time: 0.158, data: 0.041) loss: 0.589 
(epoch: 65, iters: 2032, time: 0.157, data: 0.000) loss: 1.230 
(epoch: 65, iters: 2112, time: 0.158, data: 0.010) loss: 1.056 
(epoch: 65, iters: 2192, time: 0.157, data: 0.000) loss: 0.615 
(epoch: 65, iters: 2272, time: 0.161, data: 0.017) loss: 0.733 
(epoch: 65, iters: 2352, time: 0.159, data: 0.008) loss: 0.454 
(epoch: 65, iters: 2432, time: 0.161, data: 0.000) loss: 0.701 
(epoch: 65, iters: 2512, time: 0.158, data: 0.000) loss: 0.639 
(epoch: 65, iters: 2592, time: 0.159, data: 0.000) loss: 1.325 
(epoch: 65, iters: 2672, time: 0.158, data: 0.006) loss: 1.355 
(epoch: 65, iters: 2752, time: 0.159, data: 0.005) loss: 0.438 
(epoch: 65, iters: 2832, time: 0.158, data: 0.000) loss: 0.793 
(epoch: 65, iters: 2912, time: 0.158, data: 0.000) loss: 0.940 
(epoch: 65, iters: 2992, time: 0.160, data: 0.021) loss: 1.103 
(epoch: 65, iters: 3072, time: 0.157, data: 0.019) loss: 0.625 
(epoch: 65, iters: 3152, time: 0.158, data: 0.000) loss: 0.455 
(epoch: 65, iters: 3232, time: 0.159, data: 0.000) loss: 0.665 
(epoch: 65, iters: 3312, time: 0.161, data: 0.000) loss: 0.527 
(epoch: 65, iters: 3392, time: 0.158, data: 0.017) loss: 1.023 
(epoch: 65, iters: 3472, time: 0.157, data: 0.000) loss: 0.720 
(epoch: 65, iters: 3552, time: 0.157, data: 0.005) loss: 0.342 
(epoch: 65, iters: 3632, time: 0.159, data: 0.000) loss: 0.486 
(epoch: 65, iters: 3712, time: 0.170, data: 0.009) loss: 0.501 
(epoch: 65, iters: 3792, time: 0.160, data: 0.020) loss: 0.643 
(epoch: 65, iters: 3872, time: 0.161, data: 0.000) loss: 0.613 
(epoch: 65, iters: 3952, time: 0.156, data: 0.032) loss: 0.256 
saving the latest model (epoch 65, total_steps 656304)
(epoch: 65, iters: 4032, time: 0.161, data: 0.000) loss: 0.813 
(epoch: 65, iters: 4112, time: 0.156, data: 0.020) loss: 0.940 
(epoch: 65, iters: 4192, time: 0.158, data: 0.013) loss: 0.892 
(epoch: 65, iters: 4272, time: 0.158, data: 0.000) loss: 0.268 
(epoch: 65, iters: 4352, time: 0.158, data: 0.005) loss: 0.635 
(epoch: 65, iters: 4432, time: 0.161, data: 0.000) loss: 0.326 
(epoch: 65, iters: 4512, time: 0.158, data: 0.000) loss: 0.922 
(epoch: 65, iters: 4592, time: 0.160, data: 0.025) loss: 0.551 
(epoch: 65, iters: 4672, time: 0.158, data: 0.000) loss: 0.828 
(epoch: 65, iters: 4752, time: 0.156, data: 0.000) loss: 0.333 
(epoch: 65, iters: 4832, time: 0.165, data: 0.000) loss: 0.541 
(epoch: 65, iters: 4912, time: 0.157, data: 0.008) loss: 0.308 
(epoch: 65, iters: 4992, time: 0.157, data: 0.005) loss: 0.801 
(epoch: 65, iters: 5072, time: 0.160, data: 0.015) loss: 0.692 
(epoch: 65, iters: 5152, time: 0.157, data: 0.005) loss: 0.747 
(epoch: 65, iters: 5232, time: 0.158, data: 0.008) loss: 1.445 
(epoch: 65, iters: 5312, time: 0.158, data: 0.000) loss: 0.801 
(epoch: 65, iters: 5392, time: 0.158, data: 0.000) loss: 0.674 
(epoch: 65, iters: 5472, time: 0.156, data: 0.009) loss: 0.706 
(epoch: 65, iters: 5552, time: 0.157, data: 0.000) loss: 1.413 
(epoch: 65, iters: 5632, time: 0.156, data: 0.000) loss: 0.499 
(epoch: 65, iters: 5712, time: 0.159, data: 0.008) loss: 1.050 
(epoch: 65, iters: 5792, time: 0.160, data: 0.000) loss: 1.342 
(epoch: 65, iters: 5872, time: 0.160, data: 0.000) loss: 0.641 
(epoch: 65, iters: 5952, time: 0.158, data: 0.006) loss: 0.958 
(epoch: 65, iters: 6032, time: 0.154, data: 0.000) loss: 0.583 
(epoch: 65, iters: 6112, time: 0.156, data: 0.005) loss: 1.103 
(epoch: 65, iters: 6192, time: 0.156, data: 0.000) loss: 0.638 
(epoch: 65, iters: 6272, time: 0.157, data: 0.009) loss: 0.336 
(epoch: 65, iters: 6352, time: 0.155, data: 0.000) loss: 0.539 
(epoch: 65, iters: 6432, time: 0.159, data: 0.005) loss: 0.736 
(epoch: 65, iters: 6512, time: 0.160, data: 0.000) loss: 0.559 
(epoch: 65, iters: 6592, time: 0.157, data: 0.000) loss: 0.360 
(epoch: 65, iters: 6672, time: 0.156, data: 0.014) loss: 0.525 
(epoch: 65, iters: 6752, time: 0.158, data: 0.000) loss: 0.776 
(epoch: 65, iters: 6832, time: 0.156, data: 0.000) loss: 0.237 
(epoch: 65, iters: 6912, time: 0.156, data: 0.000) loss: 0.362 
(epoch: 65, iters: 6992, time: 0.159, data: 0.000) loss: 1.433 
(epoch: 65, iters: 7072, time: 0.156, data: 0.005) loss: 0.540 
(epoch: 65, iters: 7152, time: 0.156, data: 0.009) loss: 0.738 
(epoch: 65, iters: 7232, time: 0.160, data: 0.008) loss: 0.882 
(epoch: 65, iters: 7312, time: 0.155, data: 0.000) loss: 0.469 
(epoch: 65, iters: 7392, time: 0.157, data: 0.000) loss: 1.041 
(epoch: 65, iters: 7472, time: 0.157, data: 0.000) loss: 0.919 
(epoch: 65, iters: 7552, time: 0.157, data: 0.000) loss: 0.542 
(epoch: 65, iters: 7632, time: 0.161, data: 0.024) loss: 0.790 
(epoch: 65, iters: 7712, time: 0.159, data: 0.000) loss: 0.978 
(epoch: 65, iters: 7792, time: 0.159, data: 0.032) loss: 0.830 
(epoch: 65, iters: 7872, time: 0.161, data: 0.000) loss: 0.323 
(epoch: 65, iters: 7952, time: 0.159, data: 0.040) loss: 1.240 
saving the latest model (epoch 65, total_steps 660304)
(epoch: 65, iters: 8032, time: 0.164, data: 0.000) loss: 0.747 
(epoch: 65, iters: 8112, time: 0.160, data: 0.000) loss: 0.556 
(epoch: 65, iters: 8192, time: 0.158, data: 0.000) loss: 0.826 
(epoch: 65, iters: 8272, time: 0.156, data: 0.018) loss: 0.573 
(epoch: 65, iters: 8352, time: 0.160, data: 0.009) loss: 0.286 
(epoch: 65, iters: 8432, time: 0.156, data: 0.000) loss: 0.617 
(epoch: 65, iters: 8512, time: 0.157, data: 0.005) loss: 0.568 
(epoch: 65, iters: 8592, time: 0.157, data: 0.000) loss: 1.219 
(epoch: 65, iters: 8672, time: 0.158, data: 0.006) loss: 0.677 
(epoch: 65, iters: 8752, time: 0.162, data: 0.000) loss: 0.665 
(epoch: 65, iters: 8832, time: 0.156, data: 0.000) loss: 0.395 
(epoch: 65, iters: 8912, time: 0.159, data: 0.005) loss: 0.768 
(epoch: 65, iters: 8992, time: 0.158, data: 0.000) loss: 1.147 
(epoch: 65, iters: 9072, time: 0.158, data: 0.000) loss: 0.727 
(epoch: 65, iters: 9152, time: 0.155, data: 0.028) loss: 0.353 
(epoch: 65, iters: 9232, time: 0.159, data: 0.000) loss: 0.400 
(epoch: 65, iters: 9312, time: 0.159, data: 0.006) loss: 1.362 
(epoch: 65, iters: 9392, time: 0.160, data: 0.000) loss: 0.597 
(epoch: 65, iters: 9472, time: 0.156, data: 0.000) loss: 1.000 
(epoch: 65, iters: 9552, time: 0.157, data: 0.008) loss: 0.824 
(epoch: 65, iters: 9632, time: 0.158, data: 0.006) loss: 0.349 
(epoch: 65, iters: 9712, time: 0.159, data: 0.000) loss: 0.717 
(epoch: 65, iters: 9792, time: 0.160, data: 0.000) loss: 0.965 
(epoch: 65, iters: 9872, time: 0.158, data: 0.005) loss: 0.428 
(epoch: 65, iters: 9952, time: 0.160, data: 0.006) loss: 0.451 
(epoch: 65, iters: 10032, time: 0.159, data: 0.000) loss: 0.458 
(epoch: 65, iters: 10112, time: 0.162, data: 0.000) loss: 0.870 
(epoch: 65, iters: 10192, time: 0.096, data: 0.000) loss: 0.919 
saving the model at the end of epoch 65, iters 662480
End of epoch 65 / 200 	 Time Taken: 1617 sec
learning rate = 0.0002000
saving the latest model (epoch 66, total_steps 662496)
(epoch: 66, iters: 80, time: 0.160, data: 0.187) loss: 0.617 
(epoch: 66, iters: 160, time: 0.160, data: 0.010) loss: 0.450 
(epoch: 66, iters: 240, time: 0.161, data: 0.000) loss: 0.312 
(epoch: 66, iters: 320, time: 0.164, data: 0.000) loss: 0.708 
(epoch: 66, iters: 400, time: 0.160, data: 0.000) loss: 0.857 
(epoch: 66, iters: 480, time: 0.159, data: 0.000) loss: 0.768 
(epoch: 66, iters: 560, time: 0.169, data: 0.021) loss: 0.648 
(epoch: 66, iters: 640, time: 0.160, data: 0.000) loss: 0.764 
(epoch: 66, iters: 720, time: 0.158, data: 0.000) loss: 0.598 
(epoch: 66, iters: 800, time: 0.163, data: 0.014) loss: 0.548 
(epoch: 66, iters: 880, time: 0.163, data: 0.000) loss: 0.708 
(epoch: 66, iters: 960, time: 0.162, data: 0.014) loss: 1.022 
(epoch: 66, iters: 1040, time: 0.159, data: 0.025) loss: 0.486 
(epoch: 66, iters: 1120, time: 0.160, data: 0.005) loss: 1.043 
(epoch: 66, iters: 1200, time: 0.160, data: 0.000) loss: 0.755 
(epoch: 66, iters: 1280, time: 0.161, data: 0.018) loss: 0.299 
(epoch: 66, iters: 1360, time: 0.160, data: 0.021) loss: 0.976 
(epoch: 66, iters: 1440, time: 0.161, data: 0.000) loss: 0.412 
(epoch: 66, iters: 1520, time: 0.158, data: 0.000) loss: 0.613 
(epoch: 66, iters: 1600, time: 0.160, data: 0.016) loss: 0.432 
(epoch: 66, iters: 1680, time: 0.164, data: 0.027) loss: 0.714 
(epoch: 66, iters: 1760, time: 0.160, data: 0.000) loss: 0.815 
(epoch: 66, iters: 1840, time: 0.159, data: 0.000) loss: 0.866 
(epoch: 66, iters: 1920, time: 0.160, data: 0.026) loss: 0.552 
(epoch: 66, iters: 2000, time: 0.160, data: 0.000) loss: 1.172 
(epoch: 66, iters: 2080, time: 0.160, data: 0.014) loss: 0.789 
(epoch: 66, iters: 2160, time: 0.159, data: 0.000) loss: 0.442 
(epoch: 66, iters: 2240, time: 0.158, data: 0.000) loss: 0.478 
(epoch: 66, iters: 2320, time: 0.160, data: 0.000) loss: 1.110 
(epoch: 66, iters: 2400, time: 0.161, data: 0.000) loss: 0.278 
(epoch: 66, iters: 2480, time: 0.161, data: 0.000) loss: 0.233 
(epoch: 66, iters: 2560, time: 0.160, data: 0.000) loss: 0.783 
(epoch: 66, iters: 2640, time: 0.160, data: 0.006) loss: 1.011 
(epoch: 66, iters: 2720, time: 0.161, data: 0.000) loss: 0.394 
(epoch: 66, iters: 2800, time: 0.160, data: 0.006) loss: 1.023 
(epoch: 66, iters: 2880, time: 0.170, data: 0.005) loss: 0.634 
(epoch: 66, iters: 2960, time: 0.160, data: 0.000) loss: 1.793 
(epoch: 66, iters: 3040, time: 0.159, data: 0.000) loss: 0.721 
(epoch: 66, iters: 3120, time: 0.160, data: 0.000) loss: 0.816 
(epoch: 66, iters: 3200, time: 0.160, data: 0.015) loss: 1.105 
(epoch: 66, iters: 3280, time: 0.161, data: 0.010) loss: 0.607 
(epoch: 66, iters: 3360, time: 0.164, data: 0.000) loss: 0.635 
(epoch: 66, iters: 3440, time: 0.162, data: 0.000) loss: 1.051 
(epoch: 66, iters: 3520, time: 0.161, data: 0.009) loss: 0.756 
(epoch: 66, iters: 3600, time: 0.161, data: 0.000) loss: 0.878 
(epoch: 66, iters: 3680, time: 0.164, data: 0.011) loss: 0.597 
(epoch: 66, iters: 3760, time: 0.158, data: 0.005) loss: 0.550 
(epoch: 66, iters: 3840, time: 0.159, data: 0.008) loss: 0.534 
(epoch: 66, iters: 3920, time: 0.158, data: 0.014) loss: 0.784 
(epoch: 66, iters: 4000, time: 0.161, data: 0.000) loss: 0.884 
saving the latest model (epoch 66, total_steps 666496)
(epoch: 66, iters: 4080, time: 0.160, data: 0.000) loss: 0.446 
(epoch: 66, iters: 4160, time: 0.163, data: 0.000) loss: 0.529 
(epoch: 66, iters: 4240, time: 0.161, data: 0.022) loss: 1.026 
(epoch: 66, iters: 4320, time: 0.160, data: 0.000) loss: 1.278 
(epoch: 66, iters: 4400, time: 0.163, data: 0.013) loss: 0.577 
(epoch: 66, iters: 4480, time: 0.161, data: 0.000) loss: 0.690 
(epoch: 66, iters: 4560, time: 0.160, data: 0.000) loss: 1.169 
(epoch: 66, iters: 4640, time: 0.160, data: 0.000) loss: 0.352 
(epoch: 66, iters: 4720, time: 0.162, data: 0.024) loss: 0.955 
(epoch: 66, iters: 4800, time: 0.164, data: 0.000) loss: 0.956 
(epoch: 66, iters: 4880, time: 0.161, data: 0.000) loss: 0.353 
(epoch: 66, iters: 4960, time: 0.160, data: 0.007) loss: 0.848 
(epoch: 66, iters: 5040, time: 0.159, data: 0.000) loss: 0.524 
(epoch: 66, iters: 5120, time: 0.157, data: 0.000) loss: 0.466 
(epoch: 66, iters: 5200, time: 0.160, data: 0.000) loss: 1.134 
(epoch: 66, iters: 5280, time: 0.160, data: 0.000) loss: 0.412 
(epoch: 66, iters: 5360, time: 0.159, data: 0.008) loss: 0.697 
(epoch: 66, iters: 5440, time: 0.159, data: 0.018) loss: 0.300 
(epoch: 66, iters: 5520, time: 0.162, data: 0.000) loss: 0.545 
(epoch: 66, iters: 5600, time: 0.160, data: 0.000) loss: 0.231 
(epoch: 66, iters: 5680, time: 0.159, data: 0.000) loss: 0.708 
(epoch: 66, iters: 5760, time: 0.158, data: 0.005) loss: 0.427 
(epoch: 66, iters: 5840, time: 0.161, data: 0.000) loss: 0.437 
(epoch: 66, iters: 5920, time: 0.160, data: 0.000) loss: 1.417 
(epoch: 66, iters: 6000, time: 0.160, data: 0.000) loss: 0.406 
(epoch: 66, iters: 6080, time: 0.163, data: 0.030) loss: 0.662 
(epoch: 66, iters: 6160, time: 0.160, data: 0.000) loss: 0.726 
(epoch: 66, iters: 6240, time: 0.157, data: 0.000) loss: 0.568 
(epoch: 66, iters: 6320, time: 0.161, data: 0.033) loss: 0.621 
(epoch: 66, iters: 6400, time: 0.160, data: 0.000) loss: 0.502 
(epoch: 66, iters: 6480, time: 0.161, data: 0.000) loss: 0.682 
(epoch: 66, iters: 6560, time: 0.162, data: 0.000) loss: 0.971 
(epoch: 66, iters: 6640, time: 0.163, data: 0.005) loss: 0.424 
(epoch: 66, iters: 6720, time: 0.160, data: 0.005) loss: 1.047 
(epoch: 66, iters: 6800, time: 0.158, data: 0.009) loss: 0.889 
(epoch: 66, iters: 6880, time: 0.162, data: 0.000) loss: 0.858 
(epoch: 66, iters: 6960, time: 0.159, data: 0.010) loss: 0.094 
(epoch: 66, iters: 7040, time: 0.160, data: 0.000) loss: 0.620 
(epoch: 66, iters: 7120, time: 0.165, data: 0.005) loss: 0.562 
(epoch: 66, iters: 7200, time: 0.159, data: 0.000) loss: 0.850 
(epoch: 66, iters: 7280, time: 0.160, data: 0.000) loss: 0.596 
(epoch: 66, iters: 7360, time: 0.158, data: 0.000) loss: 0.532 
(epoch: 66, iters: 7440, time: 0.160, data: 0.000) loss: 0.824 
(epoch: 66, iters: 7520, time: 0.161, data: 0.017) loss: 0.166 
(epoch: 66, iters: 7600, time: 0.159, data: 0.000) loss: 0.677 
(epoch: 66, iters: 7680, time: 0.159, data: 0.015) loss: 0.669 
(epoch: 66, iters: 7760, time: 0.159, data: 0.000) loss: 0.935 
(epoch: 66, iters: 7840, time: 0.158, data: 0.000) loss: 0.854 
(epoch: 66, iters: 7920, time: 0.158, data: 0.020) loss: 0.879 
(epoch: 66, iters: 8000, time: 0.160, data: 0.024) loss: 0.393 
saving the latest model (epoch 66, total_steps 670496)
(epoch: 66, iters: 8080, time: 0.158, data: 0.000) loss: 0.816 
(epoch: 66, iters: 8160, time: 0.159, data: 0.011) loss: 0.396 
(epoch: 66, iters: 8240, time: 0.159, data: 0.000) loss: 0.540 
(epoch: 66, iters: 8320, time: 0.159, data: 0.019) loss: 0.480 
(epoch: 66, iters: 8400, time: 0.161, data: 0.000) loss: 0.166 
(epoch: 66, iters: 8480, time: 0.159, data: 0.022) loss: 0.992 
(epoch: 66, iters: 8560, time: 0.159, data: 0.000) loss: 0.688 
(epoch: 66, iters: 8640, time: 0.161, data: 0.000) loss: 1.046 
(epoch: 66, iters: 8720, time: 0.160, data: 0.000) loss: 0.306 
(epoch: 66, iters: 8800, time: 0.162, data: 0.010) loss: 0.584 
(epoch: 66, iters: 8880, time: 0.162, data: 0.005) loss: 0.878 
(epoch: 66, iters: 8960, time: 0.158, data: 0.022) loss: 0.977 
(epoch: 66, iters: 9040, time: 0.162, data: 0.000) loss: 0.839 
(epoch: 66, iters: 9120, time: 0.161, data: 0.017) loss: 0.844 
(epoch: 66, iters: 9200, time: 0.159, data: 0.000) loss: 0.425 
(epoch: 66, iters: 9280, time: 0.160, data: 0.027) loss: 0.901 
(epoch: 66, iters: 9360, time: 0.159, data: 0.000) loss: 1.294 
(epoch: 66, iters: 9440, time: 0.166, data: 0.000) loss: 0.699 
(epoch: 66, iters: 9520, time: 0.159, data: 0.000) loss: 1.020 
(epoch: 66, iters: 9600, time: 0.159, data: 0.018) loss: 0.410 
(epoch: 66, iters: 9680, time: 0.159, data: 0.022) loss: 0.453 
(epoch: 66, iters: 9760, time: 0.157, data: 0.000) loss: 0.905 
(epoch: 66, iters: 9840, time: 0.158, data: 0.000) loss: 0.371 
(epoch: 66, iters: 9920, time: 0.160, data: 0.005) loss: 0.538 
(epoch: 66, iters: 10000, time: 0.159, data: 0.000) loss: 0.837 
(epoch: 66, iters: 10080, time: 0.162, data: 0.000) loss: 0.557 
(epoch: 66, iters: 10160, time: 0.159, data: 0.005) loss: 0.381 
saving the model at the end of epoch 66, iters 672672
End of epoch 66 / 200 	 Time Taken: 1639 sec
learning rate = 0.0002000
saving the latest model (epoch 67, total_steps 672688)
(epoch: 67, iters: 48, time: 0.164, data: 0.000) loss: 0.827 
(epoch: 67, iters: 128, time: 0.163, data: 0.010) loss: 0.354 
(epoch: 67, iters: 208, time: 0.160, data: 0.009) loss: 0.360 
(epoch: 67, iters: 288, time: 0.158, data: 0.000) loss: 0.959 
(epoch: 67, iters: 368, time: 0.160, data: 0.000) loss: 0.709 
(epoch: 67, iters: 448, time: 0.158, data: 0.000) loss: 0.894 
(epoch: 67, iters: 528, time: 0.156, data: 0.019) loss: 0.529 
(epoch: 67, iters: 608, time: 0.156, data: 0.009) loss: 1.138 
(epoch: 67, iters: 688, time: 0.159, data: 0.000) loss: 0.284 
(epoch: 67, iters: 768, time: 0.158, data: 0.022) loss: 0.612 
(epoch: 67, iters: 848, time: 0.157, data: 0.000) loss: 0.968 
(epoch: 67, iters: 928, time: 0.157, data: 0.008) loss: 0.579 
(epoch: 67, iters: 1008, time: 0.160, data: 0.006) loss: 0.645 
(epoch: 67, iters: 1088, time: 0.155, data: 0.000) loss: 0.498 
(epoch: 67, iters: 1168, time: 0.160, data: 0.006) loss: 0.404 
(epoch: 67, iters: 1248, time: 0.158, data: 0.009) loss: 0.730 
(epoch: 67, iters: 1328, time: 0.160, data: 0.006) loss: 0.957 
(epoch: 67, iters: 1408, time: 0.159, data: 0.000) loss: 0.284 
(epoch: 67, iters: 1488, time: 0.161, data: 0.000) loss: 1.021 
(epoch: 67, iters: 1568, time: 0.156, data: 0.016) loss: 1.076 
(epoch: 67, iters: 1648, time: 0.159, data: 0.000) loss: 0.647 
(epoch: 67, iters: 1728, time: 0.157, data: 0.018) loss: 0.687 
(epoch: 67, iters: 1808, time: 0.157, data: 0.024) loss: 0.591 
(epoch: 67, iters: 1888, time: 0.159, data: 0.000) loss: 0.458 
(epoch: 67, iters: 1968, time: 0.165, data: 0.000) loss: 0.738 
(epoch: 67, iters: 2048, time: 0.157, data: 0.000) loss: 0.416 
(epoch: 67, iters: 2128, time: 0.158, data: 0.000) loss: 0.659 
(epoch: 67, iters: 2208, time: 0.159, data: 0.005) loss: 0.439 
(epoch: 67, iters: 2288, time: 0.157, data: 0.000) loss: 0.677 
(epoch: 67, iters: 2368, time: 0.162, data: 0.037) loss: 0.509 
(epoch: 67, iters: 2448, time: 0.160, data: 0.000) loss: 0.716 
(epoch: 67, iters: 2528, time: 0.158, data: 0.000) loss: 0.937 
(epoch: 67, iters: 2608, time: 0.158, data: 0.032) loss: 0.401 
(epoch: 67, iters: 2688, time: 0.158, data: 0.000) loss: 0.637 
(epoch: 67, iters: 2768, time: 0.160, data: 0.000) loss: 0.857 
(epoch: 67, iters: 2848, time: 0.161, data: 0.005) loss: 0.815 
(epoch: 67, iters: 2928, time: 0.156, data: 0.000) loss: 0.920 
(epoch: 67, iters: 3008, time: 0.159, data: 0.005) loss: 0.878 
(epoch: 67, iters: 3088, time: 0.160, data: 0.000) loss: 0.719 
(epoch: 67, iters: 3168, time: 0.157, data: 0.013) loss: 1.166 
(epoch: 67, iters: 3248, time: 0.160, data: 0.000) loss: 0.409 
(epoch: 67, iters: 3328, time: 0.159, data: 0.000) loss: 0.909 
(epoch: 67, iters: 3408, time: 0.162, data: 0.017) loss: 0.654 
(epoch: 67, iters: 3488, time: 0.158, data: 0.008) loss: 0.441 
(epoch: 67, iters: 3568, time: 0.157, data: 0.000) loss: 0.230 
(epoch: 67, iters: 3648, time: 0.158, data: 0.014) loss: 1.014 
(epoch: 67, iters: 3728, time: 0.158, data: 0.018) loss: 0.792 
(epoch: 67, iters: 3808, time: 0.160, data: 0.014) loss: 0.744 
(epoch: 67, iters: 3888, time: 0.157, data: 0.015) loss: 0.573 
(epoch: 67, iters: 3968, time: 0.160, data: 0.020) loss: 0.812 
saving the latest model (epoch 67, total_steps 676688)
(epoch: 67, iters: 4048, time: 0.157, data: 0.000) loss: 0.899 
(epoch: 67, iters: 4128, time: 0.157, data: 0.000) loss: 1.061 
(epoch: 67, iters: 4208, time: 0.157, data: 0.008) loss: 0.592 
(epoch: 67, iters: 4288, time: 0.158, data: 0.020) loss: 0.946 
(epoch: 67, iters: 4368, time: 0.157, data: 0.005) loss: 0.298 
(epoch: 67, iters: 4448, time: 0.156, data: 0.014) loss: 0.468 
(epoch: 67, iters: 4528, time: 0.156, data: 0.000) loss: 0.580 
(epoch: 67, iters: 4608, time: 0.157, data: 0.024) loss: 1.121 
(epoch: 67, iters: 4688, time: 0.158, data: 0.000) loss: 0.571 
(epoch: 67, iters: 4768, time: 0.160, data: 0.000) loss: 0.723 
(epoch: 67, iters: 4848, time: 0.159, data: 0.000) loss: 0.751 
(epoch: 67, iters: 4928, time: 0.157, data: 0.000) loss: 0.520 
(epoch: 67, iters: 5008, time: 0.158, data: 0.000) loss: 0.693 
(epoch: 67, iters: 5088, time: 0.158, data: 0.024) loss: 0.960 
(epoch: 67, iters: 5168, time: 0.157, data: 0.000) loss: 0.764 
(epoch: 67, iters: 5248, time: 0.156, data: 0.000) loss: 0.878 
(epoch: 67, iters: 5328, time: 0.158, data: 0.000) loss: 0.924 
(epoch: 67, iters: 5408, time: 0.158, data: 0.000) loss: 0.963 
(epoch: 67, iters: 5488, time: 0.160, data: 0.000) loss: 1.042 
(epoch: 67, iters: 5568, time: 0.156, data: 0.000) loss: 0.535 
(epoch: 67, iters: 5648, time: 0.157, data: 0.014) loss: 0.906 
(epoch: 67, iters: 5728, time: 0.159, data: 0.014) loss: 0.546 
(epoch: 67, iters: 5808, time: 0.159, data: 0.000) loss: 0.667 
(epoch: 67, iters: 5888, time: 0.161, data: 0.000) loss: 0.752 
(epoch: 67, iters: 5968, time: 0.160, data: 0.000) loss: 0.634 
(epoch: 67, iters: 6048, time: 0.157, data: 0.010) loss: 0.597 
(epoch: 67, iters: 6128, time: 0.157, data: 0.000) loss: 0.598 
(epoch: 67, iters: 6208, time: 0.158, data: 0.000) loss: 0.194 
(epoch: 67, iters: 6288, time: 0.162, data: 0.000) loss: 0.401 
(epoch: 67, iters: 6368, time: 0.159, data: 0.000) loss: 0.908 
(epoch: 67, iters: 6448, time: 0.158, data: 0.008) loss: 1.143 
(epoch: 67, iters: 6528, time: 0.158, data: 0.025) loss: 0.817 
(epoch: 67, iters: 6608, time: 0.158, data: 0.000) loss: 0.857 
(epoch: 67, iters: 6688, time: 0.156, data: 0.017) loss: 0.783 
(epoch: 67, iters: 6768, time: 0.160, data: 0.005) loss: 0.998 
(epoch: 67, iters: 6848, time: 0.157, data: 0.000) loss: 1.332 
(epoch: 67, iters: 6928, time: 0.157, data: 0.000) loss: 0.876 
(epoch: 67, iters: 7008, time: 0.160, data: 0.011) loss: 0.455 
(epoch: 67, iters: 7088, time: 0.158, data: 0.000) loss: 0.621 
(epoch: 67, iters: 7168, time: 0.158, data: 0.022) loss: 0.637 
(epoch: 67, iters: 7248, time: 0.158, data: 0.000) loss: 0.565 
(epoch: 67, iters: 7328, time: 0.157, data: 0.000) loss: 0.704 
(epoch: 67, iters: 7408, time: 0.154, data: 0.000) loss: 0.755 
(epoch: 67, iters: 7488, time: 0.158, data: 0.000) loss: 0.595 
(epoch: 67, iters: 7568, time: 0.160, data: 0.016) loss: 0.796 
(epoch: 67, iters: 7648, time: 0.157, data: 0.000) loss: 0.897 
(epoch: 67, iters: 7728, time: 0.159, data: 0.000) loss: 1.069 
(epoch: 67, iters: 7808, time: 0.158, data: 0.000) loss: 0.706 
(epoch: 67, iters: 7888, time: 0.159, data: 0.005) loss: 0.625 
(epoch: 67, iters: 7968, time: 0.158, data: 0.018) loss: 0.992 
saving the latest model (epoch 67, total_steps 680688)
(epoch: 67, iters: 8048, time: 0.158, data: 0.000) loss: 0.277 
(epoch: 67, iters: 8128, time: 0.162, data: 0.008) loss: 1.269 
(epoch: 67, iters: 8208, time: 0.157, data: 0.000) loss: 0.131 
(epoch: 67, iters: 8288, time: 0.159, data: 0.000) loss: 0.759 
(epoch: 67, iters: 8368, time: 0.156, data: 0.000) loss: 0.960 
(epoch: 67, iters: 8448, time: 0.157, data: 0.037) loss: 0.438 
(epoch: 67, iters: 8528, time: 0.160, data: 0.013) loss: 1.140 
(epoch: 67, iters: 8608, time: 0.159, data: 0.000) loss: 0.450 
(epoch: 67, iters: 8688, time: 0.157, data: 0.005) loss: 1.896 
(epoch: 67, iters: 8768, time: 0.158, data: 0.000) loss: 0.505 
(epoch: 67, iters: 8848, time: 0.157, data: 0.000) loss: 0.478 
(epoch: 67, iters: 8928, time: 0.157, data: 0.005) loss: 0.678 
(epoch: 67, iters: 9008, time: 0.161, data: 0.000) loss: 1.216 
(epoch: 67, iters: 9088, time: 0.158, data: 0.000) loss: 1.525 
(epoch: 67, iters: 9168, time: 0.156, data: 0.021) loss: 0.824 
(epoch: 67, iters: 9248, time: 0.158, data: 0.000) loss: 0.787 
(epoch: 67, iters: 9328, time: 0.156, data: 0.005) loss: 0.169 
(epoch: 67, iters: 9408, time: 0.158, data: 0.000) loss: 0.576 
(epoch: 67, iters: 9488, time: 0.158, data: 0.008) loss: 0.279 
(epoch: 67, iters: 9568, time: 0.155, data: 0.014) loss: 0.966 
(epoch: 67, iters: 9648, time: 0.157, data: 0.005) loss: 0.634 
(epoch: 67, iters: 9728, time: 0.157, data: 0.005) loss: 0.975 
(epoch: 67, iters: 9808, time: 0.162, data: 0.000) loss: 0.683 
(epoch: 67, iters: 9888, time: 0.157, data: 0.023) loss: 0.559 
(epoch: 67, iters: 9968, time: 0.156, data: 0.006) loss: 0.786 
(epoch: 67, iters: 10048, time: 0.159, data: 0.000) loss: 0.488 
(epoch: 67, iters: 10128, time: 0.156, data: 0.006) loss: 0.450 
saving the model at the end of epoch 67, iters 682864
End of epoch 67 / 200 	 Time Taken: 1616 sec
learning rate = 0.0002000
(epoch: 68, iters: 16, time: 0.188, data: 0.008) loss: 0.573 
saving the latest model (epoch 68, total_steps 682880)
(epoch: 68, iters: 96, time: 0.162, data: 0.035) loss: 1.360 
(epoch: 68, iters: 176, time: 0.161, data: 0.008) loss: 0.962 
(epoch: 68, iters: 256, time: 0.158, data: 0.000) loss: 0.774 
(epoch: 68, iters: 336, time: 0.162, data: 0.007) loss: 1.227 
(epoch: 68, iters: 416, time: 0.171, data: 0.000) loss: 0.456 
(epoch: 68, iters: 496, time: 0.159, data: 0.000) loss: 1.214 
(epoch: 68, iters: 576, time: 0.158, data: 0.000) loss: 0.578 
(epoch: 68, iters: 656, time: 0.158, data: 0.009) loss: 0.668 
(epoch: 68, iters: 736, time: 0.158, data: 0.000) loss: 0.936 
(epoch: 68, iters: 816, time: 0.159, data: 0.005) loss: 0.607 
(epoch: 68, iters: 896, time: 0.158, data: 0.000) loss: 0.928 
(epoch: 68, iters: 976, time: 0.161, data: 0.013) loss: 1.000 
(epoch: 68, iters: 1056, time: 0.159, data: 0.005) loss: 0.842 
(epoch: 68, iters: 1136, time: 0.158, data: 0.005) loss: 0.946 
(epoch: 68, iters: 1216, time: 0.158, data: 0.010) loss: 0.581 
(epoch: 68, iters: 1296, time: 0.154, data: 0.000) loss: 0.866 
(epoch: 68, iters: 1376, time: 0.160, data: 0.000) loss: 0.581 
(epoch: 68, iters: 1456, time: 0.158, data: 0.005) loss: 0.654 
(epoch: 68, iters: 1536, time: 0.160, data: 0.000) loss: 0.946 
(epoch: 68, iters: 1616, time: 0.159, data: 0.018) loss: 1.238 
(epoch: 68, iters: 1696, time: 0.158, data: 0.000) loss: 0.426 
(epoch: 68, iters: 1776, time: 0.157, data: 0.005) loss: 0.649 
(epoch: 68, iters: 1856, time: 0.156, data: 0.000) loss: 0.329 
(epoch: 68, iters: 1936, time: 0.159, data: 0.000) loss: 0.568 
(epoch: 68, iters: 2016, time: 0.156, data: 0.006) loss: 0.584 
(epoch: 68, iters: 2096, time: 0.162, data: 0.017) loss: 0.506 
(epoch: 68, iters: 2176, time: 0.159, data: 0.000) loss: 1.341 
(epoch: 68, iters: 2256, time: 0.161, data: 0.016) loss: 0.335 
(epoch: 68, iters: 2336, time: 0.164, data: 0.000) loss: 0.834 
(epoch: 68, iters: 2416, time: 0.161, data: 0.009) loss: 0.436 
(epoch: 68, iters: 2496, time: 0.163, data: 0.000) loss: 1.070 
(epoch: 68, iters: 2576, time: 0.162, data: 0.000) loss: 0.667 
(epoch: 68, iters: 2656, time: 0.161, data: 0.009) loss: 0.713 
(epoch: 68, iters: 2736, time: 0.165, data: 0.005) loss: 0.680 
(epoch: 68, iters: 2816, time: 0.160, data: 0.000) loss: 0.813 
(epoch: 68, iters: 2896, time: 0.160, data: 0.005) loss: 0.719 
(epoch: 68, iters: 2976, time: 0.159, data: 0.000) loss: 0.506 
(epoch: 68, iters: 3056, time: 0.162, data: 0.005) loss: 0.409 
(epoch: 68, iters: 3136, time: 0.161, data: 0.005) loss: 0.967 
(epoch: 68, iters: 3216, time: 0.161, data: 0.005) loss: 0.361 
(epoch: 68, iters: 3296, time: 0.162, data: 0.000) loss: 0.518 
(epoch: 68, iters: 3376, time: 0.160, data: 0.000) loss: 0.627 
(epoch: 68, iters: 3456, time: 0.156, data: 0.000) loss: 0.100 
(epoch: 68, iters: 3536, time: 0.159, data: 0.006) loss: 0.923 
(epoch: 68, iters: 3616, time: 0.158, data: 0.005) loss: 0.551 
(epoch: 68, iters: 3696, time: 0.161, data: 0.000) loss: 0.925 
(epoch: 68, iters: 3776, time: 0.159, data: 0.008) loss: 0.235 
(epoch: 68, iters: 3856, time: 0.157, data: 0.000) loss: 0.449 
(epoch: 68, iters: 3936, time: 0.161, data: 0.000) loss: 0.807 
(epoch: 68, iters: 4016, time: 0.158, data: 0.015) loss: 0.235 
saving the latest model (epoch 68, total_steps 686880)
(epoch: 68, iters: 4096, time: 0.158, data: 0.012) loss: 0.870 
(epoch: 68, iters: 4176, time: 0.157, data: 0.000) loss: 0.860 
(epoch: 68, iters: 4256, time: 0.158, data: 0.000) loss: 0.779 
(epoch: 68, iters: 4336, time: 0.160, data: 0.000) loss: 0.548 
(epoch: 68, iters: 4416, time: 0.161, data: 0.008) loss: 0.463 
(epoch: 68, iters: 4496, time: 0.163, data: 0.000) loss: 1.035 
(epoch: 68, iters: 4576, time: 0.159, data: 0.005) loss: 0.661 
(epoch: 68, iters: 4656, time: 0.161, data: 0.000) loss: 1.266 
(epoch: 68, iters: 4736, time: 0.162, data: 0.020) loss: 0.623 
(epoch: 68, iters: 4816, time: 0.162, data: 0.005) loss: 0.678 
(epoch: 68, iters: 4896, time: 0.161, data: 0.000) loss: 0.201 
(epoch: 68, iters: 4976, time: 0.158, data: 0.000) loss: 0.596 
(epoch: 68, iters: 5056, time: 0.168, data: 0.006) loss: 0.641 
(epoch: 68, iters: 5136, time: 0.160, data: 0.000) loss: 0.975 
(epoch: 68, iters: 5216, time: 0.158, data: 0.000) loss: 0.538 
(epoch: 68, iters: 5296, time: 0.161, data: 0.000) loss: 0.278 
(epoch: 68, iters: 5376, time: 0.159, data: 0.025) loss: 0.580 
(epoch: 68, iters: 5456, time: 0.160, data: 0.000) loss: 0.721 
(epoch: 68, iters: 5536, time: 0.162, data: 0.000) loss: 0.306 
(epoch: 68, iters: 5616, time: 0.159, data: 0.005) loss: 1.453 
(epoch: 68, iters: 5696, time: 0.159, data: 0.000) loss: 0.668 
(epoch: 68, iters: 5776, time: 0.162, data: 0.006) loss: 0.816 
(epoch: 68, iters: 5856, time: 0.160, data: 0.000) loss: 0.544 
(epoch: 68, iters: 5936, time: 0.159, data: 0.000) loss: 0.771 
(epoch: 68, iters: 6016, time: 0.160, data: 0.020) loss: 0.344 
(epoch: 68, iters: 6096, time: 0.159, data: 0.000) loss: 0.237 
(epoch: 68, iters: 6176, time: 0.161, data: 0.014) loss: 0.806 
(epoch: 68, iters: 6256, time: 0.160, data: 0.000) loss: 0.663 
(epoch: 68, iters: 6336, time: 0.161, data: 0.024) loss: 0.370 
(epoch: 68, iters: 6416, time: 0.161, data: 0.000) loss: 0.284 
(epoch: 68, iters: 6496, time: 0.162, data: 0.000) loss: 0.761 
(epoch: 68, iters: 6576, time: 0.160, data: 0.000) loss: 0.481 
(epoch: 68, iters: 6656, time: 0.164, data: 0.020) loss: 1.068 
(epoch: 68, iters: 6736, time: 0.158, data: 0.020) loss: 0.706 
(epoch: 68, iters: 6816, time: 0.161, data: 0.000) loss: 0.919 
(epoch: 68, iters: 6896, time: 0.161, data: 0.000) loss: 0.471 
(epoch: 68, iters: 6976, time: 0.163, data: 0.005) loss: 0.707 
(epoch: 68, iters: 7056, time: 0.158, data: 0.000) loss: 0.614 
(epoch: 68, iters: 7136, time: 0.159, data: 0.000) loss: 0.563 
(epoch: 68, iters: 7216, time: 0.161, data: 0.000) loss: 0.190 
(epoch: 68, iters: 7296, time: 0.161, data: 0.000) loss: 0.929 
(epoch: 68, iters: 7376, time: 0.163, data: 0.000) loss: 0.632 
(epoch: 68, iters: 7456, time: 0.160, data: 0.005) loss: 0.859 
(epoch: 68, iters: 7536, time: 0.160, data: 0.000) loss: 0.653 
(epoch: 68, iters: 7616, time: 0.160, data: 0.000) loss: 0.510 
(epoch: 68, iters: 7696, time: 0.160, data: 0.010) loss: 0.855 
(epoch: 68, iters: 7776, time: 0.159, data: 0.008) loss: 0.769 
(epoch: 68, iters: 7856, time: 0.159, data: 0.000) loss: 0.557 
(epoch: 68, iters: 7936, time: 0.162, data: 0.000) loss: 0.764 
(epoch: 68, iters: 8016, time: 0.159, data: 0.000) loss: 0.251 
saving the latest model (epoch 68, total_steps 690880)
(epoch: 68, iters: 8096, time: 0.160, data: 0.000) loss: 0.489 
(epoch: 68, iters: 8176, time: 0.157, data: 0.029) loss: 1.061 
(epoch: 68, iters: 8256, time: 0.159, data: 0.000) loss: 0.855 
(epoch: 68, iters: 8336, time: 0.158, data: 0.009) loss: 0.904 
(epoch: 68, iters: 8416, time: 0.160, data: 0.000) loss: 0.366 
(epoch: 68, iters: 8496, time: 0.158, data: 0.006) loss: 0.862 
(epoch: 68, iters: 8576, time: 0.156, data: 0.018) loss: 1.061 
(epoch: 68, iters: 8656, time: 0.156, data: 0.000) loss: 0.392 
(epoch: 68, iters: 8736, time: 0.160, data: 0.024) loss: 0.631 
(epoch: 68, iters: 8816, time: 0.159, data: 0.000) loss: 0.714 
(epoch: 68, iters: 8896, time: 0.156, data: 0.028) loss: 0.327 
(epoch: 68, iters: 8976, time: 0.157, data: 0.000) loss: 0.768 
(epoch: 68, iters: 9056, time: 0.157, data: 0.008) loss: 0.825 
(epoch: 68, iters: 9136, time: 0.157, data: 0.009) loss: 0.476 
(epoch: 68, iters: 9216, time: 0.161, data: 0.000) loss: 1.372 
(epoch: 68, iters: 9296, time: 0.157, data: 0.032) loss: 0.361 
(epoch: 68, iters: 9376, time: 0.159, data: 0.000) loss: 0.672 
(epoch: 68, iters: 9456, time: 0.157, data: 0.025) loss: 0.936 
(epoch: 68, iters: 9536, time: 0.161, data: 0.000) loss: 0.438 
(epoch: 68, iters: 9616, time: 0.159, data: 0.025) loss: 0.589 
(epoch: 68, iters: 9696, time: 0.161, data: 0.000) loss: 0.323 
(epoch: 68, iters: 9776, time: 0.159, data: 0.032) loss: 0.350 
(epoch: 68, iters: 9856, time: 0.160, data: 0.000) loss: 0.492 
(epoch: 68, iters: 9936, time: 0.159, data: 0.009) loss: 0.193 
(epoch: 68, iters: 10016, time: 0.162, data: 0.009) loss: 0.602 
(epoch: 68, iters: 10096, time: 0.159, data: 0.015) loss: 0.568 
(epoch: 68, iters: 10176, time: 0.160, data: 0.009) loss: 0.649 
saving the model at the end of epoch 68, iters 693056
End of epoch 68 / 200 	 Time Taken: 1631 sec
learning rate = 0.0002000
saving the latest model (epoch 69, total_steps 693072)
(epoch: 69, iters: 64, time: 0.159, data: 0.003) loss: 0.891 
(epoch: 69, iters: 144, time: 0.155, data: 0.024) loss: 0.698 
(epoch: 69, iters: 224, time: 0.155, data: 0.000) loss: 0.520 
(epoch: 69, iters: 304, time: 0.162, data: 0.000) loss: 0.493 
(epoch: 69, iters: 384, time: 0.155, data: 0.021) loss: 0.483 
(epoch: 69, iters: 464, time: 0.160, data: 0.000) loss: 0.323 
(epoch: 69, iters: 544, time: 0.154, data: 0.038) loss: 0.508 
(epoch: 69, iters: 624, time: 0.155, data: 0.000) loss: 0.530 
(epoch: 69, iters: 704, time: 0.163, data: 0.031) loss: 1.337 
(epoch: 69, iters: 784, time: 0.159, data: 0.000) loss: 1.034 
(epoch: 69, iters: 864, time: 0.159, data: 0.000) loss: 1.179 
(epoch: 69, iters: 944, time: 0.157, data: 0.000) loss: 0.788 
(epoch: 69, iters: 1024, time: 0.158, data: 0.000) loss: 0.295 
(epoch: 69, iters: 1104, time: 0.163, data: 0.025) loss: 0.567 
(epoch: 69, iters: 1184, time: 0.157, data: 0.000) loss: 0.623 
(epoch: 69, iters: 1264, time: 0.156, data: 0.010) loss: 0.532 
(epoch: 69, iters: 1344, time: 0.155, data: 0.000) loss: 0.362 
(epoch: 69, iters: 1424, time: 0.160, data: 0.000) loss: 0.861 
(epoch: 69, iters: 1504, time: 0.157, data: 0.006) loss: 0.485 
(epoch: 69, iters: 1584, time: 0.159, data: 0.000) loss: 0.590 
(epoch: 69, iters: 1664, time: 0.155, data: 0.005) loss: 0.599 
(epoch: 69, iters: 1744, time: 0.158, data: 0.000) loss: 0.881 
(epoch: 69, iters: 1824, time: 0.155, data: 0.017) loss: 0.398 
(epoch: 69, iters: 1904, time: 0.156, data: 0.005) loss: 1.001 
(epoch: 69, iters: 1984, time: 0.158, data: 0.005) loss: 0.687 
(epoch: 69, iters: 2064, time: 0.156, data: 0.009) loss: 0.372 
(epoch: 69, iters: 2144, time: 0.154, data: 0.000) loss: 0.486 
(epoch: 69, iters: 2224, time: 0.154, data: 0.028) loss: 0.474 
(epoch: 69, iters: 2304, time: 0.155, data: 0.000) loss: 0.484 
(epoch: 69, iters: 2384, time: 0.154, data: 0.010) loss: 1.382 
(epoch: 69, iters: 2464, time: 0.158, data: 0.000) loss: 0.488 
(epoch: 69, iters: 2544, time: 0.160, data: 0.000) loss: 0.632 
(epoch: 69, iters: 2624, time: 0.154, data: 0.029) loss: 0.322 
(epoch: 69, iters: 2704, time: 0.158, data: 0.027) loss: 0.529 
(epoch: 69, iters: 2784, time: 0.157, data: 0.000) loss: 0.887 
(epoch: 69, iters: 2864, time: 0.156, data: 0.009) loss: 0.565 
(epoch: 69, iters: 2944, time: 0.160, data: 0.000) loss: 1.090 
(epoch: 69, iters: 3024, time: 0.156, data: 0.025) loss: 0.837 
(epoch: 69, iters: 3104, time: 0.156, data: 0.000) loss: 0.445 
(epoch: 69, iters: 3184, time: 0.159, data: 0.013) loss: 0.122 
(epoch: 69, iters: 3264, time: 0.158, data: 0.009) loss: 0.990 
(epoch: 69, iters: 3344, time: 0.155, data: 0.005) loss: 1.244 
(epoch: 69, iters: 3424, time: 0.155, data: 0.000) loss: 0.674 
(epoch: 69, iters: 3504, time: 0.155, data: 0.000) loss: 0.958 
(epoch: 69, iters: 3584, time: 0.154, data: 0.000) loss: 0.488 
(epoch: 69, iters: 3664, time: 0.159, data: 0.000) loss: 0.826 
(epoch: 69, iters: 3744, time: 0.157, data: 0.005) loss: 0.474 
(epoch: 69, iters: 3824, time: 0.155, data: 0.000) loss: 0.211 
(epoch: 69, iters: 3904, time: 0.154, data: 0.000) loss: 0.584 
(epoch: 69, iters: 3984, time: 0.157, data: 0.000) loss: 0.793 
saving the latest model (epoch 69, total_steps 697072)
(epoch: 69, iters: 4064, time: 0.155, data: 0.022) loss: 0.556 
(epoch: 69, iters: 4144, time: 0.157, data: 0.005) loss: 0.941 
(epoch: 69, iters: 4224, time: 0.154, data: 0.000) loss: 0.631 
(epoch: 69, iters: 4304, time: 0.156, data: 0.000) loss: 0.296 
(epoch: 69, iters: 4384, time: 0.156, data: 0.000) loss: 0.343 
(epoch: 69, iters: 4464, time: 0.155, data: 0.000) loss: 0.951 
(epoch: 69, iters: 4544, time: 0.157, data: 0.000) loss: 0.504 
(epoch: 69, iters: 4624, time: 0.158, data: 0.005) loss: 0.847 
(epoch: 69, iters: 4704, time: 0.157, data: 0.000) loss: 0.668 
(epoch: 69, iters: 4784, time: 0.159, data: 0.000) loss: 0.607 
(epoch: 69, iters: 4864, time: 0.156, data: 0.022) loss: 0.867 
(epoch: 69, iters: 4944, time: 0.157, data: 0.000) loss: 0.775 
(epoch: 69, iters: 5024, time: 0.157, data: 0.013) loss: 0.559 
(epoch: 69, iters: 5104, time: 0.156, data: 0.000) loss: 0.864 
(epoch: 69, iters: 5184, time: 0.156, data: 0.000) loss: 0.502 
(epoch: 69, iters: 5264, time: 0.155, data: 0.021) loss: 1.263 
(epoch: 69, iters: 5344, time: 0.157, data: 0.015) loss: 0.458 
(epoch: 69, iters: 5424, time: 0.155, data: 0.000) loss: 0.498 
(epoch: 69, iters: 5504, time: 0.160, data: 0.000) loss: 0.545 
(epoch: 69, iters: 5584, time: 0.157, data: 0.014) loss: 0.802 
(epoch: 69, iters: 5664, time: 0.154, data: 0.000) loss: 0.466 
(epoch: 69, iters: 5744, time: 0.154, data: 0.026) loss: 0.668 
(epoch: 69, iters: 5824, time: 0.155, data: 0.000) loss: 0.493 
(epoch: 69, iters: 5904, time: 0.156, data: 0.000) loss: 0.752 
(epoch: 69, iters: 5984, time: 0.157, data: 0.006) loss: 1.090 
(epoch: 69, iters: 6064, time: 0.159, data: 0.011) loss: 0.662 
(epoch: 69, iters: 6144, time: 0.158, data: 0.005) loss: 0.496 
(epoch: 69, iters: 6224, time: 0.158, data: 0.000) loss: 0.689 
(epoch: 69, iters: 6304, time: 0.160, data: 0.025) loss: 0.976 
(epoch: 69, iters: 6384, time: 0.158, data: 0.000) loss: 0.614 
(epoch: 69, iters: 6464, time: 0.158, data: 0.011) loss: 0.795 
(epoch: 69, iters: 6544, time: 0.157, data: 0.000) loss: 0.498 
(epoch: 69, iters: 6624, time: 0.161, data: 0.028) loss: 0.421 
(epoch: 69, iters: 6704, time: 0.158, data: 0.021) loss: 0.960 
(epoch: 69, iters: 6784, time: 0.160, data: 0.000) loss: 0.497 
(epoch: 69, iters: 6864, time: 0.157, data: 0.013) loss: 0.558 
(epoch: 69, iters: 6944, time: 0.160, data: 0.000) loss: 0.468 
(epoch: 69, iters: 7024, time: 0.168, data: 0.000) loss: 0.636 
(epoch: 69, iters: 7104, time: 0.159, data: 0.000) loss: 0.760 
(epoch: 69, iters: 7184, time: 0.158, data: 0.000) loss: 0.804 
(epoch: 69, iters: 7264, time: 0.159, data: 0.000) loss: 0.680 
(epoch: 69, iters: 7344, time: 0.157, data: 0.008) loss: 0.698 
(epoch: 69, iters: 7424, time: 0.158, data: 0.000) loss: 0.545 
(epoch: 69, iters: 7504, time: 0.158, data: 0.033) loss: 1.183 
(epoch: 69, iters: 7584, time: 0.159, data: 0.000) loss: 0.634 
(epoch: 69, iters: 7664, time: 0.158, data: 0.000) loss: 1.200 
(epoch: 69, iters: 7744, time: 0.156, data: 0.005) loss: 0.466 
(epoch: 69, iters: 7824, time: 0.157, data: 0.000) loss: 0.445 
(epoch: 69, iters: 7904, time: 0.156, data: 0.006) loss: 0.532 
(epoch: 69, iters: 7984, time: 0.159, data: 0.000) loss: 0.768 
saving the latest model (epoch 69, total_steps 701072)
(epoch: 69, iters: 8064, time: 0.158, data: 0.005) loss: 0.568 
(epoch: 69, iters: 8144, time: 0.160, data: 0.000) loss: 0.458 
(epoch: 69, iters: 8224, time: 0.160, data: 0.015) loss: 0.843 
(epoch: 69, iters: 8304, time: 0.161, data: 0.000) loss: 0.481 
(epoch: 69, iters: 8384, time: 0.158, data: 0.000) loss: 0.620 
(epoch: 69, iters: 8464, time: 0.159, data: 0.000) loss: 0.478 
(epoch: 69, iters: 8544, time: 0.161, data: 0.000) loss: 1.123 
(epoch: 69, iters: 8624, time: 0.160, data: 0.015) loss: 0.547 
(epoch: 69, iters: 8704, time: 0.157, data: 0.000) loss: 0.584 
(epoch: 69, iters: 8784, time: 0.160, data: 0.000) loss: 0.861 
(epoch: 69, iters: 8864, time: 0.159, data: 0.006) loss: 0.904 
(epoch: 69, iters: 8944, time: 0.159, data: 0.010) loss: 0.587 
(epoch: 69, iters: 9024, time: 0.159, data: 0.000) loss: 0.776 
(epoch: 69, iters: 9104, time: 0.160, data: 0.000) loss: 0.733 
(epoch: 69, iters: 9184, time: 0.159, data: 0.000) loss: 0.900 
(epoch: 69, iters: 9264, time: 0.160, data: 0.000) loss: 0.612 
(epoch: 69, iters: 9344, time: 0.161, data: 0.031) loss: 0.841 
(epoch: 69, iters: 9424, time: 0.158, data: 0.000) loss: 0.648 
(epoch: 69, iters: 9504, time: 0.158, data: 0.009) loss: 0.512 
(epoch: 69, iters: 9584, time: 0.157, data: 0.000) loss: 0.664 
(epoch: 69, iters: 9664, time: 0.159, data: 0.023) loss: 0.783 
(epoch: 69, iters: 9744, time: 0.163, data: 0.000) loss: 0.373 
(epoch: 69, iters: 9824, time: 0.160, data: 0.000) loss: 1.221 
(epoch: 69, iters: 9904, time: 0.162, data: 0.009) loss: 0.236 
(epoch: 69, iters: 9984, time: 0.160, data: 0.014) loss: 0.909 
(epoch: 69, iters: 10064, time: 0.157, data: 0.000) loss: 0.612 
(epoch: 69, iters: 10144, time: 0.160, data: 0.018) loss: 0.460 
saving the model at the end of epoch 69, iters 703248
End of epoch 69 / 200 	 Time Taken: 1611 sec
learning rate = 0.0002000
saving the latest model (epoch 70, total_steps 703264)
(epoch: 70, iters: 32, time: 0.170, data: 0.000) loss: 0.334 
(epoch: 70, iters: 112, time: 0.163, data: 0.017) loss: 0.718 
(epoch: 70, iters: 192, time: 0.161, data: 0.010) loss: 0.189 
(epoch: 70, iters: 272, time: 0.160, data: 0.000) loss: 0.259 
(epoch: 70, iters: 352, time: 0.160, data: 0.010) loss: 0.454 
(epoch: 70, iters: 432, time: 0.161, data: 0.032) loss: 0.840 
(epoch: 70, iters: 512, time: 0.163, data: 0.000) loss: 0.553 
(epoch: 70, iters: 592, time: 0.160, data: 0.000) loss: 0.529 
(epoch: 70, iters: 672, time: 0.162, data: 0.005) loss: 0.566 
(epoch: 70, iters: 752, time: 0.160, data: 0.043) loss: 0.310 
(epoch: 70, iters: 832, time: 0.160, data: 0.000) loss: 0.450 
(epoch: 70, iters: 912, time: 0.161, data: 0.000) loss: 0.787 
(epoch: 70, iters: 992, time: 0.162, data: 0.027) loss: 0.925 
(epoch: 70, iters: 1072, time: 0.161, data: 0.005) loss: 0.977 
(epoch: 70, iters: 1152, time: 0.161, data: 0.005) loss: 0.765 
(epoch: 70, iters: 1232, time: 0.161, data: 0.000) loss: 0.815 
(epoch: 70, iters: 1312, time: 0.160, data: 0.005) loss: 0.849 
(epoch: 70, iters: 1392, time: 0.161, data: 0.000) loss: 0.727 
(epoch: 70, iters: 1472, time: 0.163, data: 0.010) loss: 0.462 
(epoch: 70, iters: 1552, time: 0.160, data: 0.000) loss: 0.508 
(epoch: 70, iters: 1632, time: 0.160, data: 0.016) loss: 0.548 
(epoch: 70, iters: 1712, time: 0.160, data: 0.000) loss: 0.870 
(epoch: 70, iters: 1792, time: 0.159, data: 0.015) loss: 0.703 
(epoch: 70, iters: 1872, time: 0.168, data: 0.000) loss: 0.471 
(epoch: 70, iters: 1952, time: 0.158, data: 0.015) loss: 0.452 
(epoch: 70, iters: 2032, time: 0.161, data: 0.000) loss: 0.497 
(epoch: 70, iters: 2112, time: 0.159, data: 0.025) loss: 0.731 
(epoch: 70, iters: 2192, time: 0.160, data: 0.000) loss: 0.573 
(epoch: 70, iters: 2272, time: 0.159, data: 0.011) loss: 0.499 
(epoch: 70, iters: 2352, time: 0.161, data: 0.000) loss: 0.771 
(epoch: 70, iters: 2432, time: 0.160, data: 0.000) loss: 0.478 
(epoch: 70, iters: 2512, time: 0.160, data: 0.000) loss: 0.589 
(epoch: 70, iters: 2592, time: 0.159, data: 0.019) loss: 0.437 
(epoch: 70, iters: 2672, time: 0.159, data: 0.000) loss: 0.625 
(epoch: 70, iters: 2752, time: 0.161, data: 0.009) loss: 0.507 
(epoch: 70, iters: 2832, time: 0.159, data: 0.000) loss: 0.800 
(epoch: 70, iters: 2912, time: 0.159, data: 0.023) loss: 0.701 
(epoch: 70, iters: 2992, time: 0.159, data: 0.000) loss: 0.544 
(epoch: 70, iters: 3072, time: 0.160, data: 0.005) loss: 0.556 
(epoch: 70, iters: 3152, time: 0.161, data: 0.012) loss: 0.246 
(epoch: 70, iters: 3232, time: 0.160, data: 0.009) loss: 0.344 
(epoch: 70, iters: 3312, time: 0.159, data: 0.000) loss: 0.667 
(epoch: 70, iters: 3392, time: 0.161, data: 0.000) loss: 0.699 
(epoch: 70, iters: 3472, time: 0.160, data: 0.015) loss: 1.112 
(epoch: 70, iters: 3552, time: 0.163, data: 0.000) loss: 1.004 
(epoch: 70, iters: 3632, time: 0.160, data: 0.015) loss: 0.975 
(epoch: 70, iters: 3712, time: 0.164, data: 0.000) loss: 0.596 
(epoch: 70, iters: 3792, time: 0.165, data: 0.016) loss: 0.704 
(epoch: 70, iters: 3872, time: 0.159, data: 0.000) loss: 0.762 
(epoch: 70, iters: 3952, time: 0.160, data: 0.027) loss: 0.431 
saving the latest model (epoch 70, total_steps 707264)
(epoch: 70, iters: 4032, time: 0.161, data: 0.000) loss: 0.845 
(epoch: 70, iters: 4112, time: 0.163, data: 0.033) loss: 0.818 
(epoch: 70, iters: 4192, time: 0.160, data: 0.000) loss: 0.612 
(epoch: 70, iters: 4272, time: 0.159, data: 0.000) loss: 1.000 
(epoch: 70, iters: 4352, time: 0.159, data: 0.000) loss: 0.697 
(epoch: 70, iters: 4432, time: 0.158, data: 0.021) loss: 1.023 
(epoch: 70, iters: 4512, time: 0.161, data: 0.000) loss: 1.121 
(epoch: 70, iters: 4592, time: 0.157, data: 0.009) loss: 1.035 
(epoch: 70, iters: 4672, time: 0.159, data: 0.000) loss: 0.968 
(epoch: 70, iters: 4752, time: 0.161, data: 0.000) loss: 0.695 
(epoch: 70, iters: 4832, time: 0.161, data: 0.000) loss: 0.749 
(epoch: 70, iters: 4912, time: 0.160, data: 0.000) loss: 0.657 
(epoch: 70, iters: 4992, time: 0.161, data: 0.005) loss: 0.596 
(epoch: 70, iters: 5072, time: 0.161, data: 0.015) loss: 0.746 
(epoch: 70, iters: 5152, time: 0.161, data: 0.000) loss: 1.239 
(epoch: 70, iters: 5232, time: 0.161, data: 0.000) loss: 0.540 
(epoch: 70, iters: 5312, time: 0.162, data: 0.027) loss: 0.469 
(epoch: 70, iters: 5392, time: 0.161, data: 0.041) loss: 0.601 
(epoch: 70, iters: 5472, time: 0.161, data: 0.000) loss: 0.832 
(epoch: 70, iters: 5552, time: 0.159, data: 0.005) loss: 0.431 
(epoch: 70, iters: 5632, time: 0.162, data: 0.016) loss: 1.053 
(epoch: 70, iters: 5712, time: 0.167, data: 0.000) loss: 1.014 
(epoch: 70, iters: 5792, time: 0.161, data: 0.017) loss: 1.183 
(epoch: 70, iters: 5872, time: 0.162, data: 0.015) loss: 0.410 
(epoch: 70, iters: 5952, time: 0.164, data: 0.018) loss: 0.996 
(epoch: 70, iters: 6032, time: 0.160, data: 0.010) loss: 0.604 
(epoch: 70, iters: 6112, time: 0.161, data: 0.000) loss: 0.529 
(epoch: 70, iters: 6192, time: 0.158, data: 0.005) loss: 0.839 
(epoch: 70, iters: 6272, time: 0.161, data: 0.000) loss: 1.362 
(epoch: 70, iters: 6352, time: 0.158, data: 0.000) loss: 1.042 
(epoch: 70, iters: 6432, time: 0.160, data: 0.008) loss: 0.898 
(epoch: 70, iters: 6512, time: 0.160, data: 0.000) loss: 0.790 
(epoch: 70, iters: 6592, time: 0.160, data: 0.021) loss: 0.887 
(epoch: 70, iters: 6672, time: 0.161, data: 0.000) loss: 0.937 
(epoch: 70, iters: 6752, time: 0.164, data: 0.008) loss: 0.947 
(epoch: 70, iters: 6832, time: 0.159, data: 0.000) loss: 0.216 
(epoch: 70, iters: 6912, time: 0.159, data: 0.000) loss: 0.925 
(epoch: 70, iters: 6992, time: 0.161, data: 0.000) loss: 0.584 
(epoch: 70, iters: 7072, time: 0.161, data: 0.006) loss: 0.968 
(epoch: 70, iters: 7152, time: 0.160, data: 0.029) loss: 1.152 
(epoch: 70, iters: 7232, time: 0.159, data: 0.000) loss: 0.336 
(epoch: 70, iters: 7312, time: 0.161, data: 0.033) loss: 0.711 
(epoch: 70, iters: 7392, time: 0.160, data: 0.000) loss: 0.174 
(epoch: 70, iters: 7472, time: 0.161, data: 0.000) loss: 0.838 
(epoch: 70, iters: 7552, time: 0.161, data: 0.000) loss: 0.287 
(epoch: 70, iters: 7632, time: 0.169, data: 0.000) loss: 0.679 
(epoch: 70, iters: 7712, time: 0.159, data: 0.008) loss: 0.770 
(epoch: 70, iters: 7792, time: 0.161, data: 0.000) loss: 0.758 
(epoch: 70, iters: 7872, time: 0.160, data: 0.000) loss: 0.390 
(epoch: 70, iters: 7952, time: 0.160, data: 0.000) loss: 0.585 
saving the latest model (epoch 70, total_steps 711264)
(epoch: 70, iters: 8032, time: 0.160, data: 0.010) loss: 0.534 
(epoch: 70, iters: 8112, time: 0.160, data: 0.000) loss: 0.646 
(epoch: 70, iters: 8192, time: 0.160, data: 0.000) loss: 0.636 
(epoch: 70, iters: 8272, time: 0.159, data: 0.005) loss: 1.524 
(epoch: 70, iters: 8352, time: 0.158, data: 0.005) loss: 1.092 
(epoch: 70, iters: 8432, time: 0.161, data: 0.000) loss: 0.488 
(epoch: 70, iters: 8512, time: 0.158, data: 0.000) loss: 0.665 
(epoch: 70, iters: 8592, time: 0.160, data: 0.013) loss: 0.244 
(epoch: 70, iters: 8672, time: 0.159, data: 0.000) loss: 0.501 
(epoch: 70, iters: 8752, time: 0.160, data: 0.000) loss: 0.549 
(epoch: 70, iters: 8832, time: 0.158, data: 0.000) loss: 0.591 
(epoch: 70, iters: 8912, time: 0.159, data: 0.005) loss: 0.349 
(epoch: 70, iters: 8992, time: 0.160, data: 0.006) loss: 0.490 
(epoch: 70, iters: 9072, time: 0.157, data: 0.033) loss: 0.756 
(epoch: 70, iters: 9152, time: 0.159, data: 0.000) loss: 0.542 
(epoch: 70, iters: 9232, time: 0.157, data: 0.000) loss: 0.628 
(epoch: 70, iters: 9312, time: 0.161, data: 0.005) loss: 0.833 
(epoch: 70, iters: 9392, time: 0.164, data: 0.000) loss: 1.029 
(epoch: 70, iters: 9472, time: 0.161, data: 0.017) loss: 0.672 
(epoch: 70, iters: 9552, time: 0.166, data: 0.000) loss: 0.595 
(epoch: 70, iters: 9632, time: 0.161, data: 0.019) loss: 0.384 
(epoch: 70, iters: 9712, time: 0.162, data: 0.000) loss: 0.746 
(epoch: 70, iters: 9792, time: 0.160, data: 0.000) loss: 0.393 
(epoch: 70, iters: 9872, time: 0.162, data: 0.000) loss: 0.540 
(epoch: 70, iters: 9952, time: 0.160, data: 0.015) loss: 0.517 
(epoch: 70, iters: 10032, time: 0.160, data: 0.008) loss: 0.447 
(epoch: 70, iters: 10112, time: 0.160, data: 0.000) loss: 0.821 
(epoch: 70, iters: 10192, time: 0.096, data: 0.005) loss: 0.923 
saving the model at the end of epoch 70, iters 713440
End of epoch 70 / 200 	 Time Taken: 1644 sec
learning rate = 0.0002000
saving the latest model (epoch 71, total_steps 713456)
(epoch: 71, iters: 80, time: 0.165, data: 0.215) loss: 0.786 
(epoch: 71, iters: 160, time: 0.159, data: 0.000) loss: 0.701 
(epoch: 71, iters: 240, time: 0.160, data: 0.005) loss: 0.733 
(epoch: 71, iters: 320, time: 0.158, data: 0.000) loss: 0.519 
(epoch: 71, iters: 400, time: 0.157, data: 0.000) loss: 0.307 
(epoch: 71, iters: 480, time: 0.158, data: 0.016) loss: 0.463 
(epoch: 71, iters: 560, time: 0.157, data: 0.005) loss: 0.437 
(epoch: 71, iters: 640, time: 0.156, data: 0.000) loss: 0.327 
(epoch: 71, iters: 720, time: 0.156, data: 0.000) loss: 0.624 
(epoch: 71, iters: 800, time: 0.159, data: 0.000) loss: 1.071 
(epoch: 71, iters: 880, time: 0.159, data: 0.000) loss: 0.495 
(epoch: 71, iters: 960, time: 0.160, data: 0.000) loss: 0.664 
(epoch: 71, iters: 1040, time: 0.161, data: 0.026) loss: 1.064 
(epoch: 71, iters: 1120, time: 0.159, data: 0.000) loss: 0.765 
(epoch: 71, iters: 1200, time: 0.158, data: 0.000) loss: 0.736 
(epoch: 71, iters: 1280, time: 0.160, data: 0.005) loss: 0.908 
(epoch: 71, iters: 1360, time: 0.160, data: 0.025) loss: 0.863 
(epoch: 71, iters: 1440, time: 0.158, data: 0.000) loss: 1.048 
(epoch: 71, iters: 1520, time: 0.164, data: 0.000) loss: 1.318 
(epoch: 71, iters: 1600, time: 0.160, data: 0.005) loss: 0.572 
(epoch: 71, iters: 1680, time: 0.161, data: 0.000) loss: 1.095 
(epoch: 71, iters: 1760, time: 0.160, data: 0.020) loss: 1.021 
(epoch: 71, iters: 1840, time: 0.159, data: 0.005) loss: 0.456 
(epoch: 71, iters: 1920, time: 0.159, data: 0.009) loss: 0.666 
(epoch: 71, iters: 2000, time: 0.160, data: 0.000) loss: 0.416 
(epoch: 71, iters: 2080, time: 0.166, data: 0.011) loss: 0.553 
(epoch: 71, iters: 2160, time: 0.159, data: 0.000) loss: 0.424 
(epoch: 71, iters: 2240, time: 0.157, data: 0.010) loss: 0.623 
(epoch: 71, iters: 2320, time: 0.159, data: 0.000) loss: 0.487 
(epoch: 71, iters: 2400, time: 0.159, data: 0.013) loss: 0.601 
(epoch: 71, iters: 2480, time: 0.158, data: 0.015) loss: 0.460 
(epoch: 71, iters: 2560, time: 0.159, data: 0.000) loss: 0.669 
(epoch: 71, iters: 2640, time: 0.158, data: 0.000) loss: 0.566 
(epoch: 71, iters: 2720, time: 0.157, data: 0.033) loss: 0.281 
(epoch: 71, iters: 2800, time: 0.158, data: 0.000) loss: 0.350 
(epoch: 71, iters: 2880, time: 0.159, data: 0.000) loss: 0.599 
(epoch: 71, iters: 2960, time: 0.157, data: 0.010) loss: 0.390 
(epoch: 71, iters: 3040, time: 0.158, data: 0.008) loss: 0.331 
(epoch: 71, iters: 3120, time: 0.158, data: 0.000) loss: 0.761 
(epoch: 71, iters: 3200, time: 0.157, data: 0.022) loss: 1.005 
(epoch: 71, iters: 3280, time: 0.157, data: 0.000) loss: 1.171 
(epoch: 71, iters: 3360, time: 0.158, data: 0.013) loss: 1.546 
(epoch: 71, iters: 3440, time: 0.160, data: 0.000) loss: 0.570 
(epoch: 71, iters: 3520, time: 0.157, data: 0.006) loss: 0.787 
(epoch: 71, iters: 3600, time: 0.158, data: 0.006) loss: 0.876 
(epoch: 71, iters: 3680, time: 0.159, data: 0.000) loss: 0.620 
(epoch: 71, iters: 3760, time: 0.158, data: 0.000) loss: 0.583 
(epoch: 71, iters: 3840, time: 0.157, data: 0.000) loss: 0.552 
(epoch: 71, iters: 3920, time: 0.160, data: 0.000) loss: 0.407 
(epoch: 71, iters: 4000, time: 0.158, data: 0.000) loss: 1.492 
saving the latest model (epoch 71, total_steps 717456)
(epoch: 71, iters: 4080, time: 0.158, data: 0.008) loss: 0.651 
(epoch: 71, iters: 4160, time: 0.159, data: 0.014) loss: 0.440 
(epoch: 71, iters: 4240, time: 0.158, data: 0.000) loss: 0.784 
(epoch: 71, iters: 4320, time: 0.160, data: 0.014) loss: 0.952 
(epoch: 71, iters: 4400, time: 0.158, data: 0.005) loss: 0.966 
(epoch: 71, iters: 4480, time: 0.161, data: 0.000) loss: 0.925 
(epoch: 71, iters: 4560, time: 0.159, data: 0.006) loss: 0.754 
(epoch: 71, iters: 4640, time: 0.160, data: 0.000) loss: 1.150 
(epoch: 71, iters: 4720, time: 0.161, data: 0.006) loss: 0.464 
(epoch: 71, iters: 4800, time: 0.164, data: 0.000) loss: 1.089 
(epoch: 71, iters: 4880, time: 0.159, data: 0.000) loss: 0.928 
(epoch: 71, iters: 4960, time: 0.158, data: 0.005) loss: 0.564 
(epoch: 71, iters: 5040, time: 0.161, data: 0.000) loss: 0.475 
(epoch: 71, iters: 5120, time: 0.159, data: 0.000) loss: 0.239 
(epoch: 71, iters: 5200, time: 0.159, data: 0.014) loss: 1.234 
(epoch: 71, iters: 5280, time: 0.161, data: 0.000) loss: 0.918 
(epoch: 71, iters: 5360, time: 0.159, data: 0.006) loss: 0.517 
(epoch: 71, iters: 5440, time: 0.160, data: 0.013) loss: 0.703 
(epoch: 71, iters: 5520, time: 0.159, data: 0.008) loss: 0.662 
(epoch: 71, iters: 5600, time: 0.160, data: 0.000) loss: 0.388 
(epoch: 71, iters: 5680, time: 0.163, data: 0.008) loss: 0.698 
(epoch: 71, iters: 5760, time: 0.159, data: 0.000) loss: 0.913 
(epoch: 71, iters: 5840, time: 0.160, data: 0.000) loss: 0.871 
(epoch: 71, iters: 5920, time: 0.162, data: 0.000) loss: 0.650 
(epoch: 71, iters: 6000, time: 0.160, data: 0.015) loss: 0.160 
(epoch: 71, iters: 6080, time: 0.160, data: 0.028) loss: 0.400 
(epoch: 71, iters: 6160, time: 0.160, data: 0.000) loss: 0.903 
(epoch: 71, iters: 6240, time: 0.159, data: 0.000) loss: 0.689 
(epoch: 71, iters: 6320, time: 0.159, data: 0.014) loss: 0.435 
(epoch: 71, iters: 6400, time: 0.160, data: 0.000) loss: 1.136 
(epoch: 71, iters: 6480, time: 0.160, data: 0.005) loss: 0.756 
(epoch: 71, iters: 6560, time: 0.160, data: 0.009) loss: 0.880 
(epoch: 71, iters: 6640, time: 0.160, data: 0.014) loss: 0.665 
(epoch: 71, iters: 6720, time: 0.157, data: 0.006) loss: 0.881 
(epoch: 71, iters: 6800, time: 0.159, data: 0.000) loss: 0.280 
(epoch: 71, iters: 6880, time: 0.158, data: 0.013) loss: 0.718 
(epoch: 71, iters: 6960, time: 0.160, data: 0.000) loss: 1.148 
(epoch: 71, iters: 7040, time: 0.160, data: 0.015) loss: 1.124 
(epoch: 71, iters: 7120, time: 0.166, data: 0.008) loss: 0.463 
(epoch: 71, iters: 7200, time: 0.161, data: 0.000) loss: 0.555 
(epoch: 71, iters: 7280, time: 0.159, data: 0.000) loss: 1.157 
(epoch: 71, iters: 7360, time: 0.158, data: 0.015) loss: 0.709 
(epoch: 71, iters: 7440, time: 0.160, data: 0.009) loss: 0.836 
(epoch: 71, iters: 7520, time: 0.159, data: 0.016) loss: 0.411 
(epoch: 71, iters: 7600, time: 0.160, data: 0.016) loss: 1.055 
(epoch: 71, iters: 7680, time: 0.159, data: 0.000) loss: 0.505 
(epoch: 71, iters: 7760, time: 0.161, data: 0.000) loss: 0.411 
(epoch: 71, iters: 7840, time: 0.160, data: 0.005) loss: 1.111 
(epoch: 71, iters: 7920, time: 0.159, data: 0.022) loss: 0.430 
(epoch: 71, iters: 8000, time: 0.161, data: 0.005) loss: 0.503 
saving the latest model (epoch 71, total_steps 721456)
(epoch: 71, iters: 8080, time: 0.159, data: 0.000) loss: 1.112 
(epoch: 71, iters: 8160, time: 0.157, data: 0.011) loss: 0.706 
(epoch: 71, iters: 8240, time: 0.159, data: 0.000) loss: 0.840 
(epoch: 71, iters: 8320, time: 0.158, data: 0.005) loss: 0.597 
(epoch: 71, iters: 8400, time: 0.159, data: 0.005) loss: 0.553 
(epoch: 71, iters: 8480, time: 0.163, data: 0.000) loss: 0.722 
(epoch: 71, iters: 8560, time: 0.159, data: 0.025) loss: 0.750 
(epoch: 71, iters: 8640, time: 0.162, data: 0.000) loss: 0.273 
(epoch: 71, iters: 8720, time: 0.160, data: 0.000) loss: 0.614 
(epoch: 71, iters: 8800, time: 0.159, data: 0.000) loss: 0.889 
(epoch: 71, iters: 8880, time: 0.159, data: 0.000) loss: 0.497 
(epoch: 71, iters: 8960, time: 0.158, data: 0.040) loss: 0.494 
(epoch: 71, iters: 9040, time: 0.159, data: 0.000) loss: 0.690 
(epoch: 71, iters: 9120, time: 0.160, data: 0.039) loss: 1.115 
(epoch: 71, iters: 9200, time: 0.159, data: 0.000) loss: 0.202 
(epoch: 71, iters: 9280, time: 0.161, data: 0.032) loss: 0.712 
(epoch: 71, iters: 9360, time: 0.160, data: 0.000) loss: 0.256 
(epoch: 71, iters: 9440, time: 0.166, data: 0.000) loss: 0.826 
(epoch: 71, iters: 9520, time: 0.160, data: 0.022) loss: 0.555 
(epoch: 71, iters: 9600, time: 0.159, data: 0.000) loss: 1.792 
(epoch: 71, iters: 9680, time: 0.156, data: 0.000) loss: 0.401 
(epoch: 71, iters: 9760, time: 0.158, data: 0.000) loss: 0.574 
(epoch: 71, iters: 9840, time: 0.162, data: 0.000) loss: 1.080 
(epoch: 71, iters: 9920, time: 0.160, data: 0.000) loss: 0.593 
(epoch: 71, iters: 10000, time: 0.160, data: 0.009) loss: 0.522 
(epoch: 71, iters: 10080, time: 0.160, data: 0.000) loss: 0.543 
(epoch: 71, iters: 10160, time: 0.160, data: 0.017) loss: 0.456 
saving the model at the end of epoch 71, iters 723632
End of epoch 71 / 200 	 Time Taken: 1631 sec
learning rate = 0.0002000
saving the latest model (epoch 72, total_steps 723648)
(epoch: 72, iters: 48, time: 0.165, data: 0.000) loss: 0.467 
(epoch: 72, iters: 128, time: 0.164, data: 0.016) loss: 0.337 
(epoch: 72, iters: 208, time: 0.163, data: 0.000) loss: 0.600 
(epoch: 72, iters: 288, time: 0.163, data: 0.025) loss: 0.331 
(epoch: 72, iters: 368, time: 0.162, data: 0.000) loss: 0.694 
(epoch: 72, iters: 448, time: 0.161, data: 0.000) loss: 0.838 
(epoch: 72, iters: 528, time: 0.159, data: 0.006) loss: 1.012 
(epoch: 72, iters: 608, time: 0.161, data: 0.006) loss: 0.268 
(epoch: 72, iters: 688, time: 0.161, data: 0.024) loss: 0.851 
(epoch: 72, iters: 768, time: 0.162, data: 0.000) loss: 0.350 
(epoch: 72, iters: 848, time: 0.160, data: 0.000) loss: 0.745 
(epoch: 72, iters: 928, time: 0.162, data: 0.006) loss: 0.454 
(epoch: 72, iters: 1008, time: 0.162, data: 0.000) loss: 0.257 
(epoch: 72, iters: 1088, time: 0.160, data: 0.019) loss: 1.050 
(epoch: 72, iters: 1168, time: 0.169, data: 0.000) loss: 0.976 
(epoch: 72, iters: 1248, time: 0.162, data: 0.000) loss: 0.970 
(epoch: 72, iters: 1328, time: 0.161, data: 0.020) loss: 0.733 
(epoch: 72, iters: 1408, time: 0.162, data: 0.032) loss: 0.632 
(epoch: 72, iters: 1488, time: 0.160, data: 0.000) loss: 0.549 
(epoch: 72, iters: 1568, time: 0.163, data: 0.008) loss: 0.549 
(epoch: 72, iters: 1648, time: 0.162, data: 0.006) loss: 0.676 
(epoch: 72, iters: 1728, time: 0.162, data: 0.000) loss: 0.407 
(epoch: 72, iters: 1808, time: 0.162, data: 0.025) loss: 0.442 
(epoch: 72, iters: 1888, time: 0.160, data: 0.000) loss: 0.594 
(epoch: 72, iters: 1968, time: 0.161, data: 0.009) loss: 0.403 
(epoch: 72, iters: 2048, time: 0.159, data: 0.013) loss: 1.215 
(epoch: 72, iters: 2128, time: 0.163, data: 0.014) loss: 0.592 
(epoch: 72, iters: 2208, time: 0.158, data: 0.010) loss: 0.709 
(epoch: 72, iters: 2288, time: 0.164, data: 0.000) loss: 0.497 
(epoch: 72, iters: 2368, time: 0.159, data: 0.000) loss: 0.519 
(epoch: 72, iters: 2448, time: 0.159, data: 0.009) loss: 0.832 
(epoch: 72, iters: 2528, time: 0.159, data: 0.008) loss: 0.703 
(epoch: 72, iters: 2608, time: 0.160, data: 0.011) loss: 2.670 
(epoch: 72, iters: 2688, time: 0.162, data: 0.000) loss: 0.226 
(epoch: 72, iters: 2768, time: 0.159, data: 0.008) loss: 0.323 
(epoch: 72, iters: 2848, time: 0.160, data: 0.000) loss: 0.752 
(epoch: 72, iters: 2928, time: 0.161, data: 0.033) loss: 0.460 
(epoch: 72, iters: 3008, time: 0.161, data: 0.000) loss: 0.978 
(epoch: 72, iters: 3088, time: 0.162, data: 0.026) loss: 0.421 
(epoch: 72, iters: 3168, time: 0.160, data: 0.024) loss: 0.660 
(epoch: 72, iters: 3248, time: 0.162, data: 0.000) loss: 0.702 
(epoch: 72, iters: 3328, time: 0.161, data: 0.000) loss: 0.557 
(epoch: 72, iters: 3408, time: 0.158, data: 0.008) loss: 0.742 
(epoch: 72, iters: 3488, time: 0.168, data: 0.005) loss: 1.054 
(epoch: 72, iters: 3568, time: 0.158, data: 0.005) loss: 0.365 
(epoch: 72, iters: 3648, time: 0.158, data: 0.000) loss: 0.684 
(epoch: 72, iters: 3728, time: 0.160, data: 0.023) loss: 0.801 
(epoch: 72, iters: 3808, time: 0.161, data: 0.000) loss: 0.622 
(epoch: 72, iters: 3888, time: 0.158, data: 0.000) loss: 0.332 
(epoch: 72, iters: 3968, time: 0.159, data: 0.010) loss: 0.504 
saving the latest model (epoch 72, total_steps 727648)
(epoch: 72, iters: 4048, time: 0.158, data: 0.000) loss: 0.698 
(epoch: 72, iters: 4128, time: 0.157, data: 0.000) loss: 0.632 
(epoch: 72, iters: 4208, time: 0.159, data: 0.016) loss: 0.701 
(epoch: 72, iters: 4288, time: 0.159, data: 0.000) loss: 0.821 
(epoch: 72, iters: 4368, time: 0.160, data: 0.005) loss: 0.245 
(epoch: 72, iters: 4448, time: 0.162, data: 0.000) loss: 0.676 
(epoch: 72, iters: 4528, time: 0.159, data: 0.025) loss: 0.856 
(epoch: 72, iters: 4608, time: 0.159, data: 0.000) loss: 0.786 
(epoch: 72, iters: 4688, time: 0.161, data: 0.010) loss: 0.444 
(epoch: 72, iters: 4768, time: 0.163, data: 0.000) loss: 1.413 
(epoch: 72, iters: 4848, time: 0.162, data: 0.033) loss: 1.336 
(epoch: 72, iters: 4928, time: 0.161, data: 0.000) loss: 0.917 
(epoch: 72, iters: 5008, time: 0.159, data: 0.000) loss: 0.783 
(epoch: 72, iters: 5088, time: 0.161, data: 0.016) loss: 0.874 
(epoch: 72, iters: 5168, time: 0.164, data: 0.011) loss: 1.024 
(epoch: 72, iters: 5248, time: 0.162, data: 0.005) loss: 0.171 
(epoch: 72, iters: 5328, time: 0.163, data: 0.005) loss: 0.202 
(epoch: 72, iters: 5408, time: 0.163, data: 0.005) loss: 0.821 
(epoch: 72, iters: 5488, time: 0.162, data: 0.009) loss: 0.406 
(epoch: 72, iters: 5568, time: 0.163, data: 0.000) loss: 0.577 
(epoch: 72, iters: 5648, time: 0.160, data: 0.005) loss: 0.601 
(epoch: 72, iters: 5728, time: 0.161, data: 0.000) loss: 1.071 
(epoch: 72, iters: 5808, time: 0.164, data: 0.009) loss: 0.797 
(epoch: 72, iters: 5888, time: 0.162, data: 0.005) loss: 1.139 
(epoch: 72, iters: 5968, time: 0.159, data: 0.000) loss: 0.313 
(epoch: 72, iters: 6048, time: 0.160, data: 0.005) loss: 0.446 
(epoch: 72, iters: 6128, time: 0.160, data: 0.008) loss: 0.703 
(epoch: 72, iters: 6208, time: 0.159, data: 0.014) loss: 0.762 
(epoch: 72, iters: 6288, time: 0.160, data: 0.015) loss: 0.654 
(epoch: 72, iters: 6368, time: 0.160, data: 0.019) loss: 0.703 
(epoch: 72, iters: 6448, time: 0.160, data: 0.000) loss: 1.208 
(epoch: 72, iters: 6528, time: 0.159, data: 0.000) loss: 0.741 
(epoch: 72, iters: 6608, time: 0.160, data: 0.000) loss: 0.326 
(epoch: 72, iters: 6688, time: 0.159, data: 0.008) loss: 0.574 
(epoch: 72, iters: 6768, time: 0.160, data: 0.000) loss: 0.842 
(epoch: 72, iters: 6848, time: 0.159, data: 0.006) loss: 0.383 
(epoch: 72, iters: 6928, time: 0.160, data: 0.000) loss: 0.773 
(epoch: 72, iters: 7008, time: 0.159, data: 0.000) loss: 1.118 
(epoch: 72, iters: 7088, time: 0.159, data: 0.005) loss: 0.387 
(epoch: 72, iters: 7168, time: 0.159, data: 0.000) loss: 0.921 
(epoch: 72, iters: 7248, time: 0.161, data: 0.000) loss: 0.516 
(epoch: 72, iters: 7328, time: 0.160, data: 0.016) loss: 0.756 
(epoch: 72, iters: 7408, time: 0.160, data: 0.014) loss: 0.778 
(epoch: 72, iters: 7488, time: 0.161, data: 0.005) loss: 1.000 
(epoch: 72, iters: 7568, time: 0.163, data: 0.016) loss: 0.498 
(epoch: 72, iters: 7648, time: 0.161, data: 0.000) loss: 0.959 
(epoch: 72, iters: 7728, time: 0.169, data: 0.006) loss: 0.487 
(epoch: 72, iters: 7808, time: 0.159, data: 0.000) loss: 0.420 
(epoch: 72, iters: 7888, time: 0.161, data: 0.000) loss: 0.549 
(epoch: 72, iters: 7968, time: 0.161, data: 0.009) loss: 1.004 
saving the latest model (epoch 72, total_steps 731648)
(epoch: 72, iters: 8048, time: 0.160, data: 0.000) loss: 0.390 
(epoch: 72, iters: 8128, time: 0.160, data: 0.000) loss: 0.988 
(epoch: 72, iters: 8208, time: 0.159, data: 0.000) loss: 0.770 
(epoch: 72, iters: 8288, time: 0.159, data: 0.023) loss: 0.322 
(epoch: 72, iters: 8368, time: 0.160, data: 0.000) loss: 0.298 
(epoch: 72, iters: 8448, time: 0.161, data: 0.008) loss: 0.134 
(epoch: 72, iters: 8528, time: 0.159, data: 0.005) loss: 0.916 
(epoch: 72, iters: 8608, time: 0.160, data: 0.000) loss: 1.836 
(epoch: 72, iters: 8688, time: 0.159, data: 0.009) loss: 0.767 
(epoch: 72, iters: 8768, time: 0.159, data: 0.000) loss: 0.834 
(epoch: 72, iters: 8848, time: 0.159, data: 0.000) loss: 1.004 
(epoch: 72, iters: 8928, time: 0.160, data: 0.009) loss: 0.793 
(epoch: 72, iters: 9008, time: 0.160, data: 0.000) loss: 1.140 
(epoch: 72, iters: 9088, time: 0.161, data: 0.025) loss: 0.872 
(epoch: 72, iters: 9168, time: 0.161, data: 0.000) loss: 0.476 
(epoch: 72, iters: 9248, time: 0.162, data: 0.040) loss: 1.477 
(epoch: 72, iters: 9328, time: 0.162, data: 0.000) loss: 0.665 
(epoch: 72, iters: 9408, time: 0.162, data: 0.017) loss: 0.445 
(epoch: 72, iters: 9488, time: 0.160, data: 0.005) loss: 0.682 
(epoch: 72, iters: 9568, time: 0.160, data: 0.000) loss: 0.611 
(epoch: 72, iters: 9648, time: 0.161, data: 0.005) loss: 0.779 
(epoch: 72, iters: 9728, time: 0.160, data: 0.017) loss: 0.694 
(epoch: 72, iters: 9808, time: 0.162, data: 0.000) loss: 0.737 
(epoch: 72, iters: 9888, time: 0.163, data: 0.000) loss: 0.774 
(epoch: 72, iters: 9968, time: 0.160, data: 0.008) loss: 0.526 
(epoch: 72, iters: 10048, time: 0.165, data: 0.000) loss: 1.105 
(epoch: 72, iters: 10128, time: 0.160, data: 0.008) loss: 1.083 
saving the model at the end of epoch 72, iters 733824
End of epoch 72 / 200 	 Time Taken: 1644 sec
learning rate = 0.0002000
(epoch: 73, iters: 16, time: 0.180, data: 0.009) loss: 0.751 
saving the latest model (epoch 73, total_steps 733840)
(epoch: 73, iters: 96, time: 0.160, data: 0.000) loss: 0.714 
(epoch: 73, iters: 176, time: 0.159, data: 0.009) loss: 0.664 
(epoch: 73, iters: 256, time: 0.160, data: 0.000) loss: 0.633 
(epoch: 73, iters: 336, time: 0.162, data: 0.005) loss: 0.370 
(epoch: 73, iters: 416, time: 0.159, data: 0.000) loss: 0.872 
(epoch: 73, iters: 496, time: 0.159, data: 0.000) loss: 0.746 
(epoch: 73, iters: 576, time: 0.159, data: 0.000) loss: 0.459 
(epoch: 73, iters: 656, time: 0.157, data: 0.000) loss: 0.433 
(epoch: 73, iters: 736, time: 0.159, data: 0.006) loss: 0.943 
(epoch: 73, iters: 816, time: 0.158, data: 0.000) loss: 0.589 
(epoch: 73, iters: 896, time: 0.160, data: 0.026) loss: 0.380 
(epoch: 73, iters: 976, time: 0.159, data: 0.000) loss: 0.501 
(epoch: 73, iters: 1056, time: 0.158, data: 0.000) loss: 0.329 
(epoch: 73, iters: 1136, time: 0.161, data: 0.000) loss: 0.769 
(epoch: 73, iters: 1216, time: 0.160, data: 0.000) loss: 0.287 
(epoch: 73, iters: 1296, time: 0.159, data: 0.010) loss: 1.226 
(epoch: 73, iters: 1376, time: 0.159, data: 0.005) loss: 1.397 
(epoch: 73, iters: 1456, time: 0.158, data: 0.013) loss: 0.747 
(epoch: 73, iters: 1536, time: 0.158, data: 0.000) loss: 0.524 
(epoch: 73, iters: 1616, time: 0.160, data: 0.008) loss: 0.361 
(epoch: 73, iters: 1696, time: 0.160, data: 0.005) loss: 0.625 
(epoch: 73, iters: 1776, time: 0.162, data: 0.018) loss: 0.374 
(epoch: 73, iters: 1856, time: 0.161, data: 0.000) loss: 0.702 
(epoch: 73, iters: 1936, time: 0.159, data: 0.017) loss: 0.795 
(epoch: 73, iters: 2016, time: 0.164, data: 0.000) loss: 0.526 
(epoch: 73, iters: 2096, time: 0.159, data: 0.000) loss: 0.787 
(epoch: 73, iters: 2176, time: 0.166, data: 0.000) loss: 0.689 
(epoch: 73, iters: 2256, time: 0.158, data: 0.019) loss: 0.632 
(epoch: 73, iters: 2336, time: 0.158, data: 0.009) loss: 0.701 
(epoch: 73, iters: 2416, time: 0.159, data: 0.000) loss: 0.534 
(epoch: 73, iters: 2496, time: 0.158, data: 0.006) loss: 0.680 
(epoch: 73, iters: 2576, time: 0.158, data: 0.000) loss: 0.345 
(epoch: 73, iters: 2656, time: 0.158, data: 0.016) loss: 0.724 
(epoch: 73, iters: 2736, time: 0.160, data: 0.000) loss: 0.894 
(epoch: 73, iters: 2816, time: 0.160, data: 0.010) loss: 0.380 
(epoch: 73, iters: 2896, time: 0.162, data: 0.000) loss: 0.826 
(epoch: 73, iters: 2976, time: 0.160, data: 0.032) loss: 0.743 
(epoch: 73, iters: 3056, time: 0.160, data: 0.000) loss: 0.406 
(epoch: 73, iters: 3136, time: 0.160, data: 0.041) loss: 0.945 
(epoch: 73, iters: 3216, time: 0.161, data: 0.000) loss: 0.615 
(epoch: 73, iters: 3296, time: 0.161, data: 0.000) loss: 0.361 
(epoch: 73, iters: 3376, time: 0.161, data: 0.024) loss: 0.830 
(epoch: 73, iters: 3456, time: 0.162, data: 0.000) loss: 0.636 
(epoch: 73, iters: 3536, time: 0.161, data: 0.000) loss: 0.857 
(epoch: 73, iters: 3616, time: 0.160, data: 0.000) loss: 1.255 
(epoch: 73, iters: 3696, time: 0.161, data: 0.000) loss: 0.383 
(epoch: 73, iters: 3776, time: 0.162, data: 0.008) loss: 0.322 
(epoch: 73, iters: 3856, time: 0.160, data: 0.000) loss: 0.691 
(epoch: 73, iters: 3936, time: 0.161, data: 0.007) loss: 1.264 
(epoch: 73, iters: 4016, time: 0.160, data: 0.025) loss: 0.374 
saving the latest model (epoch 73, total_steps 737840)
(epoch: 73, iters: 4096, time: 0.159, data: 0.000) loss: 0.737 
(epoch: 73, iters: 4176, time: 0.157, data: 0.011) loss: 0.246 
(epoch: 73, iters: 4256, time: 0.160, data: 0.009) loss: 0.747 
(epoch: 73, iters: 4336, time: 0.159, data: 0.005) loss: 0.693 
(epoch: 73, iters: 4416, time: 0.160, data: 0.000) loss: 0.546 
(epoch: 73, iters: 4496, time: 0.161, data: 0.000) loss: 0.470 
(epoch: 73, iters: 4576, time: 0.160, data: 0.016) loss: 0.696 
(epoch: 73, iters: 4656, time: 0.163, data: 0.000) loss: 0.390 
(epoch: 73, iters: 4736, time: 0.160, data: 0.015) loss: 0.962 
(epoch: 73, iters: 4816, time: 0.161, data: 0.021) loss: 0.437 
(epoch: 73, iters: 4896, time: 0.156, data: 0.000) loss: 0.527 
(epoch: 73, iters: 4976, time: 0.157, data: 0.014) loss: 0.322 
(epoch: 73, iters: 5056, time: 0.158, data: 0.006) loss: 0.311 
(epoch: 73, iters: 5136, time: 0.162, data: 0.000) loss: 0.312 
(epoch: 73, iters: 5216, time: 0.160, data: 0.005) loss: 0.636 
(epoch: 73, iters: 5296, time: 0.162, data: 0.000) loss: 0.315 
(epoch: 73, iters: 5376, time: 0.161, data: 0.013) loss: 0.499 
(epoch: 73, iters: 5456, time: 0.158, data: 0.000) loss: 0.431 
(epoch: 73, iters: 5536, time: 0.160, data: 0.024) loss: 0.885 
(epoch: 73, iters: 5616, time: 0.162, data: 0.000) loss: 0.749 
(epoch: 73, iters: 5696, time: 0.159, data: 0.000) loss: 0.538 
(epoch: 73, iters: 5776, time: 0.161, data: 0.000) loss: 0.350 
(epoch: 73, iters: 5856, time: 0.160, data: 0.000) loss: 1.020 
(epoch: 73, iters: 5936, time: 0.160, data: 0.029) loss: 0.402 
(epoch: 73, iters: 6016, time: 0.162, data: 0.000) loss: 0.779 
(epoch: 73, iters: 6096, time: 0.160, data: 0.011) loss: 0.742 
(epoch: 73, iters: 6176, time: 0.159, data: 0.000) loss: 0.978 
(epoch: 73, iters: 6256, time: 0.159, data: 0.000) loss: 0.319 
(epoch: 73, iters: 6336, time: 0.158, data: 0.006) loss: 0.502 
(epoch: 73, iters: 6416, time: 0.159, data: 0.008) loss: 0.564 
(epoch: 73, iters: 6496, time: 0.159, data: 0.005) loss: 0.919 
(epoch: 73, iters: 6576, time: 0.163, data: 0.024) loss: 0.247 
(epoch: 73, iters: 6656, time: 0.159, data: 0.000) loss: 0.555 
(epoch: 73, iters: 6736, time: 0.160, data: 0.013) loss: 0.862 
(epoch: 73, iters: 6816, time: 0.160, data: 0.000) loss: 1.146 
(epoch: 73, iters: 6896, time: 0.160, data: 0.000) loss: 0.615 
(epoch: 73, iters: 6976, time: 0.159, data: 0.000) loss: 0.642 
(epoch: 73, iters: 7056, time: 0.160, data: 0.025) loss: 0.417 
(epoch: 73, iters: 7136, time: 0.160, data: 0.000) loss: 1.096 
(epoch: 73, iters: 7216, time: 0.161, data: 0.012) loss: 1.727 
(epoch: 73, iters: 7296, time: 0.158, data: 0.000) loss: 1.009 
(epoch: 73, iters: 7376, time: 0.159, data: 0.027) loss: 0.765 
(epoch: 73, iters: 7456, time: 0.159, data: 0.000) loss: 0.967 
(epoch: 73, iters: 7536, time: 0.159, data: 0.025) loss: 0.672 
(epoch: 73, iters: 7616, time: 0.157, data: 0.000) loss: 0.581 
(epoch: 73, iters: 7696, time: 0.160, data: 0.010) loss: 0.539 
(epoch: 73, iters: 7776, time: 0.159, data: 0.000) loss: 0.496 
(epoch: 73, iters: 7856, time: 0.160, data: 0.024) loss: 0.392 
(epoch: 73, iters: 7936, time: 0.160, data: 0.000) loss: 0.817 
(epoch: 73, iters: 8016, time: 0.161, data: 0.000) loss: 0.944 
saving the latest model (epoch 73, total_steps 741840)
(epoch: 73, iters: 8096, time: 0.159, data: 0.005) loss: 0.757 
(epoch: 73, iters: 8176, time: 0.157, data: 0.000) loss: 0.340 
(epoch: 73, iters: 8256, time: 0.159, data: 0.000) loss: 1.083 
(epoch: 73, iters: 8336, time: 0.159, data: 0.000) loss: 0.597 
(epoch: 73, iters: 8416, time: 0.160, data: 0.016) loss: 1.567 
(epoch: 73, iters: 8496, time: 0.158, data: 0.009) loss: 0.559 
(epoch: 73, iters: 8576, time: 0.159, data: 0.006) loss: 0.506 
(epoch: 73, iters: 8656, time: 0.160, data: 0.025) loss: 0.682 
(epoch: 73, iters: 8736, time: 0.158, data: 0.000) loss: 0.795 
(epoch: 73, iters: 8816, time: 0.156, data: 0.000) loss: 1.109 
(epoch: 73, iters: 8896, time: 0.162, data: 0.000) loss: 0.370 
(epoch: 73, iters: 8976, time: 0.160, data: 0.005) loss: 0.741 
(epoch: 73, iters: 9056, time: 0.158, data: 0.011) loss: 0.523 
(epoch: 73, iters: 9136, time: 0.160, data: 0.006) loss: 0.509 
(epoch: 73, iters: 9216, time: 0.158, data: 0.020) loss: 0.609 
(epoch: 73, iters: 9296, time: 0.157, data: 0.000) loss: 0.577 
(epoch: 73, iters: 9376, time: 0.159, data: 0.000) loss: 1.177 
(epoch: 73, iters: 9456, time: 0.158, data: 0.005) loss: 0.679 
(epoch: 73, iters: 9536, time: 0.158, data: 0.000) loss: 1.210 
(epoch: 73, iters: 9616, time: 0.160, data: 0.008) loss: 0.842 
(epoch: 73, iters: 9696, time: 0.160, data: 0.023) loss: 0.668 
(epoch: 73, iters: 9776, time: 0.160, data: 0.000) loss: 1.059 
(epoch: 73, iters: 9856, time: 0.156, data: 0.000) loss: 0.472 
(epoch: 73, iters: 9936, time: 0.157, data: 0.005) loss: 0.647 
(epoch: 73, iters: 10016, time: 0.157, data: 0.023) loss: 0.284 
(epoch: 73, iters: 10096, time: 0.160, data: 0.000) loss: 1.419 
(epoch: 73, iters: 10176, time: 0.156, data: 0.010) loss: 0.370 
saving the model at the end of epoch 73, iters 744016
End of epoch 73 / 200 	 Time Taken: 1633 sec
learning rate = 0.0002000
saving the latest model (epoch 74, total_steps 744032)
(epoch: 74, iters: 64, time: 0.163, data: 0.000) loss: 0.503 
(epoch: 74, iters: 144, time: 0.161, data: 0.027) loss: 0.209 
(epoch: 74, iters: 224, time: 0.158, data: 0.000) loss: 0.512 
(epoch: 74, iters: 304, time: 0.158, data: 0.012) loss: 0.809 
(epoch: 74, iters: 384, time: 0.159, data: 0.000) loss: 0.628 
(epoch: 74, iters: 464, time: 0.159, data: 0.000) loss: 0.871 
(epoch: 74, iters: 544, time: 0.156, data: 0.000) loss: 0.784 
(epoch: 74, iters: 624, time: 0.159, data: 0.005) loss: 0.990 
(epoch: 74, iters: 704, time: 0.159, data: 0.017) loss: 0.786 
(epoch: 74, iters: 784, time: 0.159, data: 0.000) loss: 0.522 
(epoch: 74, iters: 864, time: 0.157, data: 0.023) loss: 1.081 
(epoch: 74, iters: 944, time: 0.161, data: 0.000) loss: 0.488 
(epoch: 74, iters: 1024, time: 0.160, data: 0.015) loss: 1.368 
(epoch: 74, iters: 1104, time: 0.161, data: 0.000) loss: 0.206 
(epoch: 74, iters: 1184, time: 0.160, data: 0.000) loss: 0.446 
(epoch: 74, iters: 1264, time: 0.160, data: 0.032) loss: 0.667 
(epoch: 74, iters: 1344, time: 0.161, data: 0.000) loss: 0.589 
(epoch: 74, iters: 1424, time: 0.165, data: 0.000) loss: 0.480 
(epoch: 74, iters: 1504, time: 0.161, data: 0.005) loss: 0.856 
(epoch: 74, iters: 1584, time: 0.161, data: 0.000) loss: 0.869 
(epoch: 74, iters: 1664, time: 0.159, data: 0.005) loss: 0.478 
(epoch: 74, iters: 1744, time: 0.160, data: 0.005) loss: 0.826 
(epoch: 74, iters: 1824, time: 0.163, data: 0.005) loss: 0.588 
(epoch: 74, iters: 1904, time: 0.161, data: 0.000) loss: 0.530 
(epoch: 74, iters: 1984, time: 0.161, data: 0.000) loss: 0.807 
(epoch: 74, iters: 2064, time: 0.161, data: 0.000) loss: 0.376 
(epoch: 74, iters: 2144, time: 0.159, data: 0.000) loss: 0.553 
(epoch: 74, iters: 2224, time: 0.159, data: 0.016) loss: 0.384 
(epoch: 74, iters: 2304, time: 0.163, data: 0.000) loss: 0.833 
(epoch: 74, iters: 2384, time: 0.162, data: 0.005) loss: 0.749 
(epoch: 74, iters: 2464, time: 0.163, data: 0.005) loss: 1.306 
(epoch: 74, iters: 2544, time: 0.169, data: 0.033) loss: 0.404 
(epoch: 74, iters: 2624, time: 0.162, data: 0.000) loss: 0.438 
(epoch: 74, iters: 2704, time: 0.161, data: 0.000) loss: 0.992 
(epoch: 74, iters: 2784, time: 0.162, data: 0.000) loss: 0.291 
(epoch: 74, iters: 2864, time: 0.161, data: 0.015) loss: 0.774 
(epoch: 74, iters: 2944, time: 0.162, data: 0.010) loss: 0.419 
(epoch: 74, iters: 3024, time: 0.162, data: 0.028) loss: 0.611 
(epoch: 74, iters: 3104, time: 0.163, data: 0.006) loss: 0.561 
(epoch: 74, iters: 3184, time: 0.162, data: 0.006) loss: 0.393 
(epoch: 74, iters: 3264, time: 0.159, data: 0.000) loss: 0.287 
(epoch: 74, iters: 3344, time: 0.161, data: 0.000) loss: 0.357 
(epoch: 74, iters: 3424, time: 0.164, data: 0.015) loss: 1.011 
(epoch: 74, iters: 3504, time: 0.162, data: 0.000) loss: 0.496 
(epoch: 74, iters: 3584, time: 0.160, data: 0.031) loss: 0.556 
(epoch: 74, iters: 3664, time: 0.162, data: 0.000) loss: 0.815 
(epoch: 74, iters: 3744, time: 0.159, data: 0.016) loss: 0.887 
(epoch: 74, iters: 3824, time: 0.162, data: 0.020) loss: 0.167 
(epoch: 74, iters: 3904, time: 0.161, data: 0.000) loss: 0.409 
(epoch: 74, iters: 3984, time: 0.161, data: 0.000) loss: 0.965 
saving the latest model (epoch 74, total_steps 748032)
(epoch: 74, iters: 4064, time: 0.163, data: 0.006) loss: 0.502 
(epoch: 74, iters: 4144, time: 0.161, data: 0.000) loss: 0.756 
(epoch: 74, iters: 4224, time: 0.158, data: 0.000) loss: 0.474 
(epoch: 74, iters: 4304, time: 0.161, data: 0.000) loss: 1.103 
(epoch: 74, iters: 4384, time: 0.160, data: 0.024) loss: 0.569 
(epoch: 74, iters: 4464, time: 0.163, data: 0.000) loss: 0.410 
(epoch: 74, iters: 4544, time: 0.161, data: 0.000) loss: 0.609 
(epoch: 74, iters: 4624, time: 0.159, data: 0.000) loss: 0.457 
(epoch: 74, iters: 4704, time: 0.161, data: 0.000) loss: 1.157 
(epoch: 74, iters: 4784, time: 0.160, data: 0.013) loss: 0.518 
(epoch: 74, iters: 4864, time: 0.160, data: 0.018) loss: 0.747 
(epoch: 74, iters: 4944, time: 0.161, data: 0.010) loss: 0.766 
(epoch: 74, iters: 5024, time: 0.159, data: 0.000) loss: 0.470 
(epoch: 74, iters: 5104, time: 0.159, data: 0.000) loss: 0.827 
(epoch: 74, iters: 5184, time: 0.162, data: 0.000) loss: 0.413 
(epoch: 74, iters: 5264, time: 0.162, data: 0.025) loss: 0.896 
(epoch: 74, iters: 5344, time: 0.160, data: 0.036) loss: 0.831 
(epoch: 74, iters: 5424, time: 0.162, data: 0.000) loss: 0.426 
(epoch: 74, iters: 5504, time: 0.161, data: 0.000) loss: 0.420 
(epoch: 74, iters: 5584, time: 0.159, data: 0.000) loss: 0.317 
(epoch: 74, iters: 5664, time: 0.161, data: 0.023) loss: 0.962 
(epoch: 74, iters: 5744, time: 0.165, data: 0.008) loss: 0.529 
(epoch: 74, iters: 5824, time: 0.162, data: 0.009) loss: 0.999 
(epoch: 74, iters: 5904, time: 0.163, data: 0.000) loss: 0.762 
(epoch: 74, iters: 5984, time: 0.161, data: 0.000) loss: 0.470 
(epoch: 74, iters: 6064, time: 0.161, data: 0.000) loss: 0.772 
(epoch: 74, iters: 6144, time: 0.159, data: 0.000) loss: 0.939 
(epoch: 74, iters: 6224, time: 0.160, data: 0.018) loss: 0.824 
(epoch: 74, iters: 6304, time: 0.161, data: 0.006) loss: 0.385 
(epoch: 74, iters: 6384, time: 0.161, data: 0.000) loss: 0.434 
(epoch: 74, iters: 6464, time: 0.160, data: 0.000) loss: 0.575 
(epoch: 74, iters: 6544, time: 0.161, data: 0.000) loss: 1.004 
(epoch: 74, iters: 6624, time: 0.161, data: 0.000) loss: 0.863 
(epoch: 74, iters: 6704, time: 0.162, data: 0.006) loss: 0.451 
(epoch: 74, iters: 6784, time: 0.160, data: 0.000) loss: 0.408 
(epoch: 74, iters: 6864, time: 0.163, data: 0.000) loss: 0.345 
(epoch: 74, iters: 6944, time: 0.159, data: 0.000) loss: 0.607 
(epoch: 74, iters: 7024, time: 0.162, data: 0.005) loss: 0.435 
(epoch: 74, iters: 7104, time: 0.160, data: 0.000) loss: 0.827 
(epoch: 74, iters: 7184, time: 0.161, data: 0.025) loss: 0.789 
(epoch: 74, iters: 7264, time: 0.161, data: 0.000) loss: 0.655 
(epoch: 74, iters: 7344, time: 0.161, data: 0.016) loss: 0.744 
(epoch: 74, iters: 7424, time: 0.161, data: 0.000) loss: 0.451 
(epoch: 74, iters: 7504, time: 0.161, data: 0.000) loss: 0.837 
(epoch: 74, iters: 7584, time: 0.160, data: 0.000) loss: 0.333 
(epoch: 74, iters: 7664, time: 0.162, data: 0.000) loss: 1.026 
(epoch: 74, iters: 7744, time: 0.162, data: 0.000) loss: 1.387 
(epoch: 74, iters: 7824, time: 0.162, data: 0.005) loss: 0.400 
(epoch: 74, iters: 7904, time: 0.160, data: 0.023) loss: 0.438 
(epoch: 74, iters: 7984, time: 0.160, data: 0.000) loss: 0.656 
saving the latest model (epoch 74, total_steps 752032)
(epoch: 74, iters: 8064, time: 0.159, data: 0.026) loss: 1.665 
(epoch: 74, iters: 8144, time: 0.161, data: 0.000) loss: 0.859 
(epoch: 74, iters: 8224, time: 0.160, data: 0.000) loss: 1.099 
(epoch: 74, iters: 8304, time: 0.160, data: 0.000) loss: 1.087 
(epoch: 74, iters: 8384, time: 0.160, data: 0.005) loss: 0.438 
(epoch: 74, iters: 8464, time: 0.161, data: 0.011) loss: 0.912 
(epoch: 74, iters: 8544, time: 0.159, data: 0.000) loss: 0.824 
(epoch: 74, iters: 8624, time: 0.162, data: 0.000) loss: 0.310 
(epoch: 74, iters: 8704, time: 0.160, data: 0.015) loss: 0.550 
(epoch: 74, iters: 8784, time: 0.160, data: 0.000) loss: 0.979 
(epoch: 74, iters: 8864, time: 0.158, data: 0.018) loss: 0.804 
(epoch: 74, iters: 8944, time: 0.163, data: 0.000) loss: 0.738 
(epoch: 74, iters: 9024, time: 0.162, data: 0.022) loss: 1.121 
(epoch: 74, iters: 9104, time: 0.161, data: 0.010) loss: 0.812 
(epoch: 74, iters: 9184, time: 0.159, data: 0.006) loss: 0.228 
(epoch: 74, iters: 9264, time: 0.160, data: 0.005) loss: 0.212 
(epoch: 74, iters: 9344, time: 0.163, data: 0.000) loss: 0.989 
(epoch: 74, iters: 9424, time: 0.160, data: 0.017) loss: 0.258 
(epoch: 74, iters: 9504, time: 0.162, data: 0.014) loss: 0.329 
(epoch: 74, iters: 9584, time: 0.161, data: 0.018) loss: 0.483 
(epoch: 74, iters: 9664, time: 0.161, data: 0.000) loss: 0.589 
(epoch: 74, iters: 9744, time: 0.163, data: 0.000) loss: 1.550 
(epoch: 74, iters: 9824, time: 0.161, data: 0.000) loss: 0.516 
(epoch: 74, iters: 9904, time: 0.160, data: 0.000) loss: 0.514 
(epoch: 74, iters: 9984, time: 0.160, data: 0.000) loss: 0.652 
(epoch: 74, iters: 10064, time: 0.159, data: 0.000) loss: 0.417 
(epoch: 74, iters: 10144, time: 0.162, data: 0.000) loss: 1.040 
saving the model at the end of epoch 74, iters 754208
End of epoch 74 / 200 	 Time Taken: 1644 sec
learning rate = 0.0002000
saving the latest model (epoch 75, total_steps 754224)
(epoch: 75, iters: 32, time: 0.169, data: 0.000) loss: 0.453 
(epoch: 75, iters: 112, time: 0.160, data: 0.025) loss: 0.498 
(epoch: 75, iters: 192, time: 0.160, data: 0.000) loss: 0.377 
(epoch: 75, iters: 272, time: 0.160, data: 0.000) loss: 1.040 
(epoch: 75, iters: 352, time: 0.159, data: 0.000) loss: 0.941 
(epoch: 75, iters: 432, time: 0.159, data: 0.007) loss: 1.177 
(epoch: 75, iters: 512, time: 0.161, data: 0.008) loss: 1.139 
(epoch: 75, iters: 592, time: 0.160, data: 0.006) loss: 1.226 
(epoch: 75, iters: 672, time: 0.161, data: 0.006) loss: 0.354 
(epoch: 75, iters: 752, time: 0.159, data: 0.024) loss: 0.564 
(epoch: 75, iters: 832, time: 0.159, data: 0.000) loss: 0.254 
(epoch: 75, iters: 912, time: 0.156, data: 0.005) loss: 0.709 
(epoch: 75, iters: 992, time: 0.160, data: 0.000) loss: 0.938 
(epoch: 75, iters: 1072, time: 0.159, data: 0.009) loss: 0.365 
(epoch: 75, iters: 1152, time: 0.158, data: 0.000) loss: 1.187 
(epoch: 75, iters: 1232, time: 0.157, data: 0.006) loss: 0.402 
(epoch: 75, iters: 1312, time: 0.157, data: 0.000) loss: 0.644 
(epoch: 75, iters: 1392, time: 0.158, data: 0.005) loss: 0.640 
(epoch: 75, iters: 1472, time: 0.158, data: 0.000) loss: 0.692 
(epoch: 75, iters: 1552, time: 0.157, data: 0.014) loss: 0.831 
(epoch: 75, iters: 1632, time: 0.159, data: 0.000) loss: 0.604 
(epoch: 75, iters: 1712, time: 0.160, data: 0.000) loss: 0.455 
(epoch: 75, iters: 1792, time: 0.158, data: 0.016) loss: 0.305 
(epoch: 75, iters: 1872, time: 0.157, data: 0.000) loss: 0.580 
(epoch: 75, iters: 1952, time: 0.159, data: 0.009) loss: 0.428 
(epoch: 75, iters: 2032, time: 0.159, data: 0.008) loss: 0.984 
(epoch: 75, iters: 2112, time: 0.158, data: 0.006) loss: 1.072 
(epoch: 75, iters: 2192, time: 0.158, data: 0.005) loss: 1.084 
(epoch: 75, iters: 2272, time: 0.157, data: 0.010) loss: 0.720 
(epoch: 75, iters: 2352, time: 0.158, data: 0.000) loss: 0.438 
(epoch: 75, iters: 2432, time: 0.159, data: 0.006) loss: 0.861 
(epoch: 75, iters: 2512, time: 0.158, data: 0.008) loss: 0.678 
(epoch: 75, iters: 2592, time: 0.157, data: 0.000) loss: 0.188 
(epoch: 75, iters: 2672, time: 0.158, data: 0.016) loss: 0.487 
(epoch: 75, iters: 2752, time: 0.159, data: 0.005) loss: 1.090 
(epoch: 75, iters: 2832, time: 0.158, data: 0.000) loss: 0.677 
(epoch: 75, iters: 2912, time: 0.161, data: 0.032) loss: 0.669 
(epoch: 75, iters: 2992, time: 0.160, data: 0.000) loss: 0.613 
(epoch: 75, iters: 3072, time: 0.158, data: 0.034) loss: 0.884 
(epoch: 75, iters: 3152, time: 0.160, data: 0.000) loss: 0.539 
(epoch: 75, iters: 3232, time: 0.162, data: 0.000) loss: 0.719 
(epoch: 75, iters: 3312, time: 0.159, data: 0.005) loss: 0.531 
(epoch: 75, iters: 3392, time: 0.159, data: 0.008) loss: 0.265 
(epoch: 75, iters: 3472, time: 0.159, data: 0.000) loss: 0.699 
(epoch: 75, iters: 3552, time: 0.161, data: 0.011) loss: 0.687 
(epoch: 75, iters: 3632, time: 0.160, data: 0.015) loss: 0.727 
(epoch: 75, iters: 3712, time: 0.160, data: 0.000) loss: 0.705 
(epoch: 75, iters: 3792, time: 0.158, data: 0.030) loss: 0.276 
(epoch: 75, iters: 3872, time: 0.159, data: 0.000) loss: 1.759 
(epoch: 75, iters: 3952, time: 0.159, data: 0.000) loss: 0.978 
saving the latest model (epoch 75, total_steps 758224)
(epoch: 75, iters: 4032, time: 0.157, data: 0.005) loss: 1.442 
(epoch: 75, iters: 4112, time: 0.160, data: 0.000) loss: 1.187 
(epoch: 75, iters: 4192, time: 0.159, data: 0.020) loss: 0.893 
(epoch: 75, iters: 4272, time: 0.158, data: 0.012) loss: 0.534 
(epoch: 75, iters: 4352, time: 0.159, data: 0.000) loss: 0.955 
(epoch: 75, iters: 4432, time: 0.161, data: 0.019) loss: 0.815 
(epoch: 75, iters: 4512, time: 0.160, data: 0.000) loss: 0.699 
(epoch: 75, iters: 4592, time: 0.159, data: 0.000) loss: 0.463 
(epoch: 75, iters: 4672, time: 0.160, data: 0.000) loss: 0.740 
(epoch: 75, iters: 4752, time: 0.157, data: 0.005) loss: 0.933 
(epoch: 75, iters: 4832, time: 0.157, data: 0.006) loss: 0.644 
(epoch: 75, iters: 4912, time: 0.160, data: 0.000) loss: 0.862 
(epoch: 75, iters: 4992, time: 0.159, data: 0.013) loss: 0.644 
(epoch: 75, iters: 5072, time: 0.162, data: 0.000) loss: 0.527 
(epoch: 75, iters: 5152, time: 0.163, data: 0.033) loss: 1.056 
(epoch: 75, iters: 5232, time: 0.160, data: 0.000) loss: 0.378 
(epoch: 75, iters: 5312, time: 0.156, data: 0.000) loss: 0.354 
(epoch: 75, iters: 5392, time: 0.158, data: 0.006) loss: 0.404 
(epoch: 75, iters: 5472, time: 0.156, data: 0.000) loss: 0.493 
(epoch: 75, iters: 5552, time: 0.158, data: 0.000) loss: 0.278 
(epoch: 75, iters: 5632, time: 0.158, data: 0.000) loss: 0.803 
(epoch: 75, iters: 5712, time: 0.160, data: 0.006) loss: 0.395 
(epoch: 75, iters: 5792, time: 0.159, data: 0.000) loss: 0.368 
(epoch: 75, iters: 5872, time: 0.157, data: 0.000) loss: 0.725 
(epoch: 75, iters: 5952, time: 0.160, data: 0.000) loss: 0.299 
(epoch: 75, iters: 6032, time: 0.160, data: 0.005) loss: 0.558 
(epoch: 75, iters: 6112, time: 0.160, data: 0.000) loss: 0.599 
(epoch: 75, iters: 6192, time: 0.160, data: 0.000) loss: 0.736 
(epoch: 75, iters: 6272, time: 0.159, data: 0.005) loss: 0.504 
(epoch: 75, iters: 6352, time: 0.161, data: 0.006) loss: 1.001 
(epoch: 75, iters: 6432, time: 0.160, data: 0.000) loss: 1.086 
(epoch: 75, iters: 6512, time: 0.158, data: 0.032) loss: 0.541 
(epoch: 75, iters: 6592, time: 0.160, data: 0.000) loss: 1.518 
(epoch: 75, iters: 6672, time: 0.158, data: 0.000) loss: 0.557 
(epoch: 75, iters: 6752, time: 0.160, data: 0.005) loss: 0.838 
(epoch: 75, iters: 6832, time: 0.159, data: 0.000) loss: 0.510 
(epoch: 75, iters: 6912, time: 0.155, data: 0.015) loss: 0.436 
(epoch: 75, iters: 6992, time: 0.158, data: 0.010) loss: 1.078 
(epoch: 75, iters: 7072, time: 0.158, data: 0.000) loss: 0.420 
(epoch: 75, iters: 7152, time: 0.158, data: 0.000) loss: 0.597 
(epoch: 75, iters: 7232, time: 0.161, data: 0.025) loss: 0.870 
(epoch: 75, iters: 7312, time: 0.160, data: 0.023) loss: 0.647 
(epoch: 75, iters: 7392, time: 0.160, data: 0.000) loss: 0.890 
(epoch: 75, iters: 7472, time: 0.158, data: 0.013) loss: 0.906 
(epoch: 75, iters: 7552, time: 0.158, data: 0.016) loss: 0.366 
(epoch: 75, iters: 7632, time: 0.159, data: 0.011) loss: 0.717 
(epoch: 75, iters: 7712, time: 0.158, data: 0.033) loss: 0.394 
(epoch: 75, iters: 7792, time: 0.163, data: 0.000) loss: 0.689 
(epoch: 75, iters: 7872, time: 0.161, data: 0.000) loss: 0.559 
(epoch: 75, iters: 7952, time: 0.162, data: 0.014) loss: 0.377 
saving the latest model (epoch 75, total_steps 762224)
(epoch: 75, iters: 8032, time: 0.160, data: 0.000) loss: 0.469 
(epoch: 75, iters: 8112, time: 0.161, data: 0.005) loss: 0.466 
(epoch: 75, iters: 8192, time: 0.162, data: 0.006) loss: 0.525 
(epoch: 75, iters: 8272, time: 0.159, data: 0.000) loss: 0.473 
(epoch: 75, iters: 8352, time: 0.160, data: 0.000) loss: 0.384 
(epoch: 75, iters: 8432, time: 0.158, data: 0.000) loss: 0.254 
(epoch: 75, iters: 8512, time: 0.160, data: 0.000) loss: 1.074 
(epoch: 75, iters: 8592, time: 0.159, data: 0.008) loss: 0.795 
(epoch: 75, iters: 8672, time: 0.159, data: 0.000) loss: 0.983 
(epoch: 75, iters: 8752, time: 0.158, data: 0.005) loss: 1.376 
(epoch: 75, iters: 8832, time: 0.159, data: 0.000) loss: 0.457 
(epoch: 75, iters: 8912, time: 0.159, data: 0.000) loss: 0.934 
(epoch: 75, iters: 8992, time: 0.161, data: 0.000) loss: 0.342 
(epoch: 75, iters: 9072, time: 0.160, data: 0.023) loss: 0.520 
(epoch: 75, iters: 9152, time: 0.161, data: 0.000) loss: 0.993 
(epoch: 75, iters: 9232, time: 0.158, data: 0.000) loss: 0.979 
(epoch: 75, iters: 9312, time: 0.160, data: 0.000) loss: 0.598 
(epoch: 75, iters: 9392, time: 0.158, data: 0.013) loss: 0.921 
(epoch: 75, iters: 9472, time: 0.156, data: 0.000) loss: 0.406 
(epoch: 75, iters: 9552, time: 0.158, data: 0.028) loss: 0.461 
(epoch: 75, iters: 9632, time: 0.159, data: 0.000) loss: 1.197 
(epoch: 75, iters: 9712, time: 0.159, data: 0.000) loss: 0.513 
(epoch: 75, iters: 9792, time: 0.159, data: 0.005) loss: 0.535 
(epoch: 75, iters: 9872, time: 0.159, data: 0.000) loss: 0.720 
(epoch: 75, iters: 9952, time: 0.158, data: 0.023) loss: 0.194 
(epoch: 75, iters: 10032, time: 0.159, data: 0.000) loss: 0.938 
(epoch: 75, iters: 10112, time: 0.158, data: 0.000) loss: 0.909 
(epoch: 75, iters: 10192, time: 0.096, data: 0.014) loss: 1.165 
saving the model at the end of epoch 75, iters 764400
End of epoch 75 / 200 	 Time Taken: 1625 sec
learning rate = 0.0002000
saving the latest model (epoch 76, total_steps 764416)
(epoch: 76, iters: 80, time: 0.162, data: 0.191) loss: 0.462 
(epoch: 76, iters: 160, time: 0.160, data: 0.047) loss: 0.644 
(epoch: 76, iters: 240, time: 0.159, data: 0.000) loss: 1.049 
(epoch: 76, iters: 320, time: 0.159, data: 0.000) loss: 0.979 
(epoch: 76, iters: 400, time: 0.158, data: 0.008) loss: 0.470 
(epoch: 76, iters: 480, time: 0.156, data: 0.008) loss: 0.550 
(epoch: 76, iters: 560, time: 0.158, data: 0.000) loss: 0.587 
(epoch: 76, iters: 640, time: 0.158, data: 0.011) loss: 0.719 
(epoch: 76, iters: 720, time: 0.157, data: 0.015) loss: 0.287 
(epoch: 76, iters: 800, time: 0.159, data: 0.000) loss: 0.538 
(epoch: 76, iters: 880, time: 0.162, data: 0.011) loss: 0.327 
(epoch: 76, iters: 960, time: 0.160, data: 0.008) loss: 1.036 
(epoch: 76, iters: 1040, time: 0.161, data: 0.000) loss: 0.818 
(epoch: 76, iters: 1120, time: 0.161, data: 0.008) loss: 0.587 
(epoch: 76, iters: 1200, time: 0.161, data: 0.016) loss: 0.499 
(epoch: 76, iters: 1280, time: 0.162, data: 0.000) loss: 0.550 
(epoch: 76, iters: 1360, time: 0.161, data: 0.000) loss: 0.483 
(epoch: 76, iters: 1440, time: 0.163, data: 0.028) loss: 0.741 
(epoch: 76, iters: 1520, time: 0.161, data: 0.013) loss: 0.649 
(epoch: 76, iters: 1600, time: 0.161, data: 0.005) loss: 1.213 
(epoch: 76, iters: 1680, time: 0.161, data: 0.000) loss: 0.486 
(epoch: 76, iters: 1760, time: 0.161, data: 0.009) loss: 0.608 
(epoch: 76, iters: 1840, time: 0.161, data: 0.000) loss: 0.294 
(epoch: 76, iters: 1920, time: 0.162, data: 0.009) loss: 0.908 
(epoch: 76, iters: 2000, time: 0.163, data: 0.009) loss: 0.458 
(epoch: 76, iters: 2080, time: 0.160, data: 0.013) loss: 0.838 
(epoch: 76, iters: 2160, time: 0.161, data: 0.032) loss: 0.630 
(epoch: 76, iters: 2240, time: 0.161, data: 0.000) loss: 0.382 
(epoch: 76, iters: 2320, time: 0.160, data: 0.000) loss: 0.598 
(epoch: 76, iters: 2400, time: 0.161, data: 0.008) loss: 1.015 
(epoch: 76, iters: 2480, time: 0.163, data: 0.018) loss: 0.267 
(epoch: 76, iters: 2560, time: 0.161, data: 0.000) loss: 0.403 
(epoch: 76, iters: 2640, time: 0.160, data: 0.000) loss: 1.071 
(epoch: 76, iters: 2720, time: 0.160, data: 0.006) loss: 0.411 
(epoch: 76, iters: 2800, time: 0.160, data: 0.000) loss: 0.698 
(epoch: 76, iters: 2880, time: 0.160, data: 0.000) loss: 0.543 
(epoch: 76, iters: 2960, time: 0.160, data: 0.000) loss: 1.250 
(epoch: 76, iters: 3040, time: 0.160, data: 0.009) loss: 0.377 
(epoch: 76, iters: 3120, time: 0.159, data: 0.000) loss: 1.008 
(epoch: 76, iters: 3200, time: 0.159, data: 0.000) loss: 0.818 
(epoch: 76, iters: 3280, time: 0.162, data: 0.029) loss: 0.302 
(epoch: 76, iters: 3360, time: 0.160, data: 0.000) loss: 0.390 
(epoch: 76, iters: 3440, time: 0.160, data: 0.044) loss: 0.524 
(epoch: 76, iters: 3520, time: 0.161, data: 0.000) loss: 0.865 
(epoch: 76, iters: 3600, time: 0.162, data: 0.000) loss: 0.586 
(epoch: 76, iters: 3680, time: 0.163, data: 0.005) loss: 0.223 
(epoch: 76, iters: 3760, time: 0.161, data: 0.000) loss: 0.514 
(epoch: 76, iters: 3840, time: 0.162, data: 0.005) loss: 0.899 
(epoch: 76, iters: 3920, time: 0.161, data: 0.017) loss: 0.493 
(epoch: 76, iters: 4000, time: 0.162, data: 0.000) loss: 0.488 
saving the latest model (epoch 76, total_steps 768416)
(epoch: 76, iters: 4080, time: 0.162, data: 0.013) loss: 0.907 
(epoch: 76, iters: 4160, time: 0.162, data: 0.014) loss: 1.535 
(epoch: 76, iters: 4240, time: 0.161, data: 0.011) loss: 0.444 
(epoch: 76, iters: 4320, time: 0.161, data: 0.000) loss: 0.740 
(epoch: 76, iters: 4400, time: 0.161, data: 0.011) loss: 0.734 
(epoch: 76, iters: 4480, time: 0.162, data: 0.006) loss: 0.701 
(epoch: 76, iters: 4560, time: 0.161, data: 0.006) loss: 0.686 
(epoch: 76, iters: 4640, time: 0.163, data: 0.000) loss: 0.650 
(epoch: 76, iters: 4720, time: 0.161, data: 0.026) loss: 0.787 
(epoch: 76, iters: 4800, time: 0.163, data: 0.000) loss: 0.373 
(epoch: 76, iters: 4880, time: 0.161, data: 0.000) loss: 0.619 
(epoch: 76, iters: 4960, time: 0.160, data: 0.000) loss: 0.830 
(epoch: 76, iters: 5040, time: 0.161, data: 0.000) loss: 0.450 
(epoch: 76, iters: 5120, time: 0.160, data: 0.021) loss: 0.898 
(epoch: 76, iters: 5200, time: 0.162, data: 0.000) loss: 0.325 
(epoch: 76, iters: 5280, time: 0.162, data: 0.021) loss: 1.594 
(epoch: 76, iters: 5360, time: 0.162, data: 0.005) loss: 0.344 
(epoch: 76, iters: 5440, time: 0.160, data: 0.000) loss: 0.711 
(epoch: 76, iters: 5520, time: 0.162, data: 0.029) loss: 0.608 
(epoch: 76, iters: 5600, time: 0.161, data: 0.008) loss: 0.658 
(epoch: 76, iters: 5680, time: 0.160, data: 0.000) loss: 0.355 
(epoch: 76, iters: 5760, time: 0.160, data: 0.005) loss: 0.840 
(epoch: 76, iters: 5840, time: 0.160, data: 0.013) loss: 1.158 
(epoch: 76, iters: 5920, time: 0.159, data: 0.000) loss: 0.349 
(epoch: 76, iters: 6000, time: 0.160, data: 0.020) loss: 0.595 
(epoch: 76, iters: 6080, time: 0.160, data: 0.000) loss: 0.671 
(epoch: 76, iters: 6160, time: 0.158, data: 0.033) loss: 0.470 
(epoch: 76, iters: 6240, time: 0.160, data: 0.000) loss: 0.573 
(epoch: 76, iters: 6320, time: 0.163, data: 0.000) loss: 0.316 
(epoch: 76, iters: 6400, time: 0.158, data: 0.000) loss: 0.453 
(epoch: 76, iters: 6480, time: 0.158, data: 0.008) loss: 0.304 
(epoch: 76, iters: 6560, time: 0.161, data: 0.009) loss: 0.557 
(epoch: 76, iters: 6640, time: 0.159, data: 0.006) loss: 0.411 
(epoch: 76, iters: 6720, time: 0.159, data: 0.000) loss: 0.256 
(epoch: 76, iters: 6800, time: 0.159, data: 0.006) loss: 0.611 
(epoch: 76, iters: 6880, time: 0.159, data: 0.000) loss: 0.483 
(epoch: 76, iters: 6960, time: 0.159, data: 0.000) loss: 0.793 
(epoch: 76, iters: 7040, time: 0.160, data: 0.000) loss: 0.857 
(epoch: 76, iters: 7120, time: 0.158, data: 0.000) loss: 0.369 
(epoch: 76, iters: 7200, time: 0.158, data: 0.022) loss: 0.714 
(epoch: 76, iters: 7280, time: 0.161, data: 0.000) loss: 0.636 
(epoch: 76, iters: 7360, time: 0.159, data: 0.042) loss: 0.609 
(epoch: 76, iters: 7440, time: 0.161, data: 0.000) loss: 0.406 
(epoch: 76, iters: 7520, time: 0.157, data: 0.012) loss: 0.693 
(epoch: 76, iters: 7600, time: 0.159, data: 0.005) loss: 0.353 
(epoch: 76, iters: 7680, time: 0.160, data: 0.000) loss: 0.226 
(epoch: 76, iters: 7760, time: 0.161, data: 0.005) loss: 0.745 
(epoch: 76, iters: 7840, time: 0.160, data: 0.005) loss: 0.947 
(epoch: 76, iters: 7920, time: 0.161, data: 0.000) loss: 0.479 
(epoch: 76, iters: 8000, time: 0.161, data: 0.031) loss: 0.902 
saving the latest model (epoch 76, total_steps 772416)
(epoch: 76, iters: 8080, time: 0.160, data: 0.000) loss: 0.542 
(epoch: 76, iters: 8160, time: 0.159, data: 0.000) loss: 1.211 
(epoch: 76, iters: 8240, time: 0.161, data: 0.000) loss: 0.671 
(epoch: 76, iters: 8320, time: 0.161, data: 0.016) loss: 0.152 
(epoch: 76, iters: 8400, time: 0.162, data: 0.000) loss: 0.816 
(epoch: 76, iters: 8480, time: 0.161, data: 0.027) loss: 0.446 
(epoch: 76, iters: 8560, time: 0.160, data: 0.000) loss: 0.561 
(epoch: 76, iters: 8640, time: 0.161, data: 0.000) loss: 0.311 
(epoch: 76, iters: 8720, time: 0.161, data: 0.000) loss: 0.723 
(epoch: 76, iters: 8800, time: 0.162, data: 0.021) loss: 0.587 
(epoch: 76, iters: 8880, time: 0.161, data: 0.008) loss: 0.488 
(epoch: 76, iters: 8960, time: 0.159, data: 0.000) loss: 1.240 
(epoch: 76, iters: 9040, time: 0.160, data: 0.027) loss: 0.413 
(epoch: 76, iters: 9120, time: 0.160, data: 0.000) loss: 0.621 
(epoch: 76, iters: 9200, time: 0.163, data: 0.000) loss: 0.403 
(epoch: 76, iters: 9280, time: 0.161, data: 0.015) loss: 0.575 
(epoch: 76, iters: 9360, time: 0.162, data: 0.005) loss: 0.485 
(epoch: 76, iters: 9440, time: 0.162, data: 0.008) loss: 0.299 
(epoch: 76, iters: 9520, time: 0.161, data: 0.011) loss: 0.307 
(epoch: 76, iters: 9600, time: 0.160, data: 0.013) loss: 0.397 
(epoch: 76, iters: 9680, time: 0.159, data: 0.008) loss: 0.875 
(epoch: 76, iters: 9760, time: 0.161, data: 0.000) loss: 1.230 
(epoch: 76, iters: 9840, time: 0.162, data: 0.000) loss: 0.643 
(epoch: 76, iters: 9920, time: 0.161, data: 0.000) loss: 0.454 
(epoch: 76, iters: 10000, time: 0.160, data: 0.000) loss: 0.622 
(epoch: 76, iters: 10080, time: 0.161, data: 0.016) loss: 0.490 
(epoch: 76, iters: 10160, time: 0.161, data: 0.000) loss: 0.803 
saving the model at the end of epoch 76, iters 774592
End of epoch 76 / 200 	 Time Taken: 1643 sec
learning rate = 0.0002000
saving the latest model (epoch 77, total_steps 774608)
(epoch: 77, iters: 48, time: 0.167, data: 0.005) loss: 0.599 
(epoch: 77, iters: 128, time: 0.160, data: 0.050) loss: 0.501 
(epoch: 77, iters: 208, time: 0.157, data: 0.000) loss: 0.536 
(epoch: 77, iters: 288, time: 0.158, data: 0.010) loss: 0.451 
(epoch: 77, iters: 368, time: 0.157, data: 0.000) loss: 0.540 
(epoch: 77, iters: 448, time: 0.156, data: 0.012) loss: 0.521 
(epoch: 77, iters: 528, time: 0.157, data: 0.000) loss: 0.545 
(epoch: 77, iters: 608, time: 0.157, data: 0.000) loss: 1.137 
(epoch: 77, iters: 688, time: 0.157, data: 0.000) loss: 1.356 
(epoch: 77, iters: 768, time: 0.158, data: 0.006) loss: 0.372 
(epoch: 77, iters: 848, time: 0.156, data: 0.000) loss: 0.663 
(epoch: 77, iters: 928, time: 0.156, data: 0.000) loss: 0.785 
(epoch: 77, iters: 1008, time: 0.158, data: 0.018) loss: 0.611 
(epoch: 77, iters: 1088, time: 0.159, data: 0.000) loss: 0.168 
(epoch: 77, iters: 1168, time: 0.157, data: 0.000) loss: 0.765 
(epoch: 77, iters: 1248, time: 0.157, data: 0.008) loss: 0.630 
(epoch: 77, iters: 1328, time: 0.156, data: 0.000) loss: 0.650 
(epoch: 77, iters: 1408, time: 0.156, data: 0.000) loss: 0.596 
(epoch: 77, iters: 1488, time: 0.157, data: 0.011) loss: 0.314 
(epoch: 77, iters: 1568, time: 0.158, data: 0.000) loss: 0.279 
(epoch: 77, iters: 1648, time: 0.157, data: 0.000) loss: 0.486 
(epoch: 77, iters: 1728, time: 0.157, data: 0.013) loss: 0.619 
(epoch: 77, iters: 1808, time: 0.157, data: 0.005) loss: 1.464 
(epoch: 77, iters: 1888, time: 0.158, data: 0.000) loss: 0.689 
(epoch: 77, iters: 1968, time: 0.157, data: 0.005) loss: 1.000 
(epoch: 77, iters: 2048, time: 0.159, data: 0.006) loss: 0.466 
(epoch: 77, iters: 2128, time: 0.158, data: 0.000) loss: 0.541 
(epoch: 77, iters: 2208, time: 0.159, data: 0.024) loss: 0.692 
(epoch: 77, iters: 2288, time: 0.157, data: 0.000) loss: 0.720 
(epoch: 77, iters: 2368, time: 0.158, data: 0.006) loss: 0.354 
(epoch: 77, iters: 2448, time: 0.157, data: 0.000) loss: 0.393 
(epoch: 77, iters: 2528, time: 0.158, data: 0.000) loss: 0.602 
(epoch: 77, iters: 2608, time: 0.158, data: 0.000) loss: 0.990 
(epoch: 77, iters: 2688, time: 0.157, data: 0.028) loss: 0.620 
(epoch: 77, iters: 2768, time: 0.155, data: 0.000) loss: 0.639 
(epoch: 77, iters: 2848, time: 0.156, data: 0.023) loss: 0.590 
(epoch: 77, iters: 2928, time: 0.158, data: 0.000) loss: 0.321 
(epoch: 77, iters: 3008, time: 0.158, data: 0.023) loss: 0.468 
(epoch: 77, iters: 3088, time: 0.158, data: 0.000) loss: 0.523 
(epoch: 77, iters: 3168, time: 0.158, data: 0.000) loss: 0.829 
(epoch: 77, iters: 3248, time: 0.159, data: 0.000) loss: 0.345 
(epoch: 77, iters: 3328, time: 0.161, data: 0.019) loss: 1.338 
(epoch: 77, iters: 3408, time: 0.161, data: 0.000) loss: 0.275 
(epoch: 77, iters: 3488, time: 0.159, data: 0.005) loss: 0.503 
(epoch: 77, iters: 3568, time: 0.161, data: 0.006) loss: 0.336 
(epoch: 77, iters: 3648, time: 0.159, data: 0.000) loss: 0.333 
(epoch: 77, iters: 3728, time: 0.159, data: 0.012) loss: 0.804 
(epoch: 77, iters: 3808, time: 0.161, data: 0.000) loss: 0.404 
(epoch: 77, iters: 3888, time: 0.160, data: 0.000) loss: 0.713 
(epoch: 77, iters: 3968, time: 0.163, data: 0.005) loss: 0.477 
saving the latest model (epoch 77, total_steps 778608)
(epoch: 77, iters: 4048, time: 0.158, data: 0.000) loss: 0.847 
(epoch: 77, iters: 4128, time: 0.159, data: 0.000) loss: 0.665 
(epoch: 77, iters: 4208, time: 0.160, data: 0.019) loss: 0.715 
(epoch: 77, iters: 4288, time: 0.162, data: 0.000) loss: 0.792 
(epoch: 77, iters: 4368, time: 0.159, data: 0.000) loss: 0.550 
(epoch: 77, iters: 4448, time: 0.160, data: 0.008) loss: 0.542 
(epoch: 77, iters: 4528, time: 0.160, data: 0.000) loss: 0.521 
(epoch: 77, iters: 4608, time: 0.159, data: 0.000) loss: 0.868 
(epoch: 77, iters: 4688, time: 0.159, data: 0.006) loss: 1.053 
(epoch: 77, iters: 4768, time: 0.158, data: 0.000) loss: 0.558 
(epoch: 77, iters: 4848, time: 0.159, data: 0.017) loss: 0.730 
(epoch: 77, iters: 4928, time: 0.159, data: 0.000) loss: 0.751 
(epoch: 77, iters: 5008, time: 0.159, data: 0.021) loss: 0.966 
(epoch: 77, iters: 5088, time: 0.158, data: 0.005) loss: 0.167 
(epoch: 77, iters: 5168, time: 0.161, data: 0.009) loss: 0.555 
(epoch: 77, iters: 5248, time: 0.159, data: 0.000) loss: 0.733 
(epoch: 77, iters: 5328, time: 0.159, data: 0.009) loss: 0.542 
(epoch: 77, iters: 5408, time: 0.159, data: 0.000) loss: 0.432 
(epoch: 77, iters: 5488, time: 0.161, data: 0.026) loss: 0.504 
(epoch: 77, iters: 5568, time: 0.158, data: 0.000) loss: 0.881 
(epoch: 77, iters: 5648, time: 0.160, data: 0.000) loss: 0.337 
(epoch: 77, iters: 5728, time: 0.159, data: 0.000) loss: 0.511 
(epoch: 77, iters: 5808, time: 0.158, data: 0.016) loss: 1.131 
(epoch: 77, iters: 5888, time: 0.161, data: 0.000) loss: 0.449 
(epoch: 77, iters: 5968, time: 0.161, data: 0.000) loss: 0.398 
(epoch: 77, iters: 6048, time: 0.162, data: 0.000) loss: 0.359 
(epoch: 77, iters: 6128, time: 0.161, data: 0.000) loss: 0.782 
(epoch: 77, iters: 6208, time: 0.161, data: 0.033) loss: 1.015 
(epoch: 77, iters: 6288, time: 0.159, data: 0.000) loss: 1.060 
(epoch: 77, iters: 6368, time: 0.160, data: 0.011) loss: 0.883 
(epoch: 77, iters: 6448, time: 0.158, data: 0.025) loss: 0.350 
(epoch: 77, iters: 6528, time: 0.160, data: 0.000) loss: 0.322 
(epoch: 77, iters: 6608, time: 0.160, data: 0.000) loss: 0.585 
(epoch: 77, iters: 6688, time: 0.160, data: 0.006) loss: 0.705 
(epoch: 77, iters: 6768, time: 0.161, data: 0.000) loss: 1.150 
(epoch: 77, iters: 6848, time: 0.160, data: 0.000) loss: 0.944 
(epoch: 77, iters: 6928, time: 0.158, data: 0.000) loss: 0.520 
(epoch: 77, iters: 7008, time: 0.160, data: 0.000) loss: 0.716 
(epoch: 77, iters: 7088, time: 0.158, data: 0.021) loss: 0.442 
(epoch: 77, iters: 7168, time: 0.166, data: 0.005) loss: 0.400 
(epoch: 77, iters: 7248, time: 0.160, data: 0.020) loss: 0.780 
(epoch: 77, iters: 7328, time: 0.159, data: 0.000) loss: 0.454 
(epoch: 77, iters: 7408, time: 0.161, data: 0.000) loss: 0.579 
(epoch: 77, iters: 7488, time: 0.159, data: 0.000) loss: 0.704 
(epoch: 77, iters: 7568, time: 0.159, data: 0.014) loss: 0.529 
(epoch: 77, iters: 7648, time: 0.174, data: 0.000) loss: 0.571 
(epoch: 77, iters: 7728, time: 0.158, data: 0.009) loss: 0.251 
(epoch: 77, iters: 7808, time: 0.159, data: 0.000) loss: 0.476 
(epoch: 77, iters: 7888, time: 0.185, data: 0.005) loss: 0.623 
(epoch: 77, iters: 7968, time: 0.159, data: 0.000) loss: 1.006 
saving the latest model (epoch 77, total_steps 782608)
(epoch: 77, iters: 8048, time: 0.159, data: 0.014) loss: 0.679 
(epoch: 77, iters: 8128, time: 0.157, data: 0.008) loss: 0.620 
(epoch: 77, iters: 8208, time: 0.157, data: 0.000) loss: 0.595 
(epoch: 77, iters: 8288, time: 0.159, data: 0.008) loss: 0.996 
(epoch: 77, iters: 8368, time: 0.158, data: 0.006) loss: 0.726 
(epoch: 77, iters: 8448, time: 0.159, data: 0.025) loss: 0.929 
(epoch: 77, iters: 8528, time: 0.157, data: 0.000) loss: 1.222 
(epoch: 77, iters: 8608, time: 0.157, data: 0.000) loss: 1.206 
(epoch: 77, iters: 8688, time: 0.158, data: 0.000) loss: 0.897 
(epoch: 77, iters: 8768, time: 0.157, data: 0.021) loss: 0.794 
(epoch: 77, iters: 8848, time: 0.158, data: 0.000) loss: 1.105 
(epoch: 77, iters: 8928, time: 0.156, data: 0.006) loss: 0.241 
(epoch: 77, iters: 9008, time: 0.156, data: 0.011) loss: 0.513 
(epoch: 77, iters: 9088, time: 0.157, data: 0.006) loss: 1.283 
(epoch: 77, iters: 9168, time: 0.157, data: 0.013) loss: 0.380 
(epoch: 77, iters: 9248, time: 0.158, data: 0.000) loss: 0.258 
(epoch: 77, iters: 9328, time: 0.157, data: 0.034) loss: 0.188 
(epoch: 77, iters: 9408, time: 0.158, data: 0.000) loss: 0.743 
(epoch: 77, iters: 9488, time: 0.156, data: 0.000) loss: 0.443 
(epoch: 77, iters: 9568, time: 0.156, data: 0.024) loss: 0.751 
(epoch: 77, iters: 9648, time: 0.156, data: 0.000) loss: 0.273 
(epoch: 77, iters: 9728, time: 0.156, data: 0.008) loss: 0.437 
(epoch: 77, iters: 9808, time: 0.156, data: 0.000) loss: 1.131 
(epoch: 77, iters: 9888, time: 0.159, data: 0.000) loss: 0.644 
(epoch: 77, iters: 9968, time: 0.157, data: 0.000) loss: 0.572 
(epoch: 77, iters: 10048, time: 0.156, data: 0.000) loss: 0.503 
(epoch: 77, iters: 10128, time: 0.155, data: 0.017) loss: 0.525 
saving the model at the end of epoch 77, iters 784784
End of epoch 77 / 200 	 Time Taken: 1622 sec
learning rate = 0.0002000
(epoch: 78, iters: 16, time: 0.181, data: 0.008) loss: 0.687 
saving the latest model (epoch 78, total_steps 784800)
(epoch: 78, iters: 96, time: 0.160, data: 0.000) loss: 0.792 
(epoch: 78, iters: 176, time: 0.162, data: 0.000) loss: 0.471 
(epoch: 78, iters: 256, time: 0.161, data: 0.006) loss: 0.452 
(epoch: 78, iters: 336, time: 0.160, data: 0.000) loss: 0.894 
(epoch: 78, iters: 416, time: 0.160, data: 0.006) loss: 0.538 
(epoch: 78, iters: 496, time: 0.160, data: 0.014) loss: 0.554 
(epoch: 78, iters: 576, time: 0.161, data: 0.000) loss: 0.195 
(epoch: 78, iters: 656, time: 0.160, data: 0.008) loss: 0.661 
(epoch: 78, iters: 736, time: 0.159, data: 0.000) loss: 0.554 
(epoch: 78, iters: 816, time: 0.160, data: 0.030) loss: 0.634 
(epoch: 78, iters: 896, time: 0.158, data: 0.000) loss: 1.183 
(epoch: 78, iters: 976, time: 0.159, data: 0.000) loss: 0.574 
(epoch: 78, iters: 1056, time: 0.159, data: 0.015) loss: 0.478 
(epoch: 78, iters: 1136, time: 0.160, data: 0.000) loss: 0.317 
(epoch: 78, iters: 1216, time: 0.159, data: 0.000) loss: 0.421 
(epoch: 78, iters: 1296, time: 0.159, data: 0.000) loss: 0.353 
(epoch: 78, iters: 1376, time: 0.159, data: 0.000) loss: 1.109 
(epoch: 78, iters: 1456, time: 0.159, data: 0.005) loss: 0.587 
(epoch: 78, iters: 1536, time: 0.160, data: 0.022) loss: 0.875 
(epoch: 78, iters: 1616, time: 0.159, data: 0.000) loss: 0.561 
(epoch: 78, iters: 1696, time: 0.159, data: 0.008) loss: 0.630 
(epoch: 78, iters: 1776, time: 0.159, data: 0.014) loss: 0.615 
(epoch: 78, iters: 1856, time: 0.160, data: 0.000) loss: 0.426 
(epoch: 78, iters: 1936, time: 0.158, data: 0.000) loss: 0.510 
(epoch: 78, iters: 2016, time: 0.160, data: 0.000) loss: 0.464 
(epoch: 78, iters: 2096, time: 0.159, data: 0.000) loss: 0.663 
(epoch: 78, iters: 2176, time: 0.159, data: 0.033) loss: 0.590 
(epoch: 78, iters: 2256, time: 0.161, data: 0.000) loss: 0.567 
(epoch: 78, iters: 2336, time: 0.158, data: 0.000) loss: 0.339 
(epoch: 78, iters: 2416, time: 0.160, data: 0.000) loss: 0.961 
(epoch: 78, iters: 2496, time: 0.160, data: 0.000) loss: 0.631 
(epoch: 78, iters: 2576, time: 0.162, data: 0.006) loss: 0.468 
(epoch: 78, iters: 2656, time: 0.158, data: 0.010) loss: 0.510 
(epoch: 78, iters: 2736, time: 0.157, data: 0.000) loss: 0.473 
(epoch: 78, iters: 2816, time: 0.158, data: 0.000) loss: 0.505 
(epoch: 78, iters: 2896, time: 0.157, data: 0.005) loss: 0.528 
(epoch: 78, iters: 2976, time: 0.159, data: 0.011) loss: 0.920 
(epoch: 78, iters: 3056, time: 0.159, data: 0.000) loss: 0.818 
(epoch: 78, iters: 3136, time: 0.159, data: 0.000) loss: 0.224 
(epoch: 78, iters: 3216, time: 0.161, data: 0.006) loss: 0.881 
(epoch: 78, iters: 3296, time: 0.159, data: 0.000) loss: 0.408 
(epoch: 78, iters: 3376, time: 0.160, data: 0.010) loss: 0.371 
(epoch: 78, iters: 3456, time: 0.160, data: 0.000) loss: 0.680 
(epoch: 78, iters: 3536, time: 0.160, data: 0.040) loss: 0.375 
(epoch: 78, iters: 3616, time: 0.160, data: 0.000) loss: 0.473 
(epoch: 78, iters: 3696, time: 0.160, data: 0.017) loss: 0.645 
(epoch: 78, iters: 3776, time: 0.161, data: 0.000) loss: 0.428 
(epoch: 78, iters: 3856, time: 0.159, data: 0.000) loss: 0.327 
(epoch: 78, iters: 3936, time: 0.161, data: 0.000) loss: 0.734 
(epoch: 78, iters: 4016, time: 0.159, data: 0.000) loss: 0.876 
saving the latest model (epoch 78, total_steps 788800)
(epoch: 78, iters: 4096, time: 0.158, data: 0.009) loss: 0.507 
(epoch: 78, iters: 4176, time: 0.161, data: 0.005) loss: 0.607 
(epoch: 78, iters: 4256, time: 0.163, data: 0.000) loss: 0.742 
(epoch: 78, iters: 4336, time: 0.159, data: 0.011) loss: 0.568 
(epoch: 78, iters: 4416, time: 0.162, data: 0.000) loss: 0.489 
(epoch: 78, iters: 4496, time: 0.158, data: 0.010) loss: 1.177 
(epoch: 78, iters: 4576, time: 0.159, data: 0.005) loss: 0.579 
(epoch: 78, iters: 4656, time: 0.164, data: 0.000) loss: 0.666 
(epoch: 78, iters: 4736, time: 0.160, data: 0.006) loss: 0.826 
(epoch: 78, iters: 4816, time: 0.159, data: 0.000) loss: 0.838 
(epoch: 78, iters: 4896, time: 0.159, data: 0.000) loss: 0.892 
(epoch: 78, iters: 4976, time: 0.160, data: 0.000) loss: 0.586 
(epoch: 78, iters: 5056, time: 0.163, data: 0.006) loss: 0.431 
(epoch: 78, iters: 5136, time: 0.160, data: 0.005) loss: 0.495 
(epoch: 78, iters: 5216, time: 0.160, data: 0.005) loss: 0.460 
(epoch: 78, iters: 5296, time: 0.160, data: 0.000) loss: 0.443 
(epoch: 78, iters: 5376, time: 0.160, data: 0.000) loss: 0.300 
(epoch: 78, iters: 5456, time: 0.162, data: 0.000) loss: 0.499 
(epoch: 78, iters: 5536, time: 0.159, data: 0.000) loss: 0.731 
(epoch: 78, iters: 5616, time: 0.158, data: 0.005) loss: 0.598 
(epoch: 78, iters: 5696, time: 0.158, data: 0.005) loss: 0.586 
(epoch: 78, iters: 5776, time: 0.159, data: 0.000) loss: 0.269 
(epoch: 78, iters: 5856, time: 0.160, data: 0.020) loss: 0.560 
(epoch: 78, iters: 5936, time: 0.160, data: 0.005) loss: 0.277 
(epoch: 78, iters: 6016, time: 0.160, data: 0.005) loss: 0.586 
(epoch: 78, iters: 6096, time: 0.159, data: 0.000) loss: 0.339 
(epoch: 78, iters: 6176, time: 0.162, data: 0.000) loss: 0.416 
(epoch: 78, iters: 6256, time: 0.160, data: 0.013) loss: 0.348 
(epoch: 78, iters: 6336, time: 0.160, data: 0.005) loss: 0.338 
(epoch: 78, iters: 6416, time: 0.162, data: 0.016) loss: 0.940 
(epoch: 78, iters: 6496, time: 0.159, data: 0.005) loss: 0.629 
(epoch: 78, iters: 6576, time: 0.159, data: 0.008) loss: 0.477 
(epoch: 78, iters: 6656, time: 0.159, data: 0.000) loss: 0.274 
(epoch: 78, iters: 6736, time: 0.162, data: 0.000) loss: 0.933 
(epoch: 78, iters: 6816, time: 0.159, data: 0.015) loss: 0.956 
(epoch: 78, iters: 6896, time: 0.161, data: 0.000) loss: 0.217 
(epoch: 78, iters: 6976, time: 0.161, data: 0.014) loss: 0.812 
(epoch: 78, iters: 7056, time: 0.162, data: 0.006) loss: 0.611 
(epoch: 78, iters: 7136, time: 0.159, data: 0.000) loss: 0.862 
(epoch: 78, iters: 7216, time: 0.159, data: 0.010) loss: 0.407 
(epoch: 78, iters: 7296, time: 0.161, data: 0.000) loss: 0.638 
(epoch: 78, iters: 7376, time: 0.159, data: 0.008) loss: 1.388 
(epoch: 78, iters: 7456, time: 0.159, data: 0.017) loss: 0.385 
(epoch: 78, iters: 7536, time: 0.159, data: 0.000) loss: 0.433 
(epoch: 78, iters: 7616, time: 0.159, data: 0.026) loss: 0.754 
(epoch: 78, iters: 7696, time: 0.157, data: 0.000) loss: 0.671 
(epoch: 78, iters: 7776, time: 0.160, data: 0.000) loss: 0.438 
(epoch: 78, iters: 7856, time: 0.162, data: 0.016) loss: 0.486 
(epoch: 78, iters: 7936, time: 0.162, data: 0.005) loss: 0.913 
(epoch: 78, iters: 8016, time: 0.161, data: 0.000) loss: 0.802 
saving the latest model (epoch 78, total_steps 792800)
(epoch: 78, iters: 8096, time: 0.164, data: 0.000) loss: 1.103 
(epoch: 78, iters: 8176, time: 0.161, data: 0.008) loss: 0.563 
(epoch: 78, iters: 8256, time: 0.160, data: 0.013) loss: 0.445 
(epoch: 78, iters: 8336, time: 0.160, data: 0.006) loss: 0.679 
(epoch: 78, iters: 8416, time: 0.162, data: 0.000) loss: 1.470 
(epoch: 78, iters: 8496, time: 0.159, data: 0.000) loss: 0.322 
(epoch: 78, iters: 8576, time: 0.160, data: 0.008) loss: 0.587 
(epoch: 78, iters: 8656, time: 0.160, data: 0.023) loss: 0.732 
(epoch: 78, iters: 8736, time: 0.160, data: 0.000) loss: 0.566 
(epoch: 78, iters: 8816, time: 0.161, data: 0.012) loss: 0.670 
(epoch: 78, iters: 8896, time: 0.160, data: 0.000) loss: 0.269 
(epoch: 78, iters: 8976, time: 0.160, data: 0.005) loss: 0.616 
(epoch: 78, iters: 9056, time: 0.160, data: 0.000) loss: 0.647 
(epoch: 78, iters: 9136, time: 0.160, data: 0.000) loss: 0.924 
(epoch: 78, iters: 9216, time: 0.159, data: 0.025) loss: 0.640 
(epoch: 78, iters: 9296, time: 0.158, data: 0.000) loss: 0.437 
(epoch: 78, iters: 9376, time: 0.159, data: 0.008) loss: 1.493 
(epoch: 78, iters: 9456, time: 0.163, data: 0.005) loss: 0.952 
(epoch: 78, iters: 9536, time: 0.161, data: 0.000) loss: 1.235 
(epoch: 78, iters: 9616, time: 0.159, data: 0.033) loss: 0.544 
(epoch: 78, iters: 9696, time: 0.162, data: 0.005) loss: 0.680 
(epoch: 78, iters: 9776, time: 0.161, data: 0.000) loss: 0.597 
(epoch: 78, iters: 9856, time: 0.159, data: 0.000) loss: 0.507 
(epoch: 78, iters: 9936, time: 0.161, data: 0.000) loss: 0.423 
(epoch: 78, iters: 10016, time: 0.162, data: 0.000) loss: 0.757 
(epoch: 78, iters: 10096, time: 0.161, data: 0.008) loss: 0.222 
(epoch: 78, iters: 10176, time: 0.160, data: 0.000) loss: 0.597 
saving the model at the end of epoch 78, iters 794976
End of epoch 78 / 200 	 Time Taken: 1637 sec
learning rate = 0.0002000
saving the latest model (epoch 79, total_steps 794992)
(epoch: 79, iters: 64, time: 0.162, data: 0.003) loss: 0.494 
(epoch: 79, iters: 144, time: 0.160, data: 0.027) loss: 0.295 
(epoch: 79, iters: 224, time: 0.158, data: 0.000) loss: 1.112 
(epoch: 79, iters: 304, time: 0.158, data: 0.000) loss: 0.648 
(epoch: 79, iters: 384, time: 0.158, data: 0.000) loss: 0.647 
(epoch: 79, iters: 464, time: 0.156, data: 0.013) loss: 0.329 
(epoch: 79, iters: 544, time: 0.158, data: 0.000) loss: 0.577 
(epoch: 79, iters: 624, time: 0.158, data: 0.006) loss: 0.704 
(epoch: 79, iters: 704, time: 0.157, data: 0.014) loss: 0.585 
(epoch: 79, iters: 784, time: 0.156, data: 0.000) loss: 0.523 
(epoch: 79, iters: 864, time: 0.157, data: 0.000) loss: 0.979 
(epoch: 79, iters: 944, time: 0.158, data: 0.000) loss: 0.654 
(epoch: 79, iters: 1024, time: 0.160, data: 0.000) loss: 0.364 
(epoch: 79, iters: 1104, time: 0.159, data: 0.005) loss: 0.454 
(epoch: 79, iters: 1184, time: 0.157, data: 0.008) loss: 0.369 
(epoch: 79, iters: 1264, time: 0.158, data: 0.008) loss: 0.240 
(epoch: 79, iters: 1344, time: 0.157, data: 0.006) loss: 0.556 
(epoch: 79, iters: 1424, time: 0.159, data: 0.011) loss: 1.101 
(epoch: 79, iters: 1504, time: 0.159, data: 0.000) loss: 0.808 
(epoch: 79, iters: 1584, time: 0.159, data: 0.000) loss: 1.351 
(epoch: 79, iters: 1664, time: 0.161, data: 0.006) loss: 0.640 
(epoch: 79, iters: 1744, time: 0.156, data: 0.000) loss: 1.161 
(epoch: 79, iters: 1824, time: 0.157, data: 0.000) loss: 0.352 
(epoch: 79, iters: 1904, time: 0.159, data: 0.016) loss: 0.395 
(epoch: 79, iters: 1984, time: 0.158, data: 0.000) loss: 0.323 
(epoch: 79, iters: 2064, time: 0.159, data: 0.000) loss: 0.532 
(epoch: 79, iters: 2144, time: 0.160, data: 0.000) loss: 0.665 
(epoch: 79, iters: 2224, time: 0.158, data: 0.005) loss: 0.496 
(epoch: 79, iters: 2304, time: 0.158, data: 0.000) loss: 0.656 
(epoch: 79, iters: 2384, time: 0.159, data: 0.005) loss: 0.238 
(epoch: 79, iters: 2464, time: 0.160, data: 0.000) loss: 1.194 
(epoch: 79, iters: 2544, time: 0.158, data: 0.000) loss: 0.346 
(epoch: 79, iters: 2624, time: 0.158, data: 0.020) loss: 0.339 
(epoch: 79, iters: 2704, time: 0.156, data: 0.000) loss: 0.658 
(epoch: 79, iters: 2784, time: 0.157, data: 0.000) loss: 0.394 
(epoch: 79, iters: 2864, time: 0.160, data: 0.016) loss: 0.311 
(epoch: 79, iters: 2944, time: 0.160, data: 0.000) loss: 0.704 
(epoch: 79, iters: 3024, time: 0.159, data: 0.023) loss: 0.581 
(epoch: 79, iters: 3104, time: 0.159, data: 0.000) loss: 0.503 
(epoch: 79, iters: 3184, time: 0.157, data: 0.011) loss: 1.164 
(epoch: 79, iters: 3264, time: 0.157, data: 0.000) loss: 0.491 
(epoch: 79, iters: 3344, time: 0.160, data: 0.040) loss: 0.330 
(epoch: 79, iters: 3424, time: 0.158, data: 0.000) loss: 0.240 
(epoch: 79, iters: 3504, time: 0.161, data: 0.000) loss: 0.260 
(epoch: 79, iters: 3584, time: 0.159, data: 0.005) loss: 0.598 
(epoch: 79, iters: 3664, time: 0.157, data: 0.009) loss: 0.614 
(epoch: 79, iters: 3744, time: 0.157, data: 0.000) loss: 0.578 
(epoch: 79, iters: 3824, time: 0.159, data: 0.010) loss: 0.350 
(epoch: 79, iters: 3904, time: 0.157, data: 0.000) loss: 0.247 
(epoch: 79, iters: 3984, time: 0.161, data: 0.000) loss: 1.012 
saving the latest model (epoch 79, total_steps 798992)
(epoch: 79, iters: 4064, time: 0.162, data: 0.006) loss: 0.616 
(epoch: 79, iters: 4144, time: 0.159, data: 0.000) loss: 0.915 
(epoch: 79, iters: 4224, time: 0.158, data: 0.000) loss: 0.645 
(epoch: 79, iters: 4304, time: 0.161, data: 0.000) loss: 0.499 
(epoch: 79, iters: 4384, time: 0.158, data: 0.014) loss: 0.635 
(epoch: 79, iters: 4464, time: 0.160, data: 0.000) loss: 0.496 
(epoch: 79, iters: 4544, time: 0.159, data: 0.000) loss: 0.696 
(epoch: 79, iters: 4624, time: 0.158, data: 0.005) loss: 0.516 
(epoch: 79, iters: 4704, time: 0.156, data: 0.006) loss: 0.814 
(epoch: 79, iters: 4784, time: 0.159, data: 0.006) loss: 0.885 
(epoch: 79, iters: 4864, time: 0.157, data: 0.000) loss: 0.479 
(epoch: 79, iters: 4944, time: 0.157, data: 0.000) loss: 0.338 
(epoch: 79, iters: 5024, time: 0.157, data: 0.005) loss: 0.553 
(epoch: 79, iters: 5104, time: 0.159, data: 0.006) loss: 1.061 
(epoch: 79, iters: 5184, time: 0.156, data: 0.006) loss: 1.187 
(epoch: 79, iters: 5264, time: 0.157, data: 0.000) loss: 0.350 
(epoch: 79, iters: 5344, time: 0.157, data: 0.032) loss: 0.551 
(epoch: 79, iters: 5424, time: 0.157, data: 0.000) loss: 0.396 
(epoch: 79, iters: 5504, time: 0.156, data: 0.041) loss: 0.581 
(epoch: 79, iters: 5584, time: 0.158, data: 0.000) loss: 1.018 
(epoch: 79, iters: 5664, time: 0.160, data: 0.008) loss: 0.583 
(epoch: 79, iters: 5744, time: 0.159, data: 0.000) loss: 0.622 
(epoch: 79, iters: 5824, time: 0.160, data: 0.011) loss: 0.374 
(epoch: 79, iters: 5904, time: 0.159, data: 0.000) loss: 1.027 
(epoch: 79, iters: 5984, time: 0.159, data: 0.000) loss: 1.376 
(epoch: 79, iters: 6064, time: 0.158, data: 0.014) loss: 0.718 
(epoch: 79, iters: 6144, time: 0.157, data: 0.000) loss: 0.787 
(epoch: 79, iters: 6224, time: 0.157, data: 0.000) loss: 0.343 
(epoch: 79, iters: 6304, time: 0.157, data: 0.032) loss: 0.550 
(epoch: 79, iters: 6384, time: 0.157, data: 0.000) loss: 0.715 
(epoch: 79, iters: 6464, time: 0.158, data: 0.014) loss: 0.544 
(epoch: 79, iters: 6544, time: 0.158, data: 0.000) loss: 0.839 
(epoch: 79, iters: 6624, time: 0.159, data: 0.031) loss: 0.381 
(epoch: 79, iters: 6704, time: 0.159, data: 0.000) loss: 0.821 
(epoch: 79, iters: 6784, time: 0.158, data: 0.000) loss: 0.296 
(epoch: 79, iters: 6864, time: 0.158, data: 0.000) loss: 1.165 
(epoch: 79, iters: 6944, time: 0.159, data: 0.000) loss: 0.687 
(epoch: 79, iters: 7024, time: 0.157, data: 0.000) loss: 0.498 
(epoch: 79, iters: 7104, time: 0.158, data: 0.000) loss: 0.322 
(epoch: 79, iters: 7184, time: 0.156, data: 0.006) loss: 0.790 
(epoch: 79, iters: 7264, time: 0.156, data: 0.009) loss: 0.750 
(epoch: 79, iters: 7344, time: 0.156, data: 0.031) loss: 0.593 
(epoch: 79, iters: 7424, time: 0.159, data: 0.000) loss: 0.666 
(epoch: 79, iters: 7504, time: 0.158, data: 0.000) loss: 0.738 
(epoch: 79, iters: 7584, time: 0.158, data: 0.032) loss: 0.726 
(epoch: 79, iters: 7664, time: 0.158, data: 0.000) loss: 0.480 
(epoch: 79, iters: 7744, time: 0.160, data: 0.025) loss: 0.563 
(epoch: 79, iters: 7824, time: 0.158, data: 0.000) loss: 0.945 
(epoch: 79, iters: 7904, time: 0.160, data: 0.034) loss: 0.295 
(epoch: 79, iters: 7984, time: 0.158, data: 0.000) loss: 0.508 
saving the latest model (epoch 79, total_steps 802992)
(epoch: 79, iters: 8064, time: 0.160, data: 0.016) loss: 0.361 
(epoch: 79, iters: 8144, time: 0.159, data: 0.009) loss: 0.793 
(epoch: 79, iters: 8224, time: 0.158, data: 0.000) loss: 0.712 
(epoch: 79, iters: 8304, time: 0.160, data: 0.000) loss: 0.957 
(epoch: 79, iters: 8384, time: 0.156, data: 0.000) loss: 0.933 
(epoch: 79, iters: 8464, time: 0.158, data: 0.015) loss: 0.166 
(epoch: 79, iters: 8544, time: 0.157, data: 0.000) loss: 0.451 
(epoch: 79, iters: 8624, time: 0.159, data: 0.026) loss: 0.486 
(epoch: 79, iters: 8704, time: 0.160, data: 0.000) loss: 0.750 
(epoch: 79, iters: 8784, time: 0.161, data: 0.000) loss: 0.370 
(epoch: 79, iters: 8864, time: 0.159, data: 0.025) loss: 0.784 
(epoch: 79, iters: 8944, time: 0.159, data: 0.000) loss: 0.329 
(epoch: 79, iters: 9024, time: 0.159, data: 0.033) loss: 1.104 
(epoch: 79, iters: 9104, time: 0.159, data: 0.000) loss: 0.290 
(epoch: 79, iters: 9184, time: 0.161, data: 0.000) loss: 0.398 
(epoch: 79, iters: 9264, time: 0.160, data: 0.000) loss: 0.329 
(epoch: 79, iters: 9344, time: 0.160, data: 0.008) loss: 0.709 
(epoch: 79, iters: 9424, time: 0.159, data: 0.000) loss: 0.792 
(epoch: 79, iters: 9504, time: 0.160, data: 0.000) loss: 0.479 
(epoch: 79, iters: 9584, time: 0.160, data: 0.000) loss: 0.782 
(epoch: 79, iters: 9664, time: 0.161, data: 0.028) loss: 0.838 
(epoch: 79, iters: 9744, time: 0.157, data: 0.005) loss: 0.634 
(epoch: 79, iters: 9824, time: 0.159, data: 0.000) loss: 0.713 
(epoch: 79, iters: 9904, time: 0.159, data: 0.024) loss: 1.460 
(epoch: 79, iters: 9984, time: 0.158, data: 0.000) loss: 1.069 
(epoch: 79, iters: 10064, time: 0.157, data: 0.010) loss: 0.770 
(epoch: 79, iters: 10144, time: 0.159, data: 0.000) loss: 0.643 
saving the model at the end of epoch 79, iters 805168
End of epoch 79 / 200 	 Time Taken: 1619 sec
learning rate = 0.0002000
saving the latest model (epoch 80, total_steps 805184)
(epoch: 80, iters: 32, time: 0.167, data: 0.009) loss: 0.494 
(epoch: 80, iters: 112, time: 0.162, data: 0.000) loss: 0.846 
(epoch: 80, iters: 192, time: 0.162, data: 0.000) loss: 0.763 
(epoch: 80, iters: 272, time: 0.163, data: 0.000) loss: 0.306 
(epoch: 80, iters: 352, time: 0.160, data: 0.031) loss: 0.411 
(epoch: 80, iters: 432, time: 0.161, data: 0.000) loss: 0.863 
(epoch: 80, iters: 512, time: 0.161, data: 0.000) loss: 0.551 
(epoch: 80, iters: 592, time: 0.162, data: 0.021) loss: 0.822 
(epoch: 80, iters: 672, time: 0.161, data: 0.000) loss: 0.900 
(epoch: 80, iters: 752, time: 0.160, data: 0.000) loss: 0.860 
(epoch: 80, iters: 832, time: 0.160, data: 0.024) loss: 0.647 
(epoch: 80, iters: 912, time: 0.161, data: 0.000) loss: 0.726 
(epoch: 80, iters: 992, time: 0.161, data: 0.005) loss: 0.525 
(epoch: 80, iters: 1072, time: 0.160, data: 0.000) loss: 0.639 
(epoch: 80, iters: 1152, time: 0.160, data: 0.020) loss: 0.987 
(epoch: 80, iters: 1232, time: 0.160, data: 0.000) loss: 0.502 
(epoch: 80, iters: 1312, time: 0.160, data: 0.000) loss: 0.536 
(epoch: 80, iters: 1392, time: 0.160, data: 0.000) loss: 0.563 
(epoch: 80, iters: 1472, time: 0.162, data: 0.000) loss: 0.892 
(epoch: 80, iters: 1552, time: 0.156, data: 0.000) loss: 0.728 
(epoch: 80, iters: 1632, time: 0.159, data: 0.013) loss: 0.326 
(epoch: 80, iters: 1712, time: 0.159, data: 0.025) loss: 0.441 
(epoch: 80, iters: 1792, time: 0.160, data: 0.000) loss: 0.691 
(epoch: 80, iters: 1872, time: 0.159, data: 0.005) loss: 0.606 
(epoch: 80, iters: 1952, time: 0.160, data: 0.000) loss: 0.434 
(epoch: 80, iters: 2032, time: 0.161, data: 0.006) loss: 0.800 
(epoch: 80, iters: 2112, time: 0.160, data: 0.000) loss: 1.032 
(epoch: 80, iters: 2192, time: 0.158, data: 0.000) loss: 0.841 
(epoch: 80, iters: 2272, time: 0.160, data: 0.000) loss: 0.850 
(epoch: 80, iters: 2352, time: 0.160, data: 0.005) loss: 0.687 
(epoch: 80, iters: 2432, time: 0.160, data: 0.000) loss: 0.532 
(epoch: 80, iters: 2512, time: 0.159, data: 0.005) loss: 0.499 
(epoch: 80, iters: 2592, time: 0.159, data: 0.006) loss: 0.595 
(epoch: 80, iters: 2672, time: 0.160, data: 0.000) loss: 0.486 
(epoch: 80, iters: 2752, time: 0.159, data: 0.000) loss: 0.689 
(epoch: 80, iters: 2832, time: 0.162, data: 0.005) loss: 0.661 
(epoch: 80, iters: 2912, time: 0.162, data: 0.010) loss: 0.425 
(epoch: 80, iters: 2992, time: 0.163, data: 0.000) loss: 0.659 
(epoch: 80, iters: 3072, time: 0.160, data: 0.019) loss: 0.366 
(epoch: 80, iters: 3152, time: 0.159, data: 0.013) loss: 0.319 
(epoch: 80, iters: 3232, time: 0.162, data: 0.000) loss: 0.986 
(epoch: 80, iters: 3312, time: 0.160, data: 0.005) loss: 1.130 
(epoch: 80, iters: 3392, time: 0.159, data: 0.000) loss: 0.274 
(epoch: 80, iters: 3472, time: 0.159, data: 0.008) loss: 0.470 
(epoch: 80, iters: 3552, time: 0.158, data: 0.000) loss: 0.329 
(epoch: 80, iters: 3632, time: 0.158, data: 0.008) loss: 0.341 
(epoch: 80, iters: 3712, time: 0.159, data: 0.000) loss: 0.476 
(epoch: 80, iters: 3792, time: 0.158, data: 0.000) loss: 0.962 
(epoch: 80, iters: 3872, time: 0.162, data: 0.006) loss: 0.751 
(epoch: 80, iters: 3952, time: 0.161, data: 0.025) loss: 0.718 
saving the latest model (epoch 80, total_steps 809184)
(epoch: 80, iters: 4032, time: 0.162, data: 0.000) loss: 0.445 
(epoch: 80, iters: 4112, time: 0.160, data: 0.000) loss: 0.277 
(epoch: 80, iters: 4192, time: 0.159, data: 0.008) loss: 0.447 
(epoch: 80, iters: 4272, time: 0.161, data: 0.000) loss: 0.504 
(epoch: 80, iters: 4352, time: 0.159, data: 0.011) loss: 1.111 
(epoch: 80, iters: 4432, time: 0.162, data: 0.000) loss: 0.351 
(epoch: 80, iters: 4512, time: 0.160, data: 0.000) loss: 0.343 
(epoch: 80, iters: 4592, time: 0.160, data: 0.009) loss: 0.906 
(epoch: 80, iters: 4672, time: 0.157, data: 0.000) loss: 0.623 
(epoch: 80, iters: 4752, time: 0.159, data: 0.000) loss: 1.052 
(epoch: 80, iters: 4832, time: 0.157, data: 0.006) loss: 0.141 
(epoch: 80, iters: 4912, time: 0.159, data: 0.005) loss: 0.430 
(epoch: 80, iters: 4992, time: 0.159, data: 0.000) loss: 0.671 
(epoch: 80, iters: 5072, time: 0.160, data: 0.000) loss: 1.367 
(epoch: 80, iters: 5152, time: 0.160, data: 0.000) loss: 0.619 
(epoch: 80, iters: 5232, time: 0.162, data: 0.005) loss: 0.968 
(epoch: 80, iters: 5312, time: 0.159, data: 0.000) loss: 0.607 
(epoch: 80, iters: 5392, time: 0.159, data: 0.013) loss: 0.346 
(epoch: 80, iters: 5472, time: 0.160, data: 0.013) loss: 0.828 
(epoch: 80, iters: 5552, time: 0.160, data: 0.000) loss: 0.300 
(epoch: 80, iters: 5632, time: 0.162, data: 0.024) loss: 0.355 
(epoch: 80, iters: 5712, time: 0.161, data: 0.024) loss: 0.636 
(epoch: 80, iters: 5792, time: 0.160, data: 0.000) loss: 0.911 
(epoch: 80, iters: 5872, time: 0.160, data: 0.020) loss: 0.502 
(epoch: 80, iters: 5952, time: 0.157, data: 0.005) loss: 0.345 
(epoch: 80, iters: 6032, time: 0.158, data: 0.000) loss: 1.151 
(epoch: 80, iters: 6112, time: 0.160, data: 0.009) loss: 0.674 
(epoch: 80, iters: 6192, time: 0.164, data: 0.000) loss: 0.336 
(epoch: 80, iters: 6272, time: 0.162, data: 0.000) loss: 0.515 
(epoch: 80, iters: 6352, time: 0.161, data: 0.014) loss: 0.465 
(epoch: 80, iters: 6432, time: 0.162, data: 0.000) loss: 0.576 
(epoch: 80, iters: 6512, time: 0.159, data: 0.032) loss: 0.552 
(epoch: 80, iters: 6592, time: 0.159, data: 0.000) loss: 0.442 
(epoch: 80, iters: 6672, time: 0.158, data: 0.009) loss: 0.802 
(epoch: 80, iters: 6752, time: 0.160, data: 0.000) loss: 0.679 
(epoch: 80, iters: 6832, time: 0.158, data: 0.000) loss: 0.140 
(epoch: 80, iters: 6912, time: 0.159, data: 0.018) loss: 0.497 
(epoch: 80, iters: 6992, time: 0.159, data: 0.005) loss: 0.911 
(epoch: 80, iters: 7072, time: 0.161, data: 0.005) loss: 0.612 
(epoch: 80, iters: 7152, time: 0.161, data: 0.014) loss: 0.391 
(epoch: 80, iters: 7232, time: 0.158, data: 0.000) loss: 0.202 
(epoch: 80, iters: 7312, time: 0.159, data: 0.005) loss: 0.527 
(epoch: 80, iters: 7392, time: 0.162, data: 0.000) loss: 0.496 
(epoch: 80, iters: 7472, time: 0.161, data: 0.013) loss: 0.688 
(epoch: 80, iters: 7552, time: 0.158, data: 0.000) loss: 0.801 
(epoch: 80, iters: 7632, time: 0.161, data: 0.018) loss: 0.675 
(epoch: 80, iters: 7712, time: 0.158, data: 0.000) loss: 0.384 
(epoch: 80, iters: 7792, time: 0.161, data: 0.000) loss: 0.314 
(epoch: 80, iters: 7872, time: 0.161, data: 0.000) loss: 0.347 
(epoch: 80, iters: 7952, time: 0.162, data: 0.006) loss: 0.696 
saving the latest model (epoch 80, total_steps 813184)
(epoch: 80, iters: 8032, time: 0.161, data: 0.025) loss: 1.050 
(epoch: 80, iters: 8112, time: 0.160, data: 0.000) loss: 0.735 
(epoch: 80, iters: 8192, time: 0.160, data: 0.000) loss: 0.373 
(epoch: 80, iters: 8272, time: 0.159, data: 0.000) loss: 0.202 
(epoch: 80, iters: 8352, time: 0.160, data: 0.000) loss: 0.743 
(epoch: 80, iters: 8432, time: 0.158, data: 0.008) loss: 0.618 
(epoch: 80, iters: 8512, time: 0.160, data: 0.000) loss: 0.562 
(epoch: 80, iters: 8592, time: 0.159, data: 0.014) loss: 0.451 
(epoch: 80, iters: 8672, time: 0.161, data: 0.000) loss: 0.302 
(epoch: 80, iters: 8752, time: 0.158, data: 0.000) loss: 0.168 
(epoch: 80, iters: 8832, time: 0.160, data: 0.005) loss: 0.538 
(epoch: 80, iters: 8912, time: 0.163, data: 0.009) loss: 0.595 
(epoch: 80, iters: 8992, time: 0.160, data: 0.000) loss: 0.519 
(epoch: 80, iters: 9072, time: 0.158, data: 0.000) loss: 0.283 
(epoch: 80, iters: 9152, time: 0.159, data: 0.005) loss: 0.619 
(epoch: 80, iters: 9232, time: 0.158, data: 0.015) loss: 0.589 
(epoch: 80, iters: 9312, time: 0.158, data: 0.006) loss: 0.579 
(epoch: 80, iters: 9392, time: 0.159, data: 0.000) loss: 0.299 
(epoch: 80, iters: 9472, time: 0.164, data: 0.010) loss: 0.898 
(epoch: 80, iters: 9552, time: 0.161, data: 0.005) loss: 0.548 
(epoch: 80, iters: 9632, time: 0.160, data: 0.000) loss: 0.401 
(epoch: 80, iters: 9712, time: 0.161, data: 0.006) loss: 0.202 
(epoch: 80, iters: 9792, time: 0.160, data: 0.000) loss: 0.594 
(epoch: 80, iters: 9872, time: 0.161, data: 0.000) loss: 0.825 
(epoch: 80, iters: 9952, time: 0.161, data: 0.016) loss: 0.996 
(epoch: 80, iters: 10032, time: 0.160, data: 0.000) loss: 0.523 
(epoch: 80, iters: 10112, time: 0.159, data: 0.000) loss: 0.611 
(epoch: 80, iters: 10192, time: 0.096, data: 0.000) loss: 1.534 
saving the model at the end of epoch 80, iters 815360
End of epoch 80 / 200 	 Time Taken: 1638 sec
learning rate = 0.0002000
saving the latest model (epoch 81, total_steps 815376)
(epoch: 81, iters: 80, time: 0.161, data: 0.172) loss: 0.571 
(epoch: 81, iters: 160, time: 0.162, data: 0.007) loss: 0.428 
(epoch: 81, iters: 240, time: 0.159, data: 0.000) loss: 0.281 
(epoch: 81, iters: 320, time: 0.161, data: 0.000) loss: 0.972 
(epoch: 81, iters: 400, time: 0.161, data: 0.000) loss: 0.617 
(epoch: 81, iters: 480, time: 0.162, data: 0.005) loss: 0.567 
(epoch: 81, iters: 560, time: 0.161, data: 0.009) loss: 0.249 
(epoch: 81, iters: 640, time: 0.159, data: 0.000) loss: 0.260 
(epoch: 81, iters: 720, time: 0.160, data: 0.000) loss: 0.596 
(epoch: 81, iters: 800, time: 0.159, data: 0.017) loss: 0.811 
(epoch: 81, iters: 880, time: 0.160, data: 0.028) loss: 0.690 
(epoch: 81, iters: 960, time: 0.158, data: 0.000) loss: 0.434 
(epoch: 81, iters: 1040, time: 0.159, data: 0.019) loss: 0.798 
(epoch: 81, iters: 1120, time: 0.160, data: 0.000) loss: 0.471 
(epoch: 81, iters: 1200, time: 0.159, data: 0.024) loss: 0.185 
(epoch: 81, iters: 1280, time: 0.157, data: 0.000) loss: 0.277 
(epoch: 81, iters: 1360, time: 0.162, data: 0.000) loss: 1.159 
(epoch: 81, iters: 1440, time: 0.160, data: 0.021) loss: 0.193 
(epoch: 81, iters: 1520, time: 0.161, data: 0.010) loss: 0.577 
(epoch: 81, iters: 1600, time: 0.160, data: 0.000) loss: 0.418 
(epoch: 81, iters: 1680, time: 0.160, data: 0.010) loss: 0.844 
(epoch: 81, iters: 1760, time: 0.158, data: 0.000) loss: 0.527 
(epoch: 81, iters: 1840, time: 0.158, data: 0.019) loss: 0.711 
(epoch: 81, iters: 1920, time: 0.160, data: 0.000) loss: 0.700 
(epoch: 81, iters: 2000, time: 0.158, data: 0.024) loss: 0.928 
(epoch: 81, iters: 2080, time: 0.159, data: 0.000) loss: 0.532 
(epoch: 81, iters: 2160, time: 0.159, data: 0.000) loss: 0.526 
(epoch: 81, iters: 2240, time: 0.158, data: 0.005) loss: 0.363 
(epoch: 81, iters: 2320, time: 0.159, data: 0.005) loss: 0.363 
(epoch: 81, iters: 2400, time: 0.161, data: 0.000) loss: 0.856 
(epoch: 81, iters: 2480, time: 0.159, data: 0.015) loss: 0.417 
(epoch: 81, iters: 2560, time: 0.160, data: 0.000) loss: 0.737 
(epoch: 81, iters: 2640, time: 0.159, data: 0.000) loss: 0.260 
(epoch: 81, iters: 2720, time: 0.160, data: 0.008) loss: 0.232 
(epoch: 81, iters: 2800, time: 0.159, data: 0.005) loss: 0.682 
(epoch: 81, iters: 2880, time: 0.160, data: 0.006) loss: 0.639 
(epoch: 81, iters: 2960, time: 0.159, data: 0.000) loss: 0.527 
(epoch: 81, iters: 3040, time: 0.162, data: 0.000) loss: 0.448 
(epoch: 81, iters: 3120, time: 0.160, data: 0.009) loss: 0.424 
(epoch: 81, iters: 3200, time: 0.162, data: 0.000) loss: 0.452 
(epoch: 81, iters: 3280, time: 0.160, data: 0.008) loss: 0.560 
(epoch: 81, iters: 3360, time: 0.162, data: 0.005) loss: 0.731 
(epoch: 81, iters: 3440, time: 0.160, data: 0.005) loss: 0.402 
(epoch: 81, iters: 3520, time: 0.160, data: 0.000) loss: 1.040 
(epoch: 81, iters: 3600, time: 0.166, data: 0.000) loss: 0.894 
(epoch: 81, iters: 3680, time: 0.159, data: 0.034) loss: 0.962 
(epoch: 81, iters: 3760, time: 0.158, data: 0.000) loss: 0.399 
(epoch: 81, iters: 3840, time: 0.162, data: 0.000) loss: 0.654 
(epoch: 81, iters: 3920, time: 0.159, data: 0.000) loss: 0.583 
(epoch: 81, iters: 4000, time: 0.159, data: 0.000) loss: 0.466 
saving the latest model (epoch 81, total_steps 819376)
(epoch: 81, iters: 4080, time: 0.161, data: 0.021) loss: 0.527 
(epoch: 81, iters: 4160, time: 0.161, data: 0.000) loss: 0.252 
(epoch: 81, iters: 4240, time: 0.160, data: 0.000) loss: 0.374 
(epoch: 81, iters: 4320, time: 0.159, data: 0.032) loss: 0.788 
(epoch: 81, iters: 4400, time: 0.160, data: 0.000) loss: 0.808 
(epoch: 81, iters: 4480, time: 0.159, data: 0.028) loss: 0.660 
(epoch: 81, iters: 4560, time: 0.159, data: 0.000) loss: 0.398 
(epoch: 81, iters: 4640, time: 0.160, data: 0.000) loss: 1.117 
(epoch: 81, iters: 4720, time: 0.159, data: 0.015) loss: 0.418 
(epoch: 81, iters: 4800, time: 0.159, data: 0.015) loss: 0.760 
(epoch: 81, iters: 4880, time: 0.158, data: 0.005) loss: 0.912 
(epoch: 81, iters: 4960, time: 0.158, data: 0.005) loss: 0.709 
(epoch: 81, iters: 5040, time: 0.157, data: 0.000) loss: 1.059 
(epoch: 81, iters: 5120, time: 0.159, data: 0.003) loss: 0.240 
(epoch: 81, iters: 5200, time: 0.159, data: 0.010) loss: 0.576 
(epoch: 81, iters: 5280, time: 0.160, data: 0.000) loss: 0.570 
(epoch: 81, iters: 5360, time: 0.159, data: 0.005) loss: 0.753 
(epoch: 81, iters: 5440, time: 0.160, data: 0.000) loss: 0.715 
(epoch: 81, iters: 5520, time: 0.162, data: 0.014) loss: 0.518 
(epoch: 81, iters: 5600, time: 0.159, data: 0.000) loss: 0.566 
(epoch: 81, iters: 5680, time: 0.159, data: 0.000) loss: 0.518 
(epoch: 81, iters: 5760, time: 0.160, data: 0.034) loss: 1.448 
(epoch: 81, iters: 5840, time: 0.160, data: 0.000) loss: 0.913 
(epoch: 81, iters: 5920, time: 0.165, data: 0.005) loss: 0.178 
(epoch: 81, iters: 6000, time: 0.159, data: 0.000) loss: 0.774 
(epoch: 81, iters: 6080, time: 0.159, data: 0.000) loss: 1.115 
(epoch: 81, iters: 6160, time: 0.159, data: 0.009) loss: 0.878 
(epoch: 81, iters: 6240, time: 0.159, data: 0.000) loss: 0.232 
(epoch: 81, iters: 6320, time: 0.158, data: 0.009) loss: 0.879 
(epoch: 81, iters: 6400, time: 0.158, data: 0.000) loss: 0.474 
(epoch: 81, iters: 6480, time: 0.159, data: 0.000) loss: 0.598 
(epoch: 81, iters: 6560, time: 0.159, data: 0.014) loss: 0.170 
(epoch: 81, iters: 6640, time: 0.161, data: 0.009) loss: 0.896 
(epoch: 81, iters: 6720, time: 0.160, data: 0.000) loss: 0.149 
(epoch: 81, iters: 6800, time: 0.160, data: 0.014) loss: 0.604 
(epoch: 81, iters: 6880, time: 0.160, data: 0.000) loss: 0.534 
(epoch: 81, iters: 6960, time: 0.157, data: 0.000) loss: 0.587 
(epoch: 81, iters: 7040, time: 0.159, data: 0.000) loss: 0.860 
(epoch: 81, iters: 7120, time: 0.160, data: 0.020) loss: 0.729 
(epoch: 81, iters: 7200, time: 0.160, data: 0.000) loss: 0.485 
(epoch: 81, iters: 7280, time: 0.158, data: 0.019) loss: 0.509 
(epoch: 81, iters: 7360, time: 0.159, data: 0.000) loss: 0.716 
(epoch: 81, iters: 7440, time: 0.157, data: 0.026) loss: 0.521 
(epoch: 81, iters: 7520, time: 0.161, data: 0.000) loss: 0.760 
(epoch: 81, iters: 7600, time: 0.161, data: 0.000) loss: 0.363 
(epoch: 81, iters: 7680, time: 0.159, data: 0.013) loss: 0.659 
(epoch: 81, iters: 7760, time: 0.158, data: 0.000) loss: 0.617 
(epoch: 81, iters: 7840, time: 0.164, data: 0.000) loss: 1.127 
(epoch: 81, iters: 7920, time: 0.160, data: 0.008) loss: 0.407 
(epoch: 81, iters: 8000, time: 0.160, data: 0.000) loss: 1.229 
saving the latest model (epoch 81, total_steps 823376)
(epoch: 81, iters: 8080, time: 0.157, data: 0.008) loss: 0.769 
(epoch: 81, iters: 8160, time: 0.159, data: 0.000) loss: 0.451 
(epoch: 81, iters: 8240, time: 0.167, data: 0.000) loss: 0.378 
(epoch: 81, iters: 8320, time: 0.160, data: 0.000) loss: 0.364 
(epoch: 81, iters: 8400, time: 0.159, data: 0.016) loss: 1.150 
(epoch: 81, iters: 8480, time: 0.161, data: 0.000) loss: 0.498 
(epoch: 81, iters: 8560, time: 0.160, data: 0.014) loss: 0.451 
(epoch: 81, iters: 8640, time: 0.159, data: 0.005) loss: 0.632 
(epoch: 81, iters: 8720, time: 0.158, data: 0.021) loss: 0.691 
(epoch: 81, iters: 8800, time: 0.157, data: 0.000) loss: 0.532 
(epoch: 81, iters: 8880, time: 0.160, data: 0.000) loss: 0.752 
(epoch: 81, iters: 8960, time: 0.160, data: 0.005) loss: 0.442 
(epoch: 81, iters: 9040, time: 0.162, data: 0.000) loss: 0.949 
(epoch: 81, iters: 9120, time: 0.158, data: 0.031) loss: 0.379 
(epoch: 81, iters: 9200, time: 0.160, data: 0.000) loss: 0.757 
(epoch: 81, iters: 9280, time: 0.161, data: 0.024) loss: 0.818 
(epoch: 81, iters: 9360, time: 0.160, data: 0.000) loss: 1.351 
(epoch: 81, iters: 9440, time: 0.160, data: 0.005) loss: 0.379 
(epoch: 81, iters: 9520, time: 0.159, data: 0.000) loss: 1.000 
(epoch: 81, iters: 9600, time: 0.161, data: 0.032) loss: 0.332 
(epoch: 81, iters: 9680, time: 0.158, data: 0.000) loss: 0.778 
(epoch: 81, iters: 9760, time: 0.159, data: 0.030) loss: 0.294 
(epoch: 81, iters: 9840, time: 0.158, data: 0.000) loss: 0.727 
(epoch: 81, iters: 9920, time: 0.163, data: 0.000) loss: 0.350 
(epoch: 81, iters: 10000, time: 0.161, data: 0.017) loss: 0.672 
(epoch: 81, iters: 10080, time: 0.159, data: 0.000) loss: 0.554 
(epoch: 81, iters: 10160, time: 0.159, data: 0.005) loss: 0.777 
saving the model at the end of epoch 81, iters 825552
End of epoch 81 / 200 	 Time Taken: 1634 sec
learning rate = 0.0002000
saving the latest model (epoch 82, total_steps 825568)
(epoch: 82, iters: 48, time: 0.164, data: 0.000) loss: 0.796 
(epoch: 82, iters: 128, time: 0.161, data: 0.000) loss: 0.878 
(epoch: 82, iters: 208, time: 0.160, data: 0.000) loss: 0.681 
(epoch: 82, iters: 288, time: 0.163, data: 0.000) loss: 0.512 
(epoch: 82, iters: 368, time: 0.164, data: 0.005) loss: 0.811 
(epoch: 82, iters: 448, time: 0.159, data: 0.000) loss: 0.907 
(epoch: 82, iters: 528, time: 0.159, data: 0.008) loss: 0.775 
(epoch: 82, iters: 608, time: 0.158, data: 0.000) loss: 0.416 
(epoch: 82, iters: 688, time: 0.163, data: 0.000) loss: 0.373 
(epoch: 82, iters: 768, time: 0.171, data: 0.015) loss: 0.942 
(epoch: 82, iters: 848, time: 0.159, data: 0.000) loss: 0.315 
(epoch: 82, iters: 928, time: 0.161, data: 0.000) loss: 0.480 
(epoch: 82, iters: 1008, time: 0.159, data: 0.010) loss: 0.613 
(epoch: 82, iters: 1088, time: 0.160, data: 0.000) loss: 0.626 
(epoch: 82, iters: 1168, time: 0.160, data: 0.025) loss: 1.155 
(epoch: 82, iters: 1248, time: 0.159, data: 0.000) loss: 0.429 
(epoch: 82, iters: 1328, time: 0.161, data: 0.000) loss: 0.796 
(epoch: 82, iters: 1408, time: 0.161, data: 0.000) loss: 0.413 
(epoch: 82, iters: 1488, time: 0.160, data: 0.032) loss: 0.182 
(epoch: 82, iters: 1568, time: 0.160, data: 0.000) loss: 0.470 
(epoch: 82, iters: 1648, time: 0.160, data: 0.014) loss: 0.828 
(epoch: 82, iters: 1728, time: 0.160, data: 0.021) loss: 0.604 
(epoch: 82, iters: 1808, time: 0.158, data: 0.000) loss: 0.210 
(epoch: 82, iters: 1888, time: 0.159, data: 0.000) loss: 0.635 
(epoch: 82, iters: 1968, time: 0.158, data: 0.005) loss: 0.681 
(epoch: 82, iters: 2048, time: 0.159, data: 0.015) loss: 0.149 
(epoch: 82, iters: 2128, time: 0.161, data: 0.000) loss: 0.501 
(epoch: 82, iters: 2208, time: 0.166, data: 0.000) loss: 0.606 
(epoch: 82, iters: 2288, time: 0.166, data: 0.000) loss: 0.312 
(epoch: 82, iters: 2368, time: 0.157, data: 0.000) loss: 0.341 
(epoch: 82, iters: 2448, time: 0.158, data: 0.020) loss: 0.312 
(epoch: 82, iters: 2528, time: 0.157, data: 0.005) loss: 1.029 
(epoch: 82, iters: 2608, time: 0.157, data: 0.009) loss: 0.297 
(epoch: 82, iters: 2688, time: 0.161, data: 0.006) loss: 0.695 
(epoch: 82, iters: 2768, time: 0.157, data: 0.000) loss: 0.788 
(epoch: 82, iters: 2848, time: 0.158, data: 0.025) loss: 0.317 
(epoch: 82, iters: 2928, time: 0.159, data: 0.000) loss: 0.915 
(epoch: 82, iters: 3008, time: 0.158, data: 0.013) loss: 0.278 
(epoch: 82, iters: 3088, time: 0.176, data: 0.009) loss: 0.456 
(epoch: 82, iters: 3168, time: 0.157, data: 0.000) loss: 0.509 
(epoch: 82, iters: 3248, time: 0.157, data: 0.000) loss: 0.274 
(epoch: 82, iters: 3328, time: 0.157, data: 0.014) loss: 0.568 
(epoch: 82, iters: 3408, time: 0.156, data: 0.008) loss: 0.481 
(epoch: 82, iters: 3488, time: 0.161, data: 0.011) loss: 0.673 
(epoch: 82, iters: 3568, time: 0.156, data: 0.000) loss: 0.958 
(epoch: 82, iters: 3648, time: 0.157, data: 0.000) loss: 0.469 
(epoch: 82, iters: 3728, time: 0.157, data: 0.000) loss: 0.561 
(epoch: 82, iters: 3808, time: 0.157, data: 0.000) loss: 0.797 
(epoch: 82, iters: 3888, time: 0.158, data: 0.014) loss: 0.722 
(epoch: 82, iters: 3968, time: 0.158, data: 0.000) loss: 1.161 
saving the latest model (epoch 82, total_steps 829568)
(epoch: 82, iters: 4048, time: 0.157, data: 0.000) loss: 0.715 
(epoch: 82, iters: 4128, time: 0.157, data: 0.000) loss: 0.349 
(epoch: 82, iters: 4208, time: 0.159, data: 0.000) loss: 0.583 
(epoch: 82, iters: 4288, time: 0.158, data: 0.009) loss: 0.717 
(epoch: 82, iters: 4368, time: 0.159, data: 0.000) loss: 0.604 
(epoch: 82, iters: 4448, time: 0.160, data: 0.006) loss: 1.050 
(epoch: 82, iters: 4528, time: 0.158, data: 0.024) loss: 0.532 
(epoch: 82, iters: 4608, time: 0.157, data: 0.000) loss: 1.197 
(epoch: 82, iters: 4688, time: 0.157, data: 0.000) loss: 0.958 
(epoch: 82, iters: 4768, time: 0.155, data: 0.000) loss: 0.449 
(epoch: 82, iters: 4848, time: 0.158, data: 0.009) loss: 0.354 
(epoch: 82, iters: 4928, time: 0.159, data: 0.000) loss: 1.011 
(epoch: 82, iters: 5008, time: 0.158, data: 0.014) loss: 0.825 
(epoch: 82, iters: 5088, time: 0.158, data: 0.014) loss: 0.205 
(epoch: 82, iters: 5168, time: 0.160, data: 0.000) loss: 1.148 
(epoch: 82, iters: 5248, time: 0.158, data: 0.011) loss: 0.515 
(epoch: 82, iters: 5328, time: 0.159, data: 0.000) loss: 0.746 
(epoch: 82, iters: 5408, time: 0.158, data: 0.000) loss: 0.262 
(epoch: 82, iters: 5488, time: 0.156, data: 0.005) loss: 0.701 
(epoch: 82, iters: 5568, time: 0.157, data: 0.011) loss: 1.075 
(epoch: 82, iters: 5648, time: 0.158, data: 0.000) loss: 0.908 
(epoch: 82, iters: 5728, time: 0.158, data: 0.008) loss: 0.461 
(epoch: 82, iters: 5808, time: 0.156, data: 0.008) loss: 0.756 
(epoch: 82, iters: 5888, time: 0.155, data: 0.000) loss: 0.789 
(epoch: 82, iters: 5968, time: 0.157, data: 0.011) loss: 0.387 
(epoch: 82, iters: 6048, time: 0.158, data: 0.000) loss: 1.087 
(epoch: 82, iters: 6128, time: 0.156, data: 0.016) loss: 0.699 
(epoch: 82, iters: 6208, time: 0.157, data: 0.031) loss: 0.458 
(epoch: 82, iters: 6288, time: 0.158, data: 0.000) loss: 0.647 
(epoch: 82, iters: 6368, time: 0.158, data: 0.000) loss: 0.574 
(epoch: 82, iters: 6448, time: 0.160, data: 0.017) loss: 0.689 
(epoch: 82, iters: 6528, time: 0.159, data: 0.000) loss: 0.513 
(epoch: 82, iters: 6608, time: 0.162, data: 0.000) loss: 1.203 
(epoch: 82, iters: 6688, time: 0.158, data: 0.005) loss: 0.742 
(epoch: 82, iters: 6768, time: 0.157, data: 0.000) loss: 0.184 
(epoch: 82, iters: 6848, time: 0.156, data: 0.000) loss: 0.330 
(epoch: 82, iters: 6928, time: 0.157, data: 0.006) loss: 1.109 
(epoch: 82, iters: 7008, time: 0.159, data: 0.005) loss: 0.145 
(epoch: 82, iters: 7088, time: 0.161, data: 0.000) loss: 1.348 
(epoch: 82, iters: 7168, time: 0.156, data: 0.000) loss: 0.884 
(epoch: 82, iters: 7248, time: 0.156, data: 0.005) loss: 0.559 
(epoch: 82, iters: 7328, time: 0.157, data: 0.000) loss: 0.371 
(epoch: 82, iters: 7408, time: 0.161, data: 0.000) loss: 0.873 
(epoch: 82, iters: 7488, time: 0.157, data: 0.000) loss: 1.168 
(epoch: 82, iters: 7568, time: 0.159, data: 0.020) loss: 0.427 
(epoch: 82, iters: 7648, time: 0.157, data: 0.000) loss: 0.769 
(epoch: 82, iters: 7728, time: 0.157, data: 0.000) loss: 0.447 
(epoch: 82, iters: 7808, time: 0.158, data: 0.032) loss: 0.501 
(epoch: 82, iters: 7888, time: 0.159, data: 0.000) loss: 0.429 
(epoch: 82, iters: 7968, time: 0.158, data: 0.010) loss: 0.788 
saving the latest model (epoch 82, total_steps 833568)
(epoch: 82, iters: 8048, time: 0.157, data: 0.008) loss: 0.648 
(epoch: 82, iters: 8128, time: 0.157, data: 0.005) loss: 0.706 
(epoch: 82, iters: 8208, time: 0.155, data: 0.000) loss: 0.839 
(epoch: 82, iters: 8288, time: 0.157, data: 0.016) loss: 0.622 
(epoch: 82, iters: 8368, time: 0.156, data: 0.000) loss: 0.954 
(epoch: 82, iters: 8448, time: 0.159, data: 0.000) loss: 0.677 
(epoch: 82, iters: 8528, time: 0.158, data: 0.017) loss: 0.831 
(epoch: 82, iters: 8608, time: 0.160, data: 0.000) loss: 0.825 
(epoch: 82, iters: 8688, time: 0.156, data: 0.000) loss: 0.558 
(epoch: 82, iters: 8768, time: 0.159, data: 0.016) loss: 0.651 
(epoch: 82, iters: 8848, time: 0.158, data: 0.000) loss: 0.378 
(epoch: 82, iters: 8928, time: 0.157, data: 0.005) loss: 0.367 
(epoch: 82, iters: 9008, time: 0.157, data: 0.000) loss: 0.710 
(epoch: 82, iters: 9088, time: 0.157, data: 0.000) loss: 0.543 
(epoch: 82, iters: 9168, time: 0.158, data: 0.005) loss: 0.640 
(epoch: 82, iters: 9248, time: 0.157, data: 0.000) loss: 0.305 
(epoch: 82, iters: 9328, time: 0.160, data: 0.011) loss: 0.945 
(epoch: 82, iters: 9408, time: 0.158, data: 0.008) loss: 0.862 
(epoch: 82, iters: 9488, time: 0.156, data: 0.000) loss: 0.432 
(epoch: 82, iters: 9568, time: 0.157, data: 0.006) loss: 0.163 
(epoch: 82, iters: 9648, time: 0.157, data: 0.017) loss: 0.812 
(epoch: 82, iters: 9728, time: 0.158, data: 0.000) loss: 0.919 
(epoch: 82, iters: 9808, time: 0.158, data: 0.000) loss: 0.330 
(epoch: 82, iters: 9888, time: 0.157, data: 0.000) loss: 0.341 
(epoch: 82, iters: 9968, time: 0.157, data: 0.005) loss: 0.457 
(epoch: 82, iters: 10048, time: 0.159, data: 0.000) loss: 0.943 
(epoch: 82, iters: 10128, time: 0.156, data: 0.009) loss: 0.384 
saving the model at the end of epoch 82, iters 835744
End of epoch 82 / 200 	 Time Taken: 1622 sec
learning rate = 0.0002000
(epoch: 83, iters: 16, time: 0.181, data: 0.011) loss: 0.512 
saving the latest model (epoch 83, total_steps 835760)
(epoch: 83, iters: 96, time: 0.162, data: 0.000) loss: 1.139 
(epoch: 83, iters: 176, time: 0.158, data: 0.000) loss: 0.711 
(epoch: 83, iters: 256, time: 0.157, data: 0.000) loss: 0.623 
(epoch: 83, iters: 336, time: 0.158, data: 0.000) loss: 0.311 
(epoch: 83, iters: 416, time: 0.156, data: 0.018) loss: 0.668 
(epoch: 83, iters: 496, time: 0.156, data: 0.015) loss: 0.804 
(epoch: 83, iters: 576, time: 0.158, data: 0.017) loss: 0.409 
(epoch: 83, iters: 656, time: 0.159, data: 0.000) loss: 0.479 
(epoch: 83, iters: 736, time: 0.161, data: 0.011) loss: 0.549 
(epoch: 83, iters: 816, time: 0.159, data: 0.000) loss: 0.639 
(epoch: 83, iters: 896, time: 0.158, data: 0.000) loss: 0.550 
(epoch: 83, iters: 976, time: 0.159, data: 0.005) loss: 0.167 
(epoch: 83, iters: 1056, time: 0.157, data: 0.000) loss: 0.431 
(epoch: 83, iters: 1136, time: 0.163, data: 0.000) loss: 0.584 
(epoch: 83, iters: 1216, time: 0.159, data: 0.019) loss: 0.832 
(epoch: 83, iters: 1296, time: 0.158, data: 0.014) loss: 0.127 
(epoch: 83, iters: 1376, time: 0.156, data: 0.000) loss: 0.528 
(epoch: 83, iters: 1456, time: 0.155, data: 0.012) loss: 0.709 
(epoch: 83, iters: 1536, time: 0.157, data: 0.000) loss: 0.506 
(epoch: 83, iters: 1616, time: 0.158, data: 0.000) loss: 0.624 
(epoch: 83, iters: 1696, time: 0.158, data: 0.020) loss: 0.443 
(epoch: 83, iters: 1776, time: 0.159, data: 0.005) loss: 0.918 
(epoch: 83, iters: 1856, time: 0.156, data: 0.010) loss: 0.705 
(epoch: 83, iters: 1936, time: 0.161, data: 0.008) loss: 0.388 
(epoch: 83, iters: 2016, time: 0.158, data: 0.025) loss: 0.298 
(epoch: 83, iters: 2096, time: 0.158, data: 0.000) loss: 0.288 
(epoch: 83, iters: 2176, time: 0.159, data: 0.000) loss: 1.065 
(epoch: 83, iters: 2256, time: 0.160, data: 0.000) loss: 0.320 
(epoch: 83, iters: 2336, time: 0.159, data: 0.019) loss: 0.201 
(epoch: 83, iters: 2416, time: 0.158, data: 0.000) loss: 0.588 
(epoch: 83, iters: 2496, time: 0.158, data: 0.005) loss: 1.233 
(epoch: 83, iters: 2576, time: 0.160, data: 0.000) loss: 0.464 
(epoch: 83, iters: 2656, time: 0.160, data: 0.000) loss: 0.556 
(epoch: 83, iters: 2736, time: 0.159, data: 0.000) loss: 0.309 
(epoch: 83, iters: 2816, time: 0.159, data: 0.000) loss: 0.462 
(epoch: 83, iters: 2896, time: 0.160, data: 0.000) loss: 0.753 
(epoch: 83, iters: 2976, time: 0.159, data: 0.000) loss: 0.774 
(epoch: 83, iters: 3056, time: 0.158, data: 0.024) loss: 0.398 
(epoch: 83, iters: 3136, time: 0.158, data: 0.000) loss: 0.111 
(epoch: 83, iters: 3216, time: 0.157, data: 0.005) loss: 0.635 
(epoch: 83, iters: 3296, time: 0.159, data: 0.000) loss: 0.560 
(epoch: 83, iters: 3376, time: 0.157, data: 0.006) loss: 0.378 
(epoch: 83, iters: 3456, time: 0.157, data: 0.005) loss: 0.236 
(epoch: 83, iters: 3536, time: 0.158, data: 0.008) loss: 0.378 
(epoch: 83, iters: 3616, time: 0.159, data: 0.000) loss: 0.740 
(epoch: 83, iters: 3696, time: 0.158, data: 0.031) loss: 0.996 
(epoch: 83, iters: 3776, time: 0.158, data: 0.000) loss: 0.537 
(epoch: 83, iters: 3856, time: 0.161, data: 0.017) loss: 1.023 
(epoch: 83, iters: 3936, time: 0.159, data: 0.000) loss: 0.526 
(epoch: 83, iters: 4016, time: 0.159, data: 0.007) loss: 0.264 
saving the latest model (epoch 83, total_steps 839760)
(epoch: 83, iters: 4096, time: 0.161, data: 0.006) loss: 0.510 
(epoch: 83, iters: 4176, time: 0.158, data: 0.000) loss: 0.714 
(epoch: 83, iters: 4256, time: 0.163, data: 0.000) loss: 0.768 
(epoch: 83, iters: 4336, time: 0.157, data: 0.000) loss: 0.289 
(epoch: 83, iters: 4416, time: 0.161, data: 0.000) loss: 1.231 
(epoch: 83, iters: 4496, time: 0.158, data: 0.000) loss: 0.523 
(epoch: 83, iters: 4576, time: 0.158, data: 0.000) loss: 1.045 
(epoch: 83, iters: 4656, time: 0.167, data: 0.000) loss: 0.882 
(epoch: 83, iters: 4736, time: 0.160, data: 0.005) loss: 0.674 
(epoch: 83, iters: 4816, time: 0.157, data: 0.019) loss: 0.566 
(epoch: 83, iters: 4896, time: 0.157, data: 0.000) loss: 0.337 
(epoch: 83, iters: 4976, time: 0.157, data: 0.000) loss: 0.321 
(epoch: 83, iters: 5056, time: 0.158, data: 0.008) loss: 0.772 
(epoch: 83, iters: 5136, time: 0.158, data: 0.008) loss: 0.465 
(epoch: 83, iters: 5216, time: 0.158, data: 0.000) loss: 0.700 
(epoch: 83, iters: 5296, time: 0.157, data: 0.008) loss: 0.546 
(epoch: 83, iters: 5376, time: 0.157, data: 0.000) loss: 0.222 
(epoch: 83, iters: 5456, time: 0.156, data: 0.000) loss: 0.446 
(epoch: 83, iters: 5536, time: 0.157, data: 0.000) loss: 1.175 
(epoch: 83, iters: 5616, time: 0.156, data: 0.015) loss: 0.671 
(epoch: 83, iters: 5696, time: 0.158, data: 0.000) loss: 0.750 
(epoch: 83, iters: 5776, time: 0.157, data: 0.016) loss: 0.476 
(epoch: 83, iters: 5856, time: 0.157, data: 0.000) loss: 0.356 
(epoch: 83, iters: 5936, time: 0.158, data: 0.016) loss: 0.599 
(epoch: 83, iters: 6016, time: 0.158, data: 0.000) loss: 0.270 
(epoch: 83, iters: 6096, time: 0.159, data: 0.014) loss: 0.173 
(epoch: 83, iters: 6176, time: 0.159, data: 0.022) loss: 0.349 
(epoch: 83, iters: 6256, time: 0.157, data: 0.009) loss: 0.347 
(epoch: 83, iters: 6336, time: 0.158, data: 0.000) loss: 0.406 
(epoch: 83, iters: 6416, time: 0.157, data: 0.005) loss: 0.840 
(epoch: 83, iters: 6496, time: 0.158, data: 0.009) loss: 0.328 
(epoch: 83, iters: 6576, time: 0.158, data: 0.000) loss: 0.654 
(epoch: 83, iters: 6656, time: 0.160, data: 0.000) loss: 0.721 
(epoch: 83, iters: 6736, time: 0.161, data: 0.005) loss: 0.506 
(epoch: 83, iters: 6816, time: 0.161, data: 0.011) loss: 0.813 
(epoch: 83, iters: 6896, time: 0.156, data: 0.000) loss: 0.895 
(epoch: 83, iters: 6976, time: 0.158, data: 0.000) loss: 0.498 
(epoch: 83, iters: 7056, time: 0.156, data: 0.015) loss: 0.770 
(epoch: 83, iters: 7136, time: 0.158, data: 0.005) loss: 0.292 
(epoch: 83, iters: 7216, time: 0.157, data: 0.015) loss: 0.745 
(epoch: 83, iters: 7296, time: 0.157, data: 0.000) loss: 0.743 
(epoch: 83, iters: 7376, time: 0.157, data: 0.000) loss: 0.541 
(epoch: 83, iters: 7456, time: 0.156, data: 0.000) loss: 0.768 
(epoch: 83, iters: 7536, time: 0.158, data: 0.009) loss: 0.668 
(epoch: 83, iters: 7616, time: 0.158, data: 0.025) loss: 0.658 
(epoch: 83, iters: 7696, time: 0.161, data: 0.000) loss: 1.001 
(epoch: 83, iters: 7776, time: 0.157, data: 0.012) loss: 0.857 
(epoch: 83, iters: 7856, time: 0.156, data: 0.000) loss: 0.351 
(epoch: 83, iters: 7936, time: 0.158, data: 0.037) loss: 0.563 
(epoch: 83, iters: 8016, time: 0.158, data: 0.000) loss: 0.464 
saving the latest model (epoch 83, total_steps 843760)
(epoch: 83, iters: 8096, time: 0.160, data: 0.000) loss: 0.437 
(epoch: 83, iters: 8176, time: 0.158, data: 0.024) loss: 0.841 
(epoch: 83, iters: 8256, time: 0.160, data: 0.000) loss: 0.491 
(epoch: 83, iters: 8336, time: 0.161, data: 0.000) loss: 0.832 
(epoch: 83, iters: 8416, time: 0.159, data: 0.009) loss: 1.014 
(epoch: 83, iters: 8496, time: 0.159, data: 0.000) loss: 0.852 
(epoch: 83, iters: 8576, time: 0.167, data: 0.005) loss: 0.544 
(epoch: 83, iters: 8656, time: 0.158, data: 0.000) loss: 0.159 
(epoch: 83, iters: 8736, time: 0.159, data: 0.009) loss: 0.450 
(epoch: 83, iters: 8816, time: 0.159, data: 0.014) loss: 0.319 
(epoch: 83, iters: 8896, time: 0.159, data: 0.005) loss: 0.240 
(epoch: 83, iters: 8976, time: 0.165, data: 0.000) loss: 0.575 
(epoch: 83, iters: 9056, time: 0.158, data: 0.000) loss: 0.903 
(epoch: 83, iters: 9136, time: 0.158, data: 0.000) loss: 0.353 
(epoch: 83, iters: 9216, time: 0.158, data: 0.000) loss: 1.349 
(epoch: 83, iters: 9296, time: 0.160, data: 0.026) loss: 0.522 
(epoch: 83, iters: 9376, time: 0.156, data: 0.000) loss: 1.212 
(epoch: 83, iters: 9456, time: 0.157, data: 0.000) loss: 0.667 
(epoch: 83, iters: 9536, time: 0.158, data: 0.013) loss: 1.005 
(epoch: 83, iters: 9616, time: 0.158, data: 0.009) loss: 0.671 
(epoch: 83, iters: 9696, time: 0.156, data: 0.005) loss: 0.744 
(epoch: 83, iters: 9776, time: 0.156, data: 0.000) loss: 0.622 
(epoch: 83, iters: 9856, time: 0.158, data: 0.000) loss: 0.289 
(epoch: 83, iters: 9936, time: 0.157, data: 0.008) loss: 0.708 
(epoch: 83, iters: 10016, time: 0.158, data: 0.000) loss: 0.280 
(epoch: 83, iters: 10096, time: 0.156, data: 0.014) loss: 0.177 
(epoch: 83, iters: 10176, time: 0.159, data: 0.005) loss: 0.381 
saving the model at the end of epoch 83, iters 845936
End of epoch 83 / 200 	 Time Taken: 1620 sec
learning rate = 0.0002000
saving the latest model (epoch 84, total_steps 845952)
(epoch: 84, iters: 64, time: 0.161, data: 0.003) loss: 0.810 
(epoch: 84, iters: 144, time: 0.158, data: 0.054) loss: 0.461 
(epoch: 84, iters: 224, time: 0.157, data: 0.000) loss: 0.774 
(epoch: 84, iters: 304, time: 0.158, data: 0.006) loss: 0.532 
(epoch: 84, iters: 384, time: 0.158, data: 0.000) loss: 0.383 
(epoch: 84, iters: 464, time: 0.157, data: 0.012) loss: 0.409 
(epoch: 84, iters: 544, time: 0.160, data: 0.000) loss: 1.197 
(epoch: 84, iters: 624, time: 0.159, data: 0.000) loss: 0.531 
(epoch: 84, iters: 704, time: 0.157, data: 0.015) loss: 1.758 
(epoch: 84, iters: 784, time: 0.157, data: 0.000) loss: 0.472 
(epoch: 84, iters: 864, time: 0.158, data: 0.005) loss: 0.352 
(epoch: 84, iters: 944, time: 0.159, data: 0.000) loss: 0.916 
(epoch: 84, iters: 1024, time: 0.160, data: 0.010) loss: 0.616 
(epoch: 84, iters: 1104, time: 0.159, data: 0.005) loss: 0.698 
(epoch: 84, iters: 1184, time: 0.157, data: 0.000) loss: 0.477 
(epoch: 84, iters: 1264, time: 0.157, data: 0.005) loss: 0.565 
(epoch: 84, iters: 1344, time: 0.160, data: 0.000) loss: 1.003 
(epoch: 84, iters: 1424, time: 0.159, data: 0.017) loss: 0.372 
(epoch: 84, iters: 1504, time: 0.159, data: 0.014) loss: 0.494 
(epoch: 84, iters: 1584, time: 0.159, data: 0.005) loss: 0.689 
(epoch: 84, iters: 1664, time: 0.159, data: 0.000) loss: 0.727 
(epoch: 84, iters: 1744, time: 0.161, data: 0.040) loss: 0.190 
(epoch: 84, iters: 1824, time: 0.159, data: 0.000) loss: 0.273 
(epoch: 84, iters: 1904, time: 0.160, data: 0.000) loss: 0.596 
(epoch: 84, iters: 1984, time: 0.160, data: 0.000) loss: 1.305 
(epoch: 84, iters: 2064, time: 0.159, data: 0.029) loss: 0.445 
(epoch: 84, iters: 2144, time: 0.160, data: 0.000) loss: 0.391 
(epoch: 84, iters: 2224, time: 0.159, data: 0.018) loss: 0.720 
(epoch: 84, iters: 2304, time: 0.165, data: 0.000) loss: 0.625 
(epoch: 84, iters: 2384, time: 0.162, data: 0.025) loss: 0.926 
(epoch: 84, iters: 2464, time: 0.159, data: 0.000) loss: 0.172 
(epoch: 84, iters: 2544, time: 0.161, data: 0.027) loss: 0.326 
(epoch: 84, iters: 2624, time: 0.158, data: 0.000) loss: 0.407 
(epoch: 84, iters: 2704, time: 0.169, data: 0.000) loss: 0.521 
(epoch: 84, iters: 2784, time: 0.158, data: 0.005) loss: 0.739 
(epoch: 84, iters: 2864, time: 0.158, data: 0.000) loss: 0.399 
(epoch: 84, iters: 2944, time: 0.161, data: 0.000) loss: 0.530 
(epoch: 84, iters: 3024, time: 0.159, data: 0.014) loss: 0.231 
(epoch: 84, iters: 3104, time: 0.158, data: 0.000) loss: 0.360 
(epoch: 84, iters: 3184, time: 0.161, data: 0.023) loss: 0.456 
(epoch: 84, iters: 3264, time: 0.161, data: 0.000) loss: 0.371 
(epoch: 84, iters: 3344, time: 0.160, data: 0.023) loss: 0.500 
(epoch: 84, iters: 3424, time: 0.161, data: 0.000) loss: 0.720 
(epoch: 84, iters: 3504, time: 0.159, data: 0.000) loss: 0.581 
(epoch: 84, iters: 3584, time: 0.159, data: 0.000) loss: 0.472 
(epoch: 84, iters: 3664, time: 0.159, data: 0.006) loss: 0.604 
(epoch: 84, iters: 3744, time: 0.159, data: 0.009) loss: 0.391 
(epoch: 84, iters: 3824, time: 0.158, data: 0.000) loss: 0.671 
(epoch: 84, iters: 3904, time: 0.158, data: 0.005) loss: 0.293 
(epoch: 84, iters: 3984, time: 0.159, data: 0.008) loss: 0.864 
saving the latest model (epoch 84, total_steps 849952)
(epoch: 84, iters: 4064, time: 0.159, data: 0.014) loss: 0.421 
(epoch: 84, iters: 4144, time: 0.159, data: 0.000) loss: 0.523 
(epoch: 84, iters: 4224, time: 0.160, data: 0.022) loss: 0.828 
(epoch: 84, iters: 4304, time: 0.161, data: 0.000) loss: 0.594 
(epoch: 84, iters: 4384, time: 0.158, data: 0.000) loss: 0.594 
(epoch: 84, iters: 4464, time: 0.161, data: 0.005) loss: 0.928 
(epoch: 84, iters: 4544, time: 0.159, data: 0.000) loss: 0.253 
(epoch: 84, iters: 4624, time: 0.159, data: 0.000) loss: 0.503 
(epoch: 84, iters: 4704, time: 0.158, data: 0.000) loss: 0.411 
(epoch: 84, iters: 4784, time: 0.161, data: 0.008) loss: 0.567 
(epoch: 84, iters: 4864, time: 0.159, data: 0.005) loss: 0.743 
(epoch: 84, iters: 4944, time: 0.156, data: 0.009) loss: 1.090 
(epoch: 84, iters: 5024, time: 0.157, data: 0.000) loss: 0.708 
(epoch: 84, iters: 5104, time: 0.160, data: 0.008) loss: 0.532 
(epoch: 84, iters: 5184, time: 0.161, data: 0.000) loss: 0.551 
(epoch: 84, iters: 5264, time: 0.158, data: 0.020) loss: 0.436 
(epoch: 84, iters: 5344, time: 0.158, data: 0.015) loss: 0.321 
(epoch: 84, iters: 5424, time: 0.157, data: 0.000) loss: 0.785 
(epoch: 84, iters: 5504, time: 0.157, data: 0.020) loss: 0.722 
(epoch: 84, iters: 5584, time: 0.158, data: 0.008) loss: 0.453 
(epoch: 84, iters: 5664, time: 0.159, data: 0.000) loss: 0.581 
(epoch: 84, iters: 5744, time: 0.159, data: 0.016) loss: 0.822 
(epoch: 84, iters: 5824, time: 0.161, data: 0.005) loss: 0.621 
(epoch: 84, iters: 5904, time: 0.161, data: 0.008) loss: 0.799 
(epoch: 84, iters: 5984, time: 0.160, data: 0.000) loss: 0.598 
(epoch: 84, iters: 6064, time: 0.159, data: 0.016) loss: 0.455 
(epoch: 84, iters: 6144, time: 0.162, data: 0.000) loss: 0.601 
(epoch: 84, iters: 6224, time: 0.159, data: 0.021) loss: 0.518 
(epoch: 84, iters: 6304, time: 0.161, data: 0.000) loss: 0.981 
(epoch: 84, iters: 6384, time: 0.159, data: 0.000) loss: 0.520 
(epoch: 84, iters: 6464, time: 0.162, data: 0.009) loss: 0.520 
(epoch: 84, iters: 6544, time: 0.162, data: 0.006) loss: 0.468 
(epoch: 84, iters: 6624, time: 0.159, data: 0.000) loss: 0.238 
(epoch: 84, iters: 6704, time: 0.160, data: 0.000) loss: 0.255 
(epoch: 84, iters: 6784, time: 0.159, data: 0.006) loss: 0.539 
(epoch: 84, iters: 6864, time: 0.159, data: 0.000) loss: 0.408 
(epoch: 84, iters: 6944, time: 0.160, data: 0.021) loss: 0.630 
(epoch: 84, iters: 7024, time: 0.159, data: 0.006) loss: 0.444 
(epoch: 84, iters: 7104, time: 0.159, data: 0.016) loss: 0.440 
(epoch: 84, iters: 7184, time: 0.161, data: 0.000) loss: 0.478 
(epoch: 84, iters: 7264, time: 0.164, data: 0.032) loss: 1.052 
(epoch: 84, iters: 7344, time: 0.159, data: 0.000) loss: 0.873 
(epoch: 84, iters: 7424, time: 0.159, data: 0.000) loss: 1.021 
(epoch: 84, iters: 7504, time: 0.163, data: 0.000) loss: 0.664 
(epoch: 84, iters: 7584, time: 0.161, data: 0.020) loss: 0.565 
(epoch: 84, iters: 7664, time: 0.159, data: 0.014) loss: 1.037 
(epoch: 84, iters: 7744, time: 0.162, data: 0.022) loss: 0.466 
(epoch: 84, iters: 7824, time: 0.160, data: 0.005) loss: 0.505 
(epoch: 84, iters: 7904, time: 0.161, data: 0.005) loss: 0.293 
(epoch: 84, iters: 7984, time: 0.160, data: 0.000) loss: 1.246 
saving the latest model (epoch 84, total_steps 853952)
(epoch: 84, iters: 8064, time: 0.161, data: 0.000) loss: 0.515 
(epoch: 84, iters: 8144, time: 0.160, data: 0.008) loss: 0.537 
(epoch: 84, iters: 8224, time: 0.159, data: 0.008) loss: 0.484 
(epoch: 84, iters: 8304, time: 0.162, data: 0.000) loss: 0.658 
(epoch: 84, iters: 8384, time: 0.161, data: 0.009) loss: 0.542 
(epoch: 84, iters: 8464, time: 0.162, data: 0.000) loss: 0.751 
(epoch: 84, iters: 8544, time: 0.160, data: 0.005) loss: 0.613 
(epoch: 84, iters: 8624, time: 0.159, data: 0.000) loss: 0.271 
(epoch: 84, iters: 8704, time: 0.159, data: 0.009) loss: 0.542 
(epoch: 84, iters: 8784, time: 0.162, data: 0.000) loss: 0.330 
(epoch: 84, iters: 8864, time: 0.160, data: 0.006) loss: 0.294 
(epoch: 84, iters: 8944, time: 0.159, data: 0.008) loss: 0.457 
(epoch: 84, iters: 9024, time: 0.160, data: 0.000) loss: 1.068 
(epoch: 84, iters: 9104, time: 0.160, data: 0.005) loss: 0.385 
(epoch: 84, iters: 9184, time: 0.161, data: 0.000) loss: 1.087 
(epoch: 84, iters: 9264, time: 0.160, data: 0.000) loss: 0.461 
(epoch: 84, iters: 9344, time: 0.160, data: 0.000) loss: 0.300 
(epoch: 84, iters: 9424, time: 0.163, data: 0.016) loss: 0.268 
(epoch: 84, iters: 9504, time: 0.160, data: 0.005) loss: 1.215 
(epoch: 84, iters: 9584, time: 0.165, data: 0.000) loss: 0.736 
(epoch: 84, iters: 9664, time: 0.159, data: 0.021) loss: 0.389 
(epoch: 84, iters: 9744, time: 0.160, data: 0.000) loss: 0.512 
(epoch: 84, iters: 9824, time: 0.160, data: 0.009) loss: 0.362 
(epoch: 84, iters: 9904, time: 0.161, data: 0.000) loss: 1.101 
(epoch: 84, iters: 9984, time: 0.161, data: 0.013) loss: 0.281 
(epoch: 84, iters: 10064, time: 0.160, data: 0.000) loss: 0.653 
(epoch: 84, iters: 10144, time: 0.159, data: 0.024) loss: 0.319 
saving the model at the end of epoch 84, iters 856128
End of epoch 84 / 200 	 Time Taken: 1634 sec
learning rate = 0.0002000
saving the latest model (epoch 85, total_steps 856144)
(epoch: 85, iters: 32, time: 0.168, data: 0.000) loss: 0.587 
(epoch: 85, iters: 112, time: 0.158, data: 0.031) loss: 0.311 
(epoch: 85, iters: 192, time: 0.158, data: 0.000) loss: 0.637 
(epoch: 85, iters: 272, time: 0.158, data: 0.011) loss: 0.498 
(epoch: 85, iters: 352, time: 0.158, data: 0.007) loss: 1.071 
(epoch: 85, iters: 432, time: 0.157, data: 0.000) loss: 1.072 
(epoch: 85, iters: 512, time: 0.159, data: 0.009) loss: 1.393 
(epoch: 85, iters: 592, time: 0.157, data: 0.000) loss: 0.686 
(epoch: 85, iters: 672, time: 0.159, data: 0.005) loss: 0.397 
(epoch: 85, iters: 752, time: 0.159, data: 0.000) loss: 0.616 
(epoch: 85, iters: 832, time: 0.158, data: 0.022) loss: 0.323 
(epoch: 85, iters: 912, time: 0.159, data: 0.017) loss: 0.234 
(epoch: 85, iters: 992, time: 0.159, data: 0.010) loss: 0.419 
(epoch: 85, iters: 1072, time: 0.160, data: 0.000) loss: 0.466 
(epoch: 85, iters: 1152, time: 0.159, data: 0.008) loss: 0.677 
(epoch: 85, iters: 1232, time: 0.159, data: 0.005) loss: 0.646 
(epoch: 85, iters: 1312, time: 0.157, data: 0.000) loss: 0.620 
(epoch: 85, iters: 1392, time: 0.160, data: 0.009) loss: 0.941 
(epoch: 85, iters: 1472, time: 0.158, data: 0.000) loss: 0.466 
(epoch: 85, iters: 1552, time: 0.159, data: 0.000) loss: 0.612 
(epoch: 85, iters: 1632, time: 0.157, data: 0.022) loss: 0.694 
(epoch: 85, iters: 1712, time: 0.160, data: 0.000) loss: 0.964 
(epoch: 85, iters: 1792, time: 0.159, data: 0.005) loss: 0.656 
(epoch: 85, iters: 1872, time: 0.160, data: 0.000) loss: 0.621 
(epoch: 85, iters: 1952, time: 0.158, data: 0.011) loss: 0.764 
(epoch: 85, iters: 2032, time: 0.160, data: 0.000) loss: 0.726 
(epoch: 85, iters: 2112, time: 0.157, data: 0.000) loss: 0.410 
(epoch: 85, iters: 2192, time: 0.159, data: 0.008) loss: 0.744 
(epoch: 85, iters: 2272, time: 0.160, data: 0.024) loss: 0.195 
(epoch: 85, iters: 2352, time: 0.158, data: 0.000) loss: 0.502 
(epoch: 85, iters: 2432, time: 0.160, data: 0.000) loss: 0.716 
(epoch: 85, iters: 2512, time: 0.165, data: 0.000) loss: 0.703 
(epoch: 85, iters: 2592, time: 0.160, data: 0.000) loss: 0.663 
(epoch: 85, iters: 2672, time: 0.158, data: 0.000) loss: 0.519 
(epoch: 85, iters: 2752, time: 0.159, data: 0.000) loss: 0.618 
(epoch: 85, iters: 2832, time: 0.158, data: 0.013) loss: 0.283 
(epoch: 85, iters: 2912, time: 0.161, data: 0.018) loss: 0.456 
(epoch: 85, iters: 2992, time: 0.161, data: 0.000) loss: 0.625 
(epoch: 85, iters: 3072, time: 0.161, data: 0.015) loss: 0.535 
(epoch: 85, iters: 3152, time: 0.160, data: 0.000) loss: 0.348 
(epoch: 85, iters: 3232, time: 0.160, data: 0.006) loss: 0.444 
(epoch: 85, iters: 3312, time: 0.158, data: 0.000) loss: 0.760 
(epoch: 85, iters: 3392, time: 0.160, data: 0.005) loss: 0.524 
(epoch: 85, iters: 3472, time: 0.157, data: 0.005) loss: 1.081 
(epoch: 85, iters: 3552, time: 0.159, data: 0.005) loss: 0.633 
(epoch: 85, iters: 3632, time: 0.159, data: 0.000) loss: 0.526 
(epoch: 85, iters: 3712, time: 0.160, data: 0.006) loss: 0.337 
(epoch: 85, iters: 3792, time: 0.160, data: 0.005) loss: 0.455 
(epoch: 85, iters: 3872, time: 0.171, data: 0.000) loss: 0.798 
(epoch: 85, iters: 3952, time: 0.158, data: 0.027) loss: 0.640 
saving the latest model (epoch 85, total_steps 860144)
(epoch: 85, iters: 4032, time: 0.160, data: 0.000) loss: 0.632 
(epoch: 85, iters: 4112, time: 0.156, data: 0.008) loss: 0.241 
(epoch: 85, iters: 4192, time: 0.157, data: 0.000) loss: 0.317 
(epoch: 85, iters: 4272, time: 0.158, data: 0.006) loss: 0.139 
(epoch: 85, iters: 4352, time: 0.160, data: 0.000) loss: 0.514 
(epoch: 85, iters: 4432, time: 0.159, data: 0.000) loss: 0.749 
(epoch: 85, iters: 4512, time: 0.162, data: 0.008) loss: 0.363 
(epoch: 85, iters: 4592, time: 0.160, data: 0.000) loss: 1.040 
(epoch: 85, iters: 4672, time: 0.159, data: 0.000) loss: 0.738 
(epoch: 85, iters: 4752, time: 0.162, data: 0.000) loss: 0.909 
(epoch: 85, iters: 4832, time: 0.162, data: 0.021) loss: 0.489 
(epoch: 85, iters: 4912, time: 0.159, data: 0.000) loss: 0.328 
(epoch: 85, iters: 4992, time: 0.159, data: 0.017) loss: 0.625 
(epoch: 85, iters: 5072, time: 0.158, data: 0.016) loss: 0.604 
(epoch: 85, iters: 5152, time: 0.158, data: 0.000) loss: 0.242 
(epoch: 85, iters: 5232, time: 0.165, data: 0.011) loss: 0.764 
(epoch: 85, iters: 5312, time: 0.160, data: 0.000) loss: 0.382 
(epoch: 85, iters: 5392, time: 0.159, data: 0.033) loss: 0.509 
(epoch: 85, iters: 5472, time: 0.159, data: 0.000) loss: 0.841 
(epoch: 85, iters: 5552, time: 0.159, data: 0.000) loss: 0.165 
(epoch: 85, iters: 5632, time: 0.159, data: 0.032) loss: 0.769 
(epoch: 85, iters: 5712, time: 0.158, data: 0.000) loss: 0.296 
(epoch: 85, iters: 5792, time: 0.159, data: 0.000) loss: 0.318 
(epoch: 85, iters: 5872, time: 0.157, data: 0.005) loss: 0.263 
(epoch: 85, iters: 5952, time: 0.160, data: 0.000) loss: 0.442 
(epoch: 85, iters: 6032, time: 0.159, data: 0.009) loss: 0.743 
(epoch: 85, iters: 6112, time: 0.161, data: 0.000) loss: 0.608 
(epoch: 85, iters: 6192, time: 0.158, data: 0.008) loss: 1.187 
(epoch: 85, iters: 6272, time: 0.160, data: 0.000) loss: 0.928 
(epoch: 85, iters: 6352, time: 0.159, data: 0.013) loss: 0.388 
(epoch: 85, iters: 6432, time: 0.160, data: 0.005) loss: 0.413 
(epoch: 85, iters: 6512, time: 0.158, data: 0.032) loss: 0.428 
(epoch: 85, iters: 6592, time: 0.159, data: 0.000) loss: 0.747 
(epoch: 85, iters: 6672, time: 0.159, data: 0.000) loss: 0.940 
(epoch: 85, iters: 6752, time: 0.162, data: 0.000) loss: 0.237 
(epoch: 85, iters: 6832, time: 0.159, data: 0.025) loss: 0.462 
(epoch: 85, iters: 6912, time: 0.160, data: 0.000) loss: 0.635 
(epoch: 85, iters: 6992, time: 0.161, data: 0.000) loss: 0.533 
(epoch: 85, iters: 7072, time: 0.159, data: 0.000) loss: 1.041 
(epoch: 85, iters: 7152, time: 0.159, data: 0.021) loss: 0.451 
(epoch: 85, iters: 7232, time: 0.161, data: 0.015) loss: 1.158 
(epoch: 85, iters: 7312, time: 0.159, data: 0.009) loss: 0.927 
(epoch: 85, iters: 7392, time: 0.158, data: 0.017) loss: 0.312 
(epoch: 85, iters: 7472, time: 0.158, data: 0.000) loss: 0.614 
(epoch: 85, iters: 7552, time: 0.158, data: 0.000) loss: 0.432 
(epoch: 85, iters: 7632, time: 0.160, data: 0.006) loss: 0.262 
(epoch: 85, iters: 7712, time: 0.159, data: 0.000) loss: 0.548 
(epoch: 85, iters: 7792, time: 0.162, data: 0.000) loss: 0.449 
(epoch: 85, iters: 7872, time: 0.157, data: 0.017) loss: 0.724 
(epoch: 85, iters: 7952, time: 0.161, data: 0.000) loss: 0.411 
saving the latest model (epoch 85, total_steps 864144)
(epoch: 85, iters: 8032, time: 0.159, data: 0.000) loss: 0.906 
(epoch: 85, iters: 8112, time: 0.159, data: 0.000) loss: 0.996 
(epoch: 85, iters: 8192, time: 0.160, data: 0.005) loss: 0.448 
(epoch: 85, iters: 8272, time: 0.163, data: 0.000) loss: 0.417 
(epoch: 85, iters: 8352, time: 0.165, data: 0.005) loss: 0.684 
(epoch: 85, iters: 8432, time: 0.158, data: 0.000) loss: 0.285 
(epoch: 85, iters: 8512, time: 0.163, data: 0.000) loss: 1.046 
(epoch: 85, iters: 8592, time: 0.161, data: 0.009) loss: 0.398 
(epoch: 85, iters: 8672, time: 0.158, data: 0.016) loss: 0.556 
(epoch: 85, iters: 8752, time: 0.164, data: 0.018) loss: 1.021 
(epoch: 85, iters: 8832, time: 0.157, data: 0.000) loss: 0.912 
(epoch: 85, iters: 8912, time: 0.159, data: 0.000) loss: 0.272 
(epoch: 85, iters: 8992, time: 0.160, data: 0.008) loss: 0.198 
(epoch: 85, iters: 9072, time: 0.160, data: 0.009) loss: 0.420 
(epoch: 85, iters: 9152, time: 0.159, data: 0.005) loss: 0.671 
(epoch: 85, iters: 9232, time: 0.160, data: 0.000) loss: 0.570 
(epoch: 85, iters: 9312, time: 0.161, data: 0.000) loss: 0.481 
(epoch: 85, iters: 9392, time: 0.158, data: 0.009) loss: 0.260 
(epoch: 85, iters: 9472, time: 0.158, data: 0.000) loss: 0.528 
(epoch: 85, iters: 9552, time: 0.158, data: 0.010) loss: 0.716 
(epoch: 85, iters: 9632, time: 0.159, data: 0.000) loss: 0.483 
(epoch: 85, iters: 9712, time: 0.159, data: 0.009) loss: 0.710 
(epoch: 85, iters: 9792, time: 0.157, data: 0.027) loss: 0.734 
(epoch: 85, iters: 9872, time: 0.159, data: 0.000) loss: 0.721 
(epoch: 85, iters: 9952, time: 0.159, data: 0.000) loss: 0.262 
(epoch: 85, iters: 10032, time: 0.160, data: 0.000) loss: 1.397 
(epoch: 85, iters: 10112, time: 0.160, data: 0.000) loss: 0.595 
(epoch: 85, iters: 10192, time: 0.096, data: 0.015) loss: 1.232 
saving the model at the end of epoch 85, iters 866320
End of epoch 85 / 200 	 Time Taken: 1631 sec
learning rate = 0.0002000
saving the latest model (epoch 86, total_steps 866336)
(epoch: 86, iters: 80, time: 0.162, data: 0.199) loss: 0.218 
(epoch: 86, iters: 160, time: 0.160, data: 0.000) loss: 0.789 
(epoch: 86, iters: 240, time: 0.161, data: 0.000) loss: 0.250 
(epoch: 86, iters: 320, time: 0.159, data: 0.017) loss: 0.322 
(epoch: 86, iters: 400, time: 0.161, data: 0.000) loss: 0.871 
(epoch: 86, iters: 480, time: 0.160, data: 0.006) loss: 0.665 
(epoch: 86, iters: 560, time: 0.158, data: 0.011) loss: 0.702 
(epoch: 86, iters: 640, time: 0.157, data: 0.000) loss: 0.315 
(epoch: 86, iters: 720, time: 0.158, data: 0.000) loss: 0.690 
(epoch: 86, iters: 800, time: 0.156, data: 0.016) loss: 0.652 
(epoch: 86, iters: 880, time: 0.158, data: 0.000) loss: 1.123 
(epoch: 86, iters: 960, time: 0.158, data: 0.024) loss: 0.640 
(epoch: 86, iters: 1040, time: 0.157, data: 0.000) loss: 0.414 
(epoch: 86, iters: 1120, time: 0.158, data: 0.000) loss: 0.825 
(epoch: 86, iters: 1200, time: 0.159, data: 0.009) loss: 0.411 
(epoch: 86, iters: 1280, time: 0.160, data: 0.012) loss: 0.357 
(epoch: 86, iters: 1360, time: 0.158, data: 0.000) loss: 0.320 
(epoch: 86, iters: 1440, time: 0.157, data: 0.010) loss: 0.377 
(epoch: 86, iters: 1520, time: 0.160, data: 0.000) loss: 0.621 
(epoch: 86, iters: 1600, time: 0.159, data: 0.015) loss: 0.421 
(epoch: 86, iters: 1680, time: 0.156, data: 0.000) loss: 1.250 
(epoch: 86, iters: 1760, time: 0.159, data: 0.000) loss: 0.321 
(epoch: 86, iters: 1840, time: 0.160, data: 0.000) loss: 0.730 
(epoch: 86, iters: 1920, time: 0.158, data: 0.000) loss: 0.453 
(epoch: 86, iters: 2000, time: 0.160, data: 0.000) loss: 0.407 
(epoch: 86, iters: 2080, time: 0.160, data: 0.005) loss: 0.441 
(epoch: 86, iters: 2160, time: 0.160, data: 0.000) loss: 0.533 
(epoch: 86, iters: 2240, time: 0.159, data: 0.014) loss: 0.495 
(epoch: 86, iters: 2320, time: 0.160, data: 0.006) loss: 0.275 
(epoch: 86, iters: 2400, time: 0.160, data: 0.000) loss: 0.921 
(epoch: 86, iters: 2480, time: 0.161, data: 0.000) loss: 0.299 
(epoch: 86, iters: 2560, time: 0.159, data: 0.000) loss: 0.456 
(epoch: 86, iters: 2640, time: 0.158, data: 0.000) loss: 0.278 
(epoch: 86, iters: 2720, time: 0.159, data: 0.027) loss: 0.265 
(epoch: 86, iters: 2800, time: 0.157, data: 0.000) loss: 0.435 
(epoch: 86, iters: 2880, time: 0.158, data: 0.032) loss: 0.318 
(epoch: 86, iters: 2960, time: 0.160, data: 0.000) loss: 0.355 
(epoch: 86, iters: 3040, time: 0.159, data: 0.006) loss: 0.231 
(epoch: 86, iters: 3120, time: 0.157, data: 0.000) loss: 0.876 
(epoch: 86, iters: 3200, time: 0.159, data: 0.000) loss: 0.247 
(epoch: 86, iters: 3280, time: 0.157, data: 0.000) loss: 0.841 
(epoch: 86, iters: 3360, time: 0.161, data: 0.016) loss: 0.312 
(epoch: 86, iters: 3440, time: 0.159, data: 0.000) loss: 0.781 
(epoch: 86, iters: 3520, time: 0.160, data: 0.000) loss: 1.075 
(epoch: 86, iters: 3600, time: 0.158, data: 0.000) loss: 1.051 
(epoch: 86, iters: 3680, time: 0.159, data: 0.000) loss: 0.607 
(epoch: 86, iters: 3760, time: 0.158, data: 0.015) loss: 0.589 
(epoch: 86, iters: 3840, time: 0.157, data: 0.000) loss: 0.748 
(epoch: 86, iters: 3920, time: 0.158, data: 0.015) loss: 0.509 
(epoch: 86, iters: 4000, time: 0.162, data: 0.000) loss: 0.768 
saving the latest model (epoch 86, total_steps 870336)
(epoch: 86, iters: 4080, time: 0.157, data: 0.000) loss: 0.971 
(epoch: 86, iters: 4160, time: 0.160, data: 0.000) loss: 0.342 
(epoch: 86, iters: 4240, time: 0.157, data: 0.008) loss: 0.346 
(epoch: 86, iters: 4320, time: 0.157, data: 0.000) loss: 0.182 
(epoch: 86, iters: 4400, time: 0.155, data: 0.000) loss: 0.358 
(epoch: 86, iters: 4480, time: 0.158, data: 0.014) loss: 0.292 
(epoch: 86, iters: 4560, time: 0.159, data: 0.000) loss: 0.665 
(epoch: 86, iters: 4640, time: 0.160, data: 0.005) loss: 0.657 
(epoch: 86, iters: 4720, time: 0.160, data: 0.024) loss: 0.335 
(epoch: 86, iters: 4800, time: 0.160, data: 0.000) loss: 0.626 
(epoch: 86, iters: 4880, time: 0.159, data: 0.031) loss: 0.161 
(epoch: 86, iters: 4960, time: 0.160, data: 0.000) loss: 0.482 
(epoch: 86, iters: 5040, time: 0.158, data: 0.010) loss: 0.823 
(epoch: 86, iters: 5120, time: 0.160, data: 0.000) loss: 1.020 
(epoch: 86, iters: 5200, time: 0.159, data: 0.015) loss: 0.275 
(epoch: 86, iters: 5280, time: 0.159, data: 0.000) loss: 0.523 
(epoch: 86, iters: 5360, time: 0.161, data: 0.000) loss: 0.400 
(epoch: 86, iters: 5440, time: 0.158, data: 0.023) loss: 0.745 
(epoch: 86, iters: 5520, time: 0.169, data: 0.000) loss: 0.354 
(epoch: 86, iters: 5600, time: 0.166, data: 0.014) loss: 0.763 
(epoch: 86, iters: 5680, time: 0.163, data: 0.015) loss: 0.775 
(epoch: 86, iters: 5760, time: 0.163, data: 0.000) loss: 0.269 
(epoch: 86, iters: 5840, time: 0.163, data: 0.022) loss: 0.873 
(epoch: 86, iters: 5920, time: 0.165, data: 0.008) loss: 0.306 
(epoch: 86, iters: 6000, time: 0.164, data: 0.000) loss: 0.972 
(epoch: 86, iters: 6080, time: 0.163, data: 0.016) loss: 0.503 
(epoch: 86, iters: 6160, time: 0.164, data: 0.006) loss: 0.245 
(epoch: 86, iters: 6240, time: 0.163, data: 0.000) loss: 0.386 
(epoch: 86, iters: 6320, time: 0.166, data: 0.006) loss: 0.959 
(epoch: 86, iters: 6400, time: 0.164, data: 0.000) loss: 0.496 
(epoch: 86, iters: 6480, time: 0.162, data: 0.031) loss: 0.643 
(epoch: 86, iters: 6560, time: 0.164, data: 0.000) loss: 1.286 
(epoch: 86, iters: 6640, time: 0.165, data: 0.000) loss: 0.512 
(epoch: 86, iters: 6720, time: 0.166, data: 0.005) loss: 0.996 
(epoch: 86, iters: 6800, time: 0.162, data: 0.000) loss: 0.717 
(epoch: 86, iters: 6880, time: 0.162, data: 0.008) loss: 0.504 
(epoch: 86, iters: 6960, time: 0.165, data: 0.010) loss: 0.939 
(epoch: 86, iters: 7040, time: 0.164, data: 0.008) loss: 0.269 
(epoch: 86, iters: 7120, time: 0.164, data: 0.008) loss: 0.666 
(epoch: 86, iters: 7200, time: 0.163, data: 0.000) loss: 0.463 
(epoch: 86, iters: 7280, time: 0.163, data: 0.000) loss: 1.109 
(epoch: 86, iters: 7360, time: 0.163, data: 0.000) loss: 0.320 
(epoch: 86, iters: 7440, time: 0.164, data: 0.016) loss: 0.599 
(epoch: 86, iters: 7520, time: 0.164, data: 0.005) loss: 0.756 
(epoch: 86, iters: 7600, time: 0.163, data: 0.011) loss: 1.426 
(epoch: 86, iters: 7680, time: 0.163, data: 0.000) loss: 0.403 
(epoch: 86, iters: 7760, time: 0.165, data: 0.000) loss: 0.602 
(epoch: 86, iters: 7840, time: 0.164, data: 0.000) loss: 0.997 
(epoch: 86, iters: 7920, time: 0.165, data: 0.005) loss: 0.354 
(epoch: 86, iters: 8000, time: 0.164, data: 0.030) loss: 0.431 
saving the latest model (epoch 86, total_steps 874336)
(epoch: 86, iters: 8080, time: 0.165, data: 0.009) loss: 0.769 
(epoch: 86, iters: 8160, time: 0.164, data: 0.017) loss: 0.427 
(epoch: 86, iters: 8240, time: 0.163, data: 0.000) loss: 0.423 
(epoch: 86, iters: 8320, time: 0.162, data: 0.028) loss: 0.619 
(epoch: 86, iters: 8400, time: 0.164, data: 0.000) loss: 0.300 
(epoch: 86, iters: 8480, time: 0.165, data: 0.000) loss: 0.636 
(epoch: 86, iters: 8560, time: 0.162, data: 0.000) loss: 0.657 
(epoch: 86, iters: 8640, time: 0.164, data: 0.000) loss: 0.558 
(epoch: 86, iters: 8720, time: 0.163, data: 0.005) loss: 0.173 
(epoch: 86, iters: 8800, time: 0.164, data: 0.000) loss: 0.640 
(epoch: 86, iters: 8880, time: 0.163, data: 0.000) loss: 0.847 
(epoch: 86, iters: 8960, time: 0.163, data: 0.000) loss: 0.404 
(epoch: 86, iters: 9040, time: 0.162, data: 0.017) loss: 0.411 
(epoch: 86, iters: 9120, time: 0.162, data: 0.000) loss: 0.918 
(epoch: 86, iters: 9200, time: 0.163, data: 0.009) loss: 1.936 
(epoch: 86, iters: 9280, time: 0.162, data: 0.000) loss: 0.766 
(epoch: 86, iters: 9360, time: 0.164, data: 0.000) loss: 0.627 
(epoch: 86, iters: 9440, time: 0.165, data: 0.019) loss: 1.001 
(epoch: 86, iters: 9520, time: 0.163, data: 0.000) loss: 0.394 
(epoch: 86, iters: 9600, time: 0.163, data: 0.000) loss: 0.289 
(epoch: 86, iters: 9680, time: 0.164, data: 0.000) loss: 0.479 
(epoch: 86, iters: 9760, time: 0.164, data: 0.000) loss: 1.442 
(epoch: 86, iters: 9840, time: 0.164, data: 0.015) loss: 0.278 
(epoch: 86, iters: 9920, time: 0.164, data: 0.000) loss: 1.046 
(epoch: 86, iters: 10000, time: 0.163, data: 0.031) loss: 0.501 
(epoch: 86, iters: 10080, time: 0.166, data: 0.000) loss: 0.437 
(epoch: 86, iters: 10160, time: 0.165, data: 0.000) loss: 0.679 
saving the model at the end of epoch 86, iters 876512
End of epoch 86 / 200 	 Time Taken: 1647 sec
learning rate = 0.0002000
saving the latest model (epoch 87, total_steps 876528)
(epoch: 87, iters: 48, time: 0.165, data: 0.007) loss: 0.218 
(epoch: 87, iters: 128, time: 0.161, data: 0.010) loss: 0.607 
(epoch: 87, iters: 208, time: 0.158, data: 0.000) loss: 0.445 
(epoch: 87, iters: 288, time: 0.163, data: 0.000) loss: 0.607 
(epoch: 87, iters: 368, time: 0.158, data: 0.005) loss: 0.983 
(epoch: 87, iters: 448, time: 0.159, data: 0.000) loss: 0.537 
(epoch: 87, iters: 528, time: 0.162, data: 0.000) loss: 0.820 
(epoch: 87, iters: 608, time: 0.160, data: 0.025) loss: 0.313 
(epoch: 87, iters: 688, time: 0.160, data: 0.000) loss: 1.168 
(epoch: 87, iters: 768, time: 0.158, data: 0.006) loss: 0.852 
(epoch: 87, iters: 848, time: 0.159, data: 0.000) loss: 0.534 
(epoch: 87, iters: 928, time: 0.161, data: 0.025) loss: 0.596 
(epoch: 87, iters: 1008, time: 0.160, data: 0.000) loss: 0.686 
(epoch: 87, iters: 1088, time: 0.160, data: 0.008) loss: 0.350 
(epoch: 87, iters: 1168, time: 0.157, data: 0.000) loss: 0.543 
(epoch: 87, iters: 1248, time: 0.158, data: 0.010) loss: 0.814 
(epoch: 87, iters: 1328, time: 0.159, data: 0.000) loss: 0.324 
(epoch: 87, iters: 1408, time: 0.159, data: 0.000) loss: 0.586 
(epoch: 87, iters: 1488, time: 0.161, data: 0.008) loss: 0.400 
(epoch: 87, iters: 1568, time: 0.161, data: 0.000) loss: 0.261 
(epoch: 87, iters: 1648, time: 0.160, data: 0.008) loss: 0.606 
(epoch: 87, iters: 1728, time: 0.159, data: 0.005) loss: 0.417 
(epoch: 87, iters: 1808, time: 0.159, data: 0.017) loss: 0.151 
(epoch: 87, iters: 1888, time: 0.160, data: 0.000) loss: 0.459 
(epoch: 87, iters: 1968, time: 0.160, data: 0.009) loss: 0.213 
(epoch: 87, iters: 2048, time: 0.160, data: 0.000) loss: 0.238 
(epoch: 87, iters: 2128, time: 0.160, data: 0.000) loss: 0.303 
(epoch: 87, iters: 2208, time: 0.160, data: 0.000) loss: 0.411 
(epoch: 87, iters: 2288, time: 0.160, data: 0.015) loss: 1.207 
(epoch: 87, iters: 2368, time: 0.160, data: 0.000) loss: 0.893 
(epoch: 87, iters: 2448, time: 0.158, data: 0.005) loss: 0.233 
(epoch: 87, iters: 2528, time: 0.160, data: 0.000) loss: 0.351 
(epoch: 87, iters: 2608, time: 0.160, data: 0.010) loss: 0.921 
(epoch: 87, iters: 2688, time: 0.160, data: 0.000) loss: 0.805 
(epoch: 87, iters: 2768, time: 0.160, data: 0.000) loss: 0.361 
(epoch: 87, iters: 2848, time: 0.158, data: 0.005) loss: 0.943 
(epoch: 87, iters: 2928, time: 0.159, data: 0.009) loss: 0.674 
(epoch: 87, iters: 3008, time: 0.158, data: 0.000) loss: 0.969 
(epoch: 87, iters: 3088, time: 0.159, data: 0.005) loss: 0.510 
(epoch: 87, iters: 3168, time: 0.160, data: 0.000) loss: 0.843 
(epoch: 87, iters: 3248, time: 0.160, data: 0.010) loss: 1.036 
(epoch: 87, iters: 3328, time: 0.160, data: 0.020) loss: 0.656 
(epoch: 87, iters: 3408, time: 0.160, data: 0.000) loss: 0.193 
(epoch: 87, iters: 3488, time: 0.157, data: 0.000) loss: 0.718 
(epoch: 87, iters: 3568, time: 0.161, data: 0.032) loss: 0.663 
(epoch: 87, iters: 3648, time: 0.160, data: 0.000) loss: 0.587 
(epoch: 87, iters: 3728, time: 0.159, data: 0.042) loss: 0.240 
(epoch: 87, iters: 3808, time: 0.161, data: 0.000) loss: 0.324 
(epoch: 87, iters: 3888, time: 0.158, data: 0.000) loss: 0.270 
(epoch: 87, iters: 3968, time: 0.159, data: 0.000) loss: 0.826 
saving the latest model (epoch 87, total_steps 880528)
(epoch: 87, iters: 4048, time: 0.161, data: 0.006) loss: 0.402 
(epoch: 87, iters: 4128, time: 0.161, data: 0.005) loss: 0.811 
(epoch: 87, iters: 4208, time: 0.160, data: 0.015) loss: 0.649 
(epoch: 87, iters: 4288, time: 0.161, data: 0.005) loss: 0.623 
(epoch: 87, iters: 4368, time: 0.160, data: 0.000) loss: 0.840 
(epoch: 87, iters: 4448, time: 0.160, data: 0.000) loss: 0.358 
(epoch: 87, iters: 4528, time: 0.161, data: 0.000) loss: 0.515 
(epoch: 87, iters: 4608, time: 0.159, data: 0.016) loss: 0.719 
(epoch: 87, iters: 4688, time: 0.163, data: 0.000) loss: 0.536 
(epoch: 87, iters: 4768, time: 0.160, data: 0.007) loss: 0.414 
(epoch: 87, iters: 4848, time: 0.159, data: 0.000) loss: 0.241 
(epoch: 87, iters: 4928, time: 0.158, data: 0.006) loss: 0.556 
(epoch: 87, iters: 5008, time: 0.160, data: 0.020) loss: 0.479 
(epoch: 87, iters: 5088, time: 0.161, data: 0.009) loss: 0.310 
(epoch: 87, iters: 5168, time: 0.163, data: 0.009) loss: 0.528 
(epoch: 87, iters: 5248, time: 0.161, data: 0.009) loss: 0.839 
(epoch: 87, iters: 5328, time: 0.160, data: 0.010) loss: 0.516 
(epoch: 87, iters: 5408, time: 0.159, data: 0.000) loss: 0.867 
(epoch: 87, iters: 5488, time: 0.162, data: 0.000) loss: 0.716 
(epoch: 87, iters: 5568, time: 0.160, data: 0.000) loss: 0.532 
(epoch: 87, iters: 5648, time: 0.162, data: 0.008) loss: 0.441 
(epoch: 87, iters: 5728, time: 0.161, data: 0.037) loss: 0.998 
(epoch: 87, iters: 5808, time: 0.162, data: 0.000) loss: 1.278 
(epoch: 87, iters: 5888, time: 0.161, data: 0.000) loss: 0.155 
(epoch: 87, iters: 5968, time: 0.161, data: 0.000) loss: 0.734 
(epoch: 87, iters: 6048, time: 0.162, data: 0.000) loss: 0.341 
(epoch: 87, iters: 6128, time: 0.161, data: 0.008) loss: 0.781 
(epoch: 87, iters: 6208, time: 0.161, data: 0.000) loss: 0.636 
(epoch: 87, iters: 6288, time: 0.160, data: 0.015) loss: 0.676 
(epoch: 87, iters: 6368, time: 0.160, data: 0.000) loss: 0.868 
(epoch: 87, iters: 6448, time: 0.163, data: 0.005) loss: 0.451 
(epoch: 87, iters: 6528, time: 0.162, data: 0.000) loss: 0.253 
(epoch: 87, iters: 6608, time: 0.157, data: 0.011) loss: 0.659 
(epoch: 87, iters: 6688, time: 0.166, data: 0.000) loss: 0.306 
(epoch: 87, iters: 6768, time: 0.161, data: 0.008) loss: 0.140 
(epoch: 87, iters: 6848, time: 0.159, data: 0.000) loss: 0.701 
(epoch: 87, iters: 6928, time: 0.173, data: 0.000) loss: 0.278 
(epoch: 87, iters: 7008, time: 0.161, data: 0.000) loss: 0.424 
(epoch: 87, iters: 7088, time: 0.158, data: 0.000) loss: 0.578 
(epoch: 87, iters: 7168, time: 0.159, data: 0.013) loss: 0.206 
(epoch: 87, iters: 7248, time: 0.172, data: 0.000) loss: 0.766 
(epoch: 87, iters: 7328, time: 0.157, data: 0.000) loss: 0.348 
(epoch: 87, iters: 7408, time: 0.156, data: 0.000) loss: 0.966 
(epoch: 87, iters: 7488, time: 0.157, data: 0.000) loss: 0.689 
(epoch: 87, iters: 7568, time: 0.167, data: 0.000) loss: 0.706 
(epoch: 87, iters: 7648, time: 0.156, data: 0.022) loss: 0.800 
(epoch: 87, iters: 7728, time: 0.157, data: 0.021) loss: 0.251 
(epoch: 87, iters: 7808, time: 0.153, data: 0.005) loss: 0.544 
(epoch: 87, iters: 7888, time: 0.155, data: 0.009) loss: 0.548 
(epoch: 87, iters: 7968, time: 0.155, data: 0.008) loss: 0.413 
saving the latest model (epoch 87, total_steps 884528)
(epoch: 87, iters: 8048, time: 0.157, data: 0.005) loss: 0.404 
(epoch: 87, iters: 8128, time: 0.157, data: 0.000) loss: 0.587 
(epoch: 87, iters: 8208, time: 0.156, data: 0.010) loss: 0.358 
(epoch: 87, iters: 8288, time: 0.155, data: 0.006) loss: 0.532 
(epoch: 87, iters: 8368, time: 0.155, data: 0.011) loss: 1.200 
(epoch: 87, iters: 8448, time: 0.154, data: 0.017) loss: 0.448 
(epoch: 87, iters: 8528, time: 0.154, data: 0.000) loss: 0.470 
(epoch: 87, iters: 8608, time: 0.158, data: 0.005) loss: 0.590 
(epoch: 87, iters: 8688, time: 0.156, data: 0.000) loss: 0.155 
(epoch: 87, iters: 8768, time: 0.156, data: 0.000) loss: 0.320 
(epoch: 87, iters: 8848, time: 0.155, data: 0.000) loss: 1.431 
(epoch: 87, iters: 8928, time: 0.153, data: 0.005) loss: 0.411 
(epoch: 87, iters: 9008, time: 0.152, data: 0.019) loss: 0.287 
(epoch: 87, iters: 9088, time: 0.155, data: 0.000) loss: 0.515 
(epoch: 87, iters: 9168, time: 0.158, data: 0.000) loss: 0.673 
(epoch: 87, iters: 9248, time: 0.156, data: 0.000) loss: 0.598 
(epoch: 87, iters: 9328, time: 0.157, data: 0.000) loss: 0.849 
(epoch: 87, iters: 9408, time: 0.155, data: 0.024) loss: 0.742 
(epoch: 87, iters: 9488, time: 0.155, data: 0.000) loss: 0.802 
(epoch: 87, iters: 9568, time: 0.158, data: 0.011) loss: 0.945 
(epoch: 87, iters: 9648, time: 0.168, data: 0.000) loss: 0.423 
(epoch: 87, iters: 9728, time: 0.169, data: 0.000) loss: 0.701 
(epoch: 87, iters: 9808, time: 0.156, data: 0.000) loss: 0.429 
(epoch: 87, iters: 9888, time: 0.157, data: 0.000) loss: 0.644 
(epoch: 87, iters: 9968, time: 0.157, data: 0.015) loss: 0.931 
(epoch: 87, iters: 10048, time: 0.156, data: 0.000) loss: 0.755 
(epoch: 87, iters: 10128, time: 0.155, data: 0.039) loss: 0.951 
saving the model at the end of epoch 87, iters 886704
End of epoch 87 / 200 	 Time Taken: 1630 sec
learning rate = 0.0002000
(epoch: 88, iters: 16, time: 0.179, data: 0.000) loss: 0.725 
saving the latest model (epoch 88, total_steps 886720)
(epoch: 88, iters: 96, time: 0.156, data: 0.049) loss: 0.235 
(epoch: 88, iters: 176, time: 0.158, data: 0.013) loss: 0.940 
(epoch: 88, iters: 256, time: 0.158, data: 0.000) loss: 0.547 
(epoch: 88, iters: 336, time: 0.157, data: 0.005) loss: 0.708 
(epoch: 88, iters: 416, time: 0.156, data: 0.000) loss: 0.396 
(epoch: 88, iters: 496, time: 0.159, data: 0.000) loss: 0.475 
(epoch: 88, iters: 576, time: 0.157, data: 0.016) loss: 0.421 
(epoch: 88, iters: 656, time: 0.156, data: 0.000) loss: 0.382 
(epoch: 88, iters: 736, time: 0.158, data: 0.000) loss: 0.373 
(epoch: 88, iters: 816, time: 0.156, data: 0.015) loss: 0.820 
(epoch: 88, iters: 896, time: 0.162, data: 0.000) loss: 0.174 
(epoch: 88, iters: 976, time: 0.168, data: 0.008) loss: 0.375 
(epoch: 88, iters: 1056, time: 0.159, data: 0.005) loss: 0.693 
(epoch: 88, iters: 1136, time: 0.160, data: 0.005) loss: 0.377 
(epoch: 88, iters: 1216, time: 0.159, data: 0.000) loss: 0.306 
(epoch: 88, iters: 1296, time: 0.161, data: 0.000) loss: 0.694 
(epoch: 88, iters: 1376, time: 0.165, data: 0.005) loss: 0.302 
(epoch: 88, iters: 1456, time: 0.160, data: 0.018) loss: 0.177 
(epoch: 88, iters: 1536, time: 0.162, data: 0.000) loss: 1.181 
(epoch: 88, iters: 1616, time: 0.157, data: 0.010) loss: 0.480 
(epoch: 88, iters: 1696, time: 0.159, data: 0.015) loss: 1.147 
(epoch: 88, iters: 1776, time: 0.159, data: 0.011) loss: 0.516 
(epoch: 88, iters: 1856, time: 0.158, data: 0.000) loss: 0.520 
(epoch: 88, iters: 1936, time: 0.159, data: 0.000) loss: 0.435 
(epoch: 88, iters: 2016, time: 0.160, data: 0.024) loss: 0.462 
(epoch: 88, iters: 2096, time: 0.160, data: 0.005) loss: 0.751 
(epoch: 88, iters: 2176, time: 0.160, data: 0.000) loss: 0.212 
(epoch: 88, iters: 2256, time: 0.161, data: 0.008) loss: 0.914 
(epoch: 88, iters: 2336, time: 0.161, data: 0.000) loss: 0.306 
(epoch: 88, iters: 2416, time: 0.161, data: 0.018) loss: 0.483 
(epoch: 88, iters: 2496, time: 0.160, data: 0.013) loss: 0.255 
(epoch: 88, iters: 2576, time: 0.159, data: 0.000) loss: 1.139 
(epoch: 88, iters: 2656, time: 0.160, data: 0.000) loss: 0.505 
(epoch: 88, iters: 2736, time: 0.160, data: 0.006) loss: 0.329 
(epoch: 88, iters: 2816, time: 0.160, data: 0.009) loss: 0.741 
(epoch: 88, iters: 2896, time: 0.159, data: 0.000) loss: 0.577 
(epoch: 88, iters: 2976, time: 0.161, data: 0.000) loss: 1.021 
(epoch: 88, iters: 3056, time: 0.159, data: 0.021) loss: 0.543 
(epoch: 88, iters: 3136, time: 0.160, data: 0.000) loss: 0.624 
(epoch: 88, iters: 3216, time: 0.159, data: 0.005) loss: 1.035 
(epoch: 88, iters: 3296, time: 0.168, data: 0.000) loss: 0.840 
(epoch: 88, iters: 3376, time: 0.162, data: 0.005) loss: 0.495 
(epoch: 88, iters: 3456, time: 0.158, data: 0.000) loss: 0.820 
(epoch: 88, iters: 3536, time: 0.159, data: 0.011) loss: 0.692 
(epoch: 88, iters: 3616, time: 0.158, data: 0.000) loss: 0.469 
(epoch: 88, iters: 3696, time: 0.160, data: 0.000) loss: 0.565 
(epoch: 88, iters: 3776, time: 0.160, data: 0.000) loss: 0.336 
(epoch: 88, iters: 3856, time: 0.160, data: 0.000) loss: 0.849 
(epoch: 88, iters: 3936, time: 0.160, data: 0.024) loss: 0.650 
(epoch: 88, iters: 4016, time: 0.157, data: 0.032) loss: 0.281 
saving the latest model (epoch 88, total_steps 890720)
(epoch: 88, iters: 4096, time: 0.158, data: 0.000) loss: 1.047 
(epoch: 88, iters: 4176, time: 0.157, data: 0.000) loss: 0.544 
(epoch: 88, iters: 4256, time: 0.162, data: 0.000) loss: 0.483 
(epoch: 88, iters: 4336, time: 0.157, data: 0.005) loss: 0.520 
(epoch: 88, iters: 4416, time: 0.158, data: 0.000) loss: 0.779 
(epoch: 88, iters: 4496, time: 0.161, data: 0.000) loss: 0.900 
(epoch: 88, iters: 4576, time: 0.165, data: 0.000) loss: 0.954 
(epoch: 88, iters: 4656, time: 0.160, data: 0.000) loss: 0.602 
(epoch: 88, iters: 4736, time: 0.160, data: 0.000) loss: 0.535 
(epoch: 88, iters: 4816, time: 0.163, data: 0.023) loss: 0.489 
(epoch: 88, iters: 4896, time: 0.159, data: 0.000) loss: 0.392 
(epoch: 88, iters: 4976, time: 0.158, data: 0.000) loss: 1.291 
(epoch: 88, iters: 5056, time: 0.158, data: 0.000) loss: 0.895 
(epoch: 88, iters: 5136, time: 0.157, data: 0.014) loss: 0.154 
(epoch: 88, iters: 5216, time: 0.158, data: 0.000) loss: 1.616 
(epoch: 88, iters: 5296, time: 0.159, data: 0.000) loss: 0.514 
(epoch: 88, iters: 5376, time: 0.157, data: 0.015) loss: 0.805 
(epoch: 88, iters: 5456, time: 0.159, data: 0.000) loss: 0.380 
(epoch: 88, iters: 5536, time: 0.157, data: 0.006) loss: 0.401 
(epoch: 88, iters: 5616, time: 0.163, data: 0.025) loss: 0.363 
(epoch: 88, iters: 5696, time: 0.160, data: 0.000) loss: 0.520 
(epoch: 88, iters: 5776, time: 0.158, data: 0.017) loss: 0.732 
(epoch: 88, iters: 5856, time: 0.159, data: 0.000) loss: 0.566 
(epoch: 88, iters: 5936, time: 0.158, data: 0.005) loss: 0.630 
(epoch: 88, iters: 6016, time: 0.160, data: 0.008) loss: 0.976 
(epoch: 88, iters: 6096, time: 0.159, data: 0.005) loss: 0.904 
(epoch: 88, iters: 6176, time: 0.161, data: 0.000) loss: 0.257 
(epoch: 88, iters: 6256, time: 0.160, data: 0.039) loss: 0.746 
(epoch: 88, iters: 6336, time: 0.159, data: 0.000) loss: 0.826 
(epoch: 88, iters: 6416, time: 0.162, data: 0.000) loss: 0.826 
(epoch: 88, iters: 6496, time: 0.159, data: 0.020) loss: 0.397 
(epoch: 88, iters: 6576, time: 0.162, data: 0.000) loss: 0.805 
(epoch: 88, iters: 6656, time: 0.160, data: 0.009) loss: 0.914 
(epoch: 88, iters: 6736, time: 0.161, data: 0.000) loss: 0.377 
(epoch: 88, iters: 6816, time: 0.162, data: 0.009) loss: 1.344 
(epoch: 88, iters: 6896, time: 0.158, data: 0.021) loss: 0.444 
(epoch: 88, iters: 6976, time: 0.158, data: 0.000) loss: 0.507 
(epoch: 88, iters: 7056, time: 0.158, data: 0.014) loss: 0.712 
(epoch: 88, iters: 7136, time: 0.157, data: 0.005) loss: 0.468 
(epoch: 88, iters: 7216, time: 0.159, data: 0.000) loss: 0.404 
(epoch: 88, iters: 7296, time: 0.160, data: 0.009) loss: 0.410 
(epoch: 88, iters: 7376, time: 0.161, data: 0.000) loss: 0.203 
(epoch: 88, iters: 7456, time: 0.158, data: 0.005) loss: 1.027 
(epoch: 88, iters: 7536, time: 0.158, data: 0.000) loss: 0.466 
(epoch: 88, iters: 7616, time: 0.161, data: 0.008) loss: 1.152 
(epoch: 88, iters: 7696, time: 0.158, data: 0.005) loss: 0.775 
(epoch: 88, iters: 7776, time: 0.158, data: 0.000) loss: 0.637 
(epoch: 88, iters: 7856, time: 0.160, data: 0.000) loss: 0.375 
(epoch: 88, iters: 7936, time: 0.160, data: 0.005) loss: 1.029 
(epoch: 88, iters: 8016, time: 0.158, data: 0.000) loss: 1.041 
saving the latest model (epoch 88, total_steps 894720)
(epoch: 88, iters: 8096, time: 0.158, data: 0.005) loss: 0.267 
(epoch: 88, iters: 8176, time: 0.161, data: 0.000) loss: 0.773 
(epoch: 88, iters: 8256, time: 0.158, data: 0.024) loss: 0.564 
(epoch: 88, iters: 8336, time: 0.163, data: 0.012) loss: 0.763 
(epoch: 88, iters: 8416, time: 0.160, data: 0.005) loss: 0.799 
(epoch: 88, iters: 8496, time: 0.161, data: 0.020) loss: 0.588 
(epoch: 88, iters: 8576, time: 0.159, data: 0.000) loss: 0.457 
(epoch: 88, iters: 8656, time: 0.160, data: 0.000) loss: 0.534 
(epoch: 88, iters: 8736, time: 0.161, data: 0.005) loss: 0.977 
(epoch: 88, iters: 8816, time: 0.157, data: 0.000) loss: 0.493 
(epoch: 88, iters: 8896, time: 0.159, data: 0.000) loss: 0.297 
(epoch: 88, iters: 8976, time: 0.156, data: 0.000) loss: 0.332 
(epoch: 88, iters: 9056, time: 0.156, data: 0.000) loss: 0.402 
(epoch: 88, iters: 9136, time: 0.157, data: 0.006) loss: 0.422 
(epoch: 88, iters: 9216, time: 0.158, data: 0.010) loss: 0.372 
(epoch: 88, iters: 9296, time: 0.157, data: 0.010) loss: 0.946 
(epoch: 88, iters: 9376, time: 0.158, data: 0.000) loss: 0.544 
(epoch: 88, iters: 9456, time: 0.156, data: 0.000) loss: 0.841 
(epoch: 88, iters: 9536, time: 0.158, data: 0.021) loss: 0.791 
(epoch: 88, iters: 9616, time: 0.158, data: 0.010) loss: 0.198 
(epoch: 88, iters: 9696, time: 0.155, data: 0.005) loss: 0.363 
(epoch: 88, iters: 9776, time: 0.156, data: 0.000) loss: 0.676 
(epoch: 88, iters: 9856, time: 0.155, data: 0.000) loss: 1.112 
(epoch: 88, iters: 9936, time: 0.159, data: 0.020) loss: 0.580 
(epoch: 88, iters: 10016, time: 0.158, data: 0.005) loss: 0.680 
(epoch: 88, iters: 10096, time: 0.157, data: 0.000) loss: 0.414 
(epoch: 88, iters: 10176, time: 0.155, data: 0.000) loss: 0.224 
saving the model at the end of epoch 88, iters 896896
End of epoch 88 / 200 	 Time Taken: 1630 sec
learning rate = 0.0002000
saving the latest model (epoch 89, total_steps 896912)
(epoch: 89, iters: 64, time: 0.156, data: 0.003) loss: 0.511 
(epoch: 89, iters: 144, time: 0.153, data: 0.019) loss: 0.229 
(epoch: 89, iters: 224, time: 0.152, data: 0.007) loss: 1.163 
(epoch: 89, iters: 304, time: 0.154, data: 0.000) loss: 0.236 
(epoch: 89, iters: 384, time: 0.152, data: 0.005) loss: 0.271 
(epoch: 89, iters: 464, time: 0.155, data: 0.009) loss: 0.831 
(epoch: 89, iters: 544, time: 0.161, data: 0.005) loss: 0.350 
(epoch: 89, iters: 624, time: 0.158, data: 0.024) loss: 1.070 
(epoch: 89, iters: 704, time: 0.157, data: 0.000) loss: 0.982 
(epoch: 89, iters: 784, time: 0.158, data: 0.000) loss: 0.752 
(epoch: 89, iters: 864, time: 0.158, data: 0.013) loss: 0.404 
(epoch: 89, iters: 944, time: 0.157, data: 0.000) loss: 0.652 
(epoch: 89, iters: 1024, time: 0.156, data: 0.000) loss: 0.977 
(epoch: 89, iters: 1104, time: 0.159, data: 0.021) loss: 0.334 
(epoch: 89, iters: 1184, time: 0.159, data: 0.025) loss: 0.840 
(epoch: 89, iters: 1264, time: 0.158, data: 0.000) loss: 0.489 
(epoch: 89, iters: 1344, time: 0.159, data: 0.000) loss: 0.167 
(epoch: 89, iters: 1424, time: 0.158, data: 0.000) loss: 0.887 
(epoch: 89, iters: 1504, time: 0.158, data: 0.023) loss: 0.197 
(epoch: 89, iters: 1584, time: 0.157, data: 0.000) loss: 0.335 
(epoch: 89, iters: 1664, time: 0.157, data: 0.000) loss: 0.496 
(epoch: 89, iters: 1744, time: 0.158, data: 0.008) loss: 0.813 
(epoch: 89, iters: 1824, time: 0.157, data: 0.011) loss: 0.356 
(epoch: 89, iters: 1904, time: 0.156, data: 0.000) loss: 0.459 
(epoch: 89, iters: 1984, time: 0.157, data: 0.016) loss: 0.467 
(epoch: 89, iters: 2064, time: 0.161, data: 0.000) loss: 0.486 
(epoch: 89, iters: 2144, time: 0.158, data: 0.029) loss: 0.839 
(epoch: 89, iters: 2224, time: 0.157, data: 0.017) loss: 0.474 
(epoch: 89, iters: 2304, time: 0.159, data: 0.015) loss: 0.347 
(epoch: 89, iters: 2384, time: 0.158, data: 0.000) loss: 0.644 
(epoch: 89, iters: 2464, time: 0.165, data: 0.006) loss: 0.350 
(epoch: 89, iters: 2544, time: 0.159, data: 0.000) loss: 0.431 
(epoch: 89, iters: 2624, time: 0.158, data: 0.009) loss: 0.860 
(epoch: 89, iters: 2704, time: 0.159, data: 0.000) loss: 0.642 
(epoch: 89, iters: 2784, time: 0.159, data: 0.000) loss: 1.082 
(epoch: 89, iters: 2864, time: 0.157, data: 0.005) loss: 0.663 
(epoch: 89, iters: 2944, time: 0.159, data: 0.000) loss: 0.837 
(epoch: 89, iters: 3024, time: 0.156, data: 0.000) loss: 0.377 
(epoch: 89, iters: 3104, time: 0.156, data: 0.000) loss: 1.520 
(epoch: 89, iters: 3184, time: 0.158, data: 0.008) loss: 0.700 
(epoch: 89, iters: 3264, time: 0.158, data: 0.014) loss: 0.544 
(epoch: 89, iters: 3344, time: 0.161, data: 0.000) loss: 0.260 
(epoch: 89, iters: 3424, time: 0.160, data: 0.017) loss: 0.280 
(epoch: 89, iters: 3504, time: 0.159, data: 0.006) loss: 0.496 
(epoch: 89, iters: 3584, time: 0.159, data: 0.009) loss: 0.339 
(epoch: 89, iters: 3664, time: 0.158, data: 0.000) loss: 0.701 
(epoch: 89, iters: 3744, time: 0.159, data: 0.006) loss: 0.431 
(epoch: 89, iters: 3824, time: 0.158, data: 0.005) loss: 0.978 
(epoch: 89, iters: 3904, time: 0.158, data: 0.000) loss: 1.122 
(epoch: 89, iters: 3984, time: 0.157, data: 0.011) loss: 0.392 
saving the latest model (epoch 89, total_steps 900912)
(epoch: 89, iters: 4064, time: 0.156, data: 0.000) loss: 0.471 
(epoch: 89, iters: 4144, time: 0.158, data: 0.000) loss: 1.063 
(epoch: 89, iters: 4224, time: 0.157, data: 0.008) loss: 0.893 
(epoch: 89, iters: 4304, time: 0.156, data: 0.022) loss: 1.116 
(epoch: 89, iters: 4384, time: 0.158, data: 0.005) loss: 0.432 
(epoch: 89, iters: 4464, time: 0.159, data: 0.000) loss: 0.375 
(epoch: 89, iters: 4544, time: 0.158, data: 0.016) loss: 0.445 
(epoch: 89, iters: 4624, time: 0.157, data: 0.000) loss: 0.459 
(epoch: 89, iters: 4704, time: 0.157, data: 0.006) loss: 0.683 
(epoch: 89, iters: 4784, time: 0.157, data: 0.011) loss: 0.408 
(epoch: 89, iters: 4864, time: 0.158, data: 0.000) loss: 0.424 
(epoch: 89, iters: 4944, time: 0.156, data: 0.014) loss: 0.596 
(epoch: 89, iters: 5024, time: 0.156, data: 0.000) loss: 0.180 
(epoch: 89, iters: 5104, time: 0.157, data: 0.000) loss: 0.488 
(epoch: 89, iters: 5184, time: 0.161, data: 0.022) loss: 0.628 
(epoch: 89, iters: 5264, time: 0.158, data: 0.025) loss: 0.324 
(epoch: 89, iters: 5344, time: 0.160, data: 0.000) loss: 0.342 
(epoch: 89, iters: 5424, time: 0.157, data: 0.000) loss: 0.538 
(epoch: 89, iters: 5504, time: 0.159, data: 0.000) loss: 0.834 
(epoch: 89, iters: 5584, time: 0.160, data: 0.000) loss: 0.852 
(epoch: 89, iters: 5664, time: 0.158, data: 0.000) loss: 0.645 
(epoch: 89, iters: 5744, time: 0.159, data: 0.000) loss: 0.394 
(epoch: 89, iters: 5824, time: 0.158, data: 0.012) loss: 0.286 
(epoch: 89, iters: 5904, time: 0.156, data: 0.000) loss: 0.308 
(epoch: 89, iters: 5984, time: 0.164, data: 0.000) loss: 0.275 
(epoch: 89, iters: 6064, time: 0.159, data: 0.009) loss: 0.624 
(epoch: 89, iters: 6144, time: 0.160, data: 0.000) loss: 0.507 
(epoch: 89, iters: 6224, time: 0.158, data: 0.005) loss: 0.721 
(epoch: 89, iters: 6304, time: 0.160, data: 0.006) loss: 0.544 
(epoch: 89, iters: 6384, time: 0.159, data: 0.000) loss: 0.793 
(epoch: 89, iters: 6464, time: 0.158, data: 0.000) loss: 0.812 
(epoch: 89, iters: 6544, time: 0.158, data: 0.005) loss: 0.553 
(epoch: 89, iters: 6624, time: 0.158, data: 0.000) loss: 1.205 
(epoch: 89, iters: 6704, time: 0.159, data: 0.000) loss: 0.914 
(epoch: 89, iters: 6784, time: 0.158, data: 0.000) loss: 0.340 
(epoch: 89, iters: 6864, time: 0.159, data: 0.025) loss: 0.616 
(epoch: 89, iters: 6944, time: 0.160, data: 0.000) loss: 0.566 
(epoch: 89, iters: 7024, time: 0.158, data: 0.011) loss: 0.546 
(epoch: 89, iters: 7104, time: 0.158, data: 0.000) loss: 0.802 
(epoch: 89, iters: 7184, time: 0.158, data: 0.000) loss: 0.838 
(epoch: 89, iters: 7264, time: 0.156, data: 0.000) loss: 0.624 
(epoch: 89, iters: 7344, time: 0.158, data: 0.000) loss: 0.650 
(epoch: 89, iters: 7424, time: 0.154, data: 0.005) loss: 1.886 
(epoch: 89, iters: 7504, time: 0.157, data: 0.000) loss: 0.598 
(epoch: 89, iters: 7584, time: 0.157, data: 0.000) loss: 1.215 
(epoch: 89, iters: 7664, time: 0.162, data: 0.000) loss: 0.487 
(epoch: 89, iters: 7744, time: 0.156, data: 0.014) loss: 0.895 
(epoch: 89, iters: 7824, time: 0.158, data: 0.006) loss: 0.410 
(epoch: 89, iters: 7904, time: 0.158, data: 0.021) loss: 0.280 
(epoch: 89, iters: 7984, time: 0.161, data: 0.000) loss: 0.478 
saving the latest model (epoch 89, total_steps 904912)
(epoch: 89, iters: 8064, time: 0.158, data: 0.005) loss: 0.305 
(epoch: 89, iters: 8144, time: 0.156, data: 0.000) loss: 0.503 
(epoch: 89, iters: 8224, time: 0.158, data: 0.033) loss: 0.435 
(epoch: 89, iters: 8304, time: 0.160, data: 0.000) loss: 0.740 
(epoch: 89, iters: 8384, time: 0.157, data: 0.023) loss: 1.016 
(epoch: 89, iters: 8464, time: 0.156, data: 0.000) loss: 0.768 
(epoch: 89, iters: 8544, time: 0.159, data: 0.009) loss: 0.525 
(epoch: 89, iters: 8624, time: 0.159, data: 0.000) loss: 0.566 
(epoch: 89, iters: 8704, time: 0.160, data: 0.024) loss: 0.229 
(epoch: 89, iters: 8784, time: 0.159, data: 0.000) loss: 0.294 
(epoch: 89, iters: 8864, time: 0.157, data: 0.032) loss: 0.619 
(epoch: 89, iters: 8944, time: 0.157, data: 0.000) loss: 0.731 
(epoch: 89, iters: 9024, time: 0.155, data: 0.000) loss: 0.974 
(epoch: 89, iters: 9104, time: 0.160, data: 0.005) loss: 0.310 
(epoch: 89, iters: 9184, time: 0.157, data: 0.024) loss: 0.420 
(epoch: 89, iters: 9264, time: 0.160, data: 0.000) loss: 0.923 
(epoch: 89, iters: 9344, time: 0.159, data: 0.024) loss: 0.696 
(epoch: 89, iters: 9424, time: 0.156, data: 0.000) loss: 0.680 
(epoch: 89, iters: 9504, time: 0.162, data: 0.014) loss: 0.353 
(epoch: 89, iters: 9584, time: 0.159, data: 0.000) loss: 1.128 
(epoch: 89, iters: 9664, time: 0.158, data: 0.029) loss: 0.411 
(epoch: 89, iters: 9744, time: 0.157, data: 0.005) loss: 0.789 
(epoch: 89, iters: 9824, time: 0.157, data: 0.000) loss: 0.472 
(epoch: 89, iters: 9904, time: 0.157, data: 0.015) loss: 0.278 
(epoch: 89, iters: 9984, time: 0.157, data: 0.042) loss: 0.368 
(epoch: 89, iters: 10064, time: 0.158, data: 0.000) loss: 0.406 
(epoch: 89, iters: 10144, time: 0.156, data: 0.020) loss: 0.422 
saving the model at the end of epoch 89, iters 907088
End of epoch 89 / 200 	 Time Taken: 1616 sec
learning rate = 0.0002000
saving the latest model (epoch 90, total_steps 907104)
(epoch: 90, iters: 32, time: 0.170, data: 0.000) loss: 0.611 
(epoch: 90, iters: 112, time: 0.159, data: 0.020) loss: 0.526 
(epoch: 90, iters: 192, time: 0.158, data: 0.000) loss: 0.242 
(epoch: 90, iters: 272, time: 0.160, data: 0.021) loss: 0.528 
(epoch: 90, iters: 352, time: 0.158, data: 0.000) loss: 0.489 
(epoch: 90, iters: 432, time: 0.157, data: 0.000) loss: 0.523 
(epoch: 90, iters: 512, time: 0.159, data: 0.006) loss: 0.616 
(epoch: 90, iters: 592, time: 0.158, data: 0.008) loss: 0.973 
(epoch: 90, iters: 672, time: 0.158, data: 0.000) loss: 0.270 
(epoch: 90, iters: 752, time: 0.160, data: 0.000) loss: 0.412 
(epoch: 90, iters: 832, time: 0.157, data: 0.000) loss: 0.637 
(epoch: 90, iters: 912, time: 0.158, data: 0.005) loss: 0.512 
(epoch: 90, iters: 992, time: 0.158, data: 0.000) loss: 0.409 
(epoch: 90, iters: 1072, time: 0.156, data: 0.000) loss: 0.363 
(epoch: 90, iters: 1152, time: 0.158, data: 0.021) loss: 0.521 
(epoch: 90, iters: 1232, time: 0.157, data: 0.000) loss: 0.827 
(epoch: 90, iters: 1312, time: 0.154, data: 0.009) loss: 0.651 
(epoch: 90, iters: 1392, time: 0.156, data: 0.000) loss: 0.410 
(epoch: 90, iters: 1472, time: 0.158, data: 0.005) loss: 0.280 
(epoch: 90, iters: 1552, time: 0.158, data: 0.000) loss: 0.815 
(epoch: 90, iters: 1632, time: 0.158, data: 0.014) loss: 0.459 
(epoch: 90, iters: 1712, time: 0.159, data: 0.000) loss: 0.495 
(epoch: 90, iters: 1792, time: 0.158, data: 0.000) loss: 0.771 
(epoch: 90, iters: 1872, time: 0.160, data: 0.008) loss: 1.075 
(epoch: 90, iters: 1952, time: 0.158, data: 0.020) loss: 0.661 
(epoch: 90, iters: 2032, time: 0.166, data: 0.014) loss: 0.286 
(epoch: 90, iters: 2112, time: 0.158, data: 0.008) loss: 0.962 
(epoch: 90, iters: 2192, time: 0.157, data: 0.000) loss: 0.916 
(epoch: 90, iters: 2272, time: 0.158, data: 0.016) loss: 0.286 
(epoch: 90, iters: 2352, time: 0.159, data: 0.014) loss: 1.102 
(epoch: 90, iters: 2432, time: 0.160, data: 0.000) loss: 0.390 
(epoch: 90, iters: 2512, time: 0.158, data: 0.000) loss: 0.276 
(epoch: 90, iters: 2592, time: 0.158, data: 0.000) loss: 0.640 
(epoch: 90, iters: 2672, time: 0.158, data: 0.000) loss: 0.548 
(epoch: 90, iters: 2752, time: 0.161, data: 0.000) loss: 0.666 
(epoch: 90, iters: 2832, time: 0.159, data: 0.005) loss: 0.291 
(epoch: 90, iters: 2912, time: 0.158, data: 0.000) loss: 0.654 
(epoch: 90, iters: 2992, time: 0.160, data: 0.000) loss: 0.458 
(epoch: 90, iters: 3072, time: 0.158, data: 0.024) loss: 0.830 
(epoch: 90, iters: 3152, time: 0.157, data: 0.000) loss: 0.346 
(epoch: 90, iters: 3232, time: 0.159, data: 0.000) loss: 0.714 
(epoch: 90, iters: 3312, time: 0.158, data: 0.019) loss: 0.228 
(epoch: 90, iters: 3392, time: 0.159, data: 0.025) loss: 0.321 
(epoch: 90, iters: 3472, time: 0.160, data: 0.000) loss: 0.664 
(epoch: 90, iters: 3552, time: 0.157, data: 0.000) loss: 0.147 
(epoch: 90, iters: 3632, time: 0.160, data: 0.021) loss: 0.729 
(epoch: 90, iters: 3712, time: 0.160, data: 0.008) loss: 0.565 
(epoch: 90, iters: 3792, time: 0.160, data: 0.008) loss: 1.093 
(epoch: 90, iters: 3872, time: 0.160, data: 0.015) loss: 0.311 
(epoch: 90, iters: 3952, time: 0.160, data: 0.000) loss: 1.121 
saving the latest model (epoch 90, total_steps 911104)
(epoch: 90, iters: 4032, time: 0.159, data: 0.013) loss: 0.388 
(epoch: 90, iters: 4112, time: 0.158, data: 0.006) loss: 0.280 
(epoch: 90, iters: 4192, time: 0.158, data: 0.000) loss: 0.691 
(epoch: 90, iters: 4272, time: 0.159, data: 0.005) loss: 0.406 
(epoch: 90, iters: 4352, time: 0.158, data: 0.000) loss: 1.000 
(epoch: 90, iters: 4432, time: 0.159, data: 0.005) loss: 0.431 
(epoch: 90, iters: 4512, time: 0.157, data: 0.000) loss: 0.298 
(epoch: 90, iters: 4592, time: 0.159, data: 0.005) loss: 0.576 
(epoch: 90, iters: 4672, time: 0.158, data: 0.005) loss: 0.388 
(epoch: 90, iters: 4752, time: 0.167, data: 0.000) loss: 0.238 
(epoch: 90, iters: 4832, time: 0.159, data: 0.021) loss: 0.778 
(epoch: 90, iters: 4912, time: 0.159, data: 0.000) loss: 0.204 
(epoch: 90, iters: 4992, time: 0.159, data: 0.031) loss: 0.450 
(epoch: 90, iters: 5072, time: 0.157, data: 0.000) loss: 0.632 
(epoch: 90, iters: 5152, time: 0.160, data: 0.000) loss: 0.732 
(epoch: 90, iters: 5232, time: 0.159, data: 0.015) loss: 0.640 
(epoch: 90, iters: 5312, time: 0.160, data: 0.000) loss: 0.249 
(epoch: 90, iters: 5392, time: 0.158, data: 0.014) loss: 0.468 
(epoch: 90, iters: 5472, time: 0.160, data: 0.020) loss: 0.224 
(epoch: 90, iters: 5552, time: 0.160, data: 0.000) loss: 0.679 
(epoch: 90, iters: 5632, time: 0.159, data: 0.010) loss: 0.759 
(epoch: 90, iters: 5712, time: 0.160, data: 0.006) loss: 0.424 
(epoch: 90, iters: 5792, time: 0.160, data: 0.000) loss: 0.883 
(epoch: 90, iters: 5872, time: 0.161, data: 0.015) loss: 0.078 
(epoch: 90, iters: 5952, time: 0.162, data: 0.000) loss: 0.338 
(epoch: 90, iters: 6032, time: 0.158, data: 0.000) loss: 0.888 
(epoch: 90, iters: 6112, time: 0.161, data: 0.008) loss: 0.355 
(epoch: 90, iters: 6192, time: 0.160, data: 0.000) loss: 0.521 
(epoch: 90, iters: 6272, time: 0.158, data: 0.000) loss: 0.746 
(epoch: 90, iters: 6352, time: 0.160, data: 0.008) loss: 0.537 
(epoch: 90, iters: 6432, time: 0.158, data: 0.000) loss: 0.362 
(epoch: 90, iters: 6512, time: 0.157, data: 0.033) loss: 0.723 
(epoch: 90, iters: 6592, time: 0.159, data: 0.000) loss: 0.437 
(epoch: 90, iters: 6672, time: 0.158, data: 0.032) loss: 0.285 
(epoch: 90, iters: 6752, time: 0.162, data: 0.000) loss: 0.692 
(epoch: 90, iters: 6832, time: 0.160, data: 0.006) loss: 0.465 
(epoch: 90, iters: 6912, time: 0.161, data: 0.000) loss: 0.709 
(epoch: 90, iters: 6992, time: 0.159, data: 0.000) loss: 0.895 
(epoch: 90, iters: 7072, time: 0.162, data: 0.006) loss: 0.564 
(epoch: 90, iters: 7152, time: 0.160, data: 0.014) loss: 0.465 
(epoch: 90, iters: 7232, time: 0.161, data: 0.006) loss: 0.590 
(epoch: 90, iters: 7312, time: 0.157, data: 0.005) loss: 0.595 
(epoch: 90, iters: 7392, time: 0.158, data: 0.000) loss: 0.239 
(epoch: 90, iters: 7472, time: 0.164, data: 0.028) loss: 0.209 
(epoch: 90, iters: 7552, time: 0.161, data: 0.000) loss: 0.494 
(epoch: 90, iters: 7632, time: 0.160, data: 0.005) loss: 0.355 
(epoch: 90, iters: 7712, time: 0.158, data: 0.000) loss: 0.621 
(epoch: 90, iters: 7792, time: 0.158, data: 0.009) loss: 0.441 
(epoch: 90, iters: 7872, time: 0.158, data: 0.008) loss: 0.504 
(epoch: 90, iters: 7952, time: 0.156, data: 0.000) loss: 0.263 
saving the latest model (epoch 90, total_steps 915104)
(epoch: 90, iters: 8032, time: 0.159, data: 0.017) loss: 0.330 
(epoch: 90, iters: 8112, time: 0.159, data: 0.000) loss: 0.456 
(epoch: 90, iters: 8192, time: 0.159, data: 0.000) loss: 0.428 
(epoch: 90, iters: 8272, time: 0.159, data: 0.000) loss: 0.633 
(epoch: 90, iters: 8352, time: 0.160, data: 0.005) loss: 0.765 
(epoch: 90, iters: 8432, time: 0.159, data: 0.005) loss: 0.807 
(epoch: 90, iters: 8512, time: 0.160, data: 0.005) loss: 0.900 
(epoch: 90, iters: 8592, time: 0.161, data: 0.014) loss: 0.464 
(epoch: 90, iters: 8672, time: 0.156, data: 0.018) loss: 0.544 
(epoch: 90, iters: 8752, time: 0.159, data: 0.000) loss: 0.429 
(epoch: 90, iters: 8832, time: 0.158, data: 0.000) loss: 1.036 
(epoch: 90, iters: 8912, time: 0.158, data: 0.005) loss: 0.918 
(epoch: 90, iters: 8992, time: 0.156, data: 0.009) loss: 0.371 
(epoch: 90, iters: 9072, time: 0.161, data: 0.000) loss: 0.536 
(epoch: 90, iters: 9152, time: 0.162, data: 0.008) loss: 0.368 
(epoch: 90, iters: 9232, time: 0.159, data: 0.008) loss: 0.479 
(epoch: 90, iters: 9312, time: 0.159, data: 0.000) loss: 0.471 
(epoch: 90, iters: 9392, time: 0.159, data: 0.000) loss: 0.675 
(epoch: 90, iters: 9472, time: 0.160, data: 0.008) loss: 0.511 
(epoch: 90, iters: 9552, time: 0.160, data: 0.000) loss: 0.303 
(epoch: 90, iters: 9632, time: 0.157, data: 0.015) loss: 1.045 
(epoch: 90, iters: 9712, time: 0.159, data: 0.000) loss: 1.117 
(epoch: 90, iters: 9792, time: 0.163, data: 0.006) loss: 0.711 
(epoch: 90, iters: 9872, time: 0.159, data: 0.021) loss: 0.491 
(epoch: 90, iters: 9952, time: 0.158, data: 0.000) loss: 0.750 
(epoch: 90, iters: 10032, time: 0.158, data: 0.000) loss: 0.278 
(epoch: 90, iters: 10112, time: 0.158, data: 0.022) loss: 0.375 
(epoch: 90, iters: 10192, time: 0.093, data: 0.013) loss: 0.442 
saving the model at the end of epoch 90, iters 917280
End of epoch 90 / 200 	 Time Taken: 1629 sec
learning rate = 0.0002000
saving the latest model (epoch 91, total_steps 917296)
(epoch: 91, iters: 80, time: 0.162, data: 0.184) loss: 0.393 
(epoch: 91, iters: 160, time: 0.158, data: 0.000) loss: 0.434 
(epoch: 91, iters: 240, time: 0.158, data: 0.041) loss: 0.422 
(epoch: 91, iters: 320, time: 0.161, data: 0.000) loss: 0.569 
(epoch: 91, iters: 400, time: 0.158, data: 0.016) loss: 1.154 
(epoch: 91, iters: 480, time: 0.160, data: 0.008) loss: 0.488 
(epoch: 91, iters: 560, time: 0.157, data: 0.000) loss: 0.643 
(epoch: 91, iters: 640, time: 0.159, data: 0.000) loss: 0.282 
(epoch: 91, iters: 720, time: 0.159, data: 0.000) loss: 0.298 
(epoch: 91, iters: 800, time: 0.160, data: 0.006) loss: 0.290 
(epoch: 91, iters: 880, time: 0.159, data: 0.000) loss: 0.072 
(epoch: 91, iters: 960, time: 0.159, data: 0.016) loss: 0.768 
(epoch: 91, iters: 1040, time: 0.156, data: 0.000) loss: 0.686 
(epoch: 91, iters: 1120, time: 0.157, data: 0.000) loss: 0.964 
(epoch: 91, iters: 1200, time: 0.154, data: 0.006) loss: 0.448 
(epoch: 91, iters: 1280, time: 0.156, data: 0.006) loss: 0.320 
(epoch: 91, iters: 1360, time: 0.157, data: 0.000) loss: 0.489 
(epoch: 91, iters: 1440, time: 0.155, data: 0.000) loss: 0.725 
(epoch: 91, iters: 1520, time: 0.155, data: 0.021) loss: 0.917 
(epoch: 91, iters: 1600, time: 0.153, data: 0.005) loss: 0.807 
(epoch: 91, iters: 1680, time: 0.159, data: 0.000) loss: 0.621 
(epoch: 91, iters: 1760, time: 0.157, data: 0.019) loss: 1.039 
(epoch: 91, iters: 1840, time: 0.160, data: 0.000) loss: 1.041 
(epoch: 91, iters: 1920, time: 0.155, data: 0.029) loss: 0.205 
(epoch: 91, iters: 2000, time: 0.157, data: 0.000) loss: 0.543 
(epoch: 91, iters: 2080, time: 0.157, data: 0.000) loss: 0.683 
(epoch: 91, iters: 2160, time: 0.160, data: 0.005) loss: 0.303 
(epoch: 91, iters: 2240, time: 0.160, data: 0.000) loss: 0.650 
(epoch: 91, iters: 2320, time: 0.158, data: 0.027) loss: 0.585 
(epoch: 91, iters: 2400, time: 0.158, data: 0.005) loss: 0.359 
(epoch: 91, iters: 2480, time: 0.157, data: 0.000) loss: 0.870 
(epoch: 91, iters: 2560, time: 0.158, data: 0.023) loss: 0.636 
(epoch: 91, iters: 2640, time: 0.158, data: 0.040) loss: 0.773 
(epoch: 91, iters: 2720, time: 0.159, data: 0.000) loss: 0.739 
(epoch: 91, iters: 2800, time: 0.157, data: 0.000) loss: 0.297 
(epoch: 91, iters: 2880, time: 0.159, data: 0.010) loss: 0.561 
(epoch: 91, iters: 2960, time: 0.159, data: 0.000) loss: 1.041 
(epoch: 91, iters: 3040, time: 0.159, data: 0.010) loss: 0.587 
(epoch: 91, iters: 3120, time: 0.164, data: 0.008) loss: 1.045 
(epoch: 91, iters: 3200, time: 0.159, data: 0.000) loss: 0.509 
(epoch: 91, iters: 3280, time: 0.158, data: 0.023) loss: 0.436 
(epoch: 91, iters: 3360, time: 0.159, data: 0.000) loss: 0.780 
(epoch: 91, iters: 3440, time: 0.160, data: 0.000) loss: 0.863 
(epoch: 91, iters: 3520, time: 0.167, data: 0.006) loss: 0.554 
(epoch: 91, iters: 3600, time: 0.158, data: 0.005) loss: 0.149 
(epoch: 91, iters: 3680, time: 0.157, data: 0.000) loss: 0.329 
(epoch: 91, iters: 3760, time: 0.154, data: 0.008) loss: 0.594 
(epoch: 91, iters: 3840, time: 0.160, data: 0.000) loss: 0.992 
(epoch: 91, iters: 3920, time: 0.156, data: 0.022) loss: 0.626 
(epoch: 91, iters: 4000, time: 0.157, data: 0.018) loss: 0.228 
saving the latest model (epoch 91, total_steps 921296)
(epoch: 91, iters: 4080, time: 0.160, data: 0.000) loss: 0.861 
(epoch: 91, iters: 4160, time: 0.160, data: 0.027) loss: 0.409 
(epoch: 91, iters: 4240, time: 0.158, data: 0.000) loss: 0.744 
(epoch: 91, iters: 4320, time: 0.158, data: 0.013) loss: 0.136 
(epoch: 91, iters: 4400, time: 0.159, data: 0.000) loss: 0.511 
(epoch: 91, iters: 4480, time: 0.160, data: 0.021) loss: 0.523 
(epoch: 91, iters: 4560, time: 0.159, data: 0.021) loss: 1.256 
(epoch: 91, iters: 4640, time: 0.160, data: 0.000) loss: 1.236 
(epoch: 91, iters: 4720, time: 0.158, data: 0.005) loss: 0.733 
(epoch: 91, iters: 4800, time: 0.157, data: 0.005) loss: 0.425 
(epoch: 91, iters: 4880, time: 0.159, data: 0.005) loss: 1.034 
(epoch: 91, iters: 4960, time: 0.159, data: 0.000) loss: 0.968 
(epoch: 91, iters: 5040, time: 0.159, data: 0.000) loss: 0.553 
(epoch: 91, iters: 5120, time: 0.161, data: 0.008) loss: 0.207 
(epoch: 91, iters: 5200, time: 0.158, data: 0.000) loss: 0.906 
(epoch: 91, iters: 5280, time: 0.156, data: 0.000) loss: 0.512 
(epoch: 91, iters: 5360, time: 0.157, data: 0.000) loss: 0.474 
(epoch: 91, iters: 5440, time: 0.155, data: 0.006) loss: 0.766 
(epoch: 91, iters: 5520, time: 0.158, data: 0.011) loss: 0.651 
(epoch: 91, iters: 5600, time: 0.156, data: 0.008) loss: 0.290 
(epoch: 91, iters: 5680, time: 0.156, data: 0.005) loss: 0.790 
(epoch: 91, iters: 5760, time: 0.159, data: 0.011) loss: 0.403 
(epoch: 91, iters: 5840, time: 0.156, data: 0.006) loss: 0.463 
(epoch: 91, iters: 5920, time: 0.158, data: 0.000) loss: 0.903 
(epoch: 91, iters: 6000, time: 0.159, data: 0.008) loss: 1.083 
(epoch: 91, iters: 6080, time: 0.158, data: 0.000) loss: 0.230 
(epoch: 91, iters: 6160, time: 0.159, data: 0.000) loss: 0.593 
(epoch: 91, iters: 6240, time: 0.159, data: 0.008) loss: 0.977 
(epoch: 91, iters: 6320, time: 0.156, data: 0.021) loss: 0.545 
(epoch: 91, iters: 6400, time: 0.158, data: 0.000) loss: 0.366 
(epoch: 91, iters: 6480, time: 0.159, data: 0.006) loss: 0.469 
(epoch: 91, iters: 6560, time: 0.159, data: 0.000) loss: 0.390 
(epoch: 91, iters: 6640, time: 0.163, data: 0.019) loss: 0.132 
(epoch: 91, iters: 6720, time: 0.158, data: 0.000) loss: 1.318 
(epoch: 91, iters: 6800, time: 0.157, data: 0.000) loss: 0.271 
(epoch: 91, iters: 6880, time: 0.158, data: 0.008) loss: 0.509 
(epoch: 91, iters: 6960, time: 0.160, data: 0.006) loss: 0.365 
(epoch: 91, iters: 7040, time: 0.157, data: 0.012) loss: 1.033 
(epoch: 91, iters: 7120, time: 0.158, data: 0.000) loss: 0.850 
(epoch: 91, iters: 7200, time: 0.160, data: 0.006) loss: 0.866 
(epoch: 91, iters: 7280, time: 0.159, data: 0.000) loss: 0.641 
(epoch: 91, iters: 7360, time: 0.160, data: 0.000) loss: 0.772 
(epoch: 91, iters: 7440, time: 0.158, data: 0.000) loss: 0.920 
(epoch: 91, iters: 7520, time: 0.159, data: 0.008) loss: 0.514 
(epoch: 91, iters: 7600, time: 0.160, data: 0.014) loss: 0.450 
(epoch: 91, iters: 7680, time: 0.158, data: 0.000) loss: 0.470 
(epoch: 91, iters: 7760, time: 0.157, data: 0.013) loss: 0.579 
(epoch: 91, iters: 7840, time: 0.158, data: 0.000) loss: 0.469 
(epoch: 91, iters: 7920, time: 0.158, data: 0.031) loss: 0.595 
(epoch: 91, iters: 8000, time: 0.158, data: 0.000) loss: 0.849 
saving the latest model (epoch 91, total_steps 925296)
(epoch: 91, iters: 8080, time: 0.161, data: 0.000) loss: 0.363 
(epoch: 91, iters: 8160, time: 0.156, data: 0.000) loss: 0.920 
(epoch: 91, iters: 8240, time: 0.156, data: 0.000) loss: 0.905 
(epoch: 91, iters: 8320, time: 0.157, data: 0.005) loss: 0.629 
(epoch: 91, iters: 8400, time: 0.159, data: 0.000) loss: 0.329 
(epoch: 91, iters: 8480, time: 0.158, data: 0.000) loss: 0.873 
(epoch: 91, iters: 8560, time: 0.159, data: 0.013) loss: 0.973 
(epoch: 91, iters: 8640, time: 0.159, data: 0.000) loss: 1.330 
(epoch: 91, iters: 8720, time: 0.158, data: 0.000) loss: 0.621 
(epoch: 91, iters: 8800, time: 0.159, data: 0.000) loss: 0.559 
(epoch: 91, iters: 8880, time: 0.161, data: 0.030) loss: 1.058 
(epoch: 91, iters: 8960, time: 0.157, data: 0.000) loss: 0.709 
(epoch: 91, iters: 9040, time: 0.158, data: 0.000) loss: 0.280 
(epoch: 91, iters: 9120, time: 0.160, data: 0.000) loss: 0.548 
(epoch: 91, iters: 9200, time: 0.157, data: 0.006) loss: 0.605 
(epoch: 91, iters: 9280, time: 0.160, data: 0.000) loss: 0.743 
(epoch: 91, iters: 9360, time: 0.158, data: 0.016) loss: 1.100 
(epoch: 91, iters: 9440, time: 0.160, data: 0.000) loss: 0.329 
(epoch: 91, iters: 9520, time: 0.159, data: 0.006) loss: 0.601 
(epoch: 91, iters: 9600, time: 0.160, data: 0.000) loss: 0.416 
(epoch: 91, iters: 9680, time: 0.160, data: 0.014) loss: 0.356 
(epoch: 91, iters: 9760, time: 0.164, data: 0.008) loss: 0.443 
(epoch: 91, iters: 9840, time: 0.156, data: 0.000) loss: 0.870 
(epoch: 91, iters: 9920, time: 0.158, data: 0.006) loss: 0.666 
(epoch: 91, iters: 10000, time: 0.158, data: 0.000) loss: 0.646 
(epoch: 91, iters: 10080, time: 0.156, data: 0.014) loss: 0.218 
(epoch: 91, iters: 10160, time: 0.158, data: 0.008) loss: 0.534 
saving the model at the end of epoch 91, iters 927472
End of epoch 91 / 200 	 Time Taken: 1620 sec
learning rate = 0.0002000
saving the latest model (epoch 92, total_steps 927488)
(epoch: 92, iters: 48, time: 0.166, data: 0.005) loss: 1.227 
(epoch: 92, iters: 128, time: 0.161, data: 0.010) loss: 0.380 
(epoch: 92, iters: 208, time: 0.159, data: 0.005) loss: 0.564 
(epoch: 92, iters: 288, time: 0.159, data: 0.000) loss: 0.764 
(epoch: 92, iters: 368, time: 0.160, data: 0.000) loss: 0.412 
(epoch: 92, iters: 448, time: 0.162, data: 0.016) loss: 0.670 
(epoch: 92, iters: 528, time: 0.159, data: 0.017) loss: 0.613 
(epoch: 92, iters: 608, time: 0.158, data: 0.000) loss: 0.602 
(epoch: 92, iters: 688, time: 0.157, data: 0.000) loss: 0.429 
(epoch: 92, iters: 768, time: 0.158, data: 0.000) loss: 0.502 
(epoch: 92, iters: 848, time: 0.158, data: 0.006) loss: 0.389 
(epoch: 92, iters: 928, time: 0.161, data: 0.000) loss: 0.672 
(epoch: 92, iters: 1008, time: 0.160, data: 0.000) loss: 0.398 
(epoch: 92, iters: 1088, time: 0.159, data: 0.000) loss: 1.037 
(epoch: 92, iters: 1168, time: 0.161, data: 0.000) loss: 0.184 
(epoch: 92, iters: 1248, time: 0.161, data: 0.021) loss: 0.635 
(epoch: 92, iters: 1328, time: 0.161, data: 0.006) loss: 0.200 
(epoch: 92, iters: 1408, time: 0.158, data: 0.000) loss: 0.791 
(epoch: 92, iters: 1488, time: 0.158, data: 0.009) loss: 0.678 
(epoch: 92, iters: 1568, time: 0.159, data: 0.000) loss: 0.832 
(epoch: 92, iters: 1648, time: 0.159, data: 0.000) loss: 0.446 
(epoch: 92, iters: 1728, time: 0.158, data: 0.000) loss: 0.470 
(epoch: 92, iters: 1808, time: 0.158, data: 0.009) loss: 0.477 
(epoch: 92, iters: 1888, time: 0.159, data: 0.000) loss: 0.663 
(epoch: 92, iters: 1968, time: 0.160, data: 0.008) loss: 0.752 
(epoch: 92, iters: 2048, time: 0.161, data: 0.000) loss: 0.643 
(epoch: 92, iters: 2128, time: 0.161, data: 0.000) loss: 0.952 
(epoch: 92, iters: 2208, time: 0.159, data: 0.005) loss: 0.850 
(epoch: 92, iters: 2288, time: 0.168, data: 0.008) loss: 0.499 
(epoch: 92, iters: 2368, time: 0.160, data: 0.000) loss: 0.419 
(epoch: 92, iters: 2448, time: 0.159, data: 0.013) loss: 0.330 
(epoch: 92, iters: 2528, time: 0.159, data: 0.000) loss: 0.361 
(epoch: 92, iters: 2608, time: 0.158, data: 0.006) loss: 0.072 
(epoch: 92, iters: 2688, time: 0.160, data: 0.000) loss: 0.583 
(epoch: 92, iters: 2768, time: 0.162, data: 0.020) loss: 0.269 
(epoch: 92, iters: 2848, time: 0.160, data: 0.006) loss: 0.554 
(epoch: 92, iters: 2928, time: 0.161, data: 0.000) loss: 0.337 
(epoch: 92, iters: 3008, time: 0.159, data: 0.008) loss: 0.742 
(epoch: 92, iters: 3088, time: 0.157, data: 0.016) loss: 0.933 
(epoch: 92, iters: 3168, time: 0.159, data: 0.000) loss: 0.529 
(epoch: 92, iters: 3248, time: 0.158, data: 0.000) loss: 0.304 
(epoch: 92, iters: 3328, time: 0.160, data: 0.000) loss: 0.616 
(epoch: 92, iters: 3408, time: 0.162, data: 0.006) loss: 0.336 
(epoch: 92, iters: 3488, time: 0.158, data: 0.024) loss: 0.837 
(epoch: 92, iters: 3568, time: 0.158, data: 0.000) loss: 0.593 
(epoch: 92, iters: 3648, time: 0.160, data: 0.016) loss: 0.174 
(epoch: 92, iters: 3728, time: 0.159, data: 0.000) loss: 0.559 
(epoch: 92, iters: 3808, time: 0.159, data: 0.015) loss: 0.544 
(epoch: 92, iters: 3888, time: 0.159, data: 0.000) loss: 0.544 
(epoch: 92, iters: 3968, time: 0.159, data: 0.015) loss: 0.601 
saving the latest model (epoch 92, total_steps 931488)
(epoch: 92, iters: 4048, time: 0.157, data: 0.010) loss: 0.267 
(epoch: 92, iters: 4128, time: 0.158, data: 0.000) loss: 0.353 
(epoch: 92, iters: 4208, time: 0.160, data: 0.000) loss: 1.346 
(epoch: 92, iters: 4288, time: 0.158, data: 0.010) loss: 0.190 
(epoch: 92, iters: 4368, time: 0.158, data: 0.000) loss: 1.316 
(epoch: 92, iters: 4448, time: 0.160, data: 0.000) loss: 0.634 
(epoch: 92, iters: 4528, time: 0.157, data: 0.041) loss: 0.352 
(epoch: 92, iters: 4608, time: 0.161, data: 0.000) loss: 0.739 
(epoch: 92, iters: 4688, time: 0.158, data: 0.000) loss: 0.350 
(epoch: 92, iters: 4768, time: 0.160, data: 0.021) loss: 0.459 
(epoch: 92, iters: 4848, time: 0.159, data: 0.005) loss: 0.260 
(epoch: 92, iters: 4928, time: 0.159, data: 0.000) loss: 1.292 
(epoch: 92, iters: 5008, time: 0.165, data: 0.000) loss: 0.624 
(epoch: 92, iters: 5088, time: 0.158, data: 0.024) loss: 0.210 
(epoch: 92, iters: 5168, time: 0.157, data: 0.000) loss: 0.764 
(epoch: 92, iters: 5248, time: 0.158, data: 0.022) loss: 0.629 
(epoch: 92, iters: 5328, time: 0.158, data: 0.000) loss: 0.597 
(epoch: 92, iters: 5408, time: 0.159, data: 0.000) loss: 0.729 
(epoch: 92, iters: 5488, time: 0.157, data: 0.009) loss: 0.504 
(epoch: 92, iters: 5568, time: 0.158, data: 0.000) loss: 0.681 
(epoch: 92, iters: 5648, time: 0.163, data: 0.015) loss: 0.471 
(epoch: 92, iters: 5728, time: 0.158, data: 0.005) loss: 0.587 
(epoch: 92, iters: 5808, time: 0.157, data: 0.000) loss: 0.368 
(epoch: 92, iters: 5888, time: 0.157, data: 0.009) loss: 0.601 
(epoch: 92, iters: 5968, time: 0.160, data: 0.000) loss: 0.714 
(epoch: 92, iters: 6048, time: 0.160, data: 0.005) loss: 0.145 
(epoch: 92, iters: 6128, time: 0.158, data: 0.000) loss: 1.046 
(epoch: 92, iters: 6208, time: 0.158, data: 0.006) loss: 0.394 
(epoch: 92, iters: 6288, time: 0.161, data: 0.000) loss: 0.527 
(epoch: 92, iters: 6368, time: 0.160, data: 0.000) loss: 0.372 
(epoch: 92, iters: 6448, time: 0.159, data: 0.000) loss: 0.635 
(epoch: 92, iters: 6528, time: 0.161, data: 0.006) loss: 0.506 
(epoch: 92, iters: 6608, time: 0.162, data: 0.000) loss: 0.640 
(epoch: 92, iters: 6688, time: 0.160, data: 0.000) loss: 0.278 
(epoch: 92, iters: 6768, time: 0.158, data: 0.000) loss: 0.474 
(epoch: 92, iters: 6848, time: 0.159, data: 0.008) loss: 0.881 
(epoch: 92, iters: 6928, time: 0.160, data: 0.000) loss: 0.621 
(epoch: 92, iters: 7008, time: 0.162, data: 0.032) loss: 0.749 
(epoch: 92, iters: 7088, time: 0.158, data: 0.000) loss: 0.745 
(epoch: 92, iters: 7168, time: 0.163, data: 0.000) loss: 0.178 
(epoch: 92, iters: 7248, time: 0.159, data: 0.020) loss: 0.459 
(epoch: 92, iters: 7328, time: 0.158, data: 0.008) loss: 0.727 
(epoch: 92, iters: 7408, time: 0.160, data: 0.000) loss: 0.366 
(epoch: 92, iters: 7488, time: 0.160, data: 0.019) loss: 0.492 
(epoch: 92, iters: 7568, time: 0.158, data: 0.000) loss: 0.492 
(epoch: 92, iters: 7648, time: 0.158, data: 0.023) loss: 0.363 
(epoch: 92, iters: 7728, time: 0.163, data: 0.000) loss: 0.213 
(epoch: 92, iters: 7808, time: 0.160, data: 0.000) loss: 0.928 
(epoch: 92, iters: 7888, time: 0.159, data: 0.023) loss: 0.289 
(epoch: 92, iters: 7968, time: 0.159, data: 0.000) loss: 0.246 
saving the latest model (epoch 92, total_steps 935488)
(epoch: 92, iters: 8048, time: 0.157, data: 0.000) loss: 0.705 
(epoch: 92, iters: 8128, time: 0.158, data: 0.005) loss: 1.026 
(epoch: 92, iters: 8208, time: 0.159, data: 0.021) loss: 0.496 
(epoch: 92, iters: 8288, time: 0.159, data: 0.000) loss: 1.066 
(epoch: 92, iters: 8368, time: 0.159, data: 0.000) loss: 0.230 
(epoch: 92, iters: 8448, time: 0.161, data: 0.014) loss: 0.355 
(epoch: 92, iters: 8528, time: 0.159, data: 0.032) loss: 1.088 
(epoch: 92, iters: 8608, time: 0.159, data: 0.000) loss: 0.394 
(epoch: 92, iters: 8688, time: 0.160, data: 0.008) loss: 0.524 
(epoch: 92, iters: 8768, time: 0.158, data: 0.000) loss: 0.257 
(epoch: 92, iters: 8848, time: 0.160, data: 0.023) loss: 0.839 
(epoch: 92, iters: 8928, time: 0.161, data: 0.000) loss: 0.627 
(epoch: 92, iters: 9008, time: 0.158, data: 0.000) loss: 0.478 
(epoch: 92, iters: 9088, time: 0.159, data: 0.000) loss: 0.677 
(epoch: 92, iters: 9168, time: 0.157, data: 0.000) loss: 0.671 
(epoch: 92, iters: 9248, time: 0.157, data: 0.005) loss: 0.835 
(epoch: 92, iters: 9328, time: 0.157, data: 0.000) loss: 0.798 
(epoch: 92, iters: 9408, time: 0.157, data: 0.000) loss: 0.236 
(epoch: 92, iters: 9488, time: 0.157, data: 0.010) loss: 0.428 
(epoch: 92, iters: 9568, time: 0.158, data: 0.000) loss: 0.477 
(epoch: 92, iters: 9648, time: 0.160, data: 0.026) loss: 0.347 
(epoch: 92, iters: 9728, time: 0.160, data: 0.000) loss: 0.240 
(epoch: 92, iters: 9808, time: 0.158, data: 0.000) loss: 0.907 
(epoch: 92, iters: 9888, time: 0.156, data: 0.021) loss: 1.064 
(epoch: 92, iters: 9968, time: 0.159, data: 0.000) loss: 0.383 
(epoch: 92, iters: 10048, time: 0.159, data: 0.000) loss: 0.601 
(epoch: 92, iters: 10128, time: 0.161, data: 0.021) loss: 0.985 
saving the model at the end of epoch 92, iters 937664
End of epoch 92 / 200 	 Time Taken: 1630 sec
learning rate = 0.0002000
(epoch: 93, iters: 16, time: 0.181, data: 0.005) loss: 0.722 
saving the latest model (epoch 93, total_steps 937680)
(epoch: 93, iters: 96, time: 0.159, data: 0.021) loss: 0.519 
(epoch: 93, iters: 176, time: 0.160, data: 0.007) loss: 0.834 
(epoch: 93, iters: 256, time: 0.162, data: 0.006) loss: 0.525 
(epoch: 93, iters: 336, time: 0.157, data: 0.037) loss: 0.440 
(epoch: 93, iters: 416, time: 0.158, data: 0.000) loss: 0.691 
(epoch: 93, iters: 496, time: 0.157, data: 0.000) loss: 0.402 
(epoch: 93, iters: 576, time: 0.157, data: 0.000) loss: 0.606 
(epoch: 93, iters: 656, time: 0.159, data: 0.000) loss: 0.096 
(epoch: 93, iters: 736, time: 0.158, data: 0.000) loss: 0.625 
(epoch: 93, iters: 816, time: 0.158, data: 0.028) loss: 0.311 
(epoch: 93, iters: 896, time: 0.158, data: 0.000) loss: 0.350 
(epoch: 93, iters: 976, time: 0.158, data: 0.000) loss: 0.700 
(epoch: 93, iters: 1056, time: 0.157, data: 0.006) loss: 0.264 
(epoch: 93, iters: 1136, time: 0.156, data: 0.000) loss: 1.073 
(epoch: 93, iters: 1216, time: 0.157, data: 0.017) loss: 0.861 
(epoch: 93, iters: 1296, time: 0.156, data: 0.000) loss: 0.287 
(epoch: 93, iters: 1376, time: 0.155, data: 0.000) loss: 0.557 
(epoch: 93, iters: 1456, time: 0.158, data: 0.008) loss: 0.742 
(epoch: 93, iters: 1536, time: 0.154, data: 0.000) loss: 0.542 
(epoch: 93, iters: 1616, time: 0.157, data: 0.005) loss: 1.049 
(epoch: 93, iters: 1696, time: 0.158, data: 0.000) loss: 0.421 
(epoch: 93, iters: 1776, time: 0.157, data: 0.000) loss: 0.897 
(epoch: 93, iters: 1856, time: 0.156, data: 0.032) loss: 0.503 
(epoch: 93, iters: 1936, time: 0.158, data: 0.000) loss: 0.841 
(epoch: 93, iters: 2016, time: 0.157, data: 0.011) loss: 0.444 
(epoch: 93, iters: 2096, time: 0.160, data: 0.008) loss: 0.558 
(epoch: 93, iters: 2176, time: 0.159, data: 0.000) loss: 0.579 
(epoch: 93, iters: 2256, time: 0.159, data: 0.005) loss: 0.390 
(epoch: 93, iters: 2336, time: 0.154, data: 0.000) loss: 0.534 
(epoch: 93, iters: 2416, time: 0.155, data: 0.005) loss: 0.699 
(epoch: 93, iters: 2496, time: 0.157, data: 0.033) loss: 0.213 
(epoch: 93, iters: 2576, time: 0.157, data: 0.000) loss: 0.884 
(epoch: 93, iters: 2656, time: 0.156, data: 0.000) loss: 0.342 
(epoch: 93, iters: 2736, time: 0.159, data: 0.000) loss: 0.531 
(epoch: 93, iters: 2816, time: 0.157, data: 0.014) loss: 0.779 
(epoch: 93, iters: 2896, time: 0.159, data: 0.000) loss: 1.747 
(epoch: 93, iters: 2976, time: 0.158, data: 0.000) loss: 0.563 
(epoch: 93, iters: 3056, time: 0.156, data: 0.000) loss: 0.412 
(epoch: 93, iters: 3136, time: 0.157, data: 0.000) loss: 0.758 
(epoch: 93, iters: 3216, time: 0.157, data: 0.000) loss: 0.360 
(epoch: 93, iters: 3296, time: 0.155, data: 0.006) loss: 0.871 
(epoch: 93, iters: 3376, time: 0.156, data: 0.000) loss: 0.147 
(epoch: 93, iters: 3456, time: 0.157, data: 0.000) loss: 0.560 
(epoch: 93, iters: 3536, time: 0.154, data: 0.016) loss: 0.749 
(epoch: 93, iters: 3616, time: 0.156, data: 0.005) loss: 0.625 
(epoch: 93, iters: 3696, time: 0.156, data: 0.000) loss: 0.828 
(epoch: 93, iters: 3776, time: 0.157, data: 0.011) loss: 0.610 
(epoch: 93, iters: 3856, time: 0.158, data: 0.000) loss: 0.767 
(epoch: 93, iters: 3936, time: 0.155, data: 0.024) loss: 0.897 
(epoch: 93, iters: 4016, time: 0.153, data: 0.000) loss: 0.467 
saving the latest model (epoch 93, total_steps 941680)
(epoch: 93, iters: 4096, time: 0.157, data: 0.010) loss: 0.524 
(epoch: 93, iters: 4176, time: 0.158, data: 0.000) loss: 0.597 
(epoch: 93, iters: 4256, time: 0.156, data: 0.000) loss: 0.622 
(epoch: 93, iters: 4336, time: 0.154, data: 0.016) loss: 0.151 
(epoch: 93, iters: 4416, time: 0.156, data: 0.000) loss: 0.242 
(epoch: 93, iters: 4496, time: 0.157, data: 0.006) loss: 0.323 
(epoch: 93, iters: 4576, time: 0.157, data: 0.000) loss: 0.485 
(epoch: 93, iters: 4656, time: 0.157, data: 0.010) loss: 0.303 
(epoch: 93, iters: 4736, time: 0.158, data: 0.005) loss: 0.855 
(epoch: 93, iters: 4816, time: 0.158, data: 0.000) loss: 0.451 
(epoch: 93, iters: 4896, time: 0.156, data: 0.000) loss: 1.998 
(epoch: 93, iters: 4976, time: 0.163, data: 0.016) loss: 0.152 
(epoch: 93, iters: 5056, time: 0.158, data: 0.000) loss: 0.385 
(epoch: 93, iters: 5136, time: 0.159, data: 0.021) loss: 1.211 
(epoch: 93, iters: 5216, time: 0.156, data: 0.005) loss: 0.421 
(epoch: 93, iters: 5296, time: 0.161, data: 0.000) loss: 0.539 
(epoch: 93, iters: 5376, time: 0.165, data: 0.000) loss: 0.766 
(epoch: 93, iters: 5456, time: 0.157, data: 0.018) loss: 0.756 
(epoch: 93, iters: 5536, time: 0.157, data: 0.000) loss: 0.637 
(epoch: 93, iters: 5616, time: 0.158, data: 0.000) loss: 0.992 
(epoch: 93, iters: 5696, time: 0.158, data: 0.006) loss: 0.430 
(epoch: 93, iters: 5776, time: 0.157, data: 0.012) loss: 0.670 
(epoch: 93, iters: 5856, time: 0.159, data: 0.000) loss: 0.679 
(epoch: 93, iters: 5936, time: 0.156, data: 0.005) loss: 0.766 
(epoch: 93, iters: 6016, time: 0.155, data: 0.006) loss: 0.639 
(epoch: 93, iters: 6096, time: 0.156, data: 0.005) loss: 0.505 
(epoch: 93, iters: 6176, time: 0.153, data: 0.025) loss: 0.299 
(epoch: 93, iters: 6256, time: 0.154, data: 0.000) loss: 0.579 
(epoch: 93, iters: 6336, time: 0.154, data: 0.010) loss: 0.207 
(epoch: 93, iters: 6416, time: 0.154, data: 0.018) loss: 0.842 
(epoch: 93, iters: 6496, time: 0.156, data: 0.009) loss: 0.711 
(epoch: 93, iters: 6576, time: 0.155, data: 0.008) loss: 0.723 
(epoch: 93, iters: 6656, time: 0.156, data: 0.000) loss: 0.603 
(epoch: 93, iters: 6736, time: 0.157, data: 0.000) loss: 0.418 
(epoch: 93, iters: 6816, time: 0.156, data: 0.000) loss: 0.218 
(epoch: 93, iters: 6896, time: 0.154, data: 0.005) loss: 0.908 
(epoch: 93, iters: 6976, time: 0.155, data: 0.000) loss: 0.507 
(epoch: 93, iters: 7056, time: 0.161, data: 0.000) loss: 0.513 
(epoch: 93, iters: 7136, time: 0.154, data: 0.000) loss: 0.776 
(epoch: 93, iters: 7216, time: 0.156, data: 0.000) loss: 0.263 
(epoch: 93, iters: 7296, time: 0.155, data: 0.014) loss: 0.542 
(epoch: 93, iters: 7376, time: 0.154, data: 0.000) loss: 0.576 
(epoch: 93, iters: 7456, time: 0.153, data: 0.000) loss: 0.274 
(epoch: 93, iters: 7536, time: 0.156, data: 0.000) loss: 0.825 
(epoch: 93, iters: 7616, time: 0.154, data: 0.009) loss: 0.650 
(epoch: 93, iters: 7696, time: 0.155, data: 0.005) loss: 0.833 
(epoch: 93, iters: 7776, time: 0.156, data: 0.000) loss: 0.522 
(epoch: 93, iters: 7856, time: 0.155, data: 0.023) loss: 0.358 
(epoch: 93, iters: 7936, time: 0.154, data: 0.000) loss: 0.986 
(epoch: 93, iters: 8016, time: 0.153, data: 0.000) loss: 0.499 
saving the latest model (epoch 93, total_steps 945680)
(epoch: 93, iters: 8096, time: 0.155, data: 0.005) loss: 0.476 
(epoch: 93, iters: 8176, time: 0.154, data: 0.006) loss: 0.212 
(epoch: 93, iters: 8256, time: 0.156, data: 0.005) loss: 0.245 
(epoch: 93, iters: 8336, time: 0.155, data: 0.000) loss: 1.018 
(epoch: 93, iters: 8416, time: 0.154, data: 0.006) loss: 0.428 
(epoch: 93, iters: 8496, time: 0.156, data: 0.000) loss: 0.447 
(epoch: 93, iters: 8576, time: 0.157, data: 0.021) loss: 0.744 
(epoch: 93, iters: 8656, time: 0.154, data: 0.006) loss: 0.555 
(epoch: 93, iters: 8736, time: 0.152, data: 0.000) loss: 0.864 
(epoch: 93, iters: 8816, time: 0.158, data: 0.018) loss: 0.484 
(epoch: 93, iters: 8896, time: 0.158, data: 0.020) loss: 0.706 
(epoch: 93, iters: 8976, time: 0.159, data: 0.000) loss: 0.419 
(epoch: 93, iters: 9056, time: 0.157, data: 0.013) loss: 0.484 
(epoch: 93, iters: 9136, time: 0.158, data: 0.000) loss: 0.279 
(epoch: 93, iters: 9216, time: 0.157, data: 0.000) loss: 0.355 
(epoch: 93, iters: 9296, time: 0.153, data: 0.013) loss: 0.540 
(epoch: 93, iters: 9376, time: 0.157, data: 0.000) loss: 0.311 
(epoch: 93, iters: 9456, time: 0.155, data: 0.031) loss: 0.616 
(epoch: 93, iters: 9536, time: 0.154, data: 0.000) loss: 0.798 
(epoch: 93, iters: 9616, time: 0.156, data: 0.005) loss: 0.589 
(epoch: 93, iters: 9696, time: 0.155, data: 0.008) loss: 0.651 
(epoch: 93, iters: 9776, time: 0.156, data: 0.008) loss: 0.144 
(epoch: 93, iters: 9856, time: 0.156, data: 0.006) loss: 0.230 
(epoch: 93, iters: 9936, time: 0.157, data: 0.025) loss: 0.643 
(epoch: 93, iters: 10016, time: 0.154, data: 0.000) loss: 0.430 
(epoch: 93, iters: 10096, time: 0.156, data: 0.000) loss: 0.517 
(epoch: 93, iters: 10176, time: 0.155, data: 0.005) loss: 0.487 
saving the model at the end of epoch 93, iters 947856
End of epoch 93 / 200 	 Time Taken: 1602 sec
learning rate = 0.0002000
saving the latest model (epoch 94, total_steps 947872)
(epoch: 94, iters: 64, time: 0.161, data: 0.000) loss: 0.553 
(epoch: 94, iters: 144, time: 0.157, data: 0.011) loss: 0.602 
(epoch: 94, iters: 224, time: 0.157, data: 0.000) loss: 0.145 
(epoch: 94, iters: 304, time: 0.158, data: 0.000) loss: 0.612 
(epoch: 94, iters: 384, time: 0.157, data: 0.039) loss: 0.266 
(epoch: 94, iters: 464, time: 0.157, data: 0.000) loss: 0.546 
(epoch: 94, iters: 544, time: 0.160, data: 0.015) loss: 0.397 
(epoch: 94, iters: 624, time: 0.160, data: 0.000) loss: 0.915 
(epoch: 94, iters: 704, time: 0.158, data: 0.000) loss: 0.688 
(epoch: 94, iters: 784, time: 0.159, data: 0.000) loss: 0.275 
(epoch: 94, iters: 864, time: 0.159, data: 0.000) loss: 0.623 
(epoch: 94, iters: 944, time: 0.160, data: 0.005) loss: 0.526 
(epoch: 94, iters: 1024, time: 0.159, data: 0.016) loss: 0.421 
(epoch: 94, iters: 1104, time: 0.156, data: 0.000) loss: 0.426 
(epoch: 94, iters: 1184, time: 0.159, data: 0.008) loss: 0.609 
(epoch: 94, iters: 1264, time: 0.159, data: 0.006) loss: 0.604 
(epoch: 94, iters: 1344, time: 0.159, data: 0.015) loss: 0.421 
(epoch: 94, iters: 1424, time: 0.157, data: 0.000) loss: 0.328 
(epoch: 94, iters: 1504, time: 0.158, data: 0.005) loss: 0.352 
(epoch: 94, iters: 1584, time: 0.157, data: 0.019) loss: 0.491 
(epoch: 94, iters: 1664, time: 0.157, data: 0.000) loss: 0.954 
(epoch: 94, iters: 1744, time: 0.160, data: 0.000) loss: 0.391 
(epoch: 94, iters: 1824, time: 0.158, data: 0.012) loss: 0.780 
(epoch: 94, iters: 1904, time: 0.164, data: 0.009) loss: 0.523 
(epoch: 94, iters: 1984, time: 0.159, data: 0.000) loss: 0.586 
(epoch: 94, iters: 2064, time: 0.157, data: 0.008) loss: 0.533 
(epoch: 94, iters: 2144, time: 0.159, data: 0.011) loss: 0.908 
(epoch: 94, iters: 2224, time: 0.157, data: 0.000) loss: 0.728 
(epoch: 94, iters: 2304, time: 0.161, data: 0.020) loss: 0.968 
(epoch: 94, iters: 2384, time: 0.159, data: 0.000) loss: 0.515 
(epoch: 94, iters: 2464, time: 0.159, data: 0.012) loss: 0.479 
(epoch: 94, iters: 2544, time: 0.158, data: 0.005) loss: 0.512 
(epoch: 94, iters: 2624, time: 0.158, data: 0.000) loss: 0.219 
(epoch: 94, iters: 2704, time: 0.161, data: 0.025) loss: 0.671 
(epoch: 94, iters: 2784, time: 0.159, data: 0.000) loss: 0.611 
(epoch: 94, iters: 2864, time: 0.157, data: 0.018) loss: 0.386 
(epoch: 94, iters: 2944, time: 0.155, data: 0.000) loss: 0.755 
(epoch: 94, iters: 3024, time: 0.160, data: 0.017) loss: 0.699 
(epoch: 94, iters: 3104, time: 0.161, data: 0.000) loss: 0.556 
(epoch: 94, iters: 3184, time: 0.160, data: 0.009) loss: 0.663 
(epoch: 94, iters: 3264, time: 0.161, data: 0.000) loss: 0.364 
(epoch: 94, iters: 3344, time: 0.160, data: 0.005) loss: 0.542 
(epoch: 94, iters: 3424, time: 0.158, data: 0.000) loss: 0.470 
(epoch: 94, iters: 3504, time: 0.160, data: 0.026) loss: 0.586 
(epoch: 94, iters: 3584, time: 0.159, data: 0.000) loss: 0.552 
(epoch: 94, iters: 3664, time: 0.157, data: 0.000) loss: 0.371 
(epoch: 94, iters: 3744, time: 0.160, data: 0.000) loss: 0.313 
(epoch: 94, iters: 3824, time: 0.161, data: 0.000) loss: 0.778 
(epoch: 94, iters: 3904, time: 0.159, data: 0.000) loss: 0.322 
(epoch: 94, iters: 3984, time: 0.158, data: 0.016) loss: 0.578 
saving the latest model (epoch 94, total_steps 951872)
(epoch: 94, iters: 4064, time: 0.161, data: 0.000) loss: 0.644 
(epoch: 94, iters: 4144, time: 0.161, data: 0.005) loss: 0.515 
(epoch: 94, iters: 4224, time: 0.163, data: 0.000) loss: 0.437 
(epoch: 94, iters: 4304, time: 0.160, data: 0.000) loss: 0.247 
(epoch: 94, iters: 4384, time: 0.156, data: 0.006) loss: 0.352 
(epoch: 94, iters: 4464, time: 0.157, data: 0.013) loss: 0.487 
(epoch: 94, iters: 4544, time: 0.157, data: 0.008) loss: 1.500 
(epoch: 94, iters: 4624, time: 0.165, data: 0.000) loss: 0.485 
(epoch: 94, iters: 4704, time: 0.158, data: 0.006) loss: 0.455 
(epoch: 94, iters: 4784, time: 0.162, data: 0.000) loss: 0.411 
(epoch: 94, iters: 4864, time: 0.159, data: 0.006) loss: 0.682 
(epoch: 94, iters: 4944, time: 0.161, data: 0.009) loss: 1.571 
(epoch: 94, iters: 5024, time: 0.159, data: 0.000) loss: 0.488 
(epoch: 94, iters: 5104, time: 0.157, data: 0.005) loss: 1.200 
(epoch: 94, iters: 5184, time: 0.156, data: 0.000) loss: 0.765 
(epoch: 94, iters: 5264, time: 0.156, data: 0.000) loss: 0.385 
(epoch: 94, iters: 5344, time: 0.160, data: 0.017) loss: 0.475 
(epoch: 94, iters: 5424, time: 0.159, data: 0.000) loss: 0.591 
(epoch: 94, iters: 5504, time: 0.160, data: 0.014) loss: 1.171 
(epoch: 94, iters: 5584, time: 0.156, data: 0.000) loss: 0.218 
(epoch: 94, iters: 5664, time: 0.158, data: 0.000) loss: 0.459 
(epoch: 94, iters: 5744, time: 0.156, data: 0.023) loss: 0.153 
(epoch: 94, iters: 5824, time: 0.158, data: 0.000) loss: 0.316 
(epoch: 94, iters: 5904, time: 0.159, data: 0.000) loss: 0.473 
(epoch: 94, iters: 5984, time: 0.159, data: 0.005) loss: 0.908 
(epoch: 94, iters: 6064, time: 0.161, data: 0.000) loss: 0.396 
(epoch: 94, iters: 6144, time: 0.159, data: 0.005) loss: 0.736 
(epoch: 94, iters: 6224, time: 0.159, data: 0.000) loss: 0.601 
(epoch: 94, iters: 6304, time: 0.156, data: 0.015) loss: 0.641 
(epoch: 94, iters: 6384, time: 0.158, data: 0.025) loss: 0.637 
(epoch: 94, iters: 6464, time: 0.160, data: 0.000) loss: 0.419 
(epoch: 94, iters: 6544, time: 0.159, data: 0.025) loss: 0.640 
(epoch: 94, iters: 6624, time: 0.157, data: 0.000) loss: 0.219 
(epoch: 94, iters: 6704, time: 0.157, data: 0.005) loss: 0.807 
(epoch: 94, iters: 6784, time: 0.157, data: 0.008) loss: 0.309 
(epoch: 94, iters: 6864, time: 0.160, data: 0.028) loss: 0.501 
(epoch: 94, iters: 6944, time: 0.158, data: 0.005) loss: 0.872 
(epoch: 94, iters: 7024, time: 0.160, data: 0.008) loss: 0.148 
(epoch: 94, iters: 7104, time: 0.159, data: 0.000) loss: 0.543 
(epoch: 94, iters: 7184, time: 0.160, data: 0.006) loss: 0.673 
(epoch: 94, iters: 7264, time: 0.160, data: 0.000) loss: 0.572 
(epoch: 94, iters: 7344, time: 0.165, data: 0.000) loss: 0.342 
(epoch: 94, iters: 7424, time: 0.161, data: 0.005) loss: 0.593 
(epoch: 94, iters: 7504, time: 0.161, data: 0.015) loss: 0.535 
(epoch: 94, iters: 7584, time: 0.160, data: 0.000) loss: 0.392 
(epoch: 94, iters: 7664, time: 0.160, data: 0.000) loss: 0.339 
(epoch: 94, iters: 7744, time: 0.160, data: 0.000) loss: 1.197 
(epoch: 94, iters: 7824, time: 0.160, data: 0.000) loss: 0.115 
(epoch: 94, iters: 7904, time: 0.159, data: 0.000) loss: 0.451 
(epoch: 94, iters: 7984, time: 0.161, data: 0.000) loss: 1.033 
saving the latest model (epoch 94, total_steps 955872)
(epoch: 94, iters: 8064, time: 0.160, data: 0.000) loss: 1.308 
(epoch: 94, iters: 8144, time: 0.158, data: 0.000) loss: 0.665 
(epoch: 94, iters: 8224, time: 0.160, data: 0.006) loss: 0.444 
(epoch: 94, iters: 8304, time: 0.162, data: 0.000) loss: 1.001 
(epoch: 94, iters: 8384, time: 0.159, data: 0.034) loss: 0.647 
(epoch: 94, iters: 8464, time: 0.159, data: 0.000) loss: 0.256 
(epoch: 94, iters: 8544, time: 0.158, data: 0.041) loss: 0.487 
(epoch: 94, iters: 8624, time: 0.159, data: 0.000) loss: 1.278 
(epoch: 94, iters: 8704, time: 0.161, data: 0.000) loss: 1.423 
(epoch: 94, iters: 8784, time: 0.159, data: 0.034) loss: 0.494 
(epoch: 94, iters: 8864, time: 0.160, data: 0.000) loss: 1.155 
(epoch: 94, iters: 8944, time: 0.159, data: 0.010) loss: 0.547 
(epoch: 94, iters: 9024, time: 0.159, data: 0.000) loss: 0.801 
(epoch: 94, iters: 9104, time: 0.161, data: 0.005) loss: 0.192 
(epoch: 94, iters: 9184, time: 0.159, data: 0.000) loss: 0.706 
(epoch: 94, iters: 9264, time: 0.161, data: 0.000) loss: 0.533 
(epoch: 94, iters: 9344, time: 0.159, data: 0.008) loss: 0.290 
(epoch: 94, iters: 9424, time: 0.159, data: 0.000) loss: 0.729 
(epoch: 94, iters: 9504, time: 0.159, data: 0.005) loss: 0.418 
(epoch: 94, iters: 9584, time: 0.159, data: 0.000) loss: 0.696 
(epoch: 94, iters: 9664, time: 0.167, data: 0.000) loss: 0.554 
(epoch: 94, iters: 9744, time: 0.162, data: 0.000) loss: 1.117 
(epoch: 94, iters: 9824, time: 0.161, data: 0.000) loss: 0.486 
(epoch: 94, iters: 9904, time: 0.159, data: 0.005) loss: 1.416 
(epoch: 94, iters: 9984, time: 0.158, data: 0.005) loss: 0.971 
(epoch: 94, iters: 10064, time: 0.161, data: 0.000) loss: 0.439 
(epoch: 94, iters: 10144, time: 0.159, data: 0.000) loss: 1.386 
saving the model at the end of epoch 94, iters 958048
End of epoch 94 / 200 	 Time Taken: 1627 sec
learning rate = 0.0002000
saving the latest model (epoch 95, total_steps 958064)
(epoch: 95, iters: 32, time: 0.167, data: 0.000) loss: 0.462 
(epoch: 95, iters: 112, time: 0.155, data: 0.000) loss: 0.825 
(epoch: 95, iters: 192, time: 0.153, data: 0.020) loss: 0.539 
(epoch: 95, iters: 272, time: 0.156, data: 0.000) loss: 0.774 
(epoch: 95, iters: 352, time: 0.157, data: 0.005) loss: 0.459 
(epoch: 95, iters: 432, time: 0.153, data: 0.026) loss: 0.397 
(epoch: 95, iters: 512, time: 0.151, data: 0.000) loss: 0.541 
(epoch: 95, iters: 592, time: 0.153, data: 0.006) loss: 0.469 
(epoch: 95, iters: 672, time: 0.154, data: 0.028) loss: 0.122 
(epoch: 95, iters: 752, time: 0.155, data: 0.000) loss: 0.308 
(epoch: 95, iters: 832, time: 0.154, data: 0.000) loss: 0.686 
(epoch: 95, iters: 912, time: 0.157, data: 0.000) loss: 1.040 
(epoch: 95, iters: 992, time: 0.158, data: 0.015) loss: 0.185 
(epoch: 95, iters: 1072, time: 0.156, data: 0.000) loss: 0.616 
(epoch: 95, iters: 1152, time: 0.157, data: 0.032) loss: 0.821 
(epoch: 95, iters: 1232, time: 0.155, data: 0.000) loss: 0.502 
(epoch: 95, iters: 1312, time: 0.156, data: 0.011) loss: 0.253 
(epoch: 95, iters: 1392, time: 0.157, data: 0.005) loss: 0.425 
(epoch: 95, iters: 1472, time: 0.157, data: 0.000) loss: 0.464 
(epoch: 95, iters: 1552, time: 0.157, data: 0.021) loss: 0.833 
(epoch: 95, iters: 1632, time: 0.155, data: 0.011) loss: 0.674 
(epoch: 95, iters: 1712, time: 0.158, data: 0.000) loss: 0.413 
(epoch: 95, iters: 1792, time: 0.155, data: 0.021) loss: 0.621 
(epoch: 95, iters: 1872, time: 0.154, data: 0.006) loss: 0.297 
(epoch: 95, iters: 1952, time: 0.155, data: 0.016) loss: 0.783 
(epoch: 95, iters: 2032, time: 0.156, data: 0.000) loss: 0.535 
(epoch: 95, iters: 2112, time: 0.155, data: 0.017) loss: 0.541 
(epoch: 95, iters: 2192, time: 0.158, data: 0.005) loss: 0.428 
(epoch: 95, iters: 2272, time: 0.155, data: 0.006) loss: 0.387 
(epoch: 95, iters: 2352, time: 0.155, data: 0.000) loss: 0.542 
(epoch: 95, iters: 2432, time: 0.154, data: 0.000) loss: 0.398 
(epoch: 95, iters: 2512, time: 0.158, data: 0.000) loss: 0.338 
(epoch: 95, iters: 2592, time: 0.156, data: 0.019) loss: 0.524 
(epoch: 95, iters: 2672, time: 0.157, data: 0.000) loss: 0.530 
(epoch: 95, iters: 2752, time: 0.159, data: 0.017) loss: 0.888 
(epoch: 95, iters: 2832, time: 0.158, data: 0.000) loss: 0.663 
(epoch: 95, iters: 2912, time: 0.160, data: 0.026) loss: 0.714 
(epoch: 95, iters: 2992, time: 0.156, data: 0.000) loss: 0.476 
(epoch: 95, iters: 3072, time: 0.153, data: 0.000) loss: 0.713 
(epoch: 95, iters: 3152, time: 0.155, data: 0.000) loss: 0.279 
(epoch: 95, iters: 3232, time: 0.157, data: 0.000) loss: 0.555 
(epoch: 95, iters: 3312, time: 0.159, data: 0.000) loss: 0.625 
(epoch: 95, iters: 3392, time: 0.156, data: 0.005) loss: 0.410 
(epoch: 95, iters: 3472, time: 0.158, data: 0.000) loss: 0.463 
(epoch: 95, iters: 3552, time: 0.158, data: 0.017) loss: 0.817 
(epoch: 95, iters: 3632, time: 0.157, data: 0.015) loss: 0.706 
(epoch: 95, iters: 3712, time: 0.155, data: 0.027) loss: 1.009 
(epoch: 95, iters: 3792, time: 0.159, data: 0.000) loss: 0.684 
(epoch: 95, iters: 3872, time: 0.155, data: 0.008) loss: 0.769 
(epoch: 95, iters: 3952, time: 0.158, data: 0.000) loss: 0.545 
saving the latest model (epoch 95, total_steps 962064)
(epoch: 95, iters: 4032, time: 0.156, data: 0.000) loss: 0.558 
(epoch: 95, iters: 4112, time: 0.156, data: 0.000) loss: 0.666 
(epoch: 95, iters: 4192, time: 0.155, data: 0.025) loss: 1.473 
(epoch: 95, iters: 4272, time: 0.154, data: 0.005) loss: 1.126 
(epoch: 95, iters: 4352, time: 0.155, data: 0.009) loss: 0.413 
(epoch: 95, iters: 4432, time: 0.154, data: 0.000) loss: 0.185 
(epoch: 95, iters: 4512, time: 0.157, data: 0.006) loss: 0.869 
(epoch: 95, iters: 4592, time: 0.156, data: 0.000) loss: 0.472 
(epoch: 95, iters: 4672, time: 0.155, data: 0.000) loss: 0.645 
(epoch: 95, iters: 4752, time: 0.154, data: 0.008) loss: 0.624 
(epoch: 95, iters: 4832, time: 0.154, data: 0.000) loss: 0.618 
(epoch: 95, iters: 4912, time: 0.154, data: 0.000) loss: 1.227 
(epoch: 95, iters: 4992, time: 0.156, data: 0.032) loss: 0.736 
(epoch: 95, iters: 5072, time: 0.157, data: 0.000) loss: 0.399 
(epoch: 95, iters: 5152, time: 0.158, data: 0.000) loss: 0.644 
(epoch: 95, iters: 5232, time: 0.154, data: 0.000) loss: 0.607 
(epoch: 95, iters: 5312, time: 0.155, data: 0.000) loss: 0.655 
(epoch: 95, iters: 5392, time: 0.158, data: 0.000) loss: 0.463 
(epoch: 95, iters: 5472, time: 0.155, data: 0.000) loss: 0.484 
(epoch: 95, iters: 5552, time: 0.157, data: 0.024) loss: 0.283 
(epoch: 95, iters: 5632, time: 0.158, data: 0.000) loss: 0.451 
(epoch: 95, iters: 5712, time: 0.160, data: 0.005) loss: 0.955 
(epoch: 95, iters: 5792, time: 0.162, data: 0.000) loss: 1.062 
(epoch: 95, iters: 5872, time: 0.158, data: 0.005) loss: 0.433 
(epoch: 95, iters: 5952, time: 0.159, data: 0.022) loss: 0.695 
(epoch: 95, iters: 6032, time: 0.156, data: 0.006) loss: 1.149 
(epoch: 95, iters: 6112, time: 0.157, data: 0.025) loss: 0.073 
(epoch: 95, iters: 6192, time: 0.157, data: 0.000) loss: 0.132 
(epoch: 95, iters: 6272, time: 0.155, data: 0.000) loss: 0.486 
(epoch: 95, iters: 6352, time: 0.159, data: 0.014) loss: 0.577 
(epoch: 95, iters: 6432, time: 0.156, data: 0.010) loss: 0.207 
(epoch: 95, iters: 6512, time: 0.155, data: 0.005) loss: 0.493 
(epoch: 95, iters: 6592, time: 0.158, data: 0.000) loss: 0.546 
(epoch: 95, iters: 6672, time: 0.158, data: 0.000) loss: 0.236 
(epoch: 95, iters: 6752, time: 0.160, data: 0.006) loss: 0.446 
(epoch: 95, iters: 6832, time: 0.160, data: 0.019) loss: 0.329 
(epoch: 95, iters: 6912, time: 0.157, data: 0.000) loss: 0.555 
(epoch: 95, iters: 6992, time: 0.161, data: 0.028) loss: 0.312 
(epoch: 95, iters: 7072, time: 0.160, data: 0.000) loss: 0.723 
(epoch: 95, iters: 7152, time: 0.158, data: 0.000) loss: 0.548 
(epoch: 95, iters: 7232, time: 0.161, data: 0.005) loss: 0.335 
(epoch: 95, iters: 7312, time: 0.157, data: 0.000) loss: 0.235 
(epoch: 95, iters: 7392, time: 0.159, data: 0.018) loss: 0.331 
(epoch: 95, iters: 7472, time: 0.158, data: 0.000) loss: 0.340 
(epoch: 95, iters: 7552, time: 0.157, data: 0.000) loss: 0.490 
(epoch: 95, iters: 7632, time: 0.156, data: 0.000) loss: 0.441 
(epoch: 95, iters: 7712, time: 0.157, data: 0.017) loss: 0.469 
(epoch: 95, iters: 7792, time: 0.158, data: 0.000) loss: 0.744 
(epoch: 95, iters: 7872, time: 0.158, data: 0.018) loss: 0.480 
(epoch: 95, iters: 7952, time: 0.157, data: 0.000) loss: 0.366 
saving the latest model (epoch 95, total_steps 966064)
(epoch: 95, iters: 8032, time: 0.158, data: 0.009) loss: 0.956 
(epoch: 95, iters: 8112, time: 0.155, data: 0.025) loss: 0.741 
(epoch: 95, iters: 8192, time: 0.155, data: 0.000) loss: 0.629 
(epoch: 95, iters: 8272, time: 0.154, data: 0.006) loss: 0.470 
(epoch: 95, iters: 8352, time: 0.158, data: 0.000) loss: 0.258 
(epoch: 95, iters: 8432, time: 0.157, data: 0.005) loss: 0.613 
(epoch: 95, iters: 8512, time: 0.157, data: 0.005) loss: 0.323 
(epoch: 95, iters: 8592, time: 0.155, data: 0.005) loss: 0.444 
(epoch: 95, iters: 8672, time: 0.157, data: 0.000) loss: 0.297 
(epoch: 95, iters: 8752, time: 0.159, data: 0.019) loss: 0.353 
(epoch: 95, iters: 8832, time: 0.158, data: 0.000) loss: 0.522 
(epoch: 95, iters: 8912, time: 0.158, data: 0.016) loss: 0.814 
(epoch: 95, iters: 8992, time: 0.156, data: 0.000) loss: 1.053 
(epoch: 95, iters: 9072, time: 0.158, data: 0.016) loss: 0.333 
(epoch: 95, iters: 9152, time: 0.157, data: 0.006) loss: 0.483 
(epoch: 95, iters: 9232, time: 0.161, data: 0.000) loss: 0.448 
(epoch: 95, iters: 9312, time: 0.160, data: 0.005) loss: 0.784 
(epoch: 95, iters: 9392, time: 0.160, data: 0.000) loss: 0.378 
(epoch: 95, iters: 9472, time: 0.156, data: 0.005) loss: 0.822 
(epoch: 95, iters: 9552, time: 0.159, data: 0.005) loss: 0.955 
(epoch: 95, iters: 9632, time: 0.158, data: 0.000) loss: 0.722 
(epoch: 95, iters: 9712, time: 0.158, data: 0.011) loss: 0.844 
(epoch: 95, iters: 9792, time: 0.156, data: 0.000) loss: 0.857 
(epoch: 95, iters: 9872, time: 0.158, data: 0.007) loss: 0.454 
(epoch: 95, iters: 9952, time: 0.158, data: 0.000) loss: 0.704 
(epoch: 95, iters: 10032, time: 0.156, data: 0.000) loss: 0.483 
(epoch: 95, iters: 10112, time: 0.161, data: 0.005) loss: 0.895 
(epoch: 95, iters: 10192, time: 0.094, data: 0.010) loss: 0.541 
saving the model at the end of epoch 95, iters 968240
End of epoch 95 / 200 	 Time Taken: 1607 sec
learning rate = 0.0002000
saving the latest model (epoch 96, total_steps 968256)
(epoch: 96, iters: 80, time: 0.165, data: 0.171) loss: 0.382 
(epoch: 96, iters: 160, time: 0.162, data: 0.000) loss: 0.376 
(epoch: 96, iters: 240, time: 0.159, data: 0.017) loss: 0.550 
(epoch: 96, iters: 320, time: 0.158, data: 0.005) loss: 0.599 
(epoch: 96, iters: 400, time: 0.162, data: 0.005) loss: 0.460 
(epoch: 96, iters: 480, time: 0.158, data: 0.006) loss: 0.301 
(epoch: 96, iters: 560, time: 0.163, data: 0.000) loss: 0.481 
(epoch: 96, iters: 640, time: 0.160, data: 0.010) loss: 0.394 
(epoch: 96, iters: 720, time: 0.158, data: 0.000) loss: 0.545 
(epoch: 96, iters: 800, time: 0.159, data: 0.010) loss: 0.296 
(epoch: 96, iters: 880, time: 0.158, data: 0.005) loss: 0.121 
(epoch: 96, iters: 960, time: 0.158, data: 0.005) loss: 0.359 
(epoch: 96, iters: 1040, time: 0.157, data: 0.000) loss: 0.364 
(epoch: 96, iters: 1120, time: 0.159, data: 0.023) loss: 0.657 
(epoch: 96, iters: 1200, time: 0.159, data: 0.000) loss: 0.557 
(epoch: 96, iters: 1280, time: 0.156, data: 0.000) loss: 0.361 
(epoch: 96, iters: 1360, time: 0.159, data: 0.008) loss: 0.608 
(epoch: 96, iters: 1440, time: 0.160, data: 0.024) loss: 0.724 
(epoch: 96, iters: 1520, time: 0.157, data: 0.000) loss: 0.090 
(epoch: 96, iters: 1600, time: 0.160, data: 0.000) loss: 0.635 
(epoch: 96, iters: 1680, time: 0.158, data: 0.000) loss: 0.911 
(epoch: 96, iters: 1760, time: 0.158, data: 0.000) loss: 0.685 
(epoch: 96, iters: 1840, time: 0.160, data: 0.000) loss: 0.202 
(epoch: 96, iters: 1920, time: 0.158, data: 0.005) loss: 0.308 
(epoch: 96, iters: 2000, time: 0.157, data: 0.000) loss: 0.284 
(epoch: 96, iters: 2080, time: 0.159, data: 0.009) loss: 0.178 
(epoch: 96, iters: 2160, time: 0.160, data: 0.009) loss: 0.392 
(epoch: 96, iters: 2240, time: 0.164, data: 0.000) loss: 0.337 
(epoch: 96, iters: 2320, time: 0.156, data: 0.005) loss: 0.813 
(epoch: 96, iters: 2400, time: 0.157, data: 0.008) loss: 0.338 
(epoch: 96, iters: 2480, time: 0.157, data: 0.000) loss: 0.296 
(epoch: 96, iters: 2560, time: 0.155, data: 0.000) loss: 0.583 
(epoch: 96, iters: 2640, time: 0.162, data: 0.000) loss: 0.370 
(epoch: 96, iters: 2720, time: 0.156, data: 0.009) loss: 0.636 
(epoch: 96, iters: 2800, time: 0.156, data: 0.043) loss: 0.650 
(epoch: 96, iters: 2880, time: 0.161, data: 0.000) loss: 0.377 
(epoch: 96, iters: 2960, time: 0.158, data: 0.031) loss: 0.256 
(epoch: 96, iters: 3040, time: 0.159, data: 0.000) loss: 1.140 
(epoch: 96, iters: 3120, time: 0.158, data: 0.024) loss: 0.449 
(epoch: 96, iters: 3200, time: 0.159, data: 0.000) loss: 0.501 
(epoch: 96, iters: 3280, time: 0.160, data: 0.032) loss: 0.693 
(epoch: 96, iters: 3360, time: 0.159, data: 0.000) loss: 0.484 
(epoch: 96, iters: 3440, time: 0.160, data: 0.010) loss: 0.336 
(epoch: 96, iters: 3520, time: 0.155, data: 0.024) loss: 0.181 
(epoch: 96, iters: 3600, time: 0.157, data: 0.000) loss: 0.660 
(epoch: 96, iters: 3680, time: 0.156, data: 0.009) loss: 0.768 
(epoch: 96, iters: 3760, time: 0.158, data: 0.020) loss: 1.346 
(epoch: 96, iters: 3840, time: 0.158, data: 0.020) loss: 0.412 
(epoch: 96, iters: 3920, time: 0.158, data: 0.005) loss: 0.287 
(epoch: 96, iters: 4000, time: 0.157, data: 0.000) loss: 0.323 
saving the latest model (epoch 96, total_steps 972256)
(epoch: 96, iters: 4080, time: 0.158, data: 0.000) loss: 0.313 
(epoch: 96, iters: 4160, time: 0.160, data: 0.000) loss: 0.528 
(epoch: 96, iters: 4240, time: 0.158, data: 0.000) loss: 0.585 
(epoch: 96, iters: 4320, time: 0.156, data: 0.024) loss: 0.415 
(epoch: 96, iters: 4400, time: 0.158, data: 0.000) loss: 1.116 
(epoch: 96, iters: 4480, time: 0.158, data: 0.000) loss: 0.192 
(epoch: 96, iters: 4560, time: 0.160, data: 0.000) loss: 0.838 
(epoch: 96, iters: 4640, time: 0.160, data: 0.000) loss: 0.337 
(epoch: 96, iters: 4720, time: 0.158, data: 0.005) loss: 0.356 
(epoch: 96, iters: 4800, time: 0.157, data: 0.000) loss: 0.362 
(epoch: 96, iters: 4880, time: 0.156, data: 0.000) loss: 0.284 
(epoch: 96, iters: 4960, time: 0.157, data: 0.009) loss: 0.671 
(epoch: 96, iters: 5040, time: 0.155, data: 0.014) loss: 0.366 
(epoch: 96, iters: 5120, time: 0.157, data: 0.000) loss: 0.582 
(epoch: 96, iters: 5200, time: 0.156, data: 0.000) loss: 0.894 
(epoch: 96, iters: 5280, time: 0.162, data: 0.006) loss: 0.812 
(epoch: 96, iters: 5360, time: 0.158, data: 0.005) loss: 0.366 
(epoch: 96, iters: 5440, time: 0.159, data: 0.000) loss: 0.771 
(epoch: 96, iters: 5520, time: 0.160, data: 0.000) loss: 0.245 
(epoch: 96, iters: 5600, time: 0.157, data: 0.000) loss: 0.234 
(epoch: 96, iters: 5680, time: 0.158, data: 0.008) loss: 0.915 
(epoch: 96, iters: 5760, time: 0.163, data: 0.005) loss: 0.440 
(epoch: 96, iters: 5840, time: 0.159, data: 0.008) loss: 1.059 
(epoch: 96, iters: 5920, time: 0.155, data: 0.000) loss: 0.491 
(epoch: 96, iters: 6000, time: 0.159, data: 0.005) loss: 0.407 
(epoch: 96, iters: 6080, time: 0.161, data: 0.005) loss: 0.316 
(epoch: 96, iters: 6160, time: 0.167, data: 0.022) loss: 0.634 
(epoch: 96, iters: 6240, time: 0.158, data: 0.000) loss: 0.565 
(epoch: 96, iters: 6320, time: 0.157, data: 0.000) loss: 0.818 
(epoch: 96, iters: 6400, time: 0.159, data: 0.000) loss: 0.571 
(epoch: 96, iters: 6480, time: 0.160, data: 0.006) loss: 0.440 
(epoch: 96, iters: 6560, time: 0.157, data: 0.000) loss: 0.528 
(epoch: 96, iters: 6640, time: 0.159, data: 0.005) loss: 0.615 
(epoch: 96, iters: 6720, time: 0.158, data: 0.000) loss: 0.616 
(epoch: 96, iters: 6800, time: 0.156, data: 0.000) loss: 0.288 
(epoch: 96, iters: 6880, time: 0.159, data: 0.014) loss: 1.014 
(epoch: 96, iters: 6960, time: 0.159, data: 0.005) loss: 0.222 
(epoch: 96, iters: 7040, time: 0.159, data: 0.000) loss: 0.477 
(epoch: 96, iters: 7120, time: 0.158, data: 0.000) loss: 0.559 
(epoch: 96, iters: 7200, time: 0.159, data: 0.000) loss: 0.411 
(epoch: 96, iters: 7280, time: 0.159, data: 0.014) loss: 0.857 
(epoch: 96, iters: 7360, time: 0.157, data: 0.000) loss: 0.467 
(epoch: 96, iters: 7440, time: 0.158, data: 0.000) loss: 0.272 
(epoch: 96, iters: 7520, time: 0.159, data: 0.006) loss: 0.277 
(epoch: 96, iters: 7600, time: 0.159, data: 0.006) loss: 0.411 
(epoch: 96, iters: 7680, time: 0.159, data: 0.013) loss: 0.171 
(epoch: 96, iters: 7760, time: 0.156, data: 0.000) loss: 0.717 
(epoch: 96, iters: 7840, time: 0.158, data: 0.000) loss: 0.482 
(epoch: 96, iters: 7920, time: 0.158, data: 0.000) loss: 0.513 
(epoch: 96, iters: 8000, time: 0.157, data: 0.006) loss: 0.370 
saving the latest model (epoch 96, total_steps 976256)
(epoch: 96, iters: 8080, time: 0.157, data: 0.013) loss: 0.323 
(epoch: 96, iters: 8160, time: 0.158, data: 0.005) loss: 0.487 
(epoch: 96, iters: 8240, time: 0.159, data: 0.000) loss: 0.476 
(epoch: 96, iters: 8320, time: 0.158, data: 0.011) loss: 0.552 
(epoch: 96, iters: 8400, time: 0.158, data: 0.010) loss: 0.760 
(epoch: 96, iters: 8480, time: 0.159, data: 0.008) loss: 0.610 
(epoch: 96, iters: 8560, time: 0.157, data: 0.000) loss: 0.214 
(epoch: 96, iters: 8640, time: 0.158, data: 0.024) loss: 0.719 
(epoch: 96, iters: 8720, time: 0.156, data: 0.000) loss: 0.469 
(epoch: 96, iters: 8800, time: 0.159, data: 0.032) loss: 0.678 
(epoch: 96, iters: 8880, time: 0.160, data: 0.000) loss: 0.982 
(epoch: 96, iters: 8960, time: 0.157, data: 0.011) loss: 0.947 
(epoch: 96, iters: 9040, time: 0.157, data: 0.000) loss: 0.497 
(epoch: 96, iters: 9120, time: 0.158, data: 0.009) loss: 0.965 
(epoch: 96, iters: 9200, time: 0.157, data: 0.000) loss: 0.779 
(epoch: 96, iters: 9280, time: 0.169, data: 0.005) loss: 0.408 
(epoch: 96, iters: 9360, time: 0.160, data: 0.009) loss: 0.933 
(epoch: 96, iters: 9440, time: 0.162, data: 0.008) loss: 0.739 
(epoch: 96, iters: 9520, time: 0.160, data: 0.009) loss: 0.606 
(epoch: 96, iters: 9600, time: 0.160, data: 0.000) loss: 0.140 
(epoch: 96, iters: 9680, time: 0.161, data: 0.015) loss: 0.725 
(epoch: 96, iters: 9760, time: 0.157, data: 0.005) loss: 0.653 
(epoch: 96, iters: 9840, time: 0.156, data: 0.009) loss: 0.640 
(epoch: 96, iters: 9920, time: 0.159, data: 0.000) loss: 0.360 
(epoch: 96, iters: 10000, time: 0.157, data: 0.005) loss: 0.387 
(epoch: 96, iters: 10080, time: 0.157, data: 0.005) loss: 0.683 
(epoch: 96, iters: 10160, time: 0.158, data: 0.000) loss: 0.470 
saving the model at the end of epoch 96, iters 978432
End of epoch 96 / 200 	 Time Taken: 1623 sec
learning rate = 0.0002000
saving the latest model (epoch 97, total_steps 978448)
(epoch: 97, iters: 48, time: 0.163, data: 0.000) loss: 0.370 
(epoch: 97, iters: 128, time: 0.159, data: 0.022) loss: 0.806 
(epoch: 97, iters: 208, time: 0.159, data: 0.027) loss: 0.195 
(epoch: 97, iters: 288, time: 0.159, data: 0.000) loss: 0.842 
(epoch: 97, iters: 368, time: 0.157, data: 0.005) loss: 0.528 
(epoch: 97, iters: 448, time: 0.158, data: 0.000) loss: 1.057 
(epoch: 97, iters: 528, time: 0.157, data: 0.000) loss: 0.720 
(epoch: 97, iters: 608, time: 0.156, data: 0.000) loss: 1.124 
(epoch: 97, iters: 688, time: 0.154, data: 0.000) loss: 0.433 
(epoch: 97, iters: 768, time: 0.157, data: 0.020) loss: 0.519 
(epoch: 97, iters: 848, time: 0.155, data: 0.028) loss: 0.851 
(epoch: 97, iters: 928, time: 0.154, data: 0.000) loss: 0.550 
(epoch: 97, iters: 1008, time: 0.155, data: 0.024) loss: 0.109 
(epoch: 97, iters: 1088, time: 0.155, data: 0.000) loss: 0.576 
(epoch: 97, iters: 1168, time: 0.157, data: 0.005) loss: 0.487 
(epoch: 97, iters: 1248, time: 0.157, data: 0.000) loss: 0.486 
(epoch: 97, iters: 1328, time: 0.158, data: 0.000) loss: 0.686 
(epoch: 97, iters: 1408, time: 0.155, data: 0.000) loss: 0.811 
(epoch: 97, iters: 1488, time: 0.155, data: 0.009) loss: 0.571 
(epoch: 97, iters: 1568, time: 0.155, data: 0.006) loss: 0.648 
(epoch: 97, iters: 1648, time: 0.156, data: 0.000) loss: 0.992 
(epoch: 97, iters: 1728, time: 0.158, data: 0.024) loss: 0.815 
(epoch: 97, iters: 1808, time: 0.155, data: 0.000) loss: 0.321 
(epoch: 97, iters: 1888, time: 0.156, data: 0.019) loss: 0.501 
(epoch: 97, iters: 1968, time: 0.155, data: 0.000) loss: 0.741 
(epoch: 97, iters: 2048, time: 0.156, data: 0.000) loss: 0.588 
(epoch: 97, iters: 2128, time: 0.155, data: 0.005) loss: 0.434 
(epoch: 97, iters: 2208, time: 0.156, data: 0.017) loss: 0.286 
(epoch: 97, iters: 2288, time: 0.158, data: 0.000) loss: 0.472 
(epoch: 97, iters: 2368, time: 0.158, data: 0.009) loss: 0.829 
(epoch: 97, iters: 2448, time: 0.157, data: 0.006) loss: 0.676 
(epoch: 97, iters: 2528, time: 0.156, data: 0.000) loss: 0.260 
(epoch: 97, iters: 2608, time: 0.156, data: 0.023) loss: 0.666 
(epoch: 97, iters: 2688, time: 0.156, data: 0.000) loss: 0.227 
(epoch: 97, iters: 2768, time: 0.156, data: 0.000) loss: 1.194 
(epoch: 97, iters: 2848, time: 0.156, data: 0.005) loss: 0.438 
(epoch: 97, iters: 2928, time: 0.159, data: 0.000) loss: 0.215 
(epoch: 97, iters: 3008, time: 0.162, data: 0.014) loss: 0.401 
(epoch: 97, iters: 3088, time: 0.157, data: 0.026) loss: 0.615 
(epoch: 97, iters: 3168, time: 0.158, data: 0.000) loss: 1.199 
(epoch: 97, iters: 3248, time: 0.158, data: 0.000) loss: 0.969 
(epoch: 97, iters: 3328, time: 0.158, data: 0.000) loss: 0.304 
(epoch: 97, iters: 3408, time: 0.160, data: 0.014) loss: 0.708 
(epoch: 97, iters: 3488, time: 0.157, data: 0.018) loss: 0.453 
(epoch: 97, iters: 3568, time: 0.155, data: 0.000) loss: 0.697 
(epoch: 97, iters: 3648, time: 0.154, data: 0.017) loss: 0.161 
(epoch: 97, iters: 3728, time: 0.157, data: 0.000) loss: 0.944 
(epoch: 97, iters: 3808, time: 0.162, data: 0.000) loss: 0.730 
(epoch: 97, iters: 3888, time: 0.156, data: 0.000) loss: 0.572 
(epoch: 97, iters: 3968, time: 0.159, data: 0.010) loss: 0.444 
saving the latest model (epoch 97, total_steps 982448)
(epoch: 97, iters: 4048, time: 0.158, data: 0.000) loss: 0.056 
(epoch: 97, iters: 4128, time: 0.158, data: 0.000) loss: 0.836 
(epoch: 97, iters: 4208, time: 0.156, data: 0.005) loss: 0.803 
(epoch: 97, iters: 4288, time: 0.158, data: 0.000) loss: 0.348 
(epoch: 97, iters: 4368, time: 0.159, data: 0.012) loss: 0.607 
(epoch: 97, iters: 4448, time: 0.158, data: 0.006) loss: 0.607 
(epoch: 97, iters: 4528, time: 0.157, data: 0.011) loss: 0.777 
(epoch: 97, iters: 4608, time: 0.156, data: 0.005) loss: 0.661 
(epoch: 97, iters: 4688, time: 0.156, data: 0.000) loss: 0.317 
(epoch: 97, iters: 4768, time: 0.157, data: 0.000) loss: 0.236 
(epoch: 97, iters: 4848, time: 0.158, data: 0.000) loss: 0.472 
(epoch: 97, iters: 4928, time: 0.156, data: 0.000) loss: 0.497 
(epoch: 97, iters: 5008, time: 0.155, data: 0.005) loss: 0.642 
(epoch: 97, iters: 5088, time: 0.158, data: 0.000) loss: 0.250 
(epoch: 97, iters: 5168, time: 0.155, data: 0.005) loss: 0.725 
(epoch: 97, iters: 5248, time: 0.156, data: 0.000) loss: 0.135 
(epoch: 97, iters: 5328, time: 0.157, data: 0.000) loss: 0.404 
(epoch: 97, iters: 5408, time: 0.158, data: 0.000) loss: 0.562 
(epoch: 97, iters: 5488, time: 0.157, data: 0.011) loss: 0.387 
(epoch: 97, iters: 5568, time: 0.159, data: 0.024) loss: 0.540 
(epoch: 97, iters: 5648, time: 0.159, data: 0.000) loss: 0.643 
(epoch: 97, iters: 5728, time: 0.157, data: 0.000) loss: 0.626 
(epoch: 97, iters: 5808, time: 0.156, data: 0.000) loss: 0.742 
(epoch: 97, iters: 5888, time: 0.155, data: 0.000) loss: 0.950 
(epoch: 97, iters: 5968, time: 0.156, data: 0.000) loss: 0.576 
(epoch: 97, iters: 6048, time: 0.158, data: 0.000) loss: 0.273 
(epoch: 97, iters: 6128, time: 0.156, data: 0.005) loss: 0.393 
(epoch: 97, iters: 6208, time: 0.157, data: 0.000) loss: 0.297 
(epoch: 97, iters: 6288, time: 0.156, data: 0.005) loss: 0.686 
(epoch: 97, iters: 6368, time: 0.156, data: 0.009) loss: 1.037 
(epoch: 97, iters: 6448, time: 0.156, data: 0.005) loss: 1.048 
(epoch: 97, iters: 6528, time: 0.156, data: 0.016) loss: 0.621 
(epoch: 97, iters: 6608, time: 0.157, data: 0.000) loss: 0.575 
(epoch: 97, iters: 6688, time: 0.157, data: 0.024) loss: 0.495 
(epoch: 97, iters: 6768, time: 0.157, data: 0.000) loss: 0.230 
(epoch: 97, iters: 6848, time: 0.158, data: 0.013) loss: 0.772 
(epoch: 97, iters: 6928, time: 0.157, data: 0.008) loss: 0.451 
(epoch: 97, iters: 7008, time: 0.158, data: 0.000) loss: 0.465 
(epoch: 97, iters: 7088, time: 0.157, data: 0.000) loss: 0.769 
(epoch: 97, iters: 7168, time: 0.159, data: 0.008) loss: 0.811 
(epoch: 97, iters: 7248, time: 0.156, data: 0.000) loss: 0.325 
(epoch: 97, iters: 7328, time: 0.157, data: 0.000) loss: 0.496 
(epoch: 97, iters: 7408, time: 0.157, data: 0.010) loss: 0.312 
(epoch: 97, iters: 7488, time: 0.154, data: 0.009) loss: 0.464 
(epoch: 97, iters: 7568, time: 0.156, data: 0.000) loss: 0.465 
(epoch: 97, iters: 7648, time: 0.159, data: 0.000) loss: 0.431 
(epoch: 97, iters: 7728, time: 0.157, data: 0.000) loss: 0.437 
(epoch: 97, iters: 7808, time: 0.157, data: 0.000) loss: 0.426 
(epoch: 97, iters: 7888, time: 0.158, data: 0.022) loss: 0.579 
(epoch: 97, iters: 7968, time: 0.159, data: 0.000) loss: 0.198 
saving the latest model (epoch 97, total_steps 986448)
(epoch: 97, iters: 8048, time: 0.159, data: 0.000) loss: 0.511 
(epoch: 97, iters: 8128, time: 0.157, data: 0.014) loss: 0.570 
(epoch: 97, iters: 8208, time: 0.156, data: 0.026) loss: 0.460 
(epoch: 97, iters: 8288, time: 0.159, data: 0.000) loss: 0.168 
(epoch: 97, iters: 8368, time: 0.159, data: 0.000) loss: 0.404 
(epoch: 97, iters: 8448, time: 0.157, data: 0.018) loss: 0.408 
(epoch: 97, iters: 8528, time: 0.159, data: 0.024) loss: 0.482 
(epoch: 97, iters: 8608, time: 0.154, data: 0.000) loss: 0.584 
(epoch: 97, iters: 8688, time: 0.158, data: 0.013) loss: 0.369 
(epoch: 97, iters: 8768, time: 0.158, data: 0.000) loss: 0.763 
(epoch: 97, iters: 8848, time: 0.157, data: 0.000) loss: 0.439 
(epoch: 97, iters: 8928, time: 0.161, data: 0.000) loss: 0.573 
(epoch: 97, iters: 9008, time: 0.156, data: 0.000) loss: 0.471 
(epoch: 97, iters: 9088, time: 0.156, data: 0.000) loss: 0.261 
(epoch: 97, iters: 9168, time: 0.156, data: 0.000) loss: 0.201 
(epoch: 97, iters: 9248, time: 0.157, data: 0.000) loss: 0.624 
(epoch: 97, iters: 9328, time: 0.164, data: 0.000) loss: 0.735 
(epoch: 97, iters: 9408, time: 0.157, data: 0.000) loss: 0.151 
(epoch: 97, iters: 9488, time: 0.155, data: 0.005) loss: 0.312 
(epoch: 97, iters: 9568, time: 0.159, data: 0.010) loss: 0.772 
(epoch: 97, iters: 9648, time: 0.159, data: 0.000) loss: 0.553 
(epoch: 97, iters: 9728, time: 0.159, data: 0.000) loss: 0.812 
(epoch: 97, iters: 9808, time: 0.157, data: 0.005) loss: 1.164 
(epoch: 97, iters: 9888, time: 0.155, data: 0.000) loss: 0.657 
(epoch: 97, iters: 9968, time: 0.155, data: 0.016) loss: 0.409 
(epoch: 97, iters: 10048, time: 0.156, data: 0.013) loss: 0.527 
(epoch: 97, iters: 10128, time: 0.155, data: 0.000) loss: 0.534 
saving the model at the end of epoch 97, iters 988624
End of epoch 97 / 200 	 Time Taken: 1606 sec
learning rate = 0.0002000
(epoch: 98, iters: 16, time: 0.180, data: 0.000) loss: 0.414 
saving the latest model (epoch 98, total_steps 988640)
(epoch: 98, iters: 96, time: 0.159, data: 0.000) loss: 1.169 
(epoch: 98, iters: 176, time: 0.159, data: 0.005) loss: 0.679 
(epoch: 98, iters: 256, time: 0.162, data: 0.000) loss: 0.510 
(epoch: 98, iters: 336, time: 0.161, data: 0.000) loss: 0.338 
(epoch: 98, iters: 416, time: 0.158, data: 0.000) loss: 0.405 
(epoch: 98, iters: 496, time: 0.159, data: 0.010) loss: 0.589 
(epoch: 98, iters: 576, time: 0.161, data: 0.000) loss: 0.469 
(epoch: 98, iters: 656, time: 0.160, data: 0.000) loss: 0.350 
(epoch: 98, iters: 736, time: 0.160, data: 0.025) loss: 0.717 
(epoch: 98, iters: 816, time: 0.160, data: 0.000) loss: 0.127 
(epoch: 98, iters: 896, time: 0.156, data: 0.006) loss: 0.869 
(epoch: 98, iters: 976, time: 0.155, data: 0.025) loss: 0.576 
(epoch: 98, iters: 1056, time: 0.157, data: 0.000) loss: 0.489 
(epoch: 98, iters: 1136, time: 0.155, data: 0.000) loss: 0.275 
(epoch: 98, iters: 1216, time: 0.158, data: 0.000) loss: 0.567 
(epoch: 98, iters: 1296, time: 0.160, data: 0.008) loss: 0.505 
(epoch: 98, iters: 1376, time: 0.160, data: 0.000) loss: 0.356 
(epoch: 98, iters: 1456, time: 0.160, data: 0.017) loss: 0.957 
(epoch: 98, iters: 1536, time: 0.156, data: 0.000) loss: 0.279 
(epoch: 98, iters: 1616, time: 0.156, data: 0.000) loss: 1.567 
(epoch: 98, iters: 1696, time: 0.157, data: 0.000) loss: 0.492 
(epoch: 98, iters: 1776, time: 0.159, data: 0.024) loss: 0.358 
(epoch: 98, iters: 1856, time: 0.157, data: 0.000) loss: 0.293 
(epoch: 98, iters: 1936, time: 0.159, data: 0.000) loss: 0.480 
(epoch: 98, iters: 2016, time: 0.158, data: 0.000) loss: 0.646 
(epoch: 98, iters: 2096, time: 0.159, data: 0.005) loss: 0.565 
(epoch: 98, iters: 2176, time: 0.158, data: 0.000) loss: 0.483 
(epoch: 98, iters: 2256, time: 0.166, data: 0.005) loss: 0.198 
(epoch: 98, iters: 2336, time: 0.158, data: 0.008) loss: 0.258 
(epoch: 98, iters: 2416, time: 0.159, data: 0.000) loss: 0.753 
(epoch: 98, iters: 2496, time: 0.159, data: 0.005) loss: 0.409 
(epoch: 98, iters: 2576, time: 0.159, data: 0.009) loss: 0.134 
(epoch: 98, iters: 2656, time: 0.164, data: 0.000) loss: 0.998 
(epoch: 98, iters: 2736, time: 0.162, data: 0.000) loss: 0.330 
(epoch: 98, iters: 2816, time: 0.160, data: 0.000) loss: 0.244 
(epoch: 98, iters: 2896, time: 0.159, data: 0.000) loss: 0.286 
(epoch: 98, iters: 2976, time: 0.161, data: 0.000) loss: 0.348 
(epoch: 98, iters: 3056, time: 0.160, data: 0.000) loss: 0.618 
(epoch: 98, iters: 3136, time: 0.159, data: 0.010) loss: 0.447 
(epoch: 98, iters: 3216, time: 0.158, data: 0.000) loss: 0.235 
(epoch: 98, iters: 3296, time: 0.159, data: 0.000) loss: 0.176 
(epoch: 98, iters: 3376, time: 0.159, data: 0.005) loss: 0.242 
(epoch: 98, iters: 3456, time: 0.158, data: 0.000) loss: 0.893 
(epoch: 98, iters: 3536, time: 0.158, data: 0.005) loss: 0.826 
(epoch: 98, iters: 3616, time: 0.158, data: 0.000) loss: 0.798 
(epoch: 98, iters: 3696, time: 0.158, data: 0.000) loss: 0.372 
(epoch: 98, iters: 3776, time: 0.159, data: 0.000) loss: 1.230 
(epoch: 98, iters: 3856, time: 0.159, data: 0.020) loss: 0.647 
(epoch: 98, iters: 3936, time: 0.160, data: 0.000) loss: 0.145 
(epoch: 98, iters: 4016, time: 0.159, data: 0.005) loss: 0.276 
saving the latest model (epoch 98, total_steps 992640)
(epoch: 98, iters: 4096, time: 0.158, data: 0.000) loss: 0.205 
(epoch: 98, iters: 4176, time: 0.159, data: 0.005) loss: 0.795 
(epoch: 98, iters: 4256, time: 0.159, data: 0.000) loss: 0.624 
(epoch: 98, iters: 4336, time: 0.159, data: 0.000) loss: 0.392 
(epoch: 98, iters: 4416, time: 0.161, data: 0.014) loss: 0.435 
(epoch: 98, iters: 4496, time: 0.161, data: 0.000) loss: 0.661 
(epoch: 98, iters: 4576, time: 0.159, data: 0.015) loss: 0.414 
(epoch: 98, iters: 4656, time: 0.157, data: 0.000) loss: 0.638 
(epoch: 98, iters: 4736, time: 0.155, data: 0.028) loss: 0.687 
(epoch: 98, iters: 4816, time: 0.159, data: 0.024) loss: 1.852 
(epoch: 98, iters: 4896, time: 0.157, data: 0.008) loss: 0.376 
(epoch: 98, iters: 4976, time: 0.158, data: 0.006) loss: 0.411 
(epoch: 98, iters: 5056, time: 0.161, data: 0.000) loss: 0.294 
(epoch: 98, iters: 5136, time: 0.158, data: 0.032) loss: 0.466 
(epoch: 98, iters: 5216, time: 0.158, data: 0.000) loss: 0.831 
(epoch: 98, iters: 5296, time: 0.160, data: 0.000) loss: 0.410 
(epoch: 98, iters: 5376, time: 0.166, data: 0.000) loss: 0.652 
(epoch: 98, iters: 5456, time: 0.159, data: 0.006) loss: 0.232 
(epoch: 98, iters: 5536, time: 0.159, data: 0.000) loss: 0.621 
(epoch: 98, iters: 5616, time: 0.161, data: 0.010) loss: 0.791 
(epoch: 98, iters: 5696, time: 0.160, data: 0.000) loss: 0.493 
(epoch: 98, iters: 5776, time: 0.157, data: 0.006) loss: 0.851 
(epoch: 98, iters: 5856, time: 0.156, data: 0.000) loss: 0.638 
(epoch: 98, iters: 5936, time: 0.157, data: 0.000) loss: 0.348 
(epoch: 98, iters: 6016, time: 0.158, data: 0.005) loss: 0.360 
(epoch: 98, iters: 6096, time: 0.157, data: 0.005) loss: 0.777 
(epoch: 98, iters: 6176, time: 0.158, data: 0.000) loss: 0.513 
(epoch: 98, iters: 6256, time: 0.155, data: 0.012) loss: 0.544 
(epoch: 98, iters: 6336, time: 0.156, data: 0.000) loss: 0.638 
(epoch: 98, iters: 6416, time: 0.156, data: 0.031) loss: 0.527 
(epoch: 98, iters: 6496, time: 0.156, data: 0.000) loss: 0.491 
(epoch: 98, iters: 6576, time: 0.159, data: 0.008) loss: 0.744 
(epoch: 98, iters: 6656, time: 0.160, data: 0.000) loss: 0.467 
(epoch: 98, iters: 6736, time: 0.159, data: 0.000) loss: 0.486 
(epoch: 98, iters: 6816, time: 0.157, data: 0.027) loss: 0.130 
(epoch: 98, iters: 6896, time: 0.161, data: 0.010) loss: 0.907 
(epoch: 98, iters: 6976, time: 0.159, data: 0.000) loss: 0.403 
(epoch: 98, iters: 7056, time: 0.158, data: 0.005) loss: 0.160 
(epoch: 98, iters: 7136, time: 0.158, data: 0.015) loss: 0.696 
(epoch: 98, iters: 7216, time: 0.160, data: 0.009) loss: 0.940 
(epoch: 98, iters: 7296, time: 0.159, data: 0.005) loss: 0.594 
(epoch: 98, iters: 7376, time: 0.156, data: 0.005) loss: 0.559 
(epoch: 98, iters: 7456, time: 0.159, data: 0.000) loss: 0.305 
(epoch: 98, iters: 7536, time: 0.157, data: 0.005) loss: 0.471 
(epoch: 98, iters: 7616, time: 0.158, data: 0.008) loss: 0.421 
(epoch: 98, iters: 7696, time: 0.158, data: 0.009) loss: 0.207 
(epoch: 98, iters: 7776, time: 0.157, data: 0.005) loss: 0.326 
(epoch: 98, iters: 7856, time: 0.156, data: 0.005) loss: 0.385 
(epoch: 98, iters: 7936, time: 0.160, data: 0.020) loss: 0.543 
(epoch: 98, iters: 8016, time: 0.158, data: 0.000) loss: 0.314 
saving the latest model (epoch 98, total_steps 996640)
(epoch: 98, iters: 8096, time: 0.158, data: 0.000) loss: 0.532 
(epoch: 98, iters: 8176, time: 0.159, data: 0.000) loss: 0.293 
(epoch: 98, iters: 8256, time: 0.157, data: 0.000) loss: 0.444 
(epoch: 98, iters: 8336, time: 0.159, data: 0.000) loss: 0.945 
(epoch: 98, iters: 8416, time: 0.156, data: 0.000) loss: 0.071 
(epoch: 98, iters: 8496, time: 0.157, data: 0.000) loss: 0.495 
(epoch: 98, iters: 8576, time: 0.158, data: 0.000) loss: 0.369 
(epoch: 98, iters: 8656, time: 0.155, data: 0.015) loss: 0.438 
(epoch: 98, iters: 8736, time: 0.156, data: 0.000) loss: 1.113 
(epoch: 98, iters: 8816, time: 0.157, data: 0.005) loss: 0.330 
(epoch: 98, iters: 8896, time: 0.165, data: 0.008) loss: 0.443 
(epoch: 98, iters: 8976, time: 0.160, data: 0.008) loss: 0.641 
(epoch: 98, iters: 9056, time: 0.158, data: 0.010) loss: 0.323 
(epoch: 98, iters: 9136, time: 0.158, data: 0.000) loss: 0.481 
(epoch: 98, iters: 9216, time: 0.158, data: 0.005) loss: 0.550 
(epoch: 98, iters: 9296, time: 0.165, data: 0.000) loss: 0.297 
(epoch: 98, iters: 9376, time: 0.158, data: 0.015) loss: 0.737 
(epoch: 98, iters: 9456, time: 0.155, data: 0.000) loss: 0.560 
(epoch: 98, iters: 9536, time: 0.156, data: 0.006) loss: 0.645 
(epoch: 98, iters: 9616, time: 0.157, data: 0.000) loss: 0.404 
(epoch: 98, iters: 9696, time: 0.158, data: 0.000) loss: 0.431 
(epoch: 98, iters: 9776, time: 0.156, data: 0.017) loss: 0.319 
(epoch: 98, iters: 9856, time: 0.159, data: 0.000) loss: 0.633 
(epoch: 98, iters: 9936, time: 0.160, data: 0.000) loss: 0.249 
(epoch: 98, iters: 10016, time: 0.160, data: 0.006) loss: 0.522 
(epoch: 98, iters: 10096, time: 0.160, data: 0.000) loss: 0.591 
(epoch: 98, iters: 10176, time: 0.159, data: 0.005) loss: 0.341 
saving the model at the end of epoch 98, iters 998816
End of epoch 98 / 200 	 Time Taken: 1622 sec
learning rate = 0.0002000
saving the latest model (epoch 99, total_steps 998832)
(epoch: 99, iters: 64, time: 0.160, data: 0.000) loss: 0.272 
(epoch: 99, iters: 144, time: 0.155, data: 0.000) loss: 0.586 
(epoch: 99, iters: 224, time: 0.155, data: 0.000) loss: 0.456 
(epoch: 99, iters: 304, time: 0.158, data: 0.009) loss: 0.403 
(epoch: 99, iters: 384, time: 0.158, data: 0.009) loss: 0.263 
(epoch: 99, iters: 464, time: 0.158, data: 0.000) loss: 0.406 
(epoch: 99, iters: 544, time: 0.160, data: 0.000) loss: 0.392 
(epoch: 99, iters: 624, time: 0.160, data: 0.025) loss: 0.583 
(epoch: 99, iters: 704, time: 0.158, data: 0.000) loss: 0.812 
(epoch: 99, iters: 784, time: 0.159, data: 0.000) loss: 0.428 
(epoch: 99, iters: 864, time: 0.159, data: 0.005) loss: 1.073 
(epoch: 99, iters: 944, time: 0.157, data: 0.000) loss: 0.432 
(epoch: 99, iters: 1024, time: 0.158, data: 0.008) loss: 0.791 
(epoch: 99, iters: 1104, time: 0.161, data: 0.005) loss: 1.080 
(epoch: 99, iters: 1184, time: 0.159, data: 0.008) loss: 0.820 
(epoch: 99, iters: 1264, time: 0.158, data: 0.000) loss: 0.586 
(epoch: 99, iters: 1344, time: 0.158, data: 0.000) loss: 0.344 
(epoch: 99, iters: 1424, time: 0.157, data: 0.008) loss: 0.410 
(epoch: 99, iters: 1504, time: 0.157, data: 0.000) loss: 0.191 
(epoch: 99, iters: 1584, time: 0.158, data: 0.006) loss: 0.663 
(epoch: 99, iters: 1664, time: 0.159, data: 0.000) loss: 0.284 
(epoch: 99, iters: 1744, time: 0.158, data: 0.011) loss: 0.492 
(epoch: 99, iters: 1824, time: 0.155, data: 0.000) loss: 0.297 
(epoch: 99, iters: 1904, time: 0.156, data: 0.000) loss: 0.882 
(epoch: 99, iters: 1984, time: 0.158, data: 0.000) loss: 0.846 
(epoch: 99, iters: 2064, time: 0.159, data: 0.005) loss: 0.609 
(epoch: 99, iters: 2144, time: 0.159, data: 0.006) loss: 0.300 
(epoch: 99, iters: 2224, time: 0.159, data: 0.000) loss: 0.183 
(epoch: 99, iters: 2304, time: 0.157, data: 0.000) loss: 0.331 
(epoch: 99, iters: 2384, time: 0.159, data: 0.000) loss: 0.619 
(epoch: 99, iters: 2464, time: 0.155, data: 0.023) loss: 0.254 
(epoch: 99, iters: 2544, time: 0.157, data: 0.006) loss: 0.521 
(epoch: 99, iters: 2624, time: 0.162, data: 0.000) loss: 0.734 
(epoch: 99, iters: 2704, time: 0.161, data: 0.009) loss: 0.779 
(epoch: 99, iters: 2784, time: 0.172, data: 0.000) loss: 0.301 
(epoch: 99, iters: 2864, time: 0.159, data: 0.000) loss: 0.223 
(epoch: 99, iters: 2944, time: 0.158, data: 0.017) loss: 1.285 
(epoch: 99, iters: 3024, time: 0.156, data: 0.000) loss: 0.383 
(epoch: 99, iters: 3104, time: 0.166, data: 0.021) loss: 0.159 
(epoch: 99, iters: 3184, time: 0.163, data: 0.009) loss: 0.543 
(epoch: 99, iters: 3264, time: 0.155, data: 0.021) loss: 0.451 
(epoch: 99, iters: 3344, time: 0.153, data: 0.000) loss: 0.425 
(epoch: 99, iters: 3424, time: 0.166, data: 0.000) loss: 0.470 
(epoch: 99, iters: 3504, time: 0.158, data: 0.010) loss: 0.590 
(epoch: 99, iters: 3584, time: 0.155, data: 0.000) loss: 0.431 
(epoch: 99, iters: 3664, time: 0.154, data: 0.021) loss: 0.341 
(epoch: 99, iters: 3744, time: 0.156, data: 0.008) loss: 0.438 
(epoch: 99, iters: 3824, time: 0.155, data: 0.000) loss: 0.574 
(epoch: 99, iters: 3904, time: 0.168, data: 0.016) loss: 0.233 
(epoch: 99, iters: 3984, time: 0.165, data: 0.008) loss: 0.489 
saving the latest model (epoch 99, total_steps 1002832)
(epoch: 99, iters: 4064, time: 0.154, data: 0.009) loss: 0.566 
(epoch: 99, iters: 4144, time: 0.155, data: 0.000) loss: 0.554 
(epoch: 99, iters: 4224, time: 0.161, data: 0.000) loss: 0.306 
(epoch: 99, iters: 4304, time: 0.162, data: 0.009) loss: 0.392 
(epoch: 99, iters: 4384, time: 0.158, data: 0.021) loss: 0.403 
(epoch: 99, iters: 4464, time: 0.150, data: 0.000) loss: 1.252 
(epoch: 99, iters: 4544, time: 0.157, data: 0.000) loss: 0.312 
(epoch: 99, iters: 4624, time: 0.163, data: 0.013) loss: 0.526 
(epoch: 99, iters: 4704, time: 0.163, data: 0.000) loss: 0.316 
(epoch: 99, iters: 4784, time: 0.153, data: 0.000) loss: 0.876 
(epoch: 99, iters: 4864, time: 0.153, data: 0.000) loss: 0.699 
(epoch: 99, iters: 4944, time: 0.152, data: 0.000) loss: 1.117 
(epoch: 99, iters: 5024, time: 0.153, data: 0.005) loss: 0.778 
(epoch: 99, iters: 5104, time: 0.154, data: 0.008) loss: 0.298 
(epoch: 99, iters: 5184, time: 0.153, data: 0.000) loss: 0.391 
(epoch: 99, iters: 5264, time: 0.155, data: 0.011) loss: 0.356 
(epoch: 99, iters: 5344, time: 0.154, data: 0.000) loss: 0.671 
(epoch: 99, iters: 5424, time: 0.154, data: 0.005) loss: 0.441 
(epoch: 99, iters: 5504, time: 0.152, data: 0.005) loss: 0.669 
(epoch: 99, iters: 5584, time: 0.153, data: 0.000) loss: 0.866 
(epoch: 99, iters: 5664, time: 0.153, data: 0.006) loss: 0.723 
(epoch: 99, iters: 5744, time: 0.151, data: 0.000) loss: 0.238 
(epoch: 99, iters: 5824, time: 0.152, data: 0.013) loss: 0.601 
(epoch: 99, iters: 5904, time: 0.151, data: 0.017) loss: 0.515 
(epoch: 99, iters: 5984, time: 0.153, data: 0.000) loss: 0.345 
(epoch: 99, iters: 6064, time: 0.151, data: 0.032) loss: 1.502 
(epoch: 99, iters: 6144, time: 0.151, data: 0.000) loss: 0.436 
(epoch: 99, iters: 6224, time: 0.153, data: 0.000) loss: 0.608 
(epoch: 99, iters: 6304, time: 0.151, data: 0.000) loss: 0.302 
(epoch: 99, iters: 6384, time: 0.153, data: 0.008) loss: 0.222 
(epoch: 99, iters: 6464, time: 0.152, data: 0.000) loss: 0.792 
(epoch: 99, iters: 6544, time: 0.152, data: 0.000) loss: 0.554 
(epoch: 99, iters: 6624, time: 0.153, data: 0.000) loss: 0.774 
(epoch: 99, iters: 6704, time: 0.151, data: 0.029) loss: 0.684 
(epoch: 99, iters: 6784, time: 0.153, data: 0.000) loss: 0.779 
(epoch: 99, iters: 6864, time: 0.153, data: 0.022) loss: 0.613 
(epoch: 99, iters: 6944, time: 0.152, data: 0.011) loss: 0.277 
(epoch: 99, iters: 7024, time: 0.153, data: 0.000) loss: 0.524 
(epoch: 99, iters: 7104, time: 0.152, data: 0.000) loss: 0.278 
(epoch: 99, iters: 7184, time: 0.152, data: 0.005) loss: 0.577 
(epoch: 99, iters: 7264, time: 0.152, data: 0.000) loss: 0.367 
(epoch: 99, iters: 7344, time: 0.153, data: 0.000) loss: 0.717 
(epoch: 99, iters: 7424, time: 0.152, data: 0.000) loss: 0.680 
(epoch: 99, iters: 7504, time: 0.151, data: 0.000) loss: 0.857 
(epoch: 99, iters: 7584, time: 0.151, data: 0.000) loss: 0.483 
(epoch: 99, iters: 7664, time: 0.151, data: 0.032) loss: 0.183 
(epoch: 99, iters: 7744, time: 0.153, data: 0.000) loss: 0.811 
(epoch: 99, iters: 7824, time: 0.154, data: 0.000) loss: 0.130 
(epoch: 99, iters: 7904, time: 0.153, data: 0.000) loss: 0.183 
(epoch: 99, iters: 7984, time: 0.151, data: 0.005) loss: 0.370 
saving the latest model (epoch 99, total_steps 1006832)
(epoch: 99, iters: 8064, time: 0.151, data: 0.000) loss: 0.488 
(epoch: 99, iters: 8144, time: 0.153, data: 0.006) loss: 0.242 
(epoch: 99, iters: 8224, time: 0.151, data: 0.000) loss: 0.345 
(epoch: 99, iters: 8304, time: 0.153, data: 0.000) loss: 0.272 
(epoch: 99, iters: 8384, time: 0.153, data: 0.000) loss: 0.241 
(epoch: 99, iters: 8464, time: 0.153, data: 0.000) loss: 0.829 
(epoch: 99, iters: 8544, time: 0.152, data: 0.010) loss: 0.512 
(epoch: 99, iters: 8624, time: 0.151, data: 0.021) loss: 0.222 
(epoch: 99, iters: 8704, time: 0.152, data: 0.005) loss: 0.308 
(epoch: 99, iters: 8784, time: 0.153, data: 0.005) loss: 0.353 
(epoch: 99, iters: 8864, time: 0.152, data: 0.000) loss: 0.277 
(epoch: 99, iters: 8944, time: 0.151, data: 0.008) loss: 0.336 
(epoch: 99, iters: 9024, time: 0.153, data: 0.016) loss: 0.392 
(epoch: 99, iters: 9104, time: 0.152, data: 0.000) loss: 0.445 
(epoch: 99, iters: 9184, time: 0.151, data: 0.000) loss: 0.293 
(epoch: 99, iters: 9264, time: 0.152, data: 0.008) loss: 0.830 
(epoch: 99, iters: 9344, time: 0.151, data: 0.000) loss: 0.324 
(epoch: 99, iters: 9424, time: 0.152, data: 0.011) loss: 0.774 
(epoch: 99, iters: 9504, time: 0.154, data: 0.000) loss: 0.675 
(epoch: 99, iters: 9584, time: 0.154, data: 0.008) loss: 0.596 
(epoch: 99, iters: 9664, time: 0.154, data: 0.000) loss: 1.094 
(epoch: 99, iters: 9744, time: 0.153, data: 0.019) loss: 0.363 
(epoch: 99, iters: 9824, time: 0.152, data: 0.011) loss: 0.504 
(epoch: 99, iters: 9904, time: 0.151, data: 0.005) loss: 0.823 
(epoch: 99, iters: 9984, time: 0.154, data: 0.000) loss: 0.279 
(epoch: 99, iters: 10064, time: 0.151, data: 0.019) loss: 0.831 
(epoch: 99, iters: 10144, time: 0.152, data: 0.005) loss: 0.210 
saving the model at the end of epoch 99, iters 1009008
End of epoch 99 / 200 	 Time Taken: 1591 sec
learning rate = 0.0001980
saving the latest model (epoch 100, total_steps 1009024)
(epoch: 100, iters: 32, time: 0.176, data: 0.000) loss: 0.314 
(epoch: 100, iters: 112, time: 0.199, data: 0.000) loss: 0.338 
(epoch: 100, iters: 192, time: 0.167, data: 0.011) loss: 1.165 
(epoch: 100, iters: 272, time: 0.157, data: 0.029) loss: 0.481 
(epoch: 100, iters: 352, time: 0.167, data: 0.000) loss: 0.127 
(epoch: 100, iters: 432, time: 0.157, data: 0.000) loss: 0.503 
(epoch: 100, iters: 512, time: 0.159, data: 0.011) loss: 0.502 
(epoch: 100, iters: 592, time: 0.156, data: 0.000) loss: 0.188 
(epoch: 100, iters: 672, time: 0.156, data: 0.000) loss: 0.411 
(epoch: 100, iters: 752, time: 0.159, data: 0.004) loss: 0.620 
(epoch: 100, iters: 832, time: 0.157, data: 0.000) loss: 0.656 
(epoch: 100, iters: 912, time: 0.160, data: 0.000) loss: 0.235 
(epoch: 100, iters: 992, time: 0.158, data: 0.000) loss: 0.951 
(epoch: 100, iters: 1072, time: 0.167, data: 0.013) loss: 0.677 
(epoch: 100, iters: 1152, time: 0.166, data: 0.000) loss: 0.456 
(epoch: 100, iters: 1232, time: 0.165, data: 0.000) loss: 0.573 
(epoch: 100, iters: 1312, time: 0.165, data: 0.005) loss: 0.770 
(epoch: 100, iters: 1392, time: 0.166, data: 0.011) loss: 0.477 
(epoch: 100, iters: 1472, time: 0.165, data: 0.000) loss: 0.882 
(epoch: 100, iters: 1552, time: 0.164, data: 0.018) loss: 0.517 
(epoch: 100, iters: 1632, time: 0.165, data: 0.000) loss: 0.298 
(epoch: 100, iters: 1712, time: 0.158, data: 0.000) loss: 0.570 
(epoch: 100, iters: 1792, time: 0.157, data: 0.000) loss: 0.203 
(epoch: 100, iters: 1872, time: 0.159, data: 0.000) loss: 0.176 
(epoch: 100, iters: 1952, time: 0.172, data: 0.000) loss: 0.511 
(epoch: 100, iters: 2032, time: 0.168, data: 0.017) loss: 0.225 
(epoch: 100, iters: 2112, time: 0.157, data: 0.021) loss: 0.340 
(epoch: 100, iters: 2192, time: 0.156, data: 0.006) loss: 0.297 
(epoch: 100, iters: 2272, time: 0.166, data: 0.005) loss: 0.150 
(epoch: 100, iters: 2352, time: 0.166, data: 0.017) loss: 0.766 
(epoch: 100, iters: 2432, time: 0.154, data: 0.000) loss: 0.740 
(epoch: 100, iters: 2512, time: 0.153, data: 0.025) loss: 0.241 
(epoch: 100, iters: 2592, time: 0.152, data: 0.000) loss: 1.049 
(epoch: 100, iters: 2672, time: 0.157, data: 0.000) loss: 0.494 
(epoch: 100, iters: 2752, time: 0.151, data: 0.000) loss: 0.233 
(epoch: 100, iters: 2832, time: 0.152, data: 0.024) loss: 1.098 
(epoch: 100, iters: 2912, time: 0.169, data: 0.000) loss: 0.466 
(epoch: 100, iters: 2992, time: 0.165, data: 0.000) loss: 0.649 
(epoch: 100, iters: 3072, time: 0.164, data: 0.000) loss: 0.613 
(epoch: 100, iters: 3152, time: 0.154, data: 0.030) loss: 0.700 
(epoch: 100, iters: 3232, time: 0.154, data: 0.000) loss: 0.897 
(epoch: 100, iters: 3312, time: 0.153, data: 0.000) loss: 0.189 
(epoch: 100, iters: 3392, time: 0.156, data: 0.032) loss: 0.509 
(epoch: 100, iters: 3472, time: 0.154, data: 0.000) loss: 0.551 
(epoch: 100, iters: 3552, time: 0.156, data: 0.008) loss: 1.251 
(epoch: 100, iters: 3632, time: 0.155, data: 0.000) loss: 0.778 
(epoch: 100, iters: 3712, time: 0.154, data: 0.034) loss: 0.439 
(epoch: 100, iters: 3792, time: 0.153, data: 0.000) loss: 0.406 
(epoch: 100, iters: 3872, time: 0.160, data: 0.024) loss: 0.394 
(epoch: 100, iters: 3952, time: 0.152, data: 0.000) loss: 0.733 
saving the latest model (epoch 100, total_steps 1013024)
(epoch: 100, iters: 4032, time: 0.152, data: 0.009) loss: 0.486 
(epoch: 100, iters: 4112, time: 0.151, data: 0.000) loss: 0.659 
(epoch: 100, iters: 4192, time: 0.152, data: 0.011) loss: 0.622 
(epoch: 100, iters: 4272, time: 0.158, data: 0.000) loss: 0.472 
(epoch: 100, iters: 4352, time: 0.154, data: 0.000) loss: 0.308 
(epoch: 100, iters: 4432, time: 0.153, data: 0.026) loss: 0.465 
(epoch: 100, iters: 4512, time: 0.156, data: 0.000) loss: 0.601 
(epoch: 100, iters: 4592, time: 0.155, data: 0.000) loss: 0.423 
(epoch: 100, iters: 4672, time: 0.157, data: 0.024) loss: 0.661 
(epoch: 100, iters: 4752, time: 0.152, data: 0.000) loss: 0.561 
(epoch: 100, iters: 4832, time: 0.152, data: 0.000) loss: 0.736 
(epoch: 100, iters: 4912, time: 0.153, data: 0.024) loss: 1.148 
(epoch: 100, iters: 4992, time: 0.152, data: 0.000) loss: 0.611 
(epoch: 100, iters: 5072, time: 0.156, data: 0.000) loss: 0.649 
(epoch: 100, iters: 5152, time: 0.154, data: 0.014) loss: 0.258 
(epoch: 100, iters: 5232, time: 0.155, data: 0.000) loss: 0.541 
(epoch: 100, iters: 5312, time: 0.157, data: 0.005) loss: 0.295 
(epoch: 100, iters: 5392, time: 0.157, data: 0.000) loss: 0.219 
(epoch: 100, iters: 5472, time: 0.161, data: 0.008) loss: 0.759 
(epoch: 100, iters: 5552, time: 0.155, data: 0.025) loss: 0.928 
(epoch: 100, iters: 5632, time: 0.165, data: 0.000) loss: 0.207 
(epoch: 100, iters: 5712, time: 0.167, data: 0.000) loss: 0.560 
(epoch: 100, iters: 5792, time: 0.157, data: 0.000) loss: 0.297 
(epoch: 100, iters: 5872, time: 0.163, data: 0.000) loss: 0.089 
(epoch: 100, iters: 5952, time: 0.155, data: 0.021) loss: 0.531 
(epoch: 100, iters: 6032, time: 0.155, data: 0.000) loss: 0.435 
(epoch: 100, iters: 6112, time: 0.155, data: 0.000) loss: 0.868 
(epoch: 100, iters: 6192, time: 0.154, data: 0.033) loss: 0.531 
(epoch: 100, iters: 6272, time: 0.155, data: 0.000) loss: 0.750 
(epoch: 100, iters: 6352, time: 0.170, data: 0.016) loss: 0.921 
(epoch: 100, iters: 6432, time: 0.150, data: 0.021) loss: 1.236 
(epoch: 100, iters: 6512, time: 0.151, data: 0.015) loss: 0.299 
(epoch: 100, iters: 6592, time: 0.151, data: 0.000) loss: 0.505 
(epoch: 100, iters: 6672, time: 0.152, data: 0.009) loss: 0.403 
(epoch: 100, iters: 6752, time: 0.161, data: 0.018) loss: 0.297 
(epoch: 100, iters: 6832, time: 0.164, data: 0.000) loss: 0.676 
(epoch: 100, iters: 6912, time: 0.156, data: 0.000) loss: 0.661 
(epoch: 100, iters: 6992, time: 0.156, data: 0.008) loss: 0.483 
(epoch: 100, iters: 7072, time: 0.159, data: 0.017) loss: 0.559 
(epoch: 100, iters: 7152, time: 0.152, data: 0.000) loss: 0.576 
(epoch: 100, iters: 7232, time: 0.157, data: 0.029) loss: 0.397 
(epoch: 100, iters: 7312, time: 0.156, data: 0.011) loss: 0.436 
(epoch: 100, iters: 7392, time: 0.156, data: 0.000) loss: 1.393 
(epoch: 100, iters: 7472, time: 0.154, data: 0.020) loss: 0.089 
(epoch: 100, iters: 7552, time: 0.156, data: 0.018) loss: 0.579 
(epoch: 100, iters: 7632, time: 0.158, data: 0.000) loss: 0.740 
(epoch: 100, iters: 7712, time: 0.156, data: 0.017) loss: 0.637 
(epoch: 100, iters: 7792, time: 0.156, data: 0.005) loss: 0.921 
(epoch: 100, iters: 7872, time: 0.155, data: 0.024) loss: 0.348 
(epoch: 100, iters: 7952, time: 0.155, data: 0.000) loss: 0.420 
saving the latest model (epoch 100, total_steps 1017024)
(epoch: 100, iters: 8032, time: 0.154, data: 0.015) loss: 0.231 
(epoch: 100, iters: 8112, time: 0.154, data: 0.000) loss: 0.499 
(epoch: 100, iters: 8192, time: 0.158, data: 0.014) loss: 0.696 
(epoch: 100, iters: 8272, time: 0.155, data: 0.007) loss: 0.844 
(epoch: 100, iters: 8352, time: 0.159, data: 0.021) loss: 0.479 
(epoch: 100, iters: 8432, time: 0.157, data: 0.000) loss: 0.790 
(epoch: 100, iters: 8512, time: 0.160, data: 0.000) loss: 0.347 
(epoch: 100, iters: 8592, time: 0.159, data: 0.000) loss: 0.937 
(epoch: 100, iters: 8672, time: 0.163, data: 0.018) loss: 0.107 
(epoch: 100, iters: 8752, time: 0.164, data: 0.044) loss: 0.542 
(epoch: 100, iters: 8832, time: 0.164, data: 0.000) loss: 1.250 
(epoch: 100, iters: 8912, time: 0.165, data: 0.015) loss: 0.377 
(epoch: 100, iters: 8992, time: 0.170, data: 0.000) loss: 0.495 
(epoch: 100, iters: 9072, time: 0.167, data: 0.024) loss: 0.798 
(epoch: 100, iters: 9152, time: 0.177, data: 0.000) loss: 0.361 
(epoch: 100, iters: 9232, time: 0.166, data: 0.019) loss: 0.255 
(epoch: 100, iters: 9312, time: 0.178, data: 0.000) loss: 0.505 
(epoch: 100, iters: 9392, time: 0.175, data: 0.000) loss: 0.355 
(epoch: 100, iters: 9472, time: 0.158, data: 0.009) loss: 1.201 
(epoch: 100, iters: 9552, time: 0.168, data: 0.000) loss: 0.694 
(epoch: 100, iters: 9632, time: 0.162, data: 0.021) loss: 0.640 
(epoch: 100, iters: 9712, time: 0.177, data: 0.006) loss: 0.602 
(epoch: 100, iters: 9792, time: 0.158, data: 0.000) loss: 0.703 
(epoch: 100, iters: 9872, time: 0.155, data: 0.019) loss: 0.385 
(epoch: 100, iters: 9952, time: 0.156, data: 0.000) loss: 0.519 
(epoch: 100, iters: 10032, time: 0.157, data: 0.016) loss: 0.486 
(epoch: 100, iters: 10112, time: 0.154, data: 0.000) loss: 0.478 
(epoch: 100, iters: 10192, time: 0.093, data: 0.000) loss: 0.878 
saving the model at the end of epoch 100, iters 1019200
End of epoch 100 / 200 	 Time Taken: 1627 sec
learning rate = 0.0001960
saving the latest model (epoch 101, total_steps 1019216)
(epoch: 101, iters: 80, time: 0.155, data: 0.164) loss: 0.211 
(epoch: 101, iters: 160, time: 0.156, data: 0.000) loss: 0.453 
(epoch: 101, iters: 240, time: 0.154, data: 0.000) loss: 0.521 
(epoch: 101, iters: 320, time: 0.153, data: 0.000) loss: 0.149 
(epoch: 101, iters: 400, time: 0.156, data: 0.000) loss: 0.180 
(epoch: 101, iters: 480, time: 0.155, data: 0.000) loss: 0.470 
(epoch: 101, iters: 560, time: 0.156, data: 0.009) loss: 0.456 
(epoch: 101, iters: 640, time: 0.153, data: 0.000) loss: 0.529 
(epoch: 101, iters: 720, time: 0.151, data: 0.010) loss: 0.516 
(epoch: 101, iters: 800, time: 0.154, data: 0.000) loss: 0.689 
(epoch: 101, iters: 880, time: 0.156, data: 0.000) loss: 0.798 
(epoch: 101, iters: 960, time: 0.155, data: 0.005) loss: 0.323 
(epoch: 101, iters: 1040, time: 0.155, data: 0.000) loss: 0.391 
(epoch: 101, iters: 1120, time: 0.154, data: 0.008) loss: 1.271 
(epoch: 101, iters: 1200, time: 0.156, data: 0.008) loss: 0.660 
(epoch: 101, iters: 1280, time: 0.155, data: 0.000) loss: 0.337 
(epoch: 101, iters: 1360, time: 0.156, data: 0.016) loss: 0.352 
(epoch: 101, iters: 1440, time: 0.157, data: 0.000) loss: 0.420 
(epoch: 101, iters: 1520, time: 0.154, data: 0.016) loss: 0.167 
(epoch: 101, iters: 1600, time: 0.154, data: 0.000) loss: 0.792 
(epoch: 101, iters: 1680, time: 0.153, data: 0.011) loss: 0.430 
(epoch: 101, iters: 1760, time: 0.153, data: 0.000) loss: 0.258 
(epoch: 101, iters: 1840, time: 0.155, data: 0.013) loss: 0.365 
(epoch: 101, iters: 1920, time: 0.152, data: 0.000) loss: 0.485 
(epoch: 101, iters: 2000, time: 0.152, data: 0.000) loss: 0.845 
(epoch: 101, iters: 2080, time: 0.156, data: 0.000) loss: 0.283 
(epoch: 101, iters: 2160, time: 0.154, data: 0.021) loss: 0.221 
(epoch: 101, iters: 2240, time: 0.154, data: 0.005) loss: 0.882 
(epoch: 101, iters: 2320, time: 0.152, data: 0.015) loss: 0.274 
(epoch: 101, iters: 2400, time: 0.153, data: 0.000) loss: 0.829 
(epoch: 101, iters: 2480, time: 0.161, data: 0.000) loss: 0.298 
(epoch: 101, iters: 2560, time: 0.156, data: 0.009) loss: 0.136 
(epoch: 101, iters: 2640, time: 0.154, data: 0.000) loss: 0.638 
(epoch: 101, iters: 2720, time: 0.156, data: 0.000) loss: 0.609 
(epoch: 101, iters: 2800, time: 0.155, data: 0.006) loss: 0.784 
(epoch: 101, iters: 2880, time: 0.154, data: 0.000) loss: 0.783 
(epoch: 101, iters: 2960, time: 0.154, data: 0.000) loss: 0.343 
(epoch: 101, iters: 3040, time: 0.154, data: 0.005) loss: 0.308 
(epoch: 101, iters: 3120, time: 0.152, data: 0.020) loss: 0.894 
(epoch: 101, iters: 3200, time: 0.153, data: 0.008) loss: 0.484 
(epoch: 101, iters: 3280, time: 0.161, data: 0.000) loss: 0.499 
(epoch: 101, iters: 3360, time: 0.155, data: 0.000) loss: 0.406 
(epoch: 101, iters: 3440, time: 0.156, data: 0.000) loss: 0.393 
(epoch: 101, iters: 3520, time: 0.154, data: 0.006) loss: 0.816 
(epoch: 101, iters: 3600, time: 0.156, data: 0.000) loss: 0.282 
(epoch: 101, iters: 3680, time: 0.159, data: 0.005) loss: 0.401 
(epoch: 101, iters: 3760, time: 0.157, data: 0.032) loss: 0.512 
(epoch: 101, iters: 3840, time: 0.153, data: 0.000) loss: 0.678 
(epoch: 101, iters: 3920, time: 0.153, data: 0.009) loss: 0.384 
(epoch: 101, iters: 4000, time: 0.155, data: 0.008) loss: 0.167 
saving the latest model (epoch 101, total_steps 1023216)
(epoch: 101, iters: 4080, time: 0.156, data: 0.031) loss: 0.637 
(epoch: 101, iters: 4160, time: 0.155, data: 0.000) loss: 0.416 
(epoch: 101, iters: 4240, time: 0.156, data: 0.008) loss: 0.374 
(epoch: 101, iters: 4320, time: 0.154, data: 0.000) loss: 0.555 
(epoch: 101, iters: 4400, time: 0.152, data: 0.000) loss: 0.332 
(epoch: 101, iters: 4480, time: 0.157, data: 0.000) loss: 0.311 
(epoch: 101, iters: 4560, time: 0.153, data: 0.005) loss: 0.375 
(epoch: 101, iters: 4640, time: 0.151, data: 0.000) loss: 0.146 
(epoch: 101, iters: 4720, time: 0.151, data: 0.000) loss: 0.603 
(epoch: 101, iters: 4800, time: 0.152, data: 0.000) loss: 0.496 
(epoch: 101, iters: 4880, time: 0.158, data: 0.000) loss: 0.560 
(epoch: 101, iters: 4960, time: 0.153, data: 0.005) loss: 0.630 
(epoch: 101, iters: 5040, time: 0.155, data: 0.000) loss: 0.408 
(epoch: 101, iters: 5120, time: 0.153, data: 0.000) loss: 0.339 
(epoch: 101, iters: 5200, time: 0.155, data: 0.000) loss: 0.183 
(epoch: 101, iters: 5280, time: 0.161, data: 0.005) loss: 0.726 
(epoch: 101, iters: 5360, time: 0.154, data: 0.024) loss: 0.528 
(epoch: 101, iters: 5440, time: 0.155, data: 0.000) loss: 0.439 
(epoch: 101, iters: 5520, time: 0.154, data: 0.023) loss: 0.585 
(epoch: 101, iters: 5600, time: 0.155, data: 0.000) loss: 0.212 
(epoch: 101, iters: 5680, time: 0.154, data: 0.000) loss: 0.678 
(epoch: 101, iters: 5760, time: 0.154, data: 0.024) loss: 0.601 
(epoch: 101, iters: 5840, time: 0.155, data: 0.000) loss: 0.389 
(epoch: 101, iters: 5920, time: 0.152, data: 0.014) loss: 0.357 
(epoch: 101, iters: 6000, time: 0.154, data: 0.005) loss: 0.368 
(epoch: 101, iters: 6080, time: 0.168, data: 0.016) loss: 0.071 
(epoch: 101, iters: 6160, time: 0.166, data: 0.000) loss: 0.735 
(epoch: 101, iters: 6240, time: 0.165, data: 0.005) loss: 0.638 
(epoch: 101, iters: 6320, time: 0.167, data: 0.025) loss: 0.590 
(epoch: 101, iters: 6400, time: 0.168, data: 0.000) loss: 0.328 
(epoch: 101, iters: 6480, time: 0.165, data: 0.000) loss: 0.530 
(epoch: 101, iters: 6560, time: 0.165, data: 0.000) loss: 0.283 
(epoch: 101, iters: 6640, time: 0.165, data: 0.000) loss: 0.418 
(epoch: 101, iters: 6720, time: 0.165, data: 0.008) loss: 0.539 
(epoch: 101, iters: 6800, time: 0.166, data: 0.008) loss: 0.715 
(epoch: 101, iters: 6880, time: 0.166, data: 0.014) loss: 1.403 
(epoch: 101, iters: 6960, time: 0.165, data: 0.027) loss: 0.351 
(epoch: 101, iters: 7040, time: 0.168, data: 0.000) loss: 0.429 
(epoch: 101, iters: 7120, time: 0.168, data: 0.040) loss: 0.848 
(epoch: 101, iters: 7200, time: 0.176, data: 0.000) loss: 0.631 
(epoch: 101, iters: 7280, time: 0.162, data: 0.000) loss: 0.271 
(epoch: 101, iters: 7360, time: 0.157, data: 0.010) loss: 0.414 
(epoch: 101, iters: 7440, time: 0.158, data: 0.000) loss: 0.767 
(epoch: 101, iters: 7520, time: 0.158, data: 0.025) loss: 0.935 
(epoch: 101, iters: 7600, time: 0.156, data: 0.000) loss: 0.803 
(epoch: 101, iters: 7680, time: 0.159, data: 0.008) loss: 0.518 
(epoch: 101, iters: 7760, time: 0.158, data: 0.000) loss: 0.487 
(epoch: 101, iters: 7840, time: 0.158, data: 0.000) loss: 0.238 
(epoch: 101, iters: 7920, time: 0.161, data: 0.000) loss: 0.851 
(epoch: 101, iters: 8000, time: 0.158, data: 0.008) loss: 0.841 
saving the latest model (epoch 101, total_steps 1027216)
(epoch: 101, iters: 8080, time: 0.157, data: 0.000) loss: 0.414 
(epoch: 101, iters: 8160, time: 0.158, data: 0.005) loss: 0.898 
(epoch: 101, iters: 8240, time: 0.158, data: 0.000) loss: 0.573 
(epoch: 101, iters: 8320, time: 0.158, data: 0.005) loss: 0.337 
(epoch: 101, iters: 8400, time: 0.158, data: 0.008) loss: 0.612 
(epoch: 101, iters: 8480, time: 0.162, data: 0.000) loss: 0.183 
(epoch: 101, iters: 8560, time: 0.157, data: 0.024) loss: 0.216 
(epoch: 101, iters: 8640, time: 0.158, data: 0.000) loss: 0.240 
(epoch: 101, iters: 8720, time: 0.168, data: 0.021) loss: 0.483 
(epoch: 101, iters: 8800, time: 0.157, data: 0.000) loss: 0.272 
(epoch: 101, iters: 8880, time: 0.157, data: 0.005) loss: 0.329 
(epoch: 101, iters: 8960, time: 0.158, data: 0.008) loss: 0.100 
(epoch: 101, iters: 9040, time: 0.159, data: 0.023) loss: 0.104 
(epoch: 101, iters: 9120, time: 0.157, data: 0.005) loss: 0.833 
(epoch: 101, iters: 9200, time: 0.157, data: 0.000) loss: 0.358 
(epoch: 101, iters: 9280, time: 0.160, data: 0.009) loss: 0.954 
(epoch: 101, iters: 9360, time: 0.159, data: 0.005) loss: 1.178 
(epoch: 101, iters: 9440, time: 0.167, data: 0.000) loss: 0.591 
(epoch: 101, iters: 9520, time: 0.157, data: 0.000) loss: 0.458 
(epoch: 101, iters: 9600, time: 0.158, data: 0.015) loss: 0.411 
(epoch: 101, iters: 9680, time: 0.170, data: 0.024) loss: 0.491 
(epoch: 101, iters: 9760, time: 0.160, data: 0.000) loss: 0.508 
(epoch: 101, iters: 9840, time: 0.158, data: 0.013) loss: 0.416 
(epoch: 101, iters: 9920, time: 0.166, data: 0.000) loss: 0.530 
(epoch: 101, iters: 10000, time: 0.158, data: 0.032) loss: 0.485 
(epoch: 101, iters: 10080, time: 0.161, data: 0.000) loss: 0.399 
(epoch: 101, iters: 10160, time: 0.156, data: 0.000) loss: 0.760 
saving the model at the end of epoch 101, iters 1029392
End of epoch 101 / 200 	 Time Taken: 1611 sec
learning rate = 0.0001941
saving the latest model (epoch 102, total_steps 1029408)
(epoch: 102, iters: 48, time: 0.161, data: 0.005) loss: 0.456 
(epoch: 102, iters: 128, time: 0.158, data: 0.016) loss: 0.300 
(epoch: 102, iters: 208, time: 0.159, data: 0.014) loss: 0.247 
(epoch: 102, iters: 288, time: 0.155, data: 0.000) loss: 0.422 
(epoch: 102, iters: 368, time: 0.156, data: 0.000) loss: 0.160 
(epoch: 102, iters: 448, time: 0.158, data: 0.005) loss: 0.754 
(epoch: 102, iters: 528, time: 0.156, data: 0.005) loss: 0.621 
(epoch: 102, iters: 608, time: 0.159, data: 0.000) loss: 0.405 
(epoch: 102, iters: 688, time: 0.157, data: 0.011) loss: 0.947 
(epoch: 102, iters: 768, time: 0.159, data: 0.000) loss: 0.861 
(epoch: 102, iters: 848, time: 0.158, data: 0.027) loss: 0.349 
(epoch: 102, iters: 928, time: 0.158, data: 0.041) loss: 0.319 
(epoch: 102, iters: 1008, time: 0.157, data: 0.000) loss: 0.475 
(epoch: 102, iters: 1088, time: 0.158, data: 0.038) loss: 0.382 
(epoch: 102, iters: 1168, time: 0.159, data: 0.000) loss: 0.267 
(epoch: 102, iters: 1248, time: 0.157, data: 0.000) loss: 0.334 
(epoch: 102, iters: 1328, time: 0.159, data: 0.006) loss: 0.263 
(epoch: 102, iters: 1408, time: 0.159, data: 0.008) loss: 0.816 
(epoch: 102, iters: 1488, time: 0.162, data: 0.000) loss: 0.673 
(epoch: 102, iters: 1568, time: 0.157, data: 0.024) loss: 0.371 
(epoch: 102, iters: 1648, time: 0.161, data: 0.005) loss: 0.488 
(epoch: 102, iters: 1728, time: 0.159, data: 0.000) loss: 0.645 
(epoch: 102, iters: 1808, time: 0.167, data: 0.000) loss: 0.393 
(epoch: 102, iters: 1888, time: 0.157, data: 0.005) loss: 0.255 
(epoch: 102, iters: 1968, time: 0.158, data: 0.000) loss: 0.519 
(epoch: 102, iters: 2048, time: 0.157, data: 0.000) loss: 0.657 
(epoch: 102, iters: 2128, time: 0.157, data: 0.000) loss: 0.731 
(epoch: 102, iters: 2208, time: 0.158, data: 0.009) loss: 0.449 
(epoch: 102, iters: 2288, time: 0.157, data: 0.016) loss: 0.604 
(epoch: 102, iters: 2368, time: 0.155, data: 0.005) loss: 0.957 
(epoch: 102, iters: 2448, time: 0.171, data: 0.006) loss: 0.142 
(epoch: 102, iters: 2528, time: 0.150, data: 0.000) loss: 0.636 
(epoch: 102, iters: 2608, time: 0.152, data: 0.006) loss: 0.499 
(epoch: 102, iters: 2688, time: 0.203, data: 0.000) loss: 0.925 
(epoch: 102, iters: 2768, time: 0.160, data: 0.000) loss: 0.401 
(epoch: 102, iters: 2848, time: 0.160, data: 0.005) loss: 0.955 
(epoch: 102, iters: 2928, time: 0.172, data: 0.000) loss: 0.234 
(epoch: 102, iters: 3008, time: 0.160, data: 0.008) loss: 0.471 
(epoch: 102, iters: 3088, time: 0.158, data: 0.000) loss: 0.362 
(epoch: 102, iters: 3168, time: 0.159, data: 0.020) loss: 0.519 
(epoch: 102, iters: 3248, time: 0.160, data: 0.000) loss: 0.443 
(epoch: 102, iters: 3328, time: 0.163, data: 0.018) loss: 0.764 
(epoch: 102, iters: 3408, time: 0.160, data: 0.000) loss: 0.683 
(epoch: 102, iters: 3488, time: 0.163, data: 0.000) loss: 0.188 
(epoch: 102, iters: 3568, time: 0.177, data: 0.000) loss: 0.581 
(epoch: 102, iters: 3648, time: 0.162, data: 0.035) loss: 0.680 
(epoch: 102, iters: 3728, time: 0.181, data: 0.000) loss: 0.414 
(epoch: 102, iters: 3808, time: 0.173, data: 0.000) loss: 0.369 
(epoch: 102, iters: 3888, time: 0.175, data: 0.009) loss: 0.542 
(epoch: 102, iters: 3968, time: 0.176, data: 0.000) loss: 0.833 
saving the latest model (epoch 102, total_steps 1033408)
(epoch: 102, iters: 4048, time: 0.173, data: 0.005) loss: 0.175 
(epoch: 102, iters: 4128, time: 0.171, data: 0.000) loss: 0.471 
(epoch: 102, iters: 4208, time: 0.169, data: 0.000) loss: 0.832 
(epoch: 102, iters: 4288, time: 0.170, data: 0.000) loss: 0.526 
(epoch: 102, iters: 4368, time: 0.169, data: 0.000) loss: 0.847 
(epoch: 102, iters: 4448, time: 0.169, data: 0.000) loss: 0.517 
(epoch: 102, iters: 4528, time: 0.157, data: 0.030) loss: 0.557 
(epoch: 102, iters: 4608, time: 0.161, data: 0.000) loss: 0.320 
(epoch: 102, iters: 4688, time: 0.160, data: 0.000) loss: 0.623 
(epoch: 102, iters: 4768, time: 0.171, data: 0.014) loss: 0.307 
(epoch: 102, iters: 4848, time: 0.202, data: 0.000) loss: 0.492 
(epoch: 102, iters: 4928, time: 0.170, data: 0.009) loss: 0.683 
(epoch: 102, iters: 5008, time: 0.172, data: 0.000) loss: 0.769 
(epoch: 102, iters: 5088, time: 0.174, data: 0.041) loss: 0.529 
(epoch: 102, iters: 5168, time: 0.224, data: 0.000) loss: 0.465 
(epoch: 102, iters: 5248, time: 0.237, data: 0.008) loss: 0.724 
(epoch: 102, iters: 5328, time: 0.173, data: 0.000) loss: 0.527 
(epoch: 102, iters: 5408, time: 0.172, data: 0.041) loss: 0.581 
(epoch: 102, iters: 5488, time: 0.171, data: 0.000) loss: 0.576 
(epoch: 102, iters: 5568, time: 0.170, data: 0.008) loss: 0.683 
(epoch: 102, iters: 5648, time: 0.158, data: 0.000) loss: 0.494 
(epoch: 102, iters: 5728, time: 0.155, data: 0.018) loss: 0.962 
(epoch: 102, iters: 5808, time: 0.156, data: 0.018) loss: 0.776 
(epoch: 102, iters: 5888, time: 0.157, data: 0.008) loss: 0.818 
(epoch: 102, iters: 5968, time: 0.163, data: 0.006) loss: 0.396 
(epoch: 102, iters: 6048, time: 0.210, data: 0.000) loss: 0.624 
(epoch: 102, iters: 6128, time: 0.158, data: 0.000) loss: 0.636 
(epoch: 102, iters: 6208, time: 0.160, data: 0.000) loss: 1.188 
(epoch: 102, iters: 6288, time: 0.161, data: 0.000) loss: 0.413 
(epoch: 102, iters: 6368, time: 0.162, data: 0.005) loss: 0.337 
(epoch: 102, iters: 6448, time: 0.164, data: 0.021) loss: 0.650 
(epoch: 102, iters: 6528, time: 0.171, data: 0.000) loss: 0.640 
(epoch: 102, iters: 6608, time: 0.165, data: 0.012) loss: 0.614 
(epoch: 102, iters: 6688, time: 0.163, data: 0.000) loss: 0.838 
(epoch: 102, iters: 6768, time: 0.158, data: 0.000) loss: 0.223 
(epoch: 102, iters: 6848, time: 0.160, data: 0.005) loss: 0.721 
(epoch: 102, iters: 6928, time: 0.157, data: 0.000) loss: 0.306 
(epoch: 102, iters: 7008, time: 0.156, data: 0.005) loss: 0.444 
(epoch: 102, iters: 7088, time: 0.170, data: 0.000) loss: 0.635 
(epoch: 102, iters: 7168, time: 0.157, data: 0.000) loss: 0.332 
(epoch: 102, iters: 7248, time: 0.165, data: 0.013) loss: 0.437 
(epoch: 102, iters: 7328, time: 0.162, data: 0.000) loss: 0.552 
(epoch: 102, iters: 7408, time: 0.162, data: 0.000) loss: 0.147 
(epoch: 102, iters: 7488, time: 0.164, data: 0.000) loss: 0.554 
(epoch: 102, iters: 7568, time: 0.162, data: 0.005) loss: 0.418 
(epoch: 102, iters: 7648, time: 0.166, data: 0.000) loss: 0.381 
(epoch: 102, iters: 7728, time: 0.160, data: 0.006) loss: 0.908 
(epoch: 102, iters: 7808, time: 0.160, data: 0.000) loss: 0.489 
(epoch: 102, iters: 7888, time: 0.159, data: 0.010) loss: 0.437 
(epoch: 102, iters: 7968, time: 0.160, data: 0.000) loss: 0.733 
saving the latest model (epoch 102, total_steps 1037408)
(epoch: 102, iters: 8048, time: 0.168, data: 0.014) loss: 0.380 
(epoch: 102, iters: 8128, time: 0.159, data: 0.016) loss: 0.421 
(epoch: 102, iters: 8208, time: 0.164, data: 0.000) loss: 0.634 
(epoch: 102, iters: 8288, time: 0.162, data: 0.000) loss: 0.394 
(epoch: 102, iters: 8368, time: 0.164, data: 0.008) loss: 0.436 
(epoch: 102, iters: 8448, time: 0.161, data: 0.000) loss: 0.880 
(epoch: 102, iters: 8528, time: 0.169, data: 0.000) loss: 0.452 
(epoch: 102, iters: 8608, time: 0.167, data: 0.000) loss: 0.079 
(epoch: 102, iters: 8688, time: 0.165, data: 0.008) loss: 0.714 
(epoch: 102, iters: 8768, time: 0.165, data: 0.000) loss: 0.516 
(epoch: 102, iters: 8848, time: 0.163, data: 0.031) loss: 0.579 
(epoch: 102, iters: 8928, time: 0.165, data: 0.000) loss: 0.259 
(epoch: 102, iters: 9008, time: 0.165, data: 0.000) loss: 0.646 
(epoch: 102, iters: 9088, time: 0.161, data: 0.017) loss: 0.622 
(epoch: 102, iters: 9168, time: 0.163, data: 0.019) loss: 0.386 
(epoch: 102, iters: 9248, time: 0.160, data: 0.000) loss: 1.041 
(epoch: 102, iters: 9328, time: 0.164, data: 0.000) loss: 0.888 
(epoch: 102, iters: 9408, time: 0.162, data: 0.000) loss: 0.302 
(epoch: 102, iters: 9488, time: 0.161, data: 0.000) loss: 0.210 
(epoch: 102, iters: 9568, time: 0.161, data: 0.009) loss: 0.524 
(epoch: 102, iters: 9648, time: 0.160, data: 0.000) loss: 0.455 
(epoch: 102, iters: 9728, time: 0.161, data: 0.008) loss: 0.198 
(epoch: 102, iters: 9808, time: 0.160, data: 0.005) loss: 0.729 
(epoch: 102, iters: 9888, time: 0.160, data: 0.000) loss: 0.519 
(epoch: 102, iters: 9968, time: 0.161, data: 0.000) loss: 0.104 
(epoch: 102, iters: 10048, time: 0.166, data: 0.009) loss: 0.666 
(epoch: 102, iters: 10128, time: 0.165, data: 0.005) loss: 0.685 
saving the model at the end of epoch 102, iters 1039584
End of epoch 102 / 200 	 Time Taken: 1703 sec
learning rate = 0.0001921
(epoch: 103, iters: 16, time: 0.182, data: 0.000) loss: 0.451 
saving the latest model (epoch 103, total_steps 1039600)
(epoch: 103, iters: 96, time: 0.162, data: 0.038) loss: 0.403 
(epoch: 103, iters: 176, time: 0.158, data: 0.000) loss: 0.927 
(epoch: 103, iters: 256, time: 0.160, data: 0.000) loss: 0.391 
(epoch: 103, iters: 336, time: 0.158, data: 0.005) loss: 0.592 
(epoch: 103, iters: 416, time: 0.159, data: 0.000) loss: 0.758 
(epoch: 103, iters: 496, time: 0.174, data: 0.000) loss: 0.310 
(epoch: 103, iters: 576, time: 0.164, data: 0.000) loss: 0.160 
(epoch: 103, iters: 656, time: 0.155, data: 0.021) loss: 0.206 
(epoch: 103, iters: 736, time: 0.165, data: 0.005) loss: 0.760 
(epoch: 103, iters: 816, time: 0.166, data: 0.022) loss: 1.004 
(epoch: 103, iters: 896, time: 0.170, data: 0.009) loss: 0.393 
(epoch: 103, iters: 976, time: 0.158, data: 0.000) loss: 0.557 
(epoch: 103, iters: 1056, time: 0.164, data: 0.000) loss: 0.300 
(epoch: 103, iters: 1136, time: 0.161, data: 0.000) loss: 0.884 
(epoch: 103, iters: 1216, time: 0.158, data: 0.005) loss: 0.756 
(epoch: 103, iters: 1296, time: 0.156, data: 0.013) loss: 0.752 
(epoch: 103, iters: 1376, time: 0.155, data: 0.000) loss: 0.486 
(epoch: 103, iters: 1456, time: 0.152, data: 0.008) loss: 1.026 
(epoch: 103, iters: 1536, time: 0.148, data: 0.000) loss: 0.239 
(epoch: 103, iters: 1616, time: 0.149, data: 0.000) loss: 0.661 
(epoch: 103, iters: 1696, time: 0.153, data: 0.000) loss: 0.635 
(epoch: 103, iters: 1776, time: 0.151, data: 0.007) loss: 0.406 
(epoch: 103, iters: 1856, time: 0.158, data: 0.000) loss: 0.806 
(epoch: 103, iters: 1936, time: 0.156, data: 0.022) loss: 0.636 
(epoch: 103, iters: 2016, time: 0.153, data: 0.013) loss: 0.789 
(epoch: 103, iters: 2096, time: 0.154, data: 0.005) loss: 0.459 
(epoch: 103, iters: 2176, time: 0.155, data: 0.000) loss: 0.560 
(epoch: 103, iters: 2256, time: 0.164, data: 0.014) loss: 0.420 
(epoch: 103, iters: 2336, time: 0.163, data: 0.000) loss: 0.274 
(epoch: 103, iters: 2416, time: 0.155, data: 0.000) loss: 0.480 
(epoch: 103, iters: 2496, time: 0.164, data: 0.005) loss: 0.636 
(epoch: 103, iters: 2576, time: 0.156, data: 0.000) loss: 0.164 
(epoch: 103, iters: 2656, time: 0.156, data: 0.000) loss: 0.381 
(epoch: 103, iters: 2736, time: 0.155, data: 0.005) loss: 0.849 
(epoch: 103, iters: 2816, time: 0.154, data: 0.020) loss: 0.555 
(epoch: 103, iters: 2896, time: 0.155, data: 0.000) loss: 0.677 
(epoch: 103, iters: 2976, time: 0.152, data: 0.000) loss: 0.517 
(epoch: 103, iters: 3056, time: 0.151, data: 0.006) loss: 0.972 
(epoch: 103, iters: 3136, time: 0.150, data: 0.033) loss: 0.507 
(epoch: 103, iters: 3216, time: 0.151, data: 0.000) loss: 0.313 
(epoch: 103, iters: 3296, time: 0.153, data: 0.014) loss: 0.771 
(epoch: 103, iters: 3376, time: 0.151, data: 0.000) loss: 0.543 
(epoch: 103, iters: 3456, time: 0.153, data: 0.013) loss: 0.404 
(epoch: 103, iters: 3536, time: 0.152, data: 0.000) loss: 0.594 
(epoch: 103, iters: 3616, time: 0.155, data: 0.000) loss: 0.668 
(epoch: 103, iters: 3696, time: 0.157, data: 0.000) loss: 0.469 
(epoch: 103, iters: 3776, time: 0.154, data: 0.006) loss: 0.187 
(epoch: 103, iters: 3856, time: 0.156, data: 0.006) loss: 0.499 
(epoch: 103, iters: 3936, time: 0.153, data: 0.000) loss: 0.369 
(epoch: 103, iters: 4016, time: 0.154, data: 0.000) loss: 0.434 
saving the latest model (epoch 103, total_steps 1043600)
(epoch: 103, iters: 4096, time: 0.156, data: 0.006) loss: 0.260 
(epoch: 103, iters: 4176, time: 0.157, data: 0.015) loss: 0.290 
(epoch: 103, iters: 4256, time: 0.155, data: 0.000) loss: 0.582 
(epoch: 103, iters: 4336, time: 0.153, data: 0.013) loss: 1.059 
(epoch: 103, iters: 4416, time: 0.153, data: 0.000) loss: 0.391 
(epoch: 103, iters: 4496, time: 0.156, data: 0.006) loss: 0.243 
(epoch: 103, iters: 4576, time: 0.155, data: 0.008) loss: 0.521 
(epoch: 103, iters: 4656, time: 0.155, data: 0.000) loss: 0.427 
(epoch: 103, iters: 4736, time: 0.155, data: 0.000) loss: 0.526 
(epoch: 103, iters: 4816, time: 0.152, data: 0.000) loss: 0.328 
(epoch: 103, iters: 4896, time: 0.152, data: 0.008) loss: 0.497 
(epoch: 103, iters: 4976, time: 0.154, data: 0.000) loss: 0.137 
(epoch: 103, iters: 5056, time: 0.154, data: 0.000) loss: 0.423 
(epoch: 103, iters: 5136, time: 0.156, data: 0.006) loss: 1.086 
(epoch: 103, iters: 5216, time: 0.157, data: 0.000) loss: 0.181 
(epoch: 103, iters: 5296, time: 0.152, data: 0.008) loss: 0.250 
(epoch: 103, iters: 5376, time: 0.152, data: 0.000) loss: 0.380 
(epoch: 103, iters: 5456, time: 0.154, data: 0.005) loss: 0.283 
(epoch: 103, iters: 5536, time: 0.154, data: 0.000) loss: 0.499 
(epoch: 103, iters: 5616, time: 0.154, data: 0.000) loss: 0.208 
(epoch: 103, iters: 5696, time: 0.154, data: 0.000) loss: 1.140 
(epoch: 103, iters: 5776, time: 0.155, data: 0.000) loss: 0.767 
(epoch: 103, iters: 5856, time: 0.157, data: 0.000) loss: 0.798 
(epoch: 103, iters: 5936, time: 0.154, data: 0.008) loss: 0.579 
(epoch: 103, iters: 6016, time: 0.153, data: 0.000) loss: 1.011 
(epoch: 103, iters: 6096, time: 0.162, data: 0.000) loss: 0.415 
(epoch: 103, iters: 6176, time: 0.161, data: 0.010) loss: 0.389 
(epoch: 103, iters: 6256, time: 0.162, data: 0.000) loss: 1.030 
(epoch: 103, iters: 6336, time: 0.163, data: 0.022) loss: 0.970 
(epoch: 103, iters: 6416, time: 0.168, data: 0.000) loss: 0.261 
(epoch: 103, iters: 6496, time: 0.159, data: 0.000) loss: 0.703 
(epoch: 103, iters: 6576, time: 0.157, data: 0.015) loss: 0.628 
(epoch: 103, iters: 6656, time: 0.159, data: 0.000) loss: 0.424 
(epoch: 103, iters: 6736, time: 0.160, data: 0.000) loss: 0.352 
(epoch: 103, iters: 6816, time: 0.166, data: 0.000) loss: 0.659 
(epoch: 103, iters: 6896, time: 0.158, data: 0.000) loss: 0.677 
(epoch: 103, iters: 6976, time: 0.157, data: 0.019) loss: 1.077 
(epoch: 103, iters: 7056, time: 0.159, data: 0.000) loss: 0.269 
(epoch: 103, iters: 7136, time: 0.158, data: 0.000) loss: 0.772 
(epoch: 103, iters: 7216, time: 0.160, data: 0.005) loss: 0.497 
(epoch: 103, iters: 7296, time: 0.157, data: 0.000) loss: 0.629 
(epoch: 103, iters: 7376, time: 0.163, data: 0.019) loss: 0.260 
(epoch: 103, iters: 7456, time: 0.150, data: 0.005) loss: 0.552 
(epoch: 103, iters: 7536, time: 0.151, data: 0.008) loss: 0.530 
(epoch: 103, iters: 7616, time: 0.157, data: 0.000) loss: 0.484 
(epoch: 103, iters: 7696, time: 0.153, data: 0.032) loss: 0.398 
(epoch: 103, iters: 7776, time: 0.150, data: 0.000) loss: 0.392 
(epoch: 103, iters: 7856, time: 0.157, data: 0.000) loss: 0.453 
(epoch: 103, iters: 7936, time: 0.159, data: 0.008) loss: 0.398 
(epoch: 103, iters: 8016, time: 0.158, data: 0.000) loss: 0.559 
saving the latest model (epoch 103, total_steps 1047600)
(epoch: 103, iters: 8096, time: 0.160, data: 0.000) loss: 0.415 
(epoch: 103, iters: 8176, time: 0.159, data: 0.005) loss: 0.571 
(epoch: 103, iters: 8256, time: 0.161, data: 0.006) loss: 0.775 
(epoch: 103, iters: 8336, time: 0.158, data: 0.000) loss: 0.335 
(epoch: 103, iters: 8416, time: 0.157, data: 0.013) loss: 0.354 
(epoch: 103, iters: 8496, time: 0.159, data: 0.005) loss: 0.732 
(epoch: 103, iters: 8576, time: 0.159, data: 0.005) loss: 0.682 
(epoch: 103, iters: 8656, time: 0.160, data: 0.017) loss: 0.360 
(epoch: 103, iters: 8736, time: 0.158, data: 0.000) loss: 1.013 
(epoch: 103, iters: 8816, time: 0.157, data: 0.032) loss: 0.209 
(epoch: 103, iters: 8896, time: 0.158, data: 0.000) loss: 1.260 
(epoch: 103, iters: 8976, time: 0.160, data: 0.000) loss: 0.542 
(epoch: 103, iters: 9056, time: 0.159, data: 0.005) loss: 0.622 
(epoch: 103, iters: 9136, time: 0.165, data: 0.000) loss: 0.153 
(epoch: 103, iters: 9216, time: 0.158, data: 0.037) loss: 0.414 
(epoch: 103, iters: 9296, time: 0.160, data: 0.000) loss: 0.658 
(epoch: 103, iters: 9376, time: 0.158, data: 0.027) loss: 0.853 
(epoch: 103, iters: 9456, time: 0.157, data: 0.000) loss: 0.490 
(epoch: 103, iters: 9536, time: 0.160, data: 0.011) loss: 0.194 
(epoch: 103, iters: 9616, time: 0.158, data: 0.016) loss: 0.083 
(epoch: 103, iters: 9696, time: 0.158, data: 0.000) loss: 0.780 
(epoch: 103, iters: 9776, time: 0.161, data: 0.021) loss: 0.721 
(epoch: 103, iters: 9856, time: 0.162, data: 0.000) loss: 0.288 
(epoch: 103, iters: 9936, time: 0.160, data: 0.000) loss: 0.979 
(epoch: 103, iters: 10016, time: 0.160, data: 0.000) loss: 0.223 
(epoch: 103, iters: 10096, time: 0.161, data: 0.005) loss: 0.395 
(epoch: 103, iters: 10176, time: 0.160, data: 0.000) loss: 0.491 
saving the model at the end of epoch 103, iters 1049776
End of epoch 103 / 200 	 Time Taken: 1610 sec
learning rate = 0.0001901
saving the latest model (epoch 104, total_steps 1049792)
(epoch: 104, iters: 64, time: 0.162, data: 0.003) loss: 0.241 
(epoch: 104, iters: 144, time: 0.158, data: 0.012) loss: 0.126 
(epoch: 104, iters: 224, time: 0.161, data: 0.006) loss: 0.900 
(epoch: 104, iters: 304, time: 0.160, data: 0.000) loss: 1.113 
(epoch: 104, iters: 384, time: 0.163, data: 0.013) loss: 0.399 
(epoch: 104, iters: 464, time: 0.161, data: 0.000) loss: 0.192 
(epoch: 104, iters: 544, time: 0.160, data: 0.013) loss: 0.145 
(epoch: 104, iters: 624, time: 0.161, data: 0.008) loss: 0.698 
(epoch: 104, iters: 704, time: 0.158, data: 0.000) loss: 0.312 
(epoch: 104, iters: 784, time: 0.157, data: 0.000) loss: 1.082 
(epoch: 104, iters: 864, time: 0.159, data: 0.000) loss: 0.135 
(epoch: 104, iters: 944, time: 0.160, data: 0.000) loss: 0.426 
(epoch: 104, iters: 1024, time: 0.156, data: 0.032) loss: 0.399 
(epoch: 104, iters: 1104, time: 0.157, data: 0.000) loss: 1.127 
(epoch: 104, iters: 1184, time: 0.159, data: 0.015) loss: 1.133 
(epoch: 104, iters: 1264, time: 0.164, data: 0.000) loss: 0.990 
(epoch: 104, iters: 1344, time: 0.157, data: 0.017) loss: 0.641 
(epoch: 104, iters: 1424, time: 0.161, data: 0.024) loss: 0.311 
(epoch: 104, iters: 1504, time: 0.158, data: 0.000) loss: 0.576 
(epoch: 104, iters: 1584, time: 0.158, data: 0.000) loss: 0.366 
(epoch: 104, iters: 1664, time: 0.157, data: 0.013) loss: 0.441 
(epoch: 104, iters: 1744, time: 0.156, data: 0.000) loss: 0.089 
(epoch: 104, iters: 1824, time: 0.160, data: 0.005) loss: 0.834 
(epoch: 104, iters: 1904, time: 0.158, data: 0.000) loss: 0.876 
(epoch: 104, iters: 1984, time: 0.161, data: 0.000) loss: 0.626 
(epoch: 104, iters: 2064, time: 0.161, data: 0.009) loss: 0.462 
(epoch: 104, iters: 2144, time: 0.163, data: 0.005) loss: 1.191 
(epoch: 104, iters: 2224, time: 0.159, data: 0.005) loss: 0.707 
(epoch: 104, iters: 2304, time: 0.159, data: 0.000) loss: 0.449 
(epoch: 104, iters: 2384, time: 0.158, data: 0.000) loss: 0.192 
(epoch: 104, iters: 2464, time: 0.159, data: 0.011) loss: 0.954 
(epoch: 104, iters: 2544, time: 0.158, data: 0.000) loss: 0.552 
(epoch: 104, iters: 2624, time: 0.162, data: 0.000) loss: 0.380 
(epoch: 104, iters: 2704, time: 0.164, data: 0.008) loss: 0.315 
(epoch: 104, iters: 2784, time: 0.161, data: 0.000) loss: 0.454 
(epoch: 104, iters: 2864, time: 0.169, data: 0.030) loss: 0.569 
(epoch: 104, iters: 2944, time: 0.161, data: 0.000) loss: 0.207 
(epoch: 104, iters: 3024, time: 0.162, data: 0.000) loss: 0.453 
(epoch: 104, iters: 3104, time: 0.162, data: 0.005) loss: 0.946 
(epoch: 104, iters: 3184, time: 0.164, data: 0.000) loss: 0.307 
(epoch: 104, iters: 3264, time: 0.161, data: 0.000) loss: 0.355 
(epoch: 104, iters: 3344, time: 0.161, data: 0.006) loss: 0.386 
(epoch: 104, iters: 3424, time: 0.163, data: 0.005) loss: 0.518 
(epoch: 104, iters: 3504, time: 0.175, data: 0.016) loss: 0.579 
(epoch: 104, iters: 3584, time: 0.165, data: 0.000) loss: 0.542 
(epoch: 104, iters: 3664, time: 0.162, data: 0.005) loss: 0.573 
(epoch: 104, iters: 3744, time: 0.170, data: 0.008) loss: 0.151 
(epoch: 104, iters: 3824, time: 0.166, data: 0.000) loss: 0.305 
(epoch: 104, iters: 3904, time: 0.177, data: 0.005) loss: 0.353 
(epoch: 104, iters: 3984, time: 0.153, data: 0.000) loss: 0.583 
saving the latest model (epoch 104, total_steps 1053792)
(epoch: 104, iters: 4064, time: 0.156, data: 0.005) loss: 0.288 
(epoch: 104, iters: 4144, time: 0.159, data: 0.005) loss: 0.705 
(epoch: 104, iters: 4224, time: 0.163, data: 0.000) loss: 0.250 
(epoch: 104, iters: 4304, time: 0.165, data: 0.023) loss: 0.704 
(epoch: 104, iters: 4384, time: 0.163, data: 0.000) loss: 0.643 
(epoch: 104, iters: 4464, time: 0.175, data: 0.000) loss: 0.433 
(epoch: 104, iters: 4544, time: 0.162, data: 0.022) loss: 0.326 
(epoch: 104, iters: 4624, time: 0.166, data: 0.000) loss: 0.334 
(epoch: 104, iters: 4704, time: 0.165, data: 0.000) loss: 0.785 
(epoch: 104, iters: 4784, time: 0.184, data: 0.037) loss: 0.589 
(epoch: 104, iters: 4864, time: 0.182, data: 0.000) loss: 0.648 
(epoch: 104, iters: 4944, time: 0.186, data: 0.000) loss: 1.013 
(epoch: 104, iters: 5024, time: 0.166, data: 0.022) loss: 0.699 
(epoch: 104, iters: 5104, time: 0.163, data: 0.029) loss: 0.792 
(epoch: 104, iters: 5184, time: 0.159, data: 0.000) loss: 0.896 
(epoch: 104, iters: 5264, time: 0.161, data: 0.005) loss: 1.158 
(epoch: 104, iters: 5344, time: 0.162, data: 0.005) loss: 0.866 
(epoch: 104, iters: 5424, time: 0.171, data: 0.000) loss: 0.505 
(epoch: 104, iters: 5504, time: 0.161, data: 0.039) loss: 0.414 
(epoch: 104, iters: 5584, time: 0.169, data: 0.000) loss: 0.934 
(epoch: 104, iters: 5664, time: 0.160, data: 0.000) loss: 0.516 
(epoch: 104, iters: 5744, time: 0.165, data: 0.000) loss: 0.309 
(epoch: 104, iters: 5824, time: 0.165, data: 0.000) loss: 0.793 
(epoch: 104, iters: 5904, time: 0.181, data: 0.006) loss: 0.795 
(epoch: 104, iters: 5984, time: 0.164, data: 0.012) loss: 0.853 
(epoch: 104, iters: 6064, time: 0.166, data: 0.000) loss: 0.611 
(epoch: 104, iters: 6144, time: 0.166, data: 0.000) loss: 0.269 
(epoch: 104, iters: 6224, time: 0.162, data: 0.000) loss: 0.869 
(epoch: 104, iters: 6304, time: 0.165, data: 0.000) loss: 0.609 
(epoch: 104, iters: 6384, time: 0.164, data: 0.000) loss: 0.605 
(epoch: 104, iters: 6464, time: 0.164, data: 0.000) loss: 0.331 
(epoch: 104, iters: 6544, time: 0.162, data: 0.008) loss: 0.302 
(epoch: 104, iters: 6624, time: 0.161, data: 0.000) loss: 0.332 
(epoch: 104, iters: 6704, time: 0.161, data: 0.005) loss: 0.388 
(epoch: 104, iters: 6784, time: 0.160, data: 0.000) loss: 0.221 
(epoch: 104, iters: 6864, time: 0.168, data: 0.000) loss: 0.476 
(epoch: 104, iters: 6944, time: 0.165, data: 0.020) loss: 0.685 
(epoch: 104, iters: 7024, time: 0.164, data: 0.000) loss: 0.280 
(epoch: 104, iters: 7104, time: 0.167, data: 0.000) loss: 0.350 
(epoch: 104, iters: 7184, time: 0.167, data: 0.000) loss: 0.333 
(epoch: 104, iters: 7264, time: 0.169, data: 0.031) loss: 0.688 
(epoch: 104, iters: 7344, time: 0.162, data: 0.000) loss: 0.563 
(epoch: 104, iters: 7424, time: 0.158, data: 0.008) loss: 0.439 
(epoch: 104, iters: 7504, time: 0.159, data: 0.029) loss: 0.598 
(epoch: 104, iters: 7584, time: 0.162, data: 0.000) loss: 0.372 
(epoch: 104, iters: 7664, time: 0.162, data: 0.005) loss: 1.042 
(epoch: 104, iters: 7744, time: 0.158, data: 0.000) loss: 1.034 
(epoch: 104, iters: 7824, time: 0.160, data: 0.000) loss: 0.896 
(epoch: 104, iters: 7904, time: 0.158, data: 0.000) loss: 0.765 
(epoch: 104, iters: 7984, time: 0.161, data: 0.000) loss: 0.379 
saving the latest model (epoch 104, total_steps 1057792)
(epoch: 104, iters: 8064, time: 0.160, data: 0.012) loss: 0.592 
(epoch: 104, iters: 8144, time: 0.161, data: 0.000) loss: 0.424 
(epoch: 104, iters: 8224, time: 0.163, data: 0.000) loss: 0.438 
(epoch: 104, iters: 8304, time: 0.160, data: 0.000) loss: 0.542 
(epoch: 104, iters: 8384, time: 0.163, data: 0.015) loss: 0.857 
(epoch: 104, iters: 8464, time: 0.160, data: 0.000) loss: 0.252 
(epoch: 104, iters: 8544, time: 0.160, data: 0.000) loss: 0.532 
(epoch: 104, iters: 8624, time: 0.163, data: 0.000) loss: 0.222 
(epoch: 104, iters: 8704, time: 0.169, data: 0.016) loss: 0.467 
(epoch: 104, iters: 8784, time: 0.162, data: 0.000) loss: 0.313 
(epoch: 104, iters: 8864, time: 0.161, data: 0.000) loss: 0.788 
(epoch: 104, iters: 8944, time: 0.162, data: 0.029) loss: 0.593 
(epoch: 104, iters: 9024, time: 0.164, data: 0.000) loss: 0.439 
(epoch: 104, iters: 9104, time: 0.160, data: 0.022) loss: 0.203 
(epoch: 104, iters: 9184, time: 0.162, data: 0.008) loss: 0.645 
(epoch: 104, iters: 9264, time: 0.162, data: 0.008) loss: 0.575 
(epoch: 104, iters: 9344, time: 0.164, data: 0.000) loss: 0.595 
(epoch: 104, iters: 9424, time: 0.163, data: 0.039) loss: 0.366 
(epoch: 104, iters: 9504, time: 0.161, data: 0.000) loss: 0.324 
(epoch: 104, iters: 9584, time: 0.165, data: 0.000) loss: 0.796 
(epoch: 104, iters: 9664, time: 0.162, data: 0.000) loss: 0.381 
(epoch: 104, iters: 9744, time: 0.162, data: 0.000) loss: 0.286 
(epoch: 104, iters: 9824, time: 0.161, data: 0.009) loss: 0.837 
(epoch: 104, iters: 9904, time: 0.163, data: 0.000) loss: 0.849 
(epoch: 104, iters: 9984, time: 0.162, data: 0.000) loss: 1.106 
(epoch: 104, iters: 10064, time: 0.168, data: 0.000) loss: 0.397 
(epoch: 104, iters: 10144, time: 0.160, data: 0.005) loss: 0.699 
saving the model at the end of epoch 104, iters 1059968
End of epoch 104 / 200 	 Time Taken: 1671 sec
learning rate = 0.0001881
saving the latest model (epoch 105, total_steps 1059984)
(epoch: 105, iters: 32, time: 0.155, data: 0.000) loss: 0.679 
(epoch: 105, iters: 112, time: 0.159, data: 0.000) loss: 0.442 
(epoch: 105, iters: 192, time: 0.153, data: 0.000) loss: 0.477 
(epoch: 105, iters: 272, time: 0.154, data: 0.010) loss: 0.494 
(epoch: 105, iters: 352, time: 0.155, data: 0.000) loss: 0.347 
(epoch: 105, iters: 432, time: 0.155, data: 0.000) loss: 0.975 
(epoch: 105, iters: 512, time: 0.164, data: 0.011) loss: 0.489 
(epoch: 105, iters: 592, time: 0.158, data: 0.000) loss: 0.488 
(epoch: 105, iters: 672, time: 0.157, data: 0.000) loss: 0.376 
(epoch: 105, iters: 752, time: 0.160, data: 0.000) loss: 0.509 
(epoch: 105, iters: 832, time: 0.158, data: 0.023) loss: 0.482 
(epoch: 105, iters: 912, time: 0.164, data: 0.000) loss: 0.567 
(epoch: 105, iters: 992, time: 0.166, data: 0.017) loss: 0.487 
(epoch: 105, iters: 1072, time: 0.168, data: 0.000) loss: 0.206 
(epoch: 105, iters: 1152, time: 0.164, data: 0.022) loss: 0.348 
(epoch: 105, iters: 1232, time: 0.161, data: 0.024) loss: 0.697 
(epoch: 105, iters: 1312, time: 0.160, data: 0.000) loss: 0.390 
(epoch: 105, iters: 1392, time: 0.172, data: 0.008) loss: 0.106 
(epoch: 105, iters: 1472, time: 0.165, data: 0.000) loss: 0.541 
(epoch: 105, iters: 1552, time: 0.168, data: 0.016) loss: 0.494 
(epoch: 105, iters: 1632, time: 0.168, data: 0.000) loss: 0.769 
(epoch: 105, iters: 1712, time: 0.164, data: 0.000) loss: 0.554 
(epoch: 105, iters: 1792, time: 0.165, data: 0.006) loss: 0.465 
(epoch: 105, iters: 1872, time: 0.161, data: 0.005) loss: 0.534 
(epoch: 105, iters: 1952, time: 0.160, data: 0.000) loss: 0.448 
(epoch: 105, iters: 2032, time: 0.162, data: 0.008) loss: 0.878 
(epoch: 105, iters: 2112, time: 0.166, data: 0.000) loss: 0.402 
(epoch: 105, iters: 2192, time: 0.164, data: 0.009) loss: 0.208 
(epoch: 105, iters: 2272, time: 0.164, data: 0.000) loss: 0.580 
(epoch: 105, iters: 2352, time: 0.166, data: 0.009) loss: 0.091 
(epoch: 105, iters: 2432, time: 0.171, data: 0.032) loss: 0.266 
(epoch: 105, iters: 2512, time: 0.164, data: 0.000) loss: 0.573 
(epoch: 105, iters: 2592, time: 0.160, data: 0.000) loss: 0.681 
(epoch: 105, iters: 2672, time: 0.163, data: 0.000) loss: 0.676 
(epoch: 105, iters: 2752, time: 0.164, data: 0.012) loss: 0.742 
(epoch: 105, iters: 2832, time: 0.162, data: 0.000) loss: 0.445 
(epoch: 105, iters: 2912, time: 0.159, data: 0.000) loss: 0.507 
(epoch: 105, iters: 2992, time: 0.157, data: 0.021) loss: 0.286 
(epoch: 105, iters: 3072, time: 0.162, data: 0.000) loss: 0.324 
(epoch: 105, iters: 3152, time: 0.155, data: 0.005) loss: 1.284 
(epoch: 105, iters: 3232, time: 0.156, data: 0.000) loss: 0.261 
(epoch: 105, iters: 3312, time: 0.156, data: 0.006) loss: 0.438 
(epoch: 105, iters: 3392, time: 0.156, data: 0.000) loss: 0.433 
(epoch: 105, iters: 3472, time: 0.156, data: 0.041) loss: 0.919 
(epoch: 105, iters: 3552, time: 0.153, data: 0.000) loss: 0.242 
(epoch: 105, iters: 3632, time: 0.157, data: 0.005) loss: 0.289 
(epoch: 105, iters: 3712, time: 0.155, data: 0.000) loss: 0.352 
(epoch: 105, iters: 3792, time: 0.155, data: 0.031) loss: 1.164 
(epoch: 105, iters: 3872, time: 0.155, data: 0.000) loss: 0.488 
(epoch: 105, iters: 3952, time: 0.156, data: 0.005) loss: 0.329 
saving the latest model (epoch 105, total_steps 1063984)
(epoch: 105, iters: 4032, time: 0.156, data: 0.000) loss: 0.451 
(epoch: 105, iters: 4112, time: 0.157, data: 0.000) loss: 0.318 
(epoch: 105, iters: 4192, time: 0.156, data: 0.000) loss: 0.254 
(epoch: 105, iters: 4272, time: 0.155, data: 0.015) loss: 1.266 
(epoch: 105, iters: 4352, time: 0.153, data: 0.017) loss: 1.146 
(epoch: 105, iters: 4432, time: 0.154, data: 0.000) loss: 0.383 
(epoch: 105, iters: 4512, time: 0.157, data: 0.023) loss: 0.064 
(epoch: 105, iters: 4592, time: 0.154, data: 0.000) loss: 0.494 
(epoch: 105, iters: 4672, time: 0.153, data: 0.005) loss: 0.606 
(epoch: 105, iters: 4752, time: 0.157, data: 0.000) loss: 0.076 
(epoch: 105, iters: 4832, time: 0.157, data: 0.025) loss: 0.408 
(epoch: 105, iters: 4912, time: 0.163, data: 0.000) loss: 0.527 
(epoch: 105, iters: 4992, time: 0.155, data: 0.013) loss: 0.188 
(epoch: 105, iters: 5072, time: 0.159, data: 0.000) loss: 0.538 
(epoch: 105, iters: 5152, time: 0.157, data: 0.010) loss: 0.537 
(epoch: 105, iters: 5232, time: 0.155, data: 0.025) loss: 0.757 
(epoch: 105, iters: 5312, time: 0.160, data: 0.000) loss: 0.902 
(epoch: 105, iters: 5392, time: 0.155, data: 0.000) loss: 0.439 
(epoch: 105, iters: 5472, time: 0.157, data: 0.008) loss: 0.571 
(epoch: 105, iters: 5552, time: 0.157, data: 0.008) loss: 0.288 
(epoch: 105, iters: 5632, time: 0.155, data: 0.006) loss: 0.252 
(epoch: 105, iters: 5712, time: 0.158, data: 0.000) loss: 1.090 
(epoch: 105, iters: 5792, time: 0.157, data: 0.024) loss: 0.417 
(epoch: 105, iters: 5872, time: 0.154, data: 0.000) loss: 0.405 
(epoch: 105, iters: 5952, time: 0.156, data: 0.006) loss: 0.285 
(epoch: 105, iters: 6032, time: 0.161, data: 0.008) loss: 0.474 
(epoch: 105, iters: 6112, time: 0.158, data: 0.006) loss: 0.758 
(epoch: 105, iters: 6192, time: 0.159, data: 0.000) loss: 0.144 
(epoch: 105, iters: 6272, time: 0.156, data: 0.017) loss: 0.575 
(epoch: 105, iters: 6352, time: 0.156, data: 0.000) loss: 0.294 
(epoch: 105, iters: 6432, time: 0.159, data: 0.000) loss: 0.340 
(epoch: 105, iters: 6512, time: 0.160, data: 0.006) loss: 0.772 
(epoch: 105, iters: 6592, time: 0.157, data: 0.000) loss: 0.794 
(epoch: 105, iters: 6672, time: 0.159, data: 0.000) loss: 0.689 
(epoch: 105, iters: 6752, time: 0.158, data: 0.000) loss: 0.863 
(epoch: 105, iters: 6832, time: 0.157, data: 0.000) loss: 0.438 
(epoch: 105, iters: 6912, time: 0.156, data: 0.000) loss: 0.723 
(epoch: 105, iters: 6992, time: 0.156, data: 0.000) loss: 0.613 
(epoch: 105, iters: 7072, time: 0.158, data: 0.012) loss: 1.120 
(epoch: 105, iters: 7152, time: 0.156, data: 0.008) loss: 0.272 
(epoch: 105, iters: 7232, time: 0.158, data: 0.000) loss: 0.426 
(epoch: 105, iters: 7312, time: 0.158, data: 0.033) loss: 0.991 
(epoch: 105, iters: 7392, time: 0.156, data: 0.000) loss: 0.588 
(epoch: 105, iters: 7472, time: 0.155, data: 0.036) loss: 0.176 
(epoch: 105, iters: 7552, time: 0.155, data: 0.000) loss: 0.280 
(epoch: 105, iters: 7632, time: 0.155, data: 0.033) loss: 0.417 
(epoch: 105, iters: 7712, time: 0.158, data: 0.000) loss: 0.199 
(epoch: 105, iters: 7792, time: 0.155, data: 0.013) loss: 0.481 
(epoch: 105, iters: 7872, time: 0.158, data: 0.000) loss: 0.787 
(epoch: 105, iters: 7952, time: 0.155, data: 0.006) loss: 0.320 
saving the latest model (epoch 105, total_steps 1067984)
(epoch: 105, iters: 8032, time: 0.156, data: 0.000) loss: 0.241 
(epoch: 105, iters: 8112, time: 0.155, data: 0.008) loss: 1.119 
(epoch: 105, iters: 8192, time: 0.160, data: 0.000) loss: 0.893 
(epoch: 105, iters: 8272, time: 0.157, data: 0.000) loss: 0.377 
(epoch: 105, iters: 8352, time: 0.155, data: 0.009) loss: 0.949 
(epoch: 105, iters: 8432, time: 0.158, data: 0.000) loss: 0.684 
(epoch: 105, iters: 8512, time: 0.155, data: 0.005) loss: 1.230 
(epoch: 105, iters: 8592, time: 0.154, data: 0.000) loss: 0.626 
(epoch: 105, iters: 8672, time: 0.153, data: 0.016) loss: 0.604 
(epoch: 105, iters: 8752, time: 0.157, data: 0.000) loss: 0.926 
(epoch: 105, iters: 8832, time: 0.154, data: 0.013) loss: 0.666 
(epoch: 105, iters: 8912, time: 0.158, data: 0.000) loss: 0.464 
(epoch: 105, iters: 8992, time: 0.154, data: 0.000) loss: 0.496 
(epoch: 105, iters: 9072, time: 0.157, data: 0.017) loss: 0.404 
(epoch: 105, iters: 9152, time: 0.156, data: 0.000) loss: 0.292 
(epoch: 105, iters: 9232, time: 0.155, data: 0.005) loss: 0.705 
(epoch: 105, iters: 9312, time: 0.157, data: 0.000) loss: 0.190 
(epoch: 105, iters: 9392, time: 0.156, data: 0.026) loss: 0.491 
(epoch: 105, iters: 9472, time: 0.155, data: 0.000) loss: 0.607 
(epoch: 105, iters: 9552, time: 0.156, data: 0.000) loss: 0.789 
(epoch: 105, iters: 9632, time: 0.158, data: 0.037) loss: 0.473 
(epoch: 105, iters: 9712, time: 0.155, data: 0.000) loss: 0.465 
(epoch: 105, iters: 9792, time: 0.156, data: 0.000) loss: 0.289 
(epoch: 105, iters: 9872, time: 0.156, data: 0.000) loss: 0.137 
(epoch: 105, iters: 9952, time: 0.155, data: 0.000) loss: 0.600 
(epoch: 105, iters: 10032, time: 0.156, data: 0.000) loss: 0.271 
(epoch: 105, iters: 10112, time: 0.160, data: 0.000) loss: 0.430 
(epoch: 105, iters: 10192, time: 0.093, data: 0.018) loss: 0.286 
saving the model at the end of epoch 105, iters 1070160
End of epoch 105 / 200 	 Time Taken: 1618 sec
learning rate = 0.0001861
saving the latest model (epoch 106, total_steps 1070176)
(epoch: 106, iters: 80, time: 0.163, data: 0.171) loss: 0.317 
(epoch: 106, iters: 160, time: 0.160, data: 0.000) loss: 0.205 
(epoch: 106, iters: 240, time: 0.164, data: 0.014) loss: 0.562 
(epoch: 106, iters: 320, time: 0.159, data: 0.000) loss: 0.109 
(epoch: 106, iters: 400, time: 0.156, data: 0.000) loss: 0.149 
(epoch: 106, iters: 480, time: 0.158, data: 0.000) loss: 0.539 
(epoch: 106, iters: 560, time: 0.159, data: 0.022) loss: 0.631 
(epoch: 106, iters: 640, time: 0.164, data: 0.006) loss: 0.393 
(epoch: 106, iters: 720, time: 0.157, data: 0.006) loss: 0.431 
(epoch: 106, iters: 800, time: 0.157, data: 0.000) loss: 0.412 
(epoch: 106, iters: 880, time: 0.158, data: 0.015) loss: 0.166 
(epoch: 106, iters: 960, time: 0.157, data: 0.000) loss: 0.095 
(epoch: 106, iters: 1040, time: 0.158, data: 0.000) loss: 0.451 
(epoch: 106, iters: 1120, time: 0.156, data: 0.019) loss: 0.434 
(epoch: 106, iters: 1200, time: 0.158, data: 0.022) loss: 0.556 
(epoch: 106, iters: 1280, time: 0.159, data: 0.000) loss: 0.479 
(epoch: 106, iters: 1360, time: 0.156, data: 0.000) loss: 0.338 
(epoch: 106, iters: 1440, time: 0.158, data: 0.000) loss: 0.590 
(epoch: 106, iters: 1520, time: 0.156, data: 0.018) loss: 0.452 
(epoch: 106, iters: 1600, time: 0.156, data: 0.032) loss: 0.342 
(epoch: 106, iters: 1680, time: 0.156, data: 0.000) loss: 0.569 
(epoch: 106, iters: 1760, time: 0.157, data: 0.000) loss: 0.532 
(epoch: 106, iters: 1840, time: 0.157, data: 0.000) loss: 0.935 
(epoch: 106, iters: 1920, time: 0.157, data: 0.009) loss: 0.462 
(epoch: 106, iters: 2000, time: 0.156, data: 0.000) loss: 0.061 
(epoch: 106, iters: 2080, time: 0.158, data: 0.016) loss: 0.839 
(epoch: 106, iters: 2160, time: 0.158, data: 0.005) loss: 0.519 
(epoch: 106, iters: 2240, time: 0.158, data: 0.005) loss: 0.844 
(epoch: 106, iters: 2320, time: 0.156, data: 0.000) loss: 0.538 
(epoch: 106, iters: 2400, time: 0.156, data: 0.008) loss: 0.524 
(epoch: 106, iters: 2480, time: 0.158, data: 0.000) loss: 0.258 
(epoch: 106, iters: 2560, time: 0.157, data: 0.008) loss: 0.140 
(epoch: 106, iters: 2640, time: 0.155, data: 0.006) loss: 0.286 
(epoch: 106, iters: 2720, time: 0.155, data: 0.000) loss: 0.171 
(epoch: 106, iters: 2800, time: 0.155, data: 0.000) loss: 0.605 
(epoch: 106, iters: 2880, time: 0.158, data: 0.000) loss: 0.072 
(epoch: 106, iters: 2960, time: 0.158, data: 0.021) loss: 0.633 
(epoch: 106, iters: 3040, time: 0.158, data: 0.020) loss: 0.178 
(epoch: 106, iters: 3120, time: 0.156, data: 0.000) loss: 0.758 
(epoch: 106, iters: 3200, time: 0.157, data: 0.016) loss: 0.723 
(epoch: 106, iters: 3280, time: 0.157, data: 0.000) loss: 0.638 
(epoch: 106, iters: 3360, time: 0.157, data: 0.012) loss: 0.836 
(epoch: 106, iters: 3440, time: 0.158, data: 0.005) loss: 0.881 
(epoch: 106, iters: 3520, time: 0.158, data: 0.000) loss: 0.250 
(epoch: 106, iters: 3600, time: 0.157, data: 0.006) loss: 0.416 
(epoch: 106, iters: 3680, time: 0.161, data: 0.011) loss: 0.466 
(epoch: 106, iters: 3760, time: 0.157, data: 0.000) loss: 0.540 
(epoch: 106, iters: 3840, time: 0.159, data: 0.000) loss: 0.611 
(epoch: 106, iters: 3920, time: 0.160, data: 0.000) loss: 0.393 
(epoch: 106, iters: 4000, time: 0.160, data: 0.000) loss: 0.163 
saving the latest model (epoch 106, total_steps 1074176)
(epoch: 106, iters: 4080, time: 0.157, data: 0.026) loss: 0.823 
(epoch: 106, iters: 4160, time: 0.158, data: 0.034) loss: 0.223 
(epoch: 106, iters: 4240, time: 0.156, data: 0.000) loss: 0.460 
(epoch: 106, iters: 4320, time: 0.160, data: 0.005) loss: 0.507 
(epoch: 106, iters: 4400, time: 0.158, data: 0.000) loss: 0.324 
(epoch: 106, iters: 4480, time: 0.158, data: 0.026) loss: 0.179 
(epoch: 106, iters: 4560, time: 0.159, data: 0.000) loss: 0.603 
(epoch: 106, iters: 4640, time: 0.159, data: 0.006) loss: 0.529 
(epoch: 106, iters: 4720, time: 0.161, data: 0.000) loss: 0.329 
(epoch: 106, iters: 4800, time: 0.158, data: 0.032) loss: 0.679 
(epoch: 106, iters: 4880, time: 0.155, data: 0.000) loss: 0.201 
(epoch: 106, iters: 4960, time: 0.157, data: 0.000) loss: 0.252 
(epoch: 106, iters: 5040, time: 0.158, data: 0.000) loss: 0.739 
(epoch: 106, iters: 5120, time: 0.160, data: 0.025) loss: 0.390 
(epoch: 106, iters: 5200, time: 0.157, data: 0.000) loss: 0.764 
(epoch: 106, iters: 5280, time: 0.159, data: 0.000) loss: 0.519 
(epoch: 106, iters: 5360, time: 0.157, data: 0.009) loss: 0.739 
(epoch: 106, iters: 5440, time: 0.156, data: 0.013) loss: 0.734 
(epoch: 106, iters: 5520, time: 0.159, data: 0.000) loss: 0.330 
(epoch: 106, iters: 5600, time: 0.160, data: 0.014) loss: 0.347 
(epoch: 106, iters: 5680, time: 0.159, data: 0.005) loss: 0.206 
(epoch: 106, iters: 5760, time: 0.157, data: 0.000) loss: 0.208 
(epoch: 106, iters: 5840, time: 0.155, data: 0.000) loss: 0.767 
(epoch: 106, iters: 5920, time: 0.156, data: 0.008) loss: 0.150 
(epoch: 106, iters: 6000, time: 0.159, data: 0.000) loss: 0.453 
(epoch: 106, iters: 6080, time: 0.157, data: 0.000) loss: 0.277 
(epoch: 106, iters: 6160, time: 0.157, data: 0.022) loss: 0.238 
(epoch: 106, iters: 6240, time: 0.163, data: 0.000) loss: 0.204 
(epoch: 106, iters: 6320, time: 0.158, data: 0.000) loss: 0.916 
(epoch: 106, iters: 6400, time: 0.163, data: 0.005) loss: 0.468 
(epoch: 106, iters: 6480, time: 0.161, data: 0.000) loss: 0.193 
(epoch: 106, iters: 6560, time: 0.159, data: 0.021) loss: 0.574 
(epoch: 106, iters: 6640, time: 0.159, data: 0.000) loss: 0.396 
(epoch: 106, iters: 6720, time: 0.156, data: 0.000) loss: 0.244 
(epoch: 106, iters: 6800, time: 0.157, data: 0.000) loss: 0.283 
(epoch: 106, iters: 6880, time: 0.158, data: 0.000) loss: 0.912 
(epoch: 106, iters: 6960, time: 0.157, data: 0.020) loss: 0.405 
(epoch: 106, iters: 7040, time: 0.156, data: 0.000) loss: 0.287 
(epoch: 106, iters: 7120, time: 0.156, data: 0.000) loss: 0.674 
(epoch: 106, iters: 7200, time: 0.155, data: 0.000) loss: 0.837 
(epoch: 106, iters: 7280, time: 0.157, data: 0.005) loss: 0.434 
(epoch: 106, iters: 7360, time: 0.159, data: 0.000) loss: 0.160 
(epoch: 106, iters: 7440, time: 0.157, data: 0.005) loss: 0.541 
(epoch: 106, iters: 7520, time: 0.157, data: 0.000) loss: 0.135 
(epoch: 106, iters: 7600, time: 0.160, data: 0.016) loss: 0.592 
(epoch: 106, iters: 7680, time: 0.156, data: 0.000) loss: 0.339 
(epoch: 106, iters: 7760, time: 0.156, data: 0.041) loss: 0.531 
(epoch: 106, iters: 7840, time: 0.157, data: 0.000) loss: 0.444 
(epoch: 106, iters: 7920, time: 0.157, data: 0.000) loss: 0.183 
(epoch: 106, iters: 8000, time: 0.158, data: 0.005) loss: 0.599 
saving the latest model (epoch 106, total_steps 1078176)
(epoch: 106, iters: 8080, time: 0.156, data: 0.018) loss: 0.222 
(epoch: 106, iters: 8160, time: 0.158, data: 0.000) loss: 0.465 
(epoch: 106, iters: 8240, time: 0.158, data: 0.000) loss: 0.316 
(epoch: 106, iters: 8320, time: 0.157, data: 0.022) loss: 0.131 
(epoch: 106, iters: 8400, time: 0.159, data: 0.009) loss: 0.531 
(epoch: 106, iters: 8480, time: 0.158, data: 0.000) loss: 1.140 
(epoch: 106, iters: 8560, time: 0.156, data: 0.009) loss: 0.820 
(epoch: 106, iters: 8640, time: 0.158, data: 0.009) loss: 0.754 
(epoch: 106, iters: 8720, time: 0.157, data: 0.017) loss: 0.538 
(epoch: 106, iters: 8800, time: 0.158, data: 0.005) loss: 0.738 
(epoch: 106, iters: 8880, time: 0.157, data: 0.011) loss: 0.348 
(epoch: 106, iters: 8960, time: 0.157, data: 0.020) loss: 0.267 
(epoch: 106, iters: 9040, time: 0.163, data: 0.000) loss: 0.623 
(epoch: 106, iters: 9120, time: 0.155, data: 0.010) loss: 0.402 
(epoch: 106, iters: 9200, time: 0.159, data: 0.000) loss: 0.662 
(epoch: 106, iters: 9280, time: 0.156, data: 0.009) loss: 0.297 
(epoch: 106, iters: 9360, time: 0.158, data: 0.005) loss: 0.755 
(epoch: 106, iters: 9440, time: 0.159, data: 0.009) loss: 0.719 
(epoch: 106, iters: 9520, time: 0.157, data: 0.000) loss: 0.678 
(epoch: 106, iters: 9600, time: 0.158, data: 0.034) loss: 0.455 
(epoch: 106, iters: 9680, time: 0.158, data: 0.000) loss: 0.473 
(epoch: 106, iters: 9760, time: 0.156, data: 0.000) loss: 0.512 
(epoch: 106, iters: 9840, time: 0.156, data: 0.000) loss: 0.379 
(epoch: 106, iters: 9920, time: 0.158, data: 0.005) loss: 0.106 
(epoch: 106, iters: 10000, time: 0.156, data: 0.000) loss: 0.383 
(epoch: 106, iters: 10080, time: 0.158, data: 0.000) loss: 0.427 
(epoch: 106, iters: 10160, time: 0.156, data: 0.000) loss: 0.608 
saving the model at the end of epoch 106, iters 1080352
End of epoch 106 / 200 	 Time Taken: 1613 sec
learning rate = 0.0001842
saving the latest model (epoch 107, total_steps 1080368)
(epoch: 107, iters: 48, time: 0.156, data: 0.005) loss: 0.093 
(epoch: 107, iters: 128, time: 0.149, data: 0.020) loss: 0.933 
(epoch: 107, iters: 208, time: 0.151, data: 0.008) loss: 0.845 
(epoch: 107, iters: 288, time: 0.153, data: 0.005) loss: 0.306 
(epoch: 107, iters: 368, time: 0.152, data: 0.008) loss: 0.558 
(epoch: 107, iters: 448, time: 0.152, data: 0.000) loss: 0.584 
(epoch: 107, iters: 528, time: 0.148, data: 0.000) loss: 0.241 
(epoch: 107, iters: 608, time: 0.148, data: 0.008) loss: 0.596 
(epoch: 107, iters: 688, time: 0.152, data: 0.000) loss: 0.269 
(epoch: 107, iters: 768, time: 0.152, data: 0.027) loss: 0.486 
(epoch: 107, iters: 848, time: 0.154, data: 0.000) loss: 0.672 
(epoch: 107, iters: 928, time: 0.150, data: 0.000) loss: 0.809 
(epoch: 107, iters: 1008, time: 0.153, data: 0.005) loss: 0.914 
(epoch: 107, iters: 1088, time: 0.151, data: 0.000) loss: 0.563 
(epoch: 107, iters: 1168, time: 0.152, data: 0.032) loss: 0.516 
(epoch: 107, iters: 1248, time: 0.160, data: 0.000) loss: 0.764 
(epoch: 107, iters: 1328, time: 0.151, data: 0.017) loss: 0.142 
(epoch: 107, iters: 1408, time: 0.153, data: 0.000) loss: 0.488 
(epoch: 107, iters: 1488, time: 0.150, data: 0.000) loss: 0.441 
(epoch: 107, iters: 1568, time: 0.150, data: 0.024) loss: 0.232 
(epoch: 107, iters: 1648, time: 0.153, data: 0.000) loss: 0.165 
(epoch: 107, iters: 1728, time: 0.152, data: 0.000) loss: 0.944 
(epoch: 107, iters: 1808, time: 0.150, data: 0.031) loss: 0.355 
(epoch: 107, iters: 1888, time: 0.149, data: 0.000) loss: 0.274 
(epoch: 107, iters: 1968, time: 0.149, data: 0.031) loss: 0.895 
(epoch: 107, iters: 2048, time: 0.152, data: 0.000) loss: 0.325 
(epoch: 107, iters: 2128, time: 0.153, data: 0.000) loss: 0.264 
(epoch: 107, iters: 2208, time: 0.152, data: 0.008) loss: 0.718 
(epoch: 107, iters: 2288, time: 0.152, data: 0.000) loss: 0.539 
(epoch: 107, iters: 2368, time: 0.154, data: 0.017) loss: 0.574 
(epoch: 107, iters: 2448, time: 0.154, data: 0.000) loss: 0.291 
(epoch: 107, iters: 2528, time: 0.150, data: 0.015) loss: 0.642 
(epoch: 107, iters: 2608, time: 0.153, data: 0.000) loss: 0.488 
(epoch: 107, iters: 2688, time: 0.151, data: 0.005) loss: 0.286 
(epoch: 107, iters: 2768, time: 0.152, data: 0.000) loss: 0.843 
(epoch: 107, iters: 2848, time: 0.151, data: 0.009) loss: 0.310 
(epoch: 107, iters: 2928, time: 0.153, data: 0.000) loss: 0.300 
(epoch: 107, iters: 3008, time: 0.151, data: 0.009) loss: 0.339 
(epoch: 107, iters: 3088, time: 0.148, data: 0.006) loss: 1.191 
(epoch: 107, iters: 3168, time: 0.151, data: 0.018) loss: 0.706 
(epoch: 107, iters: 3248, time: 0.150, data: 0.000) loss: 0.562 
(epoch: 107, iters: 3328, time: 0.151, data: 0.000) loss: 1.131 
(epoch: 107, iters: 3408, time: 0.151, data: 0.000) loss: 0.361 
(epoch: 107, iters: 3488, time: 0.150, data: 0.000) loss: 0.445 
(epoch: 107, iters: 3568, time: 0.152, data: 0.000) loss: 0.266 
(epoch: 107, iters: 3648, time: 0.149, data: 0.009) loss: 0.285 
(epoch: 107, iters: 3728, time: 0.151, data: 0.000) loss: 0.862 
(epoch: 107, iters: 3808, time: 0.151, data: 0.000) loss: 0.711 
(epoch: 107, iters: 3888, time: 0.150, data: 0.006) loss: 0.251 
(epoch: 107, iters: 3968, time: 0.151, data: 0.000) loss: 0.521 
saving the latest model (epoch 107, total_steps 1084368)
(epoch: 107, iters: 4048, time: 0.154, data: 0.009) loss: 0.373 
(epoch: 107, iters: 4128, time: 0.154, data: 0.000) loss: 0.265 
(epoch: 107, iters: 4208, time: 0.151, data: 0.016) loss: 0.206 
(epoch: 107, iters: 4288, time: 0.151, data: 0.000) loss: 0.550 
(epoch: 107, iters: 4368, time: 0.150, data: 0.000) loss: 1.351 
(epoch: 107, iters: 4448, time: 0.152, data: 0.006) loss: 0.477 
(epoch: 107, iters: 4528, time: 0.153, data: 0.020) loss: 0.652 
(epoch: 107, iters: 4608, time: 0.152, data: 0.000) loss: 0.246 
(epoch: 107, iters: 4688, time: 0.152, data: 0.000) loss: 0.475 
(epoch: 107, iters: 4768, time: 0.150, data: 0.022) loss: 0.338 
(epoch: 107, iters: 4848, time: 0.150, data: 0.000) loss: 0.791 
(epoch: 107, iters: 4928, time: 0.151, data: 0.000) loss: 0.676 
(epoch: 107, iters: 5008, time: 0.152, data: 0.006) loss: 0.235 
(epoch: 107, iters: 5088, time: 0.152, data: 0.006) loss: 0.242 
(epoch: 107, iters: 5168, time: 0.150, data: 0.000) loss: 0.632 
(epoch: 107, iters: 5248, time: 0.150, data: 0.015) loss: 0.482 
(epoch: 107, iters: 5328, time: 0.148, data: 0.000) loss: 0.494 
(epoch: 107, iters: 5408, time: 0.150, data: 0.008) loss: 0.541 
(epoch: 107, iters: 5488, time: 0.152, data: 0.000) loss: 0.686 
(epoch: 107, iters: 5568, time: 0.148, data: 0.000) loss: 0.175 
(epoch: 107, iters: 5648, time: 0.150, data: 0.000) loss: 0.525 
(epoch: 107, iters: 5728, time: 0.150, data: 0.000) loss: 0.465 
(epoch: 107, iters: 5808, time: 0.151, data: 0.000) loss: 0.225 
(epoch: 107, iters: 5888, time: 0.150, data: 0.000) loss: 0.889 
(epoch: 107, iters: 5968, time: 0.152, data: 0.000) loss: 0.669 
(epoch: 107, iters: 6048, time: 0.150, data: 0.005) loss: 0.678 
(epoch: 107, iters: 6128, time: 0.151, data: 0.000) loss: 0.254 
(epoch: 107, iters: 6208, time: 0.152, data: 0.000) loss: 0.986 
(epoch: 107, iters: 6288, time: 0.149, data: 0.019) loss: 0.681 
(epoch: 107, iters: 6368, time: 0.153, data: 0.000) loss: 0.519 
(epoch: 107, iters: 6448, time: 0.153, data: 0.014) loss: 0.233 
(epoch: 107, iters: 6528, time: 0.151, data: 0.019) loss: 0.854 
(epoch: 107, iters: 6608, time: 0.151, data: 0.016) loss: 0.593 
(epoch: 107, iters: 6688, time: 0.148, data: 0.000) loss: 0.656 
(epoch: 107, iters: 6768, time: 0.152, data: 0.006) loss: 0.599 
(epoch: 107, iters: 6848, time: 0.150, data: 0.000) loss: 0.444 
(epoch: 107, iters: 6928, time: 0.153, data: 0.021) loss: 0.722 
(epoch: 107, iters: 7008, time: 0.151, data: 0.000) loss: 0.834 
(epoch: 107, iters: 7088, time: 0.150, data: 0.000) loss: 0.800 
(epoch: 107, iters: 7168, time: 0.150, data: 0.008) loss: 0.699 
(epoch: 107, iters: 7248, time: 0.152, data: 0.000) loss: 0.543 
(epoch: 107, iters: 7328, time: 0.151, data: 0.000) loss: 0.288 
(epoch: 107, iters: 7408, time: 0.157, data: 0.017) loss: 0.940 
(epoch: 107, iters: 7488, time: 0.149, data: 0.000) loss: 0.507 
(epoch: 107, iters: 7568, time: 0.151, data: 0.005) loss: 0.737 
(epoch: 107, iters: 7648, time: 0.149, data: 0.010) loss: 0.375 
(epoch: 107, iters: 7728, time: 0.150, data: 0.014) loss: 0.312 
(epoch: 107, iters: 7808, time: 0.154, data: 0.005) loss: 0.513 
(epoch: 107, iters: 7888, time: 0.149, data: 0.000) loss: 0.394 
(epoch: 107, iters: 7968, time: 0.149, data: 0.005) loss: 0.264 
saving the latest model (epoch 107, total_steps 1088368)
(epoch: 107, iters: 8048, time: 0.151, data: 0.000) loss: 0.832 
(epoch: 107, iters: 8128, time: 0.151, data: 0.017) loss: 0.481 
(epoch: 107, iters: 8208, time: 0.152, data: 0.000) loss: 1.024 
(epoch: 107, iters: 8288, time: 0.153, data: 0.023) loss: 0.570 
(epoch: 107, iters: 8368, time: 0.150, data: 0.000) loss: 0.362 
(epoch: 107, iters: 8448, time: 0.150, data: 0.006) loss: 0.654 
(epoch: 107, iters: 8528, time: 0.151, data: 0.000) loss: 0.466 
(epoch: 107, iters: 8608, time: 0.151, data: 0.013) loss: 0.340 
(epoch: 107, iters: 8688, time: 0.150, data: 0.005) loss: 0.242 
(epoch: 107, iters: 8768, time: 0.150, data: 0.000) loss: 0.296 
(epoch: 107, iters: 8848, time: 0.150, data: 0.000) loss: 0.287 
(epoch: 107, iters: 8928, time: 0.151, data: 0.000) loss: 0.592 
(epoch: 107, iters: 9008, time: 0.150, data: 0.015) loss: 0.077 
(epoch: 107, iters: 9088, time: 0.151, data: 0.008) loss: 0.263 
(epoch: 107, iters: 9168, time: 0.149, data: 0.000) loss: 0.325 
(epoch: 107, iters: 9248, time: 0.151, data: 0.000) loss: 0.585 
(epoch: 107, iters: 9328, time: 0.153, data: 0.000) loss: 0.229 
(epoch: 107, iters: 9408, time: 0.151, data: 0.000) loss: 0.290 
(epoch: 107, iters: 9488, time: 0.153, data: 0.013) loss: 0.411 
(epoch: 107, iters: 9568, time: 0.151, data: 0.000) loss: 0.471 
(epoch: 107, iters: 9648, time: 0.151, data: 0.000) loss: 0.405 
(epoch: 107, iters: 9728, time: 0.152, data: 0.000) loss: 0.448 
(epoch: 107, iters: 9808, time: 0.152, data: 0.000) loss: 0.505 
(epoch: 107, iters: 9888, time: 0.152, data: 0.000) loss: 0.548 
(epoch: 107, iters: 9968, time: 0.153, data: 0.000) loss: 0.333 
(epoch: 107, iters: 10048, time: 0.152, data: 0.008) loss: 0.114 
(epoch: 107, iters: 10128, time: 0.153, data: 0.016) loss: 0.590 
saving the model at the end of epoch 107, iters 1090544
End of epoch 107 / 200 	 Time Taken: 1547 sec
learning rate = 0.0001822
(epoch: 108, iters: 16, time: 0.179, data: 0.000) loss: 0.442 
saving the latest model (epoch 108, total_steps 1090560)
(epoch: 108, iters: 96, time: 0.161, data: 0.000) loss: 0.529 
(epoch: 108, iters: 176, time: 0.158, data: 0.010) loss: 0.511 
(epoch: 108, iters: 256, time: 0.158, data: 0.026) loss: 0.672 
(epoch: 108, iters: 336, time: 0.155, data: 0.000) loss: 0.849 
(epoch: 108, iters: 416, time: 0.157, data: 0.000) loss: 0.332 
(epoch: 108, iters: 496, time: 0.156, data: 0.005) loss: 0.488 
(epoch: 108, iters: 576, time: 0.157, data: 0.000) loss: 0.458 
(epoch: 108, iters: 656, time: 0.158, data: 0.000) loss: 0.776 
(epoch: 108, iters: 736, time: 0.156, data: 0.025) loss: 0.216 
(epoch: 108, iters: 816, time: 0.157, data: 0.000) loss: 1.122 
(epoch: 108, iters: 896, time: 0.158, data: 0.021) loss: 0.675 
(epoch: 108, iters: 976, time: 0.158, data: 0.000) loss: 0.377 
(epoch: 108, iters: 1056, time: 0.157, data: 0.005) loss: 0.101 
(epoch: 108, iters: 1136, time: 0.154, data: 0.000) loss: 0.113 
(epoch: 108, iters: 1216, time: 0.156, data: 0.016) loss: 0.555 
(epoch: 108, iters: 1296, time: 0.155, data: 0.000) loss: 0.372 
(epoch: 108, iters: 1376, time: 0.157, data: 0.000) loss: 0.575 
(epoch: 108, iters: 1456, time: 0.155, data: 0.006) loss: 0.414 
(epoch: 108, iters: 1536, time: 0.155, data: 0.021) loss: 0.311 
(epoch: 108, iters: 1616, time: 0.158, data: 0.000) loss: 0.102 
(epoch: 108, iters: 1696, time: 0.159, data: 0.013) loss: 0.426 
(epoch: 108, iters: 1776, time: 0.157, data: 0.000) loss: 0.267 
(epoch: 108, iters: 1856, time: 0.157, data: 0.000) loss: 0.224 
(epoch: 108, iters: 1936, time: 0.156, data: 0.000) loss: 0.396 
(epoch: 108, iters: 2016, time: 0.159, data: 0.006) loss: 0.195 
(epoch: 108, iters: 2096, time: 0.156, data: 0.000) loss: 0.323 
(epoch: 108, iters: 2176, time: 0.159, data: 0.028) loss: 0.299 
(epoch: 108, iters: 2256, time: 0.155, data: 0.006) loss: 0.953 
(epoch: 108, iters: 2336, time: 0.156, data: 0.000) loss: 0.364 
(epoch: 108, iters: 2416, time: 0.155, data: 0.014) loss: 0.695 
(epoch: 108, iters: 2496, time: 0.157, data: 0.005) loss: 0.303 
(epoch: 108, iters: 2576, time: 0.156, data: 0.000) loss: 0.535 
(epoch: 108, iters: 2656, time: 0.155, data: 0.014) loss: 0.522 
(epoch: 108, iters: 2736, time: 0.156, data: 0.000) loss: 0.518 
(epoch: 108, iters: 2816, time: 0.157, data: 0.000) loss: 0.346 
(epoch: 108, iters: 2896, time: 0.156, data: 0.000) loss: 0.571 
(epoch: 108, iters: 2976, time: 0.157, data: 0.008) loss: 0.367 
(epoch: 108, iters: 3056, time: 0.160, data: 0.000) loss: 0.224 
(epoch: 108, iters: 3136, time: 0.156, data: 0.000) loss: 0.188 
(epoch: 108, iters: 3216, time: 0.155, data: 0.000) loss: 0.427 
(epoch: 108, iters: 3296, time: 0.155, data: 0.038) loss: 0.219 
(epoch: 108, iters: 3376, time: 0.156, data: 0.000) loss: 0.198 
(epoch: 108, iters: 3456, time: 0.159, data: 0.000) loss: 0.325 
(epoch: 108, iters: 3536, time: 0.158, data: 0.014) loss: 0.302 
(epoch: 108, iters: 3616, time: 0.161, data: 0.006) loss: 0.484 
(epoch: 108, iters: 3696, time: 0.158, data: 0.005) loss: 0.461 
(epoch: 108, iters: 3776, time: 0.158, data: 0.009) loss: 0.677 
(epoch: 108, iters: 3856, time: 0.157, data: 0.009) loss: 0.636 
(epoch: 108, iters: 3936, time: 0.153, data: 0.000) loss: 0.338 
(epoch: 108, iters: 4016, time: 0.157, data: 0.000) loss: 0.770 
saving the latest model (epoch 108, total_steps 1094560)
(epoch: 108, iters: 4096, time: 0.154, data: 0.008) loss: 0.166 
(epoch: 108, iters: 4176, time: 0.152, data: 0.000) loss: 0.302 
(epoch: 108, iters: 4256, time: 0.156, data: 0.025) loss: 0.635 
(epoch: 108, iters: 4336, time: 0.153, data: 0.000) loss: 0.208 
(epoch: 108, iters: 4416, time: 0.158, data: 0.010) loss: 0.681 
(epoch: 108, iters: 4496, time: 0.156, data: 0.000) loss: 0.286 
(epoch: 108, iters: 4576, time: 0.155, data: 0.010) loss: 0.465 
(epoch: 108, iters: 4656, time: 0.156, data: 0.000) loss: 0.531 
(epoch: 108, iters: 4736, time: 0.156, data: 0.000) loss: 0.761 
(epoch: 108, iters: 4816, time: 0.159, data: 0.000) loss: 0.331 
(epoch: 108, iters: 4896, time: 0.156, data: 0.005) loss: 0.784 
(epoch: 108, iters: 4976, time: 0.155, data: 0.000) loss: 0.467 
(epoch: 108, iters: 5056, time: 0.155, data: 0.000) loss: 0.573 
(epoch: 108, iters: 5136, time: 0.155, data: 0.000) loss: 0.548 
(epoch: 108, iters: 5216, time: 0.162, data: 0.000) loss: 0.762 
(epoch: 108, iters: 5296, time: 0.154, data: 0.000) loss: 0.940 
(epoch: 108, iters: 5376, time: 0.155, data: 0.011) loss: 0.375 
(epoch: 108, iters: 5456, time: 0.157, data: 0.000) loss: 0.510 
(epoch: 108, iters: 5536, time: 0.158, data: 0.000) loss: 0.714 
(epoch: 108, iters: 5616, time: 0.159, data: 0.005) loss: 0.689 
(epoch: 108, iters: 5696, time: 0.157, data: 0.008) loss: 0.480 
(epoch: 108, iters: 5776, time: 0.158, data: 0.005) loss: 0.588 
(epoch: 108, iters: 5856, time: 0.155, data: 0.016) loss: 0.665 
(epoch: 108, iters: 5936, time: 0.156, data: 0.000) loss: 0.138 
(epoch: 108, iters: 6016, time: 0.157, data: 0.000) loss: 0.351 
(epoch: 108, iters: 6096, time: 0.156, data: 0.024) loss: 0.320 
(epoch: 108, iters: 6176, time: 0.158, data: 0.000) loss: 0.370 
(epoch: 108, iters: 6256, time: 0.154, data: 0.022) loss: 0.463 
(epoch: 108, iters: 6336, time: 0.156, data: 0.021) loss: 0.512 
(epoch: 108, iters: 6416, time: 0.156, data: 0.000) loss: 0.366 
(epoch: 108, iters: 6496, time: 0.158, data: 0.000) loss: 0.324 
(epoch: 108, iters: 6576, time: 0.160, data: 0.014) loss: 0.533 
(epoch: 108, iters: 6656, time: 0.155, data: 0.006) loss: 0.357 
(epoch: 108, iters: 6736, time: 0.155, data: 0.000) loss: 0.546 
(epoch: 108, iters: 6816, time: 0.158, data: 0.008) loss: 0.371 
(epoch: 108, iters: 6896, time: 0.158, data: 0.000) loss: 0.932 
(epoch: 108, iters: 6976, time: 0.158, data: 0.000) loss: 0.328 
(epoch: 108, iters: 7056, time: 0.157, data: 0.000) loss: 0.588 
(epoch: 108, iters: 7136, time: 0.157, data: 0.000) loss: 0.343 
(epoch: 108, iters: 7216, time: 0.156, data: 0.021) loss: 0.499 
(epoch: 108, iters: 7296, time: 0.156, data: 0.006) loss: 0.820 
(epoch: 108, iters: 7376, time: 0.159, data: 0.000) loss: 0.512 
(epoch: 108, iters: 7456, time: 0.156, data: 0.031) loss: 0.193 
(epoch: 108, iters: 7536, time: 0.157, data: 0.000) loss: 0.264 
(epoch: 108, iters: 7616, time: 0.156, data: 0.000) loss: 0.444 
(epoch: 108, iters: 7696, time: 0.156, data: 0.014) loss: 0.588 
(epoch: 108, iters: 7776, time: 0.155, data: 0.005) loss: 0.490 
(epoch: 108, iters: 7856, time: 0.158, data: 0.005) loss: 0.897 
(epoch: 108, iters: 7936, time: 0.157, data: 0.000) loss: 0.826 
(epoch: 108, iters: 8016, time: 0.160, data: 0.000) loss: 0.456 
saving the latest model (epoch 108, total_steps 1098560)
(epoch: 108, iters: 8096, time: 0.158, data: 0.006) loss: 0.658 
(epoch: 108, iters: 8176, time: 0.157, data: 0.000) loss: 0.844 
(epoch: 108, iters: 8256, time: 0.157, data: 0.005) loss: 0.550 
(epoch: 108, iters: 8336, time: 0.156, data: 0.000) loss: 0.212 
(epoch: 108, iters: 8416, time: 0.158, data: 0.024) loss: 0.480 
(epoch: 108, iters: 8496, time: 0.157, data: 0.000) loss: 0.887 
(epoch: 108, iters: 8576, time: 0.157, data: 0.000) loss: 0.507 
(epoch: 108, iters: 8656, time: 0.156, data: 0.000) loss: 0.135 
(epoch: 108, iters: 8736, time: 0.156, data: 0.025) loss: 0.432 
(epoch: 108, iters: 8816, time: 0.155, data: 0.000) loss: 0.356 
(epoch: 108, iters: 8896, time: 0.157, data: 0.000) loss: 0.368 
(epoch: 108, iters: 8976, time: 0.157, data: 0.019) loss: 0.611 
(epoch: 108, iters: 9056, time: 0.155, data: 0.010) loss: 0.571 
(epoch: 108, iters: 9136, time: 0.156, data: 0.000) loss: 0.712 
(epoch: 108, iters: 9216, time: 0.158, data: 0.000) loss: 0.374 
(epoch: 108, iters: 9296, time: 0.157, data: 0.025) loss: 0.442 
(epoch: 108, iters: 9376, time: 0.159, data: 0.000) loss: 0.369 
(epoch: 108, iters: 9456, time: 0.157, data: 0.000) loss: 0.597 
(epoch: 108, iters: 9536, time: 0.157, data: 0.005) loss: 0.960 
(epoch: 108, iters: 9616, time: 0.159, data: 0.000) loss: 0.558 
(epoch: 108, iters: 9696, time: 0.156, data: 0.005) loss: 0.325 
(epoch: 108, iters: 9776, time: 0.155, data: 0.018) loss: 0.511 
(epoch: 108, iters: 9856, time: 0.156, data: 0.000) loss: 0.947 
(epoch: 108, iters: 9936, time: 0.161, data: 0.000) loss: 0.515 
(epoch: 108, iters: 10016, time: 0.156, data: 0.008) loss: 0.618 
(epoch: 108, iters: 10096, time: 0.155, data: 0.023) loss: 0.476 
(epoch: 108, iters: 10176, time: 0.158, data: 0.025) loss: 0.944 
saving the model at the end of epoch 108, iters 1100736
End of epoch 108 / 200 	 Time Taken: 1604 sec
learning rate = 0.0001802
saving the latest model (epoch 109, total_steps 1100752)
(epoch: 109, iters: 64, time: 0.152, data: 0.000) loss: 0.548 
(epoch: 109, iters: 144, time: 0.155, data: 0.034) loss: 0.288 
(epoch: 109, iters: 224, time: 0.150, data: 0.009) loss: 0.420 
(epoch: 109, iters: 304, time: 0.151, data: 0.005) loss: 0.307 
(epoch: 109, iters: 384, time: 0.152, data: 0.028) loss: 0.881 
(epoch: 109, iters: 464, time: 0.152, data: 0.000) loss: 0.573 
(epoch: 109, iters: 544, time: 0.152, data: 0.000) loss: 0.281 
(epoch: 109, iters: 624, time: 0.149, data: 0.010) loss: 0.276 
(epoch: 109, iters: 704, time: 0.151, data: 0.000) loss: 0.217 
(epoch: 109, iters: 784, time: 0.151, data: 0.005) loss: 0.213 
(epoch: 109, iters: 864, time: 0.152, data: 0.000) loss: 0.461 
(epoch: 109, iters: 944, time: 0.151, data: 0.005) loss: 0.412 
(epoch: 109, iters: 1024, time: 0.149, data: 0.000) loss: 0.256 
(epoch: 109, iters: 1104, time: 0.149, data: 0.000) loss: 0.155 
(epoch: 109, iters: 1184, time: 0.150, data: 0.000) loss: 0.396 
(epoch: 109, iters: 1264, time: 0.148, data: 0.016) loss: 0.681 
(epoch: 109, iters: 1344, time: 0.151, data: 0.000) loss: 0.265 
(epoch: 109, iters: 1424, time: 0.151, data: 0.021) loss: 0.090 
(epoch: 109, iters: 1504, time: 0.151, data: 0.005) loss: 0.122 
(epoch: 109, iters: 1584, time: 0.151, data: 0.000) loss: 0.251 
(epoch: 109, iters: 1664, time: 0.151, data: 0.000) loss: 0.261 
(epoch: 109, iters: 1744, time: 0.152, data: 0.000) loss: 0.738 
(epoch: 109, iters: 1824, time: 0.151, data: 0.008) loss: 0.209 
(epoch: 109, iters: 1904, time: 0.152, data: 0.000) loss: 1.176 
(epoch: 109, iters: 1984, time: 0.153, data: 0.016) loss: 0.387 
(epoch: 109, iters: 2064, time: 0.152, data: 0.000) loss: 0.304 
(epoch: 109, iters: 2144, time: 0.153, data: 0.006) loss: 0.561 
(epoch: 109, iters: 2224, time: 0.154, data: 0.000) loss: 0.429 
(epoch: 109, iters: 2304, time: 0.152, data: 0.000) loss: 0.178 
(epoch: 109, iters: 2384, time: 0.152, data: 0.000) loss: 0.285 
(epoch: 109, iters: 2464, time: 0.151, data: 0.000) loss: 0.339 
(epoch: 109, iters: 2544, time: 0.152, data: 0.005) loss: 0.743 
(epoch: 109, iters: 2624, time: 0.151, data: 0.005) loss: 0.528 
(epoch: 109, iters: 2704, time: 0.151, data: 0.008) loss: 0.174 
(epoch: 109, iters: 2784, time: 0.150, data: 0.008) loss: 1.064 
(epoch: 109, iters: 2864, time: 0.152, data: 0.000) loss: 0.797 
(epoch: 109, iters: 2944, time: 0.151, data: 0.011) loss: 0.203 
(epoch: 109, iters: 3024, time: 0.151, data: 0.000) loss: 0.947 
(epoch: 109, iters: 3104, time: 0.151, data: 0.005) loss: 0.602 
(epoch: 109, iters: 3184, time: 0.150, data: 0.000) loss: 0.685 
(epoch: 109, iters: 3264, time: 0.150, data: 0.000) loss: 0.228 
(epoch: 109, iters: 3344, time: 0.152, data: 0.013) loss: 0.605 
(epoch: 109, iters: 3424, time: 0.157, data: 0.000) loss: 0.221 
(epoch: 109, iters: 3504, time: 0.153, data: 0.025) loss: 0.689 
(epoch: 109, iters: 3584, time: 0.152, data: 0.000) loss: 0.367 
(epoch: 109, iters: 3664, time: 0.152, data: 0.000) loss: 1.060 
(epoch: 109, iters: 3744, time: 0.152, data: 0.013) loss: 0.619 
(epoch: 109, iters: 3824, time: 0.155, data: 0.008) loss: 1.304 
(epoch: 109, iters: 3904, time: 0.151, data: 0.000) loss: 0.383 
(epoch: 109, iters: 3984, time: 0.150, data: 0.005) loss: 0.190 
saving the latest model (epoch 109, total_steps 1104752)
(epoch: 109, iters: 4064, time: 0.150, data: 0.016) loss: 0.745 
(epoch: 109, iters: 4144, time: 0.153, data: 0.000) loss: 0.388 
(epoch: 109, iters: 4224, time: 0.158, data: 0.024) loss: 0.453 
(epoch: 109, iters: 4304, time: 0.153, data: 0.000) loss: 0.455 
(epoch: 109, iters: 4384, time: 0.152, data: 0.000) loss: 1.108 
(epoch: 109, iters: 4464, time: 0.153, data: 0.015) loss: 0.582 
(epoch: 109, iters: 4544, time: 0.152, data: 0.000) loss: 0.035 
(epoch: 109, iters: 4624, time: 0.153, data: 0.006) loss: 0.132 
(epoch: 109, iters: 4704, time: 0.152, data: 0.000) loss: 0.632 
(epoch: 109, iters: 4784, time: 0.151, data: 0.000) loss: 0.512 
(epoch: 109, iters: 4864, time: 0.152, data: 0.000) loss: 0.205 
(epoch: 109, iters: 4944, time: 0.150, data: 0.000) loss: 0.305 
(epoch: 109, iters: 5024, time: 0.154, data: 0.000) loss: 0.763 
(epoch: 109, iters: 5104, time: 0.151, data: 0.000) loss: 0.179 
(epoch: 109, iters: 5184, time: 0.152, data: 0.000) loss: 0.524 
(epoch: 109, iters: 5264, time: 0.153, data: 0.008) loss: 0.123 
(epoch: 109, iters: 5344, time: 0.152, data: 0.024) loss: 0.338 
(epoch: 109, iters: 5424, time: 0.152, data: 0.000) loss: 0.363 
(epoch: 109, iters: 5504, time: 0.152, data: 0.022) loss: 0.490 
(epoch: 109, iters: 5584, time: 0.154, data: 0.000) loss: 0.320 
(epoch: 109, iters: 5664, time: 0.150, data: 0.000) loss: 0.490 
(epoch: 109, iters: 5744, time: 0.154, data: 0.005) loss: 0.536 
(epoch: 109, iters: 5824, time: 0.154, data: 0.031) loss: 0.201 
(epoch: 109, iters: 5904, time: 0.154, data: 0.000) loss: 0.541 
(epoch: 109, iters: 5984, time: 0.153, data: 0.008) loss: 0.182 
(epoch: 109, iters: 6064, time: 0.151, data: 0.006) loss: 0.433 
(epoch: 109, iters: 6144, time: 0.154, data: 0.000) loss: 0.437 
(epoch: 109, iters: 6224, time: 0.152, data: 0.005) loss: 0.343 
(epoch: 109, iters: 6304, time: 0.151, data: 0.040) loss: 0.644 
(epoch: 109, iters: 6384, time: 0.153, data: 0.000) loss: 0.848 
(epoch: 109, iters: 6464, time: 0.152, data: 0.000) loss: 0.479 
(epoch: 109, iters: 6544, time: 0.153, data: 0.000) loss: 0.505 
(epoch: 109, iters: 6624, time: 0.154, data: 0.000) loss: 0.266 
(epoch: 109, iters: 6704, time: 0.155, data: 0.005) loss: 0.564 
(epoch: 109, iters: 6784, time: 0.153, data: 0.000) loss: 0.564 
(epoch: 109, iters: 6864, time: 0.153, data: 0.010) loss: 0.640 
(epoch: 109, iters: 6944, time: 0.153, data: 0.000) loss: 0.406 
(epoch: 109, iters: 7024, time: 0.152, data: 0.019) loss: 0.423 
(epoch: 109, iters: 7104, time: 0.154, data: 0.000) loss: 0.410 
(epoch: 109, iters: 7184, time: 0.152, data: 0.006) loss: 0.408 
(epoch: 109, iters: 7264, time: 0.151, data: 0.008) loss: 0.560 
(epoch: 109, iters: 7344, time: 0.150, data: 0.000) loss: 0.251 
(epoch: 109, iters: 7424, time: 0.152, data: 0.015) loss: 0.284 
(epoch: 109, iters: 7504, time: 0.152, data: 0.005) loss: 0.419 
(epoch: 109, iters: 7584, time: 0.150, data: 0.021) loss: 0.476 
(epoch: 109, iters: 7664, time: 0.151, data: 0.000) loss: 1.173 
(epoch: 109, iters: 7744, time: 0.154, data: 0.000) loss: 0.251 
(epoch: 109, iters: 7824, time: 0.152, data: 0.025) loss: 0.667 
(epoch: 109, iters: 7904, time: 0.153, data: 0.000) loss: 0.171 
(epoch: 109, iters: 7984, time: 0.152, data: 0.026) loss: 0.099 
saving the latest model (epoch 109, total_steps 1108752)
(epoch: 109, iters: 8064, time: 0.153, data: 0.000) loss: 0.862 
(epoch: 109, iters: 8144, time: 0.151, data: 0.000) loss: 0.809 
(epoch: 109, iters: 8224, time: 0.151, data: 0.000) loss: 1.294 
(epoch: 109, iters: 8304, time: 0.154, data: 0.000) loss: 1.056 
(epoch: 109, iters: 8384, time: 0.150, data: 0.030) loss: 0.526 
(epoch: 109, iters: 8464, time: 0.151, data: 0.000) loss: 0.527 
(epoch: 109, iters: 8544, time: 0.151, data: 0.000) loss: 0.918 
(epoch: 109, iters: 8624, time: 0.152, data: 0.000) loss: 0.234 
(epoch: 109, iters: 8704, time: 0.158, data: 0.005) loss: 0.496 
(epoch: 109, iters: 8784, time: 0.155, data: 0.000) loss: 0.140 
(epoch: 109, iters: 8864, time: 0.154, data: 0.020) loss: 0.531 
(epoch: 109, iters: 8944, time: 0.156, data: 0.000) loss: 0.229 
(epoch: 109, iters: 9024, time: 0.154, data: 0.000) loss: 0.441 
(epoch: 109, iters: 9104, time: 0.157, data: 0.016) loss: 0.563 
(epoch: 109, iters: 9184, time: 0.155, data: 0.019) loss: 0.520 
(epoch: 109, iters: 9264, time: 0.153, data: 0.000) loss: 0.628 
(epoch: 109, iters: 9344, time: 0.152, data: 0.000) loss: 0.780 
(epoch: 109, iters: 9424, time: 0.153, data: 0.018) loss: 0.288 
(epoch: 109, iters: 9504, time: 0.156, data: 0.000) loss: 0.696 
(epoch: 109, iters: 9584, time: 0.150, data: 0.000) loss: 0.485 
(epoch: 109, iters: 9664, time: 0.151, data: 0.000) loss: 0.958 
(epoch: 109, iters: 9744, time: 0.153, data: 0.020) loss: 0.836 
(epoch: 109, iters: 9824, time: 0.151, data: 0.016) loss: 0.294 
(epoch: 109, iters: 9904, time: 0.151, data: 0.008) loss: 0.570 
(epoch: 109, iters: 9984, time: 0.151, data: 0.000) loss: 0.374 
(epoch: 109, iters: 10064, time: 0.153, data: 0.000) loss: 0.235 
(epoch: 109, iters: 10144, time: 0.152, data: 0.005) loss: 0.523 
saving the model at the end of epoch 109, iters 1110928
End of epoch 109 / 200 	 Time Taken: 1557 sec
learning rate = 0.0001782
saving the latest model (epoch 110, total_steps 1110944)
(epoch: 110, iters: 32, time: 0.167, data: 0.000) loss: 0.564 
(epoch: 110, iters: 112, time: 0.158, data: 0.000) loss: 0.064 
(epoch: 110, iters: 192, time: 0.154, data: 0.000) loss: 0.521 
(epoch: 110, iters: 272, time: 0.151, data: 0.016) loss: 0.350 
(epoch: 110, iters: 352, time: 0.153, data: 0.000) loss: 0.268 
(epoch: 110, iters: 432, time: 0.155, data: 0.000) loss: 0.608 
(epoch: 110, iters: 512, time: 0.152, data: 0.030) loss: 0.396 
(epoch: 110, iters: 592, time: 0.151, data: 0.000) loss: 0.450 
(epoch: 110, iters: 672, time: 0.151, data: 0.032) loss: 0.588 
(epoch: 110, iters: 752, time: 0.150, data: 0.000) loss: 0.488 
(epoch: 110, iters: 832, time: 0.149, data: 0.024) loss: 0.702 
(epoch: 110, iters: 912, time: 0.151, data: 0.000) loss: 0.376 
(epoch: 110, iters: 992, time: 0.151, data: 0.000) loss: 0.294 
(epoch: 110, iters: 1072, time: 0.152, data: 0.000) loss: 0.564 
(epoch: 110, iters: 1152, time: 0.150, data: 0.022) loss: 0.326 
(epoch: 110, iters: 1232, time: 0.152, data: 0.022) loss: 0.494 
(epoch: 110, iters: 1312, time: 0.154, data: 0.000) loss: 0.413 
(epoch: 110, iters: 1392, time: 0.155, data: 0.000) loss: 0.261 
(epoch: 110, iters: 1472, time: 0.155, data: 0.000) loss: 0.543 
(epoch: 110, iters: 1552, time: 0.155, data: 0.005) loss: 0.607 
(epoch: 110, iters: 1632, time: 0.157, data: 0.000) loss: 0.328 
(epoch: 110, iters: 1712, time: 0.155, data: 0.012) loss: 0.281 
(epoch: 110, iters: 1792, time: 0.160, data: 0.000) loss: 0.310 
(epoch: 110, iters: 1872, time: 0.154, data: 0.018) loss: 0.231 
(epoch: 110, iters: 1952, time: 0.158, data: 0.000) loss: 0.628 
(epoch: 110, iters: 2032, time: 0.157, data: 0.005) loss: 0.487 
(epoch: 110, iters: 2112, time: 0.156, data: 0.000) loss: 0.320 
(epoch: 110, iters: 2192, time: 0.153, data: 0.000) loss: 0.821 
(epoch: 110, iters: 2272, time: 0.153, data: 0.000) loss: 0.140 
(epoch: 110, iters: 2352, time: 0.154, data: 0.015) loss: 0.248 
(epoch: 110, iters: 2432, time: 0.155, data: 0.014) loss: 0.373 
(epoch: 110, iters: 2512, time: 0.156, data: 0.000) loss: 0.518 
(epoch: 110, iters: 2592, time: 0.158, data: 0.000) loss: 0.249 
(epoch: 110, iters: 2672, time: 0.154, data: 0.000) loss: 0.291 
(epoch: 110, iters: 2752, time: 0.152, data: 0.006) loss: 0.459 
(epoch: 110, iters: 2832, time: 0.155, data: 0.000) loss: 0.285 
(epoch: 110, iters: 2912, time: 0.155, data: 0.008) loss: 0.737 
(epoch: 110, iters: 2992, time: 0.155, data: 0.005) loss: 0.359 
(epoch: 110, iters: 3072, time: 0.156, data: 0.000) loss: 0.498 
(epoch: 110, iters: 3152, time: 0.158, data: 0.000) loss: 0.356 
(epoch: 110, iters: 3232, time: 0.156, data: 0.015) loss: 0.552 
(epoch: 110, iters: 3312, time: 0.155, data: 0.011) loss: 0.352 
(epoch: 110, iters: 3392, time: 0.156, data: 0.000) loss: 0.916 
(epoch: 110, iters: 3472, time: 0.156, data: 0.016) loss: 0.106 
(epoch: 110, iters: 3552, time: 0.157, data: 0.010) loss: 0.698 
(epoch: 110, iters: 3632, time: 0.155, data: 0.008) loss: 0.447 
(epoch: 110, iters: 3712, time: 0.154, data: 0.000) loss: 0.438 
(epoch: 110, iters: 3792, time: 0.157, data: 0.000) loss: 0.354 
(epoch: 110, iters: 3872, time: 0.157, data: 0.005) loss: 0.575 
(epoch: 110, iters: 3952, time: 0.158, data: 0.000) loss: 0.329 
saving the latest model (epoch 110, total_steps 1114944)
(epoch: 110, iters: 4032, time: 0.157, data: 0.017) loss: 0.401 
(epoch: 110, iters: 4112, time: 0.156, data: 0.016) loss: 0.392 
(epoch: 110, iters: 4192, time: 0.156, data: 0.005) loss: 0.427 
(epoch: 110, iters: 4272, time: 0.155, data: 0.000) loss: 0.486 
(epoch: 110, iters: 4352, time: 0.156, data: 0.020) loss: 0.371 
(epoch: 110, iters: 4432, time: 0.158, data: 0.009) loss: 0.333 
(epoch: 110, iters: 4512, time: 0.158, data: 0.000) loss: 0.283 
(epoch: 110, iters: 4592, time: 0.156, data: 0.006) loss: 0.534 
(epoch: 110, iters: 4672, time: 0.157, data: 0.000) loss: 0.248 
(epoch: 110, iters: 4752, time: 0.157, data: 0.011) loss: 0.223 
(epoch: 110, iters: 4832, time: 0.156, data: 0.000) loss: 1.063 
(epoch: 110, iters: 4912, time: 0.161, data: 0.000) loss: 0.202 
(epoch: 110, iters: 4992, time: 0.152, data: 0.005) loss: 0.386 
(epoch: 110, iters: 5072, time: 0.154, data: 0.011) loss: 0.920 
(epoch: 110, iters: 5152, time: 0.155, data: 0.000) loss: 0.337 
(epoch: 110, iters: 5232, time: 0.154, data: 0.000) loss: 0.127 
(epoch: 110, iters: 5312, time: 0.164, data: 0.011) loss: 0.136 
(epoch: 110, iters: 5392, time: 0.153, data: 0.000) loss: 0.114 
(epoch: 110, iters: 5472, time: 0.154, data: 0.000) loss: 0.293 
(epoch: 110, iters: 5552, time: 0.153, data: 0.021) loss: 0.258 
(epoch: 110, iters: 5632, time: 0.153, data: 0.000) loss: 0.444 
(epoch: 110, iters: 5712, time: 0.163, data: 0.017) loss: 0.950 
(epoch: 110, iters: 5792, time: 0.158, data: 0.011) loss: 0.382 
(epoch: 110, iters: 5872, time: 0.157, data: 0.015) loss: 0.473 
(epoch: 110, iters: 5952, time: 0.156, data: 0.005) loss: 0.437 
(epoch: 110, iters: 6032, time: 0.157, data: 0.000) loss: 0.402 
(epoch: 110, iters: 6112, time: 0.164, data: 0.000) loss: 0.543 
(epoch: 110, iters: 6192, time: 0.156, data: 0.016) loss: 0.275 
(epoch: 110, iters: 6272, time: 0.158, data: 0.000) loss: 0.058 
(epoch: 110, iters: 6352, time: 0.159, data: 0.014) loss: 0.229 
(epoch: 110, iters: 6432, time: 0.157, data: 0.024) loss: 0.143 
(epoch: 110, iters: 6512, time: 0.160, data: 0.000) loss: 0.495 
(epoch: 110, iters: 6592, time: 0.157, data: 0.000) loss: 1.509 
(epoch: 110, iters: 6672, time: 0.155, data: 0.000) loss: 0.226 
(epoch: 110, iters: 6752, time: 0.157, data: 0.000) loss: 0.531 
(epoch: 110, iters: 6832, time: 0.156, data: 0.016) loss: 0.477 
(epoch: 110, iters: 6912, time: 0.158, data: 0.018) loss: 0.138 
(epoch: 110, iters: 6992, time: 0.157, data: 0.000) loss: 0.651 
(epoch: 110, iters: 7072, time: 0.156, data: 0.000) loss: 0.590 
(epoch: 110, iters: 7152, time: 0.155, data: 0.005) loss: 0.283 
(epoch: 110, iters: 7232, time: 0.157, data: 0.000) loss: 0.582 
(epoch: 110, iters: 7312, time: 0.157, data: 0.015) loss: 0.769 
(epoch: 110, iters: 7392, time: 0.157, data: 0.000) loss: 0.138 
(epoch: 110, iters: 7472, time: 0.157, data: 0.008) loss: 0.765 
(epoch: 110, iters: 7552, time: 0.157, data: 0.015) loss: 0.348 
(epoch: 110, iters: 7632, time: 0.158, data: 0.000) loss: 0.607 
(epoch: 110, iters: 7712, time: 0.157, data: 0.010) loss: 0.349 
(epoch: 110, iters: 7792, time: 0.155, data: 0.000) loss: 0.307 
(epoch: 110, iters: 7872, time: 0.156, data: 0.000) loss: 0.314 
(epoch: 110, iters: 7952, time: 0.154, data: 0.017) loss: 0.363 
saving the latest model (epoch 110, total_steps 1118944)
(epoch: 110, iters: 8032, time: 0.151, data: 0.008) loss: 0.812 
(epoch: 110, iters: 8112, time: 0.152, data: 0.008) loss: 0.597 
(epoch: 110, iters: 8192, time: 0.152, data: 0.000) loss: 0.590 
(epoch: 110, iters: 8272, time: 0.151, data: 0.013) loss: 0.407 
(epoch: 110, iters: 8352, time: 0.155, data: 0.000) loss: 0.255 
(epoch: 110, iters: 8432, time: 0.156, data: 0.025) loss: 1.001 
(epoch: 110, iters: 8512, time: 0.155, data: 0.000) loss: 0.290 
(epoch: 110, iters: 8592, time: 0.154, data: 0.005) loss: 0.456 
(epoch: 110, iters: 8672, time: 0.158, data: 0.000) loss: 0.740 
(epoch: 110, iters: 8752, time: 0.156, data: 0.000) loss: 0.436 
(epoch: 110, iters: 8832, time: 0.154, data: 0.000) loss: 0.706 
(epoch: 110, iters: 8912, time: 0.155, data: 0.000) loss: 0.212 
(epoch: 110, iters: 8992, time: 0.156, data: 0.022) loss: 0.386 
(epoch: 110, iters: 9072, time: 0.157, data: 0.000) loss: 0.547 
(epoch: 110, iters: 9152, time: 0.155, data: 0.009) loss: 0.752 
(epoch: 110, iters: 9232, time: 0.154, data: 0.020) loss: 0.391 
(epoch: 110, iters: 9312, time: 0.156, data: 0.000) loss: 0.473 
(epoch: 110, iters: 9392, time: 0.156, data: 0.000) loss: 0.367 
(epoch: 110, iters: 9472, time: 0.157, data: 0.000) loss: 0.231 
(epoch: 110, iters: 9552, time: 0.157, data: 0.006) loss: 0.382 
(epoch: 110, iters: 9632, time: 0.160, data: 0.000) loss: 0.989 
(epoch: 110, iters: 9712, time: 0.153, data: 0.011) loss: 0.570 
(epoch: 110, iters: 9792, time: 0.155, data: 0.000) loss: 0.476 
(epoch: 110, iters: 9872, time: 0.155, data: 0.008) loss: 0.404 
(epoch: 110, iters: 9952, time: 0.157, data: 0.000) loss: 1.041 
(epoch: 110, iters: 10032, time: 0.157, data: 0.000) loss: 0.672 
(epoch: 110, iters: 10112, time: 0.158, data: 0.014) loss: 0.233 
(epoch: 110, iters: 10192, time: 0.094, data: 0.000) loss: 0.518 
saving the model at the end of epoch 110, iters 1121120
End of epoch 110 / 200 	 Time Taken: 1592 sec
learning rate = 0.0001762
saving the latest model (epoch 111, total_steps 1121136)
(epoch: 111, iters: 80, time: 0.157, data: 0.187) loss: 0.418 
(epoch: 111, iters: 160, time: 0.153, data: 0.000) loss: 0.677 
(epoch: 111, iters: 240, time: 0.155, data: 0.000) loss: 0.392 
(epoch: 111, iters: 320, time: 0.155, data: 0.000) loss: 0.535 
(epoch: 111, iters: 400, time: 0.155, data: 0.008) loss: 0.465 
(epoch: 111, iters: 480, time: 0.157, data: 0.000) loss: 0.209 
(epoch: 111, iters: 560, time: 0.152, data: 0.008) loss: 0.473 
(epoch: 111, iters: 640, time: 0.153, data: 0.005) loss: 0.517 
(epoch: 111, iters: 720, time: 0.150, data: 0.000) loss: 0.066 
(epoch: 111, iters: 800, time: 0.152, data: 0.015) loss: 0.699 
(epoch: 111, iters: 880, time: 0.152, data: 0.000) loss: 0.239 
(epoch: 111, iters: 960, time: 0.153, data: 0.026) loss: 0.142 
(epoch: 111, iters: 1040, time: 0.152, data: 0.000) loss: 0.756 
(epoch: 111, iters: 1120, time: 0.152, data: 0.022) loss: 0.456 
(epoch: 111, iters: 1200, time: 0.151, data: 0.000) loss: 0.981 
(epoch: 111, iters: 1280, time: 0.150, data: 0.000) loss: 0.189 
(epoch: 111, iters: 1360, time: 0.151, data: 0.006) loss: 0.396 
(epoch: 111, iters: 1440, time: 0.151, data: 0.000) loss: 0.398 
(epoch: 111, iters: 1520, time: 0.153, data: 0.000) loss: 0.642 
(epoch: 111, iters: 1600, time: 0.152, data: 0.031) loss: 0.290 
(epoch: 111, iters: 1680, time: 0.150, data: 0.000) loss: 0.427 
(epoch: 111, iters: 1760, time: 0.151, data: 0.000) loss: 0.227 
(epoch: 111, iters: 1840, time: 0.155, data: 0.009) loss: 0.378 
(epoch: 111, iters: 1920, time: 0.160, data: 0.000) loss: 0.775 
(epoch: 111, iters: 2000, time: 0.151, data: 0.000) loss: 0.155 
(epoch: 111, iters: 2080, time: 0.153, data: 0.000) loss: 0.325 
(epoch: 111, iters: 2160, time: 0.152, data: 0.000) loss: 0.571 
(epoch: 111, iters: 2240, time: 0.152, data: 0.024) loss: 0.394 
(epoch: 111, iters: 2320, time: 0.160, data: 0.014) loss: 0.539 
(epoch: 111, iters: 2400, time: 0.154, data: 0.000) loss: 0.798 
(epoch: 111, iters: 2480, time: 0.154, data: 0.006) loss: 0.265 
(epoch: 111, iters: 2560, time: 0.155, data: 0.000) loss: 0.063 
(epoch: 111, iters: 2640, time: 0.152, data: 0.000) loss: 0.355 
(epoch: 111, iters: 2720, time: 0.155, data: 0.010) loss: 0.774 
(epoch: 111, iters: 2800, time: 0.152, data: 0.000) loss: 0.431 
(epoch: 111, iters: 2880, time: 0.154, data: 0.000) loss: 0.719 
(epoch: 111, iters: 2960, time: 0.154, data: 0.000) loss: 0.550 
(epoch: 111, iters: 3040, time: 0.154, data: 0.000) loss: 0.389 
(epoch: 111, iters: 3120, time: 0.156, data: 0.000) loss: 0.442 
(epoch: 111, iters: 3200, time: 0.156, data: 0.000) loss: 0.468 
(epoch: 111, iters: 3280, time: 0.150, data: 0.021) loss: 0.310 
(epoch: 111, iters: 3360, time: 0.153, data: 0.000) loss: 0.354 
(epoch: 111, iters: 3440, time: 0.154, data: 0.000) loss: 0.611 
(epoch: 111, iters: 3520, time: 0.155, data: 0.014) loss: 0.587 
(epoch: 111, iters: 3600, time: 0.153, data: 0.008) loss: 0.548 
(epoch: 111, iters: 3680, time: 0.154, data: 0.000) loss: 0.433 
(epoch: 111, iters: 3760, time: 0.155, data: 0.000) loss: 0.425 
(epoch: 111, iters: 3840, time: 0.154, data: 0.016) loss: 0.450 
(epoch: 111, iters: 3920, time: 0.159, data: 0.000) loss: 0.719 
(epoch: 111, iters: 4000, time: 0.153, data: 0.000) loss: 0.368 
saving the latest model (epoch 111, total_steps 1125136)
(epoch: 111, iters: 4080, time: 0.153, data: 0.009) loss: 0.211 
(epoch: 111, iters: 4160, time: 0.155, data: 0.006) loss: 0.839 
(epoch: 111, iters: 4240, time: 0.152, data: 0.019) loss: 0.306 
(epoch: 111, iters: 4320, time: 0.157, data: 0.005) loss: 0.180 
(epoch: 111, iters: 4400, time: 0.157, data: 0.029) loss: 0.830 
(epoch: 111, iters: 4480, time: 0.154, data: 0.000) loss: 0.659 
(epoch: 111, iters: 4560, time: 0.156, data: 0.028) loss: 0.274 
(epoch: 111, iters: 4640, time: 0.152, data: 0.024) loss: 0.372 
(epoch: 111, iters: 4720, time: 0.156, data: 0.000) loss: 0.118 
(epoch: 111, iters: 4800, time: 0.155, data: 0.008) loss: 0.226 
(epoch: 111, iters: 4880, time: 0.154, data: 0.015) loss: 0.930 
(epoch: 111, iters: 4960, time: 0.154, data: 0.000) loss: 0.270 
(epoch: 111, iters: 5040, time: 0.155, data: 0.009) loss: 0.345 
(epoch: 111, iters: 5120, time: 0.156, data: 0.000) loss: 0.697 
(epoch: 111, iters: 5200, time: 0.153, data: 0.000) loss: 0.465 
(epoch: 111, iters: 5280, time: 0.154, data: 0.000) loss: 0.289 
(epoch: 111, iters: 5360, time: 0.152, data: 0.000) loss: 0.329 
(epoch: 111, iters: 5440, time: 0.150, data: 0.018) loss: 0.473 
(epoch: 111, iters: 5520, time: 0.154, data: 0.007) loss: 0.626 
(epoch: 111, iters: 5600, time: 0.153, data: 0.000) loss: 0.449 
(epoch: 111, iters: 5680, time: 0.155, data: 0.000) loss: 0.923 
(epoch: 111, iters: 5760, time: 0.153, data: 0.023) loss: 0.535 
(epoch: 111, iters: 5840, time: 0.154, data: 0.000) loss: 0.462 
(epoch: 111, iters: 5920, time: 0.153, data: 0.000) loss: 0.542 
(epoch: 111, iters: 6000, time: 0.153, data: 0.025) loss: 0.363 
(epoch: 111, iters: 6080, time: 0.154, data: 0.019) loss: 0.081 
(epoch: 111, iters: 6160, time: 0.155, data: 0.000) loss: 0.272 
(epoch: 111, iters: 6240, time: 0.156, data: 0.000) loss: 1.154 
(epoch: 111, iters: 6320, time: 0.153, data: 0.018) loss: 0.369 
(epoch: 111, iters: 6400, time: 0.154, data: 0.034) loss: 0.295 
(epoch: 111, iters: 6480, time: 0.154, data: 0.000) loss: 0.407 
(epoch: 111, iters: 6560, time: 0.152, data: 0.033) loss: 0.650 
(epoch: 111, iters: 6640, time: 0.152, data: 0.000) loss: 0.372 
(epoch: 111, iters: 6720, time: 0.155, data: 0.000) loss: 0.473 
(epoch: 111, iters: 6800, time: 0.152, data: 0.000) loss: 0.735 
(epoch: 111, iters: 6880, time: 0.152, data: 0.024) loss: 0.302 
(epoch: 111, iters: 6960, time: 0.154, data: 0.000) loss: 0.375 
(epoch: 111, iters: 7040, time: 0.154, data: 0.014) loss: 0.339 
(epoch: 111, iters: 7120, time: 0.152, data: 0.006) loss: 0.528 
(epoch: 111, iters: 7200, time: 0.151, data: 0.005) loss: 0.850 
(epoch: 111, iters: 7280, time: 0.152, data: 0.021) loss: 0.501 
(epoch: 111, iters: 7360, time: 0.153, data: 0.000) loss: 0.327 
(epoch: 111, iters: 7440, time: 0.155, data: 0.017) loss: 0.756 
(epoch: 111, iters: 7520, time: 0.154, data: 0.000) loss: 0.658 
(epoch: 111, iters: 7600, time: 0.154, data: 0.000) loss: 0.331 
(epoch: 111, iters: 7680, time: 0.154, data: 0.000) loss: 0.198 
(epoch: 111, iters: 7760, time: 0.153, data: 0.000) loss: 0.601 
(epoch: 111, iters: 7840, time: 0.152, data: 0.000) loss: 0.860 
(epoch: 111, iters: 7920, time: 0.156, data: 0.011) loss: 0.498 
(epoch: 111, iters: 8000, time: 0.154, data: 0.000) loss: 0.364 
saving the latest model (epoch 111, total_steps 1129136)
(epoch: 111, iters: 8080, time: 0.154, data: 0.000) loss: 0.425 
(epoch: 111, iters: 8160, time: 0.154, data: 0.000) loss: 0.675 
(epoch: 111, iters: 8240, time: 0.155, data: 0.000) loss: 0.458 
(epoch: 111, iters: 8320, time: 0.155, data: 0.000) loss: 0.721 
(epoch: 111, iters: 8400, time: 0.153, data: 0.035) loss: 0.457 
(epoch: 111, iters: 8480, time: 0.153, data: 0.000) loss: 0.464 
(epoch: 111, iters: 8560, time: 0.154, data: 0.041) loss: 0.239 
(epoch: 111, iters: 8640, time: 0.155, data: 0.000) loss: 0.588 
(epoch: 111, iters: 8720, time: 0.157, data: 0.000) loss: 1.392 
(epoch: 111, iters: 8800, time: 0.155, data: 0.008) loss: 0.373 
(epoch: 111, iters: 8880, time: 0.151, data: 0.008) loss: 0.124 
(epoch: 111, iters: 8960, time: 0.154, data: 0.006) loss: 0.195 
(epoch: 111, iters: 9040, time: 0.154, data: 0.009) loss: 0.502 
(epoch: 111, iters: 9120, time: 0.155, data: 0.005) loss: 1.502 
(epoch: 111, iters: 9200, time: 0.154, data: 0.014) loss: 0.604 
(epoch: 111, iters: 9280, time: 0.153, data: 0.005) loss: 0.522 
(epoch: 111, iters: 9360, time: 0.153, data: 0.000) loss: 0.166 
(epoch: 111, iters: 9440, time: 0.154, data: 0.021) loss: 0.371 
(epoch: 111, iters: 9520, time: 0.152, data: 0.000) loss: 0.168 
(epoch: 111, iters: 9600, time: 0.153, data: 0.015) loss: 0.751 
(epoch: 111, iters: 9680, time: 0.153, data: 0.000) loss: 0.606 
(epoch: 111, iters: 9760, time: 0.153, data: 0.000) loss: 1.179 
(epoch: 111, iters: 9840, time: 0.154, data: 0.024) loss: 0.434 
(epoch: 111, iters: 9920, time: 0.154, data: 0.000) loss: 0.440 
(epoch: 111, iters: 10000, time: 0.153, data: 0.017) loss: 0.548 
(epoch: 111, iters: 10080, time: 0.156, data: 0.000) loss: 0.223 
(epoch: 111, iters: 10160, time: 0.153, data: 0.016) loss: 0.437 
saving the model at the end of epoch 111, iters 1131312
End of epoch 111 / 200 	 Time Taken: 1571 sec
learning rate = 0.0001743
saving the latest model (epoch 112, total_steps 1131328)
(epoch: 112, iters: 48, time: 0.164, data: 0.005) loss: 0.411 
(epoch: 112, iters: 128, time: 0.152, data: 0.018) loss: 0.753 
(epoch: 112, iters: 208, time: 0.153, data: 0.016) loss: 0.378 
(epoch: 112, iters: 288, time: 0.155, data: 0.000) loss: 0.454 
(epoch: 112, iters: 368, time: 0.155, data: 0.019) loss: 0.503 
(epoch: 112, iters: 448, time: 0.155, data: 0.000) loss: 0.243 
(epoch: 112, iters: 528, time: 0.164, data: 0.000) loss: 0.880 
(epoch: 112, iters: 608, time: 0.163, data: 0.027) loss: 0.548 
(epoch: 112, iters: 688, time: 0.164, data: 0.000) loss: 0.657 
(epoch: 112, iters: 768, time: 0.164, data: 0.000) loss: 0.340 
(epoch: 112, iters: 848, time: 0.164, data: 0.008) loss: 0.507 
(epoch: 112, iters: 928, time: 0.165, data: 0.000) loss: 0.776 
(epoch: 112, iters: 1008, time: 0.164, data: 0.025) loss: 0.364 
(epoch: 112, iters: 1088, time: 0.163, data: 0.000) loss: 0.236 
(epoch: 112, iters: 1168, time: 0.164, data: 0.000) loss: 0.585 
(epoch: 112, iters: 1248, time: 0.161, data: 0.005) loss: 0.387 
(epoch: 112, iters: 1328, time: 0.169, data: 0.000) loss: 0.686 
(epoch: 112, iters: 1408, time: 0.164, data: 0.005) loss: 0.442 
(epoch: 112, iters: 1488, time: 0.164, data: 0.000) loss: 0.389 
(epoch: 112, iters: 1568, time: 0.165, data: 0.028) loss: 0.879 
(epoch: 112, iters: 1648, time: 0.162, data: 0.000) loss: 0.909 
(epoch: 112, iters: 1728, time: 0.164, data: 0.010) loss: 0.422 
(epoch: 112, iters: 1808, time: 0.162, data: 0.000) loss: 0.084 
(epoch: 112, iters: 1888, time: 0.163, data: 0.000) loss: 0.260 
(epoch: 112, iters: 1968, time: 0.160, data: 0.000) loss: 0.440 
(epoch: 112, iters: 2048, time: 0.163, data: 0.016) loss: 0.530 
(epoch: 112, iters: 2128, time: 0.162, data: 0.000) loss: 0.108 
(epoch: 112, iters: 2208, time: 0.161, data: 0.023) loss: 0.743 
(epoch: 112, iters: 2288, time: 0.164, data: 0.000) loss: 0.270 
(epoch: 112, iters: 2368, time: 0.163, data: 0.000) loss: 0.230 
(epoch: 112, iters: 2448, time: 0.163, data: 0.014) loss: 0.397 
(epoch: 112, iters: 2528, time: 0.164, data: 0.025) loss: 0.462 
(epoch: 112, iters: 2608, time: 0.163, data: 0.020) loss: 0.453 
(epoch: 112, iters: 2688, time: 0.163, data: 0.000) loss: 0.427 
(epoch: 112, iters: 2768, time: 0.163, data: 0.033) loss: 0.607 
(epoch: 112, iters: 2848, time: 0.163, data: 0.000) loss: 0.630 
(epoch: 112, iters: 2928, time: 0.163, data: 0.020) loss: 0.411 
(epoch: 112, iters: 3008, time: 0.163, data: 0.000) loss: 0.622 
(epoch: 112, iters: 3088, time: 0.163, data: 0.012) loss: 0.407 
(epoch: 112, iters: 3168, time: 0.163, data: 0.000) loss: 0.207 
(epoch: 112, iters: 3248, time: 0.163, data: 0.000) loss: 0.722 
(epoch: 112, iters: 3328, time: 0.163, data: 0.020) loss: 0.667 
(epoch: 112, iters: 3408, time: 0.164, data: 0.000) loss: 0.641 
(epoch: 112, iters: 3488, time: 0.164, data: 0.000) loss: 0.254 
(epoch: 112, iters: 3568, time: 0.163, data: 0.005) loss: 0.362 
(epoch: 112, iters: 3648, time: 0.164, data: 0.005) loss: 0.442 
(epoch: 112, iters: 3728, time: 0.162, data: 0.020) loss: 0.612 
(epoch: 112, iters: 3808, time: 0.166, data: 0.025) loss: 0.503 
(epoch: 112, iters: 3888, time: 0.163, data: 0.000) loss: 0.622 
(epoch: 112, iters: 3968, time: 0.170, data: 0.025) loss: 0.849 
saving the latest model (epoch 112, total_steps 1135328)
(epoch: 112, iters: 4048, time: 0.164, data: 0.000) loss: 0.409 
(epoch: 112, iters: 4128, time: 0.166, data: 0.000) loss: 0.705 
(epoch: 112, iters: 4208, time: 0.162, data: 0.005) loss: 0.371 
(epoch: 112, iters: 4288, time: 0.163, data: 0.000) loss: 0.253 
(epoch: 112, iters: 4368, time: 0.164, data: 0.000) loss: 0.860 
(epoch: 112, iters: 4448, time: 0.166, data: 0.005) loss: 0.312 
(epoch: 112, iters: 4528, time: 0.165, data: 0.000) loss: 1.205 
(epoch: 112, iters: 4608, time: 0.164, data: 0.000) loss: 0.599 
(epoch: 112, iters: 4688, time: 0.166, data: 0.000) loss: 0.534 
(epoch: 112, iters: 4768, time: 0.165, data: 0.023) loss: 0.229 
(epoch: 112, iters: 4848, time: 0.165, data: 0.000) loss: 0.510 
(epoch: 112, iters: 4928, time: 0.167, data: 0.006) loss: 0.391 
(epoch: 112, iters: 5008, time: 0.163, data: 0.000) loss: 0.512 
(epoch: 112, iters: 5088, time: 0.169, data: 0.014) loss: 0.198 
(epoch: 112, iters: 5168, time: 0.164, data: 0.013) loss: 0.428 
(epoch: 112, iters: 5248, time: 0.164, data: 0.005) loss: 0.453 
(epoch: 112, iters: 5328, time: 0.165, data: 0.017) loss: 0.546 
(epoch: 112, iters: 5408, time: 0.165, data: 0.000) loss: 0.340 
(epoch: 112, iters: 5488, time: 0.167, data: 0.000) loss: 0.436 
(epoch: 112, iters: 5568, time: 0.164, data: 0.000) loss: 0.727 
(epoch: 112, iters: 5648, time: 0.165, data: 0.006) loss: 0.423 
(epoch: 112, iters: 5728, time: 0.165, data: 0.000) loss: 0.388 
(epoch: 112, iters: 5808, time: 0.166, data: 0.000) loss: 0.595 
(epoch: 112, iters: 5888, time: 0.165, data: 0.017) loss: 0.069 
(epoch: 112, iters: 5968, time: 0.166, data: 0.000) loss: 0.413 
(epoch: 112, iters: 6048, time: 0.166, data: 0.005) loss: 0.564 
(epoch: 112, iters: 6128, time: 0.167, data: 0.000) loss: 0.730 
(epoch: 112, iters: 6208, time: 0.168, data: 0.024) loss: 0.401 
(epoch: 112, iters: 6288, time: 0.165, data: 0.000) loss: 0.450 
(epoch: 112, iters: 6368, time: 0.165, data: 0.017) loss: 0.530 
(epoch: 112, iters: 6448, time: 0.165, data: 0.000) loss: 0.486 
(epoch: 112, iters: 6528, time: 0.165, data: 0.000) loss: 1.130 
(epoch: 112, iters: 6608, time: 0.165, data: 0.038) loss: 0.239 
(epoch: 112, iters: 6688, time: 0.164, data: 0.000) loss: 0.111 
(epoch: 112, iters: 6768, time: 0.165, data: 0.000) loss: 0.740 
(epoch: 112, iters: 6848, time: 0.166, data: 0.005) loss: 0.884 
(epoch: 112, iters: 6928, time: 0.167, data: 0.000) loss: 0.582 
(epoch: 112, iters: 7008, time: 0.166, data: 0.000) loss: 0.617 
(epoch: 112, iters: 7088, time: 0.167, data: 0.008) loss: 0.572 
(epoch: 112, iters: 7168, time: 0.164, data: 0.015) loss: 0.777 
(epoch: 112, iters: 7248, time: 0.164, data: 0.014) loss: 0.672 
(epoch: 112, iters: 7328, time: 0.163, data: 0.000) loss: 0.456 
(epoch: 112, iters: 7408, time: 0.165, data: 0.000) loss: 0.503 
(epoch: 112, iters: 7488, time: 0.164, data: 0.008) loss: 0.405 
(epoch: 112, iters: 7568, time: 0.164, data: 0.000) loss: 0.514 
(epoch: 112, iters: 7648, time: 0.165, data: 0.000) loss: 0.744 
(epoch: 112, iters: 7728, time: 0.166, data: 0.024) loss: 0.398 
(epoch: 112, iters: 7808, time: 0.166, data: 0.000) loss: 0.853 
(epoch: 112, iters: 7888, time: 0.163, data: 0.025) loss: 0.272 
(epoch: 112, iters: 7968, time: 0.166, data: 0.000) loss: 0.545 
saving the latest model (epoch 112, total_steps 1139328)
(epoch: 112, iters: 8048, time: 0.163, data: 0.000) loss: 0.424 
(epoch: 112, iters: 8128, time: 0.165, data: 0.021) loss: 0.488 
(epoch: 112, iters: 8208, time: 0.166, data: 0.000) loss: 0.697 
(epoch: 112, iters: 8288, time: 0.165, data: 0.031) loss: 0.330 
(epoch: 112, iters: 8368, time: 0.165, data: 0.000) loss: 0.680 
(epoch: 112, iters: 8448, time: 0.167, data: 0.000) loss: 0.263 
(epoch: 112, iters: 8528, time: 0.165, data: 0.006) loss: 0.637 
(epoch: 112, iters: 8608, time: 0.164, data: 0.000) loss: 1.001 
(epoch: 112, iters: 8688, time: 0.165, data: 0.020) loss: 0.560 
(epoch: 112, iters: 8768, time: 0.166, data: 0.000) loss: 0.220 
(epoch: 112, iters: 8848, time: 0.171, data: 0.000) loss: 0.725 
(epoch: 112, iters: 8928, time: 0.166, data: 0.005) loss: 0.487 
(epoch: 112, iters: 9008, time: 0.166, data: 0.000) loss: 0.446 
(epoch: 112, iters: 9088, time: 0.167, data: 0.000) loss: 0.665 
(epoch: 112, iters: 9168, time: 0.165, data: 0.000) loss: 0.455 
(epoch: 112, iters: 9248, time: 0.166, data: 0.000) loss: 0.571 
(epoch: 112, iters: 9328, time: 0.163, data: 0.022) loss: 0.408 
(epoch: 112, iters: 9408, time: 0.166, data: 0.000) loss: 0.688 
(epoch: 112, iters: 9488, time: 0.166, data: 0.000) loss: 0.343 
(epoch: 112, iters: 9568, time: 0.164, data: 0.000) loss: 0.511 
(epoch: 112, iters: 9648, time: 0.164, data: 0.000) loss: 0.542 
(epoch: 112, iters: 9728, time: 0.165, data: 0.000) loss: 0.376 
(epoch: 112, iters: 9808, time: 0.163, data: 0.005) loss: 0.290 
(epoch: 112, iters: 9888, time: 0.164, data: 0.013) loss: 0.470 
(epoch: 112, iters: 9968, time: 0.173, data: 0.000) loss: 0.157 
(epoch: 112, iters: 10048, time: 0.164, data: 0.013) loss: 0.632 
(epoch: 112, iters: 10128, time: 0.164, data: 0.000) loss: 0.213 
saving the model at the end of epoch 112, iters 1141504
End of epoch 112 / 200 	 Time Taken: 1679 sec
learning rate = 0.0001723
(epoch: 113, iters: 16, time: 0.180, data: 0.000) loss: 0.151 
saving the latest model (epoch 113, total_steps 1141520)
(epoch: 113, iters: 96, time: 0.166, data: 0.021) loss: 0.201 
(epoch: 113, iters: 176, time: 0.163, data: 0.006) loss: 0.219 
(epoch: 113, iters: 256, time: 0.165, data: 0.018) loss: 0.087 
(epoch: 113, iters: 336, time: 0.163, data: 0.010) loss: 0.391 
(epoch: 113, iters: 416, time: 0.161, data: 0.000) loss: 0.167 
(epoch: 113, iters: 496, time: 0.159, data: 0.000) loss: 0.558 
(epoch: 113, iters: 576, time: 0.157, data: 0.000) loss: 0.733 
(epoch: 113, iters: 656, time: 0.160, data: 0.000) loss: 0.800 
(epoch: 113, iters: 736, time: 0.160, data: 0.018) loss: 0.529 
(epoch: 113, iters: 816, time: 0.161, data: 0.000) loss: 0.589 
(epoch: 113, iters: 896, time: 0.159, data: 0.000) loss: 0.125 
(epoch: 113, iters: 976, time: 0.162, data: 0.026) loss: 0.208 
(epoch: 113, iters: 1056, time: 0.162, data: 0.000) loss: 0.568 
(epoch: 113, iters: 1136, time: 0.162, data: 0.010) loss: 0.587 
(epoch: 113, iters: 1216, time: 0.160, data: 0.000) loss: 0.322 
(epoch: 113, iters: 1296, time: 0.170, data: 0.016) loss: 0.200 
(epoch: 113, iters: 1376, time: 0.160, data: 0.000) loss: 0.456 
(epoch: 113, iters: 1456, time: 0.162, data: 0.000) loss: 0.600 
(epoch: 113, iters: 1536, time: 0.160, data: 0.000) loss: 0.389 
(epoch: 113, iters: 1616, time: 0.159, data: 0.000) loss: 0.440 
(epoch: 113, iters: 1696, time: 0.162, data: 0.015) loss: 0.788 
(epoch: 113, iters: 1776, time: 0.161, data: 0.015) loss: 0.625 
(epoch: 113, iters: 1856, time: 0.161, data: 0.000) loss: 0.673 
(epoch: 113, iters: 1936, time: 0.162, data: 0.000) loss: 0.158 
(epoch: 113, iters: 2016, time: 0.163, data: 0.017) loss: 0.817 
(epoch: 113, iters: 2096, time: 0.161, data: 0.010) loss: 0.309 
(epoch: 113, iters: 2176, time: 0.159, data: 0.000) loss: 0.273 
(epoch: 113, iters: 2256, time: 0.159, data: 0.022) loss: 0.182 
(epoch: 113, iters: 2336, time: 0.160, data: 0.000) loss: 0.506 
(epoch: 113, iters: 2416, time: 0.160, data: 0.005) loss: 0.295 
(epoch: 113, iters: 2496, time: 0.158, data: 0.011) loss: 0.905 
(epoch: 113, iters: 2576, time: 0.158, data: 0.000) loss: 0.171 
(epoch: 113, iters: 2656, time: 0.159, data: 0.015) loss: 0.367 
(epoch: 113, iters: 2736, time: 0.160, data: 0.008) loss: 0.207 
(epoch: 113, iters: 2816, time: 0.159, data: 0.017) loss: 0.272 
(epoch: 113, iters: 2896, time: 0.160, data: 0.026) loss: 0.522 
(epoch: 113, iters: 2976, time: 0.160, data: 0.000) loss: 0.598 
(epoch: 113, iters: 3056, time: 0.162, data: 0.029) loss: 0.432 
(epoch: 113, iters: 3136, time: 0.159, data: 0.000) loss: 0.377 
(epoch: 113, iters: 3216, time: 0.158, data: 0.000) loss: 0.231 
(epoch: 113, iters: 3296, time: 0.161, data: 0.008) loss: 0.453 
(epoch: 113, iters: 3376, time: 0.159, data: 0.000) loss: 0.311 
(epoch: 113, iters: 3456, time: 0.161, data: 0.000) loss: 0.561 
(epoch: 113, iters: 3536, time: 0.159, data: 0.016) loss: 0.236 
(epoch: 113, iters: 3616, time: 0.165, data: 0.000) loss: 0.223 
(epoch: 113, iters: 3696, time: 0.160, data: 0.021) loss: 0.586 
(epoch: 113, iters: 3776, time: 0.163, data: 0.005) loss: 0.396 
(epoch: 113, iters: 3856, time: 0.160, data: 0.000) loss: 0.177 
(epoch: 113, iters: 3936, time: 0.162, data: 0.000) loss: 0.281 
(epoch: 113, iters: 4016, time: 0.162, data: 0.014) loss: 0.685 
saving the latest model (epoch 113, total_steps 1145520)
(epoch: 113, iters: 4096, time: 0.160, data: 0.024) loss: 0.396 
(epoch: 113, iters: 4176, time: 0.163, data: 0.000) loss: 0.259 
(epoch: 113, iters: 4256, time: 0.162, data: 0.000) loss: 0.319 
(epoch: 113, iters: 4336, time: 0.162, data: 0.017) loss: 0.228 
(epoch: 113, iters: 4416, time: 0.160, data: 0.000) loss: 0.354 
(epoch: 113, iters: 4496, time: 0.159, data: 0.024) loss: 0.316 
(epoch: 113, iters: 4576, time: 0.162, data: 0.000) loss: 0.438 
(epoch: 113, iters: 4656, time: 0.160, data: 0.000) loss: 0.299 
(epoch: 113, iters: 4736, time: 0.161, data: 0.006) loss: 0.203 
(epoch: 113, iters: 4816, time: 0.163, data: 0.022) loss: 0.493 
(epoch: 113, iters: 4896, time: 0.161, data: 0.033) loss: 0.422 
(epoch: 113, iters: 4976, time: 0.159, data: 0.000) loss: 0.962 
(epoch: 113, iters: 5056, time: 0.159, data: 0.009) loss: 0.403 
(epoch: 113, iters: 5136, time: 0.162, data: 0.005) loss: 0.591 
(epoch: 113, iters: 5216, time: 0.159, data: 0.000) loss: 0.414 
(epoch: 113, iters: 5296, time: 0.161, data: 0.000) loss: 0.287 
(epoch: 113, iters: 5376, time: 0.162, data: 0.005) loss: 0.969 
(epoch: 113, iters: 5456, time: 0.162, data: 0.006) loss: 0.158 
(epoch: 113, iters: 5536, time: 0.164, data: 0.005) loss: 0.695 
(epoch: 113, iters: 5616, time: 0.162, data: 0.000) loss: 0.914 
(epoch: 113, iters: 5696, time: 0.161, data: 0.022) loss: 0.396 
(epoch: 113, iters: 5776, time: 0.163, data: 0.000) loss: 0.635 
(epoch: 113, iters: 5856, time: 0.160, data: 0.005) loss: 0.640 
(epoch: 113, iters: 5936, time: 0.162, data: 0.000) loss: 0.201 
(epoch: 113, iters: 6016, time: 0.162, data: 0.000) loss: 0.394 
(epoch: 113, iters: 6096, time: 0.162, data: 0.032) loss: 0.225 
(epoch: 113, iters: 6176, time: 0.160, data: 0.000) loss: 0.350 
(epoch: 113, iters: 6256, time: 0.162, data: 0.017) loss: 0.572 
(epoch: 113, iters: 6336, time: 0.161, data: 0.000) loss: 0.361 
(epoch: 113, iters: 6416, time: 0.162, data: 0.000) loss: 0.147 
(epoch: 113, iters: 6496, time: 0.162, data: 0.000) loss: 0.260 
(epoch: 113, iters: 6576, time: 0.163, data: 0.000) loss: 0.222 
(epoch: 113, iters: 6656, time: 0.161, data: 0.006) loss: 0.384 
(epoch: 113, iters: 6736, time: 0.161, data: 0.025) loss: 0.423 
(epoch: 113, iters: 6816, time: 0.160, data: 0.000) loss: 0.415 
(epoch: 113, iters: 6896, time: 0.159, data: 0.005) loss: 0.210 
(epoch: 113, iters: 6976, time: 0.163, data: 0.000) loss: 0.237 
(epoch: 113, iters: 7056, time: 0.165, data: 0.006) loss: 0.349 
(epoch: 113, iters: 7136, time: 0.163, data: 0.000) loss: 0.369 
(epoch: 113, iters: 7216, time: 0.163, data: 0.006) loss: 0.427 
(epoch: 113, iters: 7296, time: 0.161, data: 0.025) loss: 0.319 
(epoch: 113, iters: 7376, time: 0.160, data: 0.000) loss: 1.091 
(epoch: 113, iters: 7456, time: 0.161, data: 0.000) loss: 0.169 
(epoch: 113, iters: 7536, time: 0.160, data: 0.000) loss: 0.602 
(epoch: 113, iters: 7616, time: 0.159, data: 0.013) loss: 0.393 
(epoch: 113, iters: 7696, time: 0.164, data: 0.009) loss: 0.386 
(epoch: 113, iters: 7776, time: 0.160, data: 0.000) loss: 0.175 
(epoch: 113, iters: 7856, time: 0.159, data: 0.011) loss: 0.475 
(epoch: 113, iters: 7936, time: 0.158, data: 0.008) loss: 0.318 
(epoch: 113, iters: 8016, time: 0.157, data: 0.000) loss: 0.797 
saving the latest model (epoch 113, total_steps 1149520)
(epoch: 113, iters: 8096, time: 0.157, data: 0.005) loss: 0.063 
(epoch: 113, iters: 8176, time: 0.156, data: 0.019) loss: 0.617 
(epoch: 113, iters: 8256, time: 0.157, data: 0.000) loss: 0.378 
(epoch: 113, iters: 8336, time: 0.159, data: 0.013) loss: 0.345 
(epoch: 113, iters: 8416, time: 0.156, data: 0.000) loss: 0.605 
(epoch: 113, iters: 8496, time: 0.156, data: 0.000) loss: 0.625 
(epoch: 113, iters: 8576, time: 0.157, data: 0.020) loss: 0.273 
(epoch: 113, iters: 8656, time: 0.159, data: 0.000) loss: 0.637 
(epoch: 113, iters: 8736, time: 0.159, data: 0.000) loss: 0.289 
(epoch: 113, iters: 8816, time: 0.160, data: 0.000) loss: 0.595 
(epoch: 113, iters: 8896, time: 0.161, data: 0.000) loss: 0.634 
(epoch: 113, iters: 8976, time: 0.160, data: 0.009) loss: 0.497 
(epoch: 113, iters: 9056, time: 0.160, data: 0.018) loss: 0.723 
(epoch: 113, iters: 9136, time: 0.158, data: 0.000) loss: 0.671 
(epoch: 113, iters: 9216, time: 0.159, data: 0.000) loss: 0.376 
(epoch: 113, iters: 9296, time: 0.163, data: 0.000) loss: 0.264 
(epoch: 113, iters: 9376, time: 0.161, data: 0.008) loss: 0.419 
(epoch: 113, iters: 9456, time: 0.160, data: 0.000) loss: 1.044 
(epoch: 113, iters: 9536, time: 0.162, data: 0.000) loss: 0.602 
(epoch: 113, iters: 9616, time: 0.161, data: 0.010) loss: 0.326 
(epoch: 113, iters: 9696, time: 0.161, data: 0.000) loss: 0.569 
(epoch: 113, iters: 9776, time: 0.164, data: 0.000) loss: 0.462 
(epoch: 113, iters: 9856, time: 0.161, data: 0.009) loss: 0.302 
(epoch: 113, iters: 9936, time: 0.158, data: 0.000) loss: 0.377 
(epoch: 113, iters: 10016, time: 0.160, data: 0.000) loss: 0.159 
(epoch: 113, iters: 10096, time: 0.158, data: 0.000) loss: 0.361 
(epoch: 113, iters: 10176, time: 0.162, data: 0.000) loss: 0.607 
saving the model at the end of epoch 113, iters 1151696
End of epoch 113 / 200 	 Time Taken: 1646 sec
learning rate = 0.0001703
saving the latest model (epoch 114, total_steps 1151712)
(epoch: 114, iters: 64, time: 0.161, data: 0.003) loss: 0.632 
(epoch: 114, iters: 144, time: 0.157, data: 0.021) loss: 0.258 
(epoch: 114, iters: 224, time: 0.156, data: 0.000) loss: 0.718 
(epoch: 114, iters: 304, time: 0.158, data: 0.020) loss: 0.484 
(epoch: 114, iters: 384, time: 0.159, data: 0.000) loss: 0.419 
(epoch: 114, iters: 464, time: 0.160, data: 0.000) loss: 0.498 
(epoch: 114, iters: 544, time: 0.158, data: 0.000) loss: 0.215 
(epoch: 114, iters: 624, time: 0.159, data: 0.000) loss: 0.754 
(epoch: 114, iters: 704, time: 0.158, data: 0.000) loss: 0.370 
(epoch: 114, iters: 784, time: 0.157, data: 0.005) loss: 0.433 
(epoch: 114, iters: 864, time: 0.161, data: 0.000) loss: 0.241 
(epoch: 114, iters: 944, time: 0.160, data: 0.000) loss: 0.384 
(epoch: 114, iters: 1024, time: 0.158, data: 0.013) loss: 0.916 
(epoch: 114, iters: 1104, time: 0.175, data: 0.000) loss: 0.718 
(epoch: 114, iters: 1184, time: 0.177, data: 0.000) loss: 0.227 
(epoch: 114, iters: 1264, time: 0.160, data: 0.008) loss: 0.364 
(epoch: 114, iters: 1344, time: 0.160, data: 0.000) loss: 0.206 
(epoch: 114, iters: 1424, time: 0.160, data: 0.000) loss: 0.567 
(epoch: 114, iters: 1504, time: 0.164, data: 0.000) loss: 0.423 
(epoch: 114, iters: 1584, time: 0.162, data: 0.000) loss: 0.273 
(epoch: 114, iters: 1664, time: 0.159, data: 0.009) loss: 0.476 
(epoch: 114, iters: 1744, time: 0.161, data: 0.006) loss: 0.623 
(epoch: 114, iters: 1824, time: 0.159, data: 0.000) loss: 0.597 
(epoch: 114, iters: 1904, time: 0.159, data: 0.013) loss: 0.520 
(epoch: 114, iters: 1984, time: 0.159, data: 0.000) loss: 0.599 
(epoch: 114, iters: 2064, time: 0.159, data: 0.000) loss: 0.297 
(epoch: 114, iters: 2144, time: 0.158, data: 0.020) loss: 0.451 
(epoch: 114, iters: 2224, time: 0.159, data: 0.009) loss: 0.436 
(epoch: 114, iters: 2304, time: 0.159, data: 0.000) loss: 0.209 
(epoch: 114, iters: 2384, time: 0.158, data: 0.000) loss: 0.331 
(epoch: 114, iters: 2464, time: 0.160, data: 0.006) loss: 0.464 
(epoch: 114, iters: 2544, time: 0.160, data: 0.000) loss: 0.316 
(epoch: 114, iters: 2624, time: 0.159, data: 0.030) loss: 0.203 
(epoch: 114, iters: 2704, time: 0.161, data: 0.000) loss: 0.285 
(epoch: 114, iters: 2784, time: 0.161, data: 0.011) loss: 0.088 
(epoch: 114, iters: 2864, time: 0.159, data: 0.000) loss: 0.161 
(epoch: 114, iters: 2944, time: 0.160, data: 0.000) loss: 0.601 
(epoch: 114, iters: 3024, time: 0.161, data: 0.026) loss: 0.557 
(epoch: 114, iters: 3104, time: 0.163, data: 0.000) loss: 0.296 
(epoch: 114, iters: 3184, time: 0.159, data: 0.005) loss: 0.804 
(epoch: 114, iters: 3264, time: 0.161, data: 0.000) loss: 0.248 
(epoch: 114, iters: 3344, time: 0.161, data: 0.000) loss: 0.171 
(epoch: 114, iters: 3424, time: 0.158, data: 0.000) loss: 0.297 
(epoch: 114, iters: 3504, time: 0.159, data: 0.018) loss: 0.297 
(epoch: 114, iters: 3584, time: 0.160, data: 0.000) loss: 0.403 
(epoch: 114, iters: 3664, time: 0.158, data: 0.000) loss: 0.485 
(epoch: 114, iters: 3744, time: 0.160, data: 0.015) loss: 0.940 
(epoch: 114, iters: 3824, time: 0.167, data: 0.013) loss: 0.389 
(epoch: 114, iters: 3904, time: 0.160, data: 0.000) loss: 0.852 
(epoch: 114, iters: 3984, time: 0.161, data: 0.000) loss: 0.300 
saving the latest model (epoch 114, total_steps 1155712)
(epoch: 114, iters: 4064, time: 0.157, data: 0.000) loss: 0.673 
(epoch: 114, iters: 4144, time: 0.158, data: 0.000) loss: 0.495 
(epoch: 114, iters: 4224, time: 0.168, data: 0.010) loss: 0.314 
(epoch: 114, iters: 4304, time: 0.160, data: 0.000) loss: 0.459 
(epoch: 114, iters: 4384, time: 0.159, data: 0.000) loss: 0.500 
(epoch: 114, iters: 4464, time: 0.160, data: 0.015) loss: 0.070 
(epoch: 114, iters: 4544, time: 0.162, data: 0.000) loss: 0.320 
(epoch: 114, iters: 4624, time: 0.159, data: 0.021) loss: 0.527 
(epoch: 114, iters: 4704, time: 0.161, data: 0.028) loss: 0.203 
(epoch: 114, iters: 4784, time: 0.158, data: 0.000) loss: 0.186 
(epoch: 114, iters: 4864, time: 0.162, data: 0.000) loss: 0.760 
(epoch: 114, iters: 4944, time: 0.159, data: 0.016) loss: 0.746 
(epoch: 114, iters: 5024, time: 0.158, data: 0.000) loss: 0.329 
(epoch: 114, iters: 5104, time: 0.158, data: 0.000) loss: 0.636 
(epoch: 114, iters: 5184, time: 0.160, data: 0.005) loss: 0.455 
(epoch: 114, iters: 5264, time: 0.160, data: 0.000) loss: 0.367 
(epoch: 114, iters: 5344, time: 0.158, data: 0.021) loss: 0.694 
(epoch: 114, iters: 5424, time: 0.160, data: 0.005) loss: 0.217 
(epoch: 114, iters: 5504, time: 0.164, data: 0.000) loss: 0.705 
(epoch: 114, iters: 5584, time: 0.162, data: 0.015) loss: 0.257 
(epoch: 114, iters: 5664, time: 0.160, data: 0.011) loss: 0.292 
(epoch: 114, iters: 5744, time: 0.158, data: 0.000) loss: 0.635 
(epoch: 114, iters: 5824, time: 0.161, data: 0.000) loss: 0.314 
(epoch: 114, iters: 5904, time: 0.160, data: 0.005) loss: 0.493 
(epoch: 114, iters: 5984, time: 0.158, data: 0.000) loss: 0.544 
(epoch: 114, iters: 6064, time: 0.159, data: 0.000) loss: 0.582 
(epoch: 114, iters: 6144, time: 0.161, data: 0.005) loss: 0.118 
(epoch: 114, iters: 6224, time: 0.158, data: 0.008) loss: 0.484 
(epoch: 114, iters: 6304, time: 0.158, data: 0.000) loss: 0.430 
(epoch: 114, iters: 6384, time: 0.158, data: 0.005) loss: 0.618 
(epoch: 114, iters: 6464, time: 0.161, data: 0.000) loss: 0.321 
(epoch: 114, iters: 6544, time: 0.164, data: 0.022) loss: 0.124 
(epoch: 114, iters: 6624, time: 0.160, data: 0.029) loss: 0.901 
(epoch: 114, iters: 6704, time: 0.158, data: 0.000) loss: 0.577 
(epoch: 114, iters: 6784, time: 0.161, data: 0.040) loss: 0.390 
(epoch: 114, iters: 6864, time: 0.161, data: 0.000) loss: 0.721 
(epoch: 114, iters: 6944, time: 0.161, data: 0.000) loss: 0.099 
(epoch: 114, iters: 7024, time: 0.158, data: 0.000) loss: 0.856 
(epoch: 114, iters: 7104, time: 0.160, data: 0.005) loss: 0.285 
(epoch: 114, iters: 7184, time: 0.162, data: 0.000) loss: 0.417 
(epoch: 114, iters: 7264, time: 0.161, data: 0.000) loss: 0.284 
(epoch: 114, iters: 7344, time: 0.163, data: 0.000) loss: 0.703 
(epoch: 114, iters: 7424, time: 0.161, data: 0.015) loss: 1.129 
(epoch: 114, iters: 7504, time: 0.160, data: 0.000) loss: 0.503 
(epoch: 114, iters: 7584, time: 0.159, data: 0.025) loss: 0.350 
(epoch: 114, iters: 7664, time: 0.159, data: 0.000) loss: 1.060 
(epoch: 114, iters: 7744, time: 0.158, data: 0.005) loss: 0.251 
(epoch: 114, iters: 7824, time: 0.160, data: 0.000) loss: 1.134 
(epoch: 114, iters: 7904, time: 0.157, data: 0.005) loss: 0.407 
(epoch: 114, iters: 7984, time: 0.160, data: 0.000) loss: 0.731 
saving the latest model (epoch 114, total_steps 1159712)
(epoch: 114, iters: 8064, time: 0.156, data: 0.021) loss: 0.353 
(epoch: 114, iters: 8144, time: 0.157, data: 0.005) loss: 0.146 
(epoch: 114, iters: 8224, time: 0.159, data: 0.008) loss: 0.086 
(epoch: 114, iters: 8304, time: 0.158, data: 0.017) loss: 0.616 
(epoch: 114, iters: 8384, time: 0.159, data: 0.000) loss: 0.585 
(epoch: 114, iters: 8464, time: 0.161, data: 0.000) loss: 0.310 
(epoch: 114, iters: 8544, time: 0.160, data: 0.000) loss: 0.182 
(epoch: 114, iters: 8624, time: 0.159, data: 0.009) loss: 0.701 
(epoch: 114, iters: 8704, time: 0.159, data: 0.000) loss: 0.139 
(epoch: 114, iters: 8784, time: 0.161, data: 0.005) loss: 0.613 
(epoch: 114, iters: 8864, time: 0.164, data: 0.000) loss: 0.985 
(epoch: 114, iters: 8944, time: 0.158, data: 0.032) loss: 0.153 
(epoch: 114, iters: 9024, time: 0.161, data: 0.000) loss: 0.187 
(epoch: 114, iters: 9104, time: 0.161, data: 0.000) loss: 0.191 
(epoch: 114, iters: 9184, time: 0.161, data: 0.009) loss: 0.457 
(epoch: 114, iters: 9264, time: 0.162, data: 0.000) loss: 0.441 
(epoch: 114, iters: 9344, time: 0.158, data: 0.008) loss: 0.295 
(epoch: 114, iters: 9424, time: 0.159, data: 0.000) loss: 0.482 
(epoch: 114, iters: 9504, time: 0.158, data: 0.000) loss: 1.074 
(epoch: 114, iters: 9584, time: 0.162, data: 0.000) loss: 0.790 
(epoch: 114, iters: 9664, time: 0.161, data: 0.000) loss: 0.402 
(epoch: 114, iters: 9744, time: 0.160, data: 0.000) loss: 0.428 
(epoch: 114, iters: 9824, time: 0.159, data: 0.005) loss: 0.427 
(epoch: 114, iters: 9904, time: 0.159, data: 0.000) loss: 0.512 
(epoch: 114, iters: 9984, time: 0.160, data: 0.014) loss: 0.211 
(epoch: 114, iters: 10064, time: 0.159, data: 0.000) loss: 0.384 
(epoch: 114, iters: 10144, time: 0.155, data: 0.005) loss: 0.570 
saving the model at the end of epoch 114, iters 1161888
End of epoch 114 / 200 	 Time Taken: 1635 sec
learning rate = 0.0001683
saving the latest model (epoch 115, total_steps 1161904)
(epoch: 115, iters: 32, time: 0.168, data: 0.010) loss: 0.536 
(epoch: 115, iters: 112, time: 0.161, data: 0.020) loss: 0.317 
(epoch: 115, iters: 192, time: 0.157, data: 0.000) loss: 1.294 
(epoch: 115, iters: 272, time: 0.160, data: 0.026) loss: 0.229 
(epoch: 115, iters: 352, time: 0.159, data: 0.000) loss: 0.285 
(epoch: 115, iters: 432, time: 0.161, data: 0.000) loss: 0.487 
(epoch: 115, iters: 512, time: 0.161, data: 0.019) loss: 0.124 
(epoch: 115, iters: 592, time: 0.159, data: 0.006) loss: 0.621 
(epoch: 115, iters: 672, time: 0.158, data: 0.016) loss: 0.724 
(epoch: 115, iters: 752, time: 0.159, data: 0.005) loss: 0.526 
(epoch: 115, iters: 832, time: 0.159, data: 0.000) loss: 0.443 
(epoch: 115, iters: 912, time: 0.160, data: 0.005) loss: 0.435 
(epoch: 115, iters: 992, time: 0.168, data: 0.005) loss: 0.649 
(epoch: 115, iters: 1072, time: 0.160, data: 0.000) loss: 0.642 
(epoch: 115, iters: 1152, time: 0.159, data: 0.000) loss: 0.329 
(epoch: 115, iters: 1232, time: 0.158, data: 0.008) loss: 0.603 
(epoch: 115, iters: 1312, time: 0.160, data: 0.006) loss: 0.329 
(epoch: 115, iters: 1392, time: 0.164, data: 0.011) loss: 0.666 
(epoch: 115, iters: 1472, time: 0.161, data: 0.000) loss: 0.363 
(epoch: 115, iters: 1552, time: 0.159, data: 0.000) loss: 0.205 
(epoch: 115, iters: 1632, time: 0.163, data: 0.000) loss: 0.676 
(epoch: 115, iters: 1712, time: 0.159, data: 0.018) loss: 0.461 
(epoch: 115, iters: 1792, time: 0.161, data: 0.000) loss: 0.370 
(epoch: 115, iters: 1872, time: 0.161, data: 0.014) loss: 0.417 
(epoch: 115, iters: 1952, time: 0.159, data: 0.006) loss: 0.257 
(epoch: 115, iters: 2032, time: 0.160, data: 0.000) loss: 0.504 
(epoch: 115, iters: 2112, time: 0.162, data: 0.005) loss: 0.749 
(epoch: 115, iters: 2192, time: 0.159, data: 0.000) loss: 0.150 
(epoch: 115, iters: 2272, time: 0.158, data: 0.000) loss: 0.352 
(epoch: 115, iters: 2352, time: 0.158, data: 0.000) loss: 0.247 
(epoch: 115, iters: 2432, time: 0.160, data: 0.009) loss: 0.307 
(epoch: 115, iters: 2512, time: 0.163, data: 0.005) loss: 0.398 
(epoch: 115, iters: 2592, time: 0.161, data: 0.000) loss: 0.741 
(epoch: 115, iters: 2672, time: 0.158, data: 0.000) loss: 0.692 
(epoch: 115, iters: 2752, time: 0.157, data: 0.009) loss: 0.260 
(epoch: 115, iters: 2832, time: 0.160, data: 0.000) loss: 0.415 
(epoch: 115, iters: 2912, time: 0.166, data: 0.019) loss: 1.105 
(epoch: 115, iters: 2992, time: 0.160, data: 0.000) loss: 0.273 
(epoch: 115, iters: 3072, time: 0.162, data: 0.023) loss: 0.850 
(epoch: 115, iters: 3152, time: 0.161, data: 0.000) loss: 0.336 
(epoch: 115, iters: 3232, time: 0.163, data: 0.005) loss: 1.076 
(epoch: 115, iters: 3312, time: 0.165, data: 0.000) loss: 0.403 
(epoch: 115, iters: 3392, time: 0.161, data: 0.000) loss: 0.607 
(epoch: 115, iters: 3472, time: 0.163, data: 0.008) loss: 0.413 
(epoch: 115, iters: 3552, time: 0.160, data: 0.000) loss: 0.278 
(epoch: 115, iters: 3632, time: 0.162, data: 0.006) loss: 0.680 
(epoch: 115, iters: 3712, time: 0.162, data: 0.005) loss: 0.285 
(epoch: 115, iters: 3792, time: 0.160, data: 0.000) loss: 0.772 
(epoch: 115, iters: 3872, time: 0.162, data: 0.000) loss: 0.226 
(epoch: 115, iters: 3952, time: 0.164, data: 0.005) loss: 0.146 
saving the latest model (epoch 115, total_steps 1165904)
(epoch: 115, iters: 4032, time: 0.160, data: 0.032) loss: 0.724 
(epoch: 115, iters: 4112, time: 0.160, data: 0.000) loss: 0.604 
(epoch: 115, iters: 4192, time: 0.161, data: 0.000) loss: 0.683 
(epoch: 115, iters: 4272, time: 0.162, data: 0.000) loss: 0.294 
(epoch: 115, iters: 4352, time: 0.162, data: 0.021) loss: 0.363 
(epoch: 115, iters: 4432, time: 0.162, data: 0.015) loss: 0.270 
(epoch: 115, iters: 4512, time: 0.159, data: 0.005) loss: 0.666 
(epoch: 115, iters: 4592, time: 0.161, data: 0.000) loss: 0.293 
(epoch: 115, iters: 4672, time: 0.161, data: 0.000) loss: 1.036 
(epoch: 115, iters: 4752, time: 0.160, data: 0.016) loss: 0.189 
(epoch: 115, iters: 4832, time: 0.161, data: 0.000) loss: 0.409 
(epoch: 115, iters: 4912, time: 0.162, data: 0.045) loss: 0.708 
(epoch: 115, iters: 4992, time: 0.160, data: 0.000) loss: 0.469 
(epoch: 115, iters: 5072, time: 0.160, data: 0.000) loss: 0.497 
(epoch: 115, iters: 5152, time: 0.162, data: 0.014) loss: 0.270 
(epoch: 115, iters: 5232, time: 0.166, data: 0.000) loss: 0.118 
(epoch: 115, iters: 5312, time: 0.162, data: 0.000) loss: 0.314 
(epoch: 115, iters: 5392, time: 0.162, data: 0.000) loss: 0.462 
(epoch: 115, iters: 5472, time: 0.162, data: 0.005) loss: 0.422 
(epoch: 115, iters: 5552, time: 0.160, data: 0.000) loss: 0.524 
(epoch: 115, iters: 5632, time: 0.161, data: 0.000) loss: 0.324 
(epoch: 115, iters: 5712, time: 0.162, data: 0.009) loss: 0.466 
(epoch: 115, iters: 5792, time: 0.164, data: 0.000) loss: 0.363 
(epoch: 115, iters: 5872, time: 0.162, data: 0.024) loss: 0.270 
(epoch: 115, iters: 5952, time: 0.161, data: 0.000) loss: 0.376 
(epoch: 115, iters: 6032, time: 0.161, data: 0.000) loss: 0.424 
(epoch: 115, iters: 6112, time: 0.163, data: 0.000) loss: 0.960 
(epoch: 115, iters: 6192, time: 0.162, data: 0.015) loss: 0.296 
(epoch: 115, iters: 6272, time: 0.160, data: 0.000) loss: 0.437 
(epoch: 115, iters: 6352, time: 0.157, data: 0.009) loss: 0.227 
(epoch: 115, iters: 6432, time: 0.156, data: 0.000) loss: 0.407 
(epoch: 115, iters: 6512, time: 0.158, data: 0.020) loss: 0.469 
(epoch: 115, iters: 6592, time: 0.162, data: 0.019) loss: 0.710 
(epoch: 115, iters: 6672, time: 0.159, data: 0.000) loss: 0.622 
(epoch: 115, iters: 6752, time: 0.157, data: 0.016) loss: 0.443 
(epoch: 115, iters: 6832, time: 0.159, data: 0.000) loss: 0.829 
(epoch: 115, iters: 6912, time: 0.160, data: 0.026) loss: 0.364 
(epoch: 115, iters: 6992, time: 0.160, data: 0.014) loss: 0.330 
(epoch: 115, iters: 7072, time: 0.158, data: 0.000) loss: 0.560 
(epoch: 115, iters: 7152, time: 0.166, data: 0.005) loss: 0.491 
(epoch: 115, iters: 7232, time: 0.159, data: 0.000) loss: 0.407 
(epoch: 115, iters: 7312, time: 0.159, data: 0.024) loss: 0.435 
(epoch: 115, iters: 7392, time: 0.162, data: 0.000) loss: 0.361 
(epoch: 115, iters: 7472, time: 0.161, data: 0.000) loss: 0.287 
(epoch: 115, iters: 7552, time: 0.162, data: 0.005) loss: 0.206 
(epoch: 115, iters: 7632, time: 0.162, data: 0.000) loss: 0.485 
(epoch: 115, iters: 7712, time: 0.168, data: 0.000) loss: 0.165 
(epoch: 115, iters: 7792, time: 0.158, data: 0.008) loss: 0.731 
(epoch: 115, iters: 7872, time: 0.159, data: 0.005) loss: 0.345 
(epoch: 115, iters: 7952, time: 0.161, data: 0.005) loss: 0.581 
saving the latest model (epoch 115, total_steps 1169904)
(epoch: 115, iters: 8032, time: 0.159, data: 0.000) loss: 0.176 
(epoch: 115, iters: 8112, time: 0.156, data: 0.000) loss: 0.437 
(epoch: 115, iters: 8192, time: 0.157, data: 0.009) loss: 0.612 
(epoch: 115, iters: 8272, time: 0.158, data: 0.008) loss: 0.279 
(epoch: 115, iters: 8352, time: 0.156, data: 0.008) loss: 0.272 
(epoch: 115, iters: 8432, time: 0.157, data: 0.018) loss: 0.623 
(epoch: 115, iters: 8512, time: 0.157, data: 0.000) loss: 0.521 
(epoch: 115, iters: 8592, time: 0.159, data: 0.000) loss: 0.845 
(epoch: 115, iters: 8672, time: 0.158, data: 0.008) loss: 0.391 
(epoch: 115, iters: 8752, time: 0.159, data: 0.000) loss: 0.296 
(epoch: 115, iters: 8832, time: 0.160, data: 0.030) loss: 0.306 
(epoch: 115, iters: 8912, time: 0.158, data: 0.000) loss: 0.544 
(epoch: 115, iters: 8992, time: 0.159, data: 0.011) loss: 0.320 
(epoch: 115, iters: 9072, time: 0.158, data: 0.000) loss: 0.369 
(epoch: 115, iters: 9152, time: 0.158, data: 0.000) loss: 0.330 
(epoch: 115, iters: 9232, time: 0.158, data: 0.005) loss: 0.081 
(epoch: 115, iters: 9312, time: 0.157, data: 0.010) loss: 0.846 
(epoch: 115, iters: 9392, time: 0.157, data: 0.005) loss: 0.316 
(epoch: 115, iters: 9472, time: 0.158, data: 0.010) loss: 0.357 
(epoch: 115, iters: 9552, time: 0.156, data: 0.005) loss: 0.348 
(epoch: 115, iters: 9632, time: 0.157, data: 0.000) loss: 0.358 
(epoch: 115, iters: 9712, time: 0.155, data: 0.008) loss: 0.459 
(epoch: 115, iters: 9792, time: 0.158, data: 0.000) loss: 0.140 
(epoch: 115, iters: 9872, time: 0.157, data: 0.005) loss: 0.231 
(epoch: 115, iters: 9952, time: 0.157, data: 0.006) loss: 0.161 
(epoch: 115, iters: 10032, time: 0.159, data: 0.000) loss: 0.174 
(epoch: 115, iters: 10112, time: 0.159, data: 0.008) loss: 0.459 
(epoch: 115, iters: 10192, time: 0.093, data: 0.005) loss: 1.014 
saving the model at the end of epoch 115, iters 1172080
End of epoch 115 / 200 	 Time Taken: 1637 sec
learning rate = 0.0001663
saving the latest model (epoch 116, total_steps 1172096)
(epoch: 116, iters: 80, time: 0.169, data: 0.183) loss: 0.816 
(epoch: 116, iters: 160, time: 0.161, data: 0.025) loss: 0.145 
(epoch: 116, iters: 240, time: 0.161, data: 0.031) loss: 0.657 
(epoch: 116, iters: 320, time: 0.161, data: 0.000) loss: 0.452 
(epoch: 116, iters: 400, time: 0.160, data: 0.025) loss: 0.478 
(epoch: 116, iters: 480, time: 0.161, data: 0.000) loss: 0.348 
(epoch: 116, iters: 560, time: 0.156, data: 0.000) loss: 0.357 
(epoch: 116, iters: 640, time: 0.158, data: 0.000) loss: 0.328 
(epoch: 116, iters: 720, time: 0.160, data: 0.006) loss: 0.397 
(epoch: 116, iters: 800, time: 0.159, data: 0.000) loss: 0.531 
(epoch: 116, iters: 880, time: 0.158, data: 0.000) loss: 0.035 
(epoch: 116, iters: 960, time: 0.159, data: 0.013) loss: 0.730 
(epoch: 116, iters: 1040, time: 0.158, data: 0.005) loss: 0.153 
(epoch: 116, iters: 1120, time: 0.157, data: 0.000) loss: 0.268 
(epoch: 116, iters: 1200, time: 0.161, data: 0.000) loss: 0.375 
(epoch: 116, iters: 1280, time: 0.159, data: 0.014) loss: 0.444 
(epoch: 116, iters: 1360, time: 0.158, data: 0.009) loss: 0.582 
(epoch: 116, iters: 1440, time: 0.160, data: 0.000) loss: 0.148 
(epoch: 116, iters: 1520, time: 0.157, data: 0.008) loss: 0.090 
(epoch: 116, iters: 1600, time: 0.157, data: 0.010) loss: 0.382 
(epoch: 116, iters: 1680, time: 0.157, data: 0.000) loss: 0.515 
(epoch: 116, iters: 1760, time: 0.158, data: 0.016) loss: 0.242 
(epoch: 116, iters: 1840, time: 0.158, data: 0.000) loss: 0.474 
(epoch: 116, iters: 1920, time: 0.157, data: 0.008) loss: 0.411 
(epoch: 116, iters: 2000, time: 0.159, data: 0.000) loss: 0.329 
(epoch: 116, iters: 2080, time: 0.158, data: 0.005) loss: 0.364 
(epoch: 116, iters: 2160, time: 0.158, data: 0.013) loss: 0.584 
(epoch: 116, iters: 2240, time: 0.158, data: 0.000) loss: 0.468 
(epoch: 116, iters: 2320, time: 0.158, data: 0.000) loss: 0.222 
(epoch: 116, iters: 2400, time: 0.161, data: 0.005) loss: 0.622 
(epoch: 116, iters: 2480, time: 0.159, data: 0.000) loss: 0.542 
(epoch: 116, iters: 2560, time: 0.160, data: 0.000) loss: 0.471 
(epoch: 116, iters: 2640, time: 0.158, data: 0.010) loss: 0.475 
(epoch: 116, iters: 2720, time: 0.159, data: 0.000) loss: 0.533 
(epoch: 116, iters: 2800, time: 0.167, data: 0.016) loss: 0.624 
(epoch: 116, iters: 2880, time: 0.161, data: 0.000) loss: 0.501 
(epoch: 116, iters: 2960, time: 0.158, data: 0.028) loss: 0.417 
(epoch: 116, iters: 3040, time: 0.162, data: 0.000) loss: 0.262 
(epoch: 116, iters: 3120, time: 0.159, data: 0.034) loss: 0.219 
(epoch: 116, iters: 3200, time: 0.164, data: 0.000) loss: 0.407 
(epoch: 116, iters: 3280, time: 0.159, data: 0.000) loss: 0.127 
(epoch: 116, iters: 3360, time: 0.160, data: 0.022) loss: 0.376 
(epoch: 116, iters: 3440, time: 0.160, data: 0.008) loss: 0.471 
(epoch: 116, iters: 3520, time: 0.160, data: 0.000) loss: 0.253 
(epoch: 116, iters: 3600, time: 0.158, data: 0.021) loss: 0.291 
(epoch: 116, iters: 3680, time: 0.158, data: 0.000) loss: 0.825 
(epoch: 116, iters: 3760, time: 0.159, data: 0.000) loss: 0.749 
(epoch: 116, iters: 3840, time: 0.159, data: 0.000) loss: 0.130 
(epoch: 116, iters: 3920, time: 0.159, data: 0.000) loss: 0.427 
(epoch: 116, iters: 4000, time: 0.159, data: 0.005) loss: 0.835 
saving the latest model (epoch 116, total_steps 1176096)
(epoch: 116, iters: 4080, time: 0.159, data: 0.005) loss: 0.355 
(epoch: 116, iters: 4160, time: 0.158, data: 0.000) loss: 0.663 
(epoch: 116, iters: 4240, time: 0.157, data: 0.000) loss: 0.608 
(epoch: 116, iters: 4320, time: 0.157, data: 0.000) loss: 0.340 
(epoch: 116, iters: 4400, time: 0.158, data: 0.000) loss: 0.598 
(epoch: 116, iters: 4480, time: 0.158, data: 0.000) loss: 0.731 
(epoch: 116, iters: 4560, time: 0.157, data: 0.033) loss: 0.483 
(epoch: 116, iters: 4640, time: 0.158, data: 0.000) loss: 0.255 
(epoch: 116, iters: 4720, time: 0.159, data: 0.026) loss: 0.355 
(epoch: 116, iters: 4800, time: 0.160, data: 0.000) loss: 0.559 
(epoch: 116, iters: 4880, time: 0.159, data: 0.000) loss: 0.785 
(epoch: 116, iters: 4960, time: 0.159, data: 0.005) loss: 0.100 
(epoch: 116, iters: 5040, time: 0.157, data: 0.000) loss: 1.015 
(epoch: 116, iters: 5120, time: 0.160, data: 0.016) loss: 0.277 
(epoch: 116, iters: 5200, time: 0.163, data: 0.010) loss: 0.793 
(epoch: 116, iters: 5280, time: 0.161, data: 0.000) loss: 0.458 
(epoch: 116, iters: 5360, time: 0.160, data: 0.008) loss: 0.387 
(epoch: 116, iters: 5440, time: 0.158, data: 0.005) loss: 0.969 
(epoch: 116, iters: 5520, time: 0.160, data: 0.000) loss: 0.603 
(epoch: 116, iters: 5600, time: 0.158, data: 0.008) loss: 0.541 
(epoch: 116, iters: 5680, time: 0.160, data: 0.000) loss: 0.505 
(epoch: 116, iters: 5760, time: 0.159, data: 0.005) loss: 0.413 
(epoch: 116, iters: 5840, time: 0.158, data: 0.000) loss: 0.278 
(epoch: 116, iters: 5920, time: 0.160, data: 0.006) loss: 0.370 
(epoch: 116, iters: 6000, time: 0.156, data: 0.010) loss: 0.607 
(epoch: 116, iters: 6080, time: 0.158, data: 0.000) loss: 0.424 
(epoch: 116, iters: 6160, time: 0.158, data: 0.000) loss: 0.676 
(epoch: 116, iters: 6240, time: 0.159, data: 0.019) loss: 0.216 
(epoch: 116, iters: 6320, time: 0.159, data: 0.000) loss: 0.137 
(epoch: 116, iters: 6400, time: 0.159, data: 0.000) loss: 0.387 
(epoch: 116, iters: 6480, time: 0.158, data: 0.000) loss: 0.919 
(epoch: 116, iters: 6560, time: 0.160, data: 0.020) loss: 0.739 
(epoch: 116, iters: 6640, time: 0.158, data: 0.000) loss: 0.333 
(epoch: 116, iters: 6720, time: 0.158, data: 0.019) loss: 0.310 
(epoch: 116, iters: 6800, time: 0.161, data: 0.016) loss: 0.657 
(epoch: 116, iters: 6880, time: 0.160, data: 0.000) loss: 0.568 
(epoch: 116, iters: 6960, time: 0.161, data: 0.021) loss: 0.150 
(epoch: 116, iters: 7040, time: 0.161, data: 0.014) loss: 0.194 
(epoch: 116, iters: 7120, time: 0.160, data: 0.005) loss: 0.215 
(epoch: 116, iters: 7200, time: 0.159, data: 0.012) loss: 0.381 
(epoch: 116, iters: 7280, time: 0.160, data: 0.008) loss: 0.142 
(epoch: 116, iters: 7360, time: 0.159, data: 0.007) loss: 0.668 
(epoch: 116, iters: 7440, time: 0.157, data: 0.006) loss: 0.403 
(epoch: 116, iters: 7520, time: 0.160, data: 0.010) loss: 0.787 
(epoch: 116, iters: 7600, time: 0.160, data: 0.006) loss: 1.018 
(epoch: 116, iters: 7680, time: 0.160, data: 0.009) loss: 0.659 
(epoch: 116, iters: 7760, time: 0.158, data: 0.014) loss: 0.368 
(epoch: 116, iters: 7840, time: 0.159, data: 0.005) loss: 0.460 
(epoch: 116, iters: 7920, time: 0.159, data: 0.000) loss: 0.134 
(epoch: 116, iters: 8000, time: 0.158, data: 0.008) loss: 0.430 
saving the latest model (epoch 116, total_steps 1180096)
(epoch: 116, iters: 8080, time: 0.159, data: 0.000) loss: 0.428 
(epoch: 116, iters: 8160, time: 0.158, data: 0.009) loss: 0.074 
(epoch: 116, iters: 8240, time: 0.160, data: 0.000) loss: 0.346 
(epoch: 116, iters: 8320, time: 0.157, data: 0.005) loss: 0.128 
(epoch: 116, iters: 8400, time: 0.159, data: 0.000) loss: 0.297 
(epoch: 116, iters: 8480, time: 0.157, data: 0.006) loss: 0.546 
(epoch: 116, iters: 8560, time: 0.156, data: 0.000) loss: 0.536 
(epoch: 116, iters: 8640, time: 0.160, data: 0.000) loss: 0.807 
(epoch: 116, iters: 8720, time: 0.159, data: 0.000) loss: 0.815 
(epoch: 116, iters: 8800, time: 0.158, data: 0.000) loss: 0.570 
(epoch: 116, iters: 8880, time: 0.158, data: 0.005) loss: 0.930 
(epoch: 116, iters: 8960, time: 0.158, data: 0.005) loss: 0.717 
(epoch: 116, iters: 9040, time: 0.165, data: 0.000) loss: 0.461 
(epoch: 116, iters: 9120, time: 0.160, data: 0.008) loss: 0.431 
(epoch: 116, iters: 9200, time: 0.158, data: 0.019) loss: 0.334 
(epoch: 116, iters: 9280, time: 0.158, data: 0.000) loss: 0.342 
(epoch: 116, iters: 9360, time: 0.159, data: 0.000) loss: 0.251 
(epoch: 116, iters: 9440, time: 0.158, data: 0.000) loss: 0.383 
(epoch: 116, iters: 9520, time: 0.158, data: 0.000) loss: 0.198 
(epoch: 116, iters: 9600, time: 0.160, data: 0.006) loss: 0.379 
(epoch: 116, iters: 9680, time: 0.157, data: 0.008) loss: 0.359 
(epoch: 116, iters: 9760, time: 0.159, data: 0.009) loss: 1.005 
(epoch: 116, iters: 9840, time: 0.157, data: 0.006) loss: 0.786 
(epoch: 116, iters: 9920, time: 0.156, data: 0.005) loss: 0.979 
(epoch: 116, iters: 10000, time: 0.160, data: 0.000) loss: 0.458 
(epoch: 116, iters: 10080, time: 0.158, data: 0.000) loss: 0.750 
(epoch: 116, iters: 10160, time: 0.160, data: 0.000) loss: 0.491 
saving the model at the end of epoch 116, iters 1182272
End of epoch 116 / 200 	 Time Taken: 1625 sec
learning rate = 0.0001644
saving the latest model (epoch 117, total_steps 1182288)
(epoch: 117, iters: 48, time: 0.163, data: 0.005) loss: 0.333 
(epoch: 117, iters: 128, time: 0.158, data: 0.021) loss: 0.423 
(epoch: 117, iters: 208, time: 0.158, data: 0.000) loss: 0.280 
(epoch: 117, iters: 288, time: 0.157, data: 0.000) loss: 0.642 
(epoch: 117, iters: 368, time: 0.158, data: 0.035) loss: 0.316 
(epoch: 117, iters: 448, time: 0.159, data: 0.000) loss: 0.356 
(epoch: 117, iters: 528, time: 0.158, data: 0.000) loss: 0.366 
(epoch: 117, iters: 608, time: 0.159, data: 0.006) loss: 0.432 
(epoch: 117, iters: 688, time: 0.158, data: 0.015) loss: 0.565 
(epoch: 117, iters: 768, time: 0.157, data: 0.000) loss: 0.584 
(epoch: 117, iters: 848, time: 0.158, data: 0.025) loss: 0.061 
(epoch: 117, iters: 928, time: 0.157, data: 0.000) loss: 0.251 
(epoch: 117, iters: 1008, time: 0.158, data: 0.032) loss: 0.300 
(epoch: 117, iters: 1088, time: 0.155, data: 0.000) loss: 0.439 
(epoch: 117, iters: 1168, time: 0.160, data: 0.006) loss: 0.288 
(epoch: 117, iters: 1248, time: 0.161, data: 0.009) loss: 0.639 
(epoch: 117, iters: 1328, time: 0.156, data: 0.000) loss: 0.858 
(epoch: 117, iters: 1408, time: 0.157, data: 0.008) loss: 0.311 
(epoch: 117, iters: 1488, time: 0.159, data: 0.000) loss: 0.304 
(epoch: 117, iters: 1568, time: 0.158, data: 0.031) loss: 0.683 
(epoch: 117, iters: 1648, time: 0.159, data: 0.000) loss: 0.629 
(epoch: 117, iters: 1728, time: 0.158, data: 0.000) loss: 0.481 
(epoch: 117, iters: 1808, time: 0.158, data: 0.000) loss: 0.410 
(epoch: 117, iters: 1888, time: 0.161, data: 0.000) loss: 0.240 
(epoch: 117, iters: 1968, time: 0.163, data: 0.021) loss: 0.343 
(epoch: 117, iters: 2048, time: 0.159, data: 0.000) loss: 0.287 
(epoch: 117, iters: 2128, time: 0.158, data: 0.005) loss: 0.393 
(epoch: 117, iters: 2208, time: 0.160, data: 0.000) loss: 0.550 
(epoch: 117, iters: 2288, time: 0.157, data: 0.000) loss: 0.498 
(epoch: 117, iters: 2368, time: 0.158, data: 0.009) loss: 0.337 
(epoch: 117, iters: 2448, time: 0.157, data: 0.000) loss: 0.256 
(epoch: 117, iters: 2528, time: 0.156, data: 0.027) loss: 0.161 
(epoch: 117, iters: 2608, time: 0.161, data: 0.000) loss: 1.097 
(epoch: 117, iters: 2688, time: 0.158, data: 0.000) loss: 0.330 
(epoch: 117, iters: 2768, time: 0.159, data: 0.000) loss: 0.311 
(epoch: 117, iters: 2848, time: 0.159, data: 0.033) loss: 0.492 
(epoch: 117, iters: 2928, time: 0.159, data: 0.000) loss: 0.294 
(epoch: 117, iters: 3008, time: 0.159, data: 0.042) loss: 0.702 
(epoch: 117, iters: 3088, time: 0.159, data: 0.000) loss: 0.480 
(epoch: 117, iters: 3168, time: 0.160, data: 0.000) loss: 0.691 
(epoch: 117, iters: 3248, time: 0.160, data: 0.000) loss: 0.252 
(epoch: 117, iters: 3328, time: 0.160, data: 0.000) loss: 0.698 
(epoch: 117, iters: 3408, time: 0.162, data: 0.015) loss: 0.162 
(epoch: 117, iters: 3488, time: 0.159, data: 0.000) loss: 0.371 
(epoch: 117, iters: 3568, time: 0.160, data: 0.013) loss: 0.217 
(epoch: 117, iters: 3648, time: 0.160, data: 0.000) loss: 0.466 
(epoch: 117, iters: 3728, time: 0.161, data: 0.021) loss: 0.732 
(epoch: 117, iters: 3808, time: 0.158, data: 0.000) loss: 0.378 
(epoch: 117, iters: 3888, time: 0.158, data: 0.000) loss: 0.238 
(epoch: 117, iters: 3968, time: 0.159, data: 0.000) loss: 0.088 
saving the latest model (epoch 117, total_steps 1186288)
(epoch: 117, iters: 4048, time: 0.157, data: 0.000) loss: 0.306 
(epoch: 117, iters: 4128, time: 0.158, data: 0.018) loss: 0.138 
(epoch: 117, iters: 4208, time: 0.158, data: 0.016) loss: 0.212 
(epoch: 117, iters: 4288, time: 0.157, data: 0.000) loss: 0.673 
(epoch: 117, iters: 4368, time: 0.157, data: 0.000) loss: 0.502 
(epoch: 117, iters: 4448, time: 0.160, data: 0.006) loss: 0.275 
(epoch: 117, iters: 4528, time: 0.156, data: 0.000) loss: 0.308 
(epoch: 117, iters: 4608, time: 0.155, data: 0.000) loss: 0.160 
(epoch: 117, iters: 4688, time: 0.163, data: 0.006) loss: 0.074 
(epoch: 117, iters: 4768, time: 0.157, data: 0.000) loss: 0.356 
(epoch: 117, iters: 4848, time: 0.158, data: 0.000) loss: 0.392 
(epoch: 117, iters: 4928, time: 0.159, data: 0.000) loss: 0.770 
(epoch: 117, iters: 5008, time: 0.158, data: 0.040) loss: 0.232 
(epoch: 117, iters: 5088, time: 0.167, data: 0.000) loss: 0.516 
(epoch: 117, iters: 5168, time: 0.159, data: 0.000) loss: 0.943 
(epoch: 117, iters: 5248, time: 0.162, data: 0.000) loss: 0.206 
(epoch: 117, iters: 5328, time: 0.159, data: 0.009) loss: 0.368 
(epoch: 117, iters: 5408, time: 0.160, data: 0.000) loss: 0.926 
(epoch: 117, iters: 5488, time: 0.161, data: 0.006) loss: 0.199 
(epoch: 117, iters: 5568, time: 0.158, data: 0.006) loss: 0.390 
(epoch: 117, iters: 5648, time: 0.160, data: 0.014) loss: 0.127 
(epoch: 117, iters: 5728, time: 0.158, data: 0.000) loss: 0.183 
(epoch: 117, iters: 5808, time: 0.158, data: 0.005) loss: 0.432 
(epoch: 117, iters: 5888, time: 0.159, data: 0.000) loss: 0.365 
(epoch: 117, iters: 5968, time: 0.158, data: 0.016) loss: 0.227 
(epoch: 117, iters: 6048, time: 0.159, data: 0.000) loss: 0.233 
(epoch: 117, iters: 6128, time: 0.157, data: 0.000) loss: 0.516 
(epoch: 117, iters: 6208, time: 0.157, data: 0.000) loss: 0.406 
(epoch: 117, iters: 6288, time: 0.159, data: 0.005) loss: 0.232 
(epoch: 117, iters: 6368, time: 0.156, data: 0.005) loss: 0.432 
(epoch: 117, iters: 6448, time: 0.159, data: 0.000) loss: 0.568 
(epoch: 117, iters: 6528, time: 0.157, data: 0.000) loss: 0.275 
(epoch: 117, iters: 6608, time: 0.159, data: 0.000) loss: 0.428 
(epoch: 117, iters: 6688, time: 0.157, data: 0.033) loss: 0.648 
(epoch: 117, iters: 6768, time: 0.159, data: 0.000) loss: 0.869 
(epoch: 117, iters: 6848, time: 0.159, data: 0.013) loss: 0.363 
(epoch: 117, iters: 6928, time: 0.158, data: 0.006) loss: 0.805 
(epoch: 117, iters: 7008, time: 0.158, data: 0.000) loss: 0.735 
(epoch: 117, iters: 7088, time: 0.160, data: 0.000) loss: 0.391 
(epoch: 117, iters: 7168, time: 0.159, data: 0.005) loss: 0.731 
(epoch: 117, iters: 7248, time: 0.160, data: 0.019) loss: 0.463 
(epoch: 117, iters: 7328, time: 0.157, data: 0.000) loss: 0.265 
(epoch: 117, iters: 7408, time: 0.160, data: 0.000) loss: 0.420 
(epoch: 117, iters: 7488, time: 0.157, data: 0.014) loss: 0.350 
(epoch: 117, iters: 7568, time: 0.157, data: 0.006) loss: 0.448 
(epoch: 117, iters: 7648, time: 0.157, data: 0.000) loss: 0.259 
(epoch: 117, iters: 7728, time: 0.157, data: 0.020) loss: 0.495 
(epoch: 117, iters: 7808, time: 0.161, data: 0.016) loss: 0.773 
(epoch: 117, iters: 7888, time: 0.159, data: 0.005) loss: 0.421 
(epoch: 117, iters: 7968, time: 0.160, data: 0.006) loss: 0.720 
saving the latest model (epoch 117, total_steps 1190288)
(epoch: 117, iters: 8048, time: 0.159, data: 0.000) loss: 0.861 
(epoch: 117, iters: 8128, time: 0.158, data: 0.011) loss: 0.500 
(epoch: 117, iters: 8208, time: 0.164, data: 0.000) loss: 0.249 
(epoch: 117, iters: 8288, time: 0.157, data: 0.015) loss: 0.358 
(epoch: 117, iters: 8368, time: 0.157, data: 0.000) loss: 0.539 
(epoch: 117, iters: 8448, time: 0.158, data: 0.009) loss: 0.407 
(epoch: 117, iters: 8528, time: 0.161, data: 0.000) loss: 0.703 
(epoch: 117, iters: 8608, time: 0.162, data: 0.000) loss: 0.368 
(epoch: 117, iters: 8688, time: 0.158, data: 0.008) loss: 0.368 
(epoch: 117, iters: 8768, time: 0.158, data: 0.000) loss: 0.406 
(epoch: 117, iters: 8848, time: 0.159, data: 0.005) loss: 0.951 
(epoch: 117, iters: 8928, time: 0.157, data: 0.000) loss: 0.510 
(epoch: 117, iters: 9008, time: 0.161, data: 0.005) loss: 0.818 
(epoch: 117, iters: 9088, time: 0.160, data: 0.000) loss: 0.637 
(epoch: 117, iters: 9168, time: 0.158, data: 0.009) loss: 0.165 
(epoch: 117, iters: 9248, time: 0.161, data: 0.000) loss: 0.457 
(epoch: 117, iters: 9328, time: 0.159, data: 0.013) loss: 0.451 
(epoch: 117, iters: 9408, time: 0.159, data: 0.000) loss: 0.209 
(epoch: 117, iters: 9488, time: 0.160, data: 0.026) loss: 0.303 
(epoch: 117, iters: 9568, time: 0.160, data: 0.000) loss: 0.305 
(epoch: 117, iters: 9648, time: 0.158, data: 0.010) loss: 0.174 
(epoch: 117, iters: 9728, time: 0.159, data: 0.008) loss: 0.353 
(epoch: 117, iters: 9808, time: 0.160, data: 0.000) loss: 0.482 
(epoch: 117, iters: 9888, time: 0.158, data: 0.005) loss: 0.468 
(epoch: 117, iters: 9968, time: 0.160, data: 0.005) loss: 0.485 
(epoch: 117, iters: 10048, time: 0.159, data: 0.000) loss: 0.189 
(epoch: 117, iters: 10128, time: 0.159, data: 0.005) loss: 0.567 
saving the model at the end of epoch 117, iters 1192464
End of epoch 117 / 200 	 Time Taken: 1625 sec
learning rate = 0.0001624
(epoch: 118, iters: 16, time: 0.181, data: 0.006) loss: 0.385 
saving the latest model (epoch 118, total_steps 1192480)
(epoch: 118, iters: 96, time: 0.157, data: 0.000) loss: 0.138 
(epoch: 118, iters: 176, time: 0.156, data: 0.007) loss: 0.155 
(epoch: 118, iters: 256, time: 0.157, data: 0.000) loss: 0.364 
(epoch: 118, iters: 336, time: 0.157, data: 0.000) loss: 0.423 
(epoch: 118, iters: 416, time: 0.157, data: 0.000) loss: 0.498 
(epoch: 118, iters: 496, time: 0.161, data: 0.009) loss: 0.311 
(epoch: 118, iters: 576, time: 0.160, data: 0.000) loss: 0.814 
(epoch: 118, iters: 656, time: 0.158, data: 0.000) loss: 0.465 
(epoch: 118, iters: 736, time: 0.164, data: 0.000) loss: 0.356 
(epoch: 118, iters: 816, time: 0.158, data: 0.015) loss: 0.594 
(epoch: 118, iters: 896, time: 0.159, data: 0.019) loss: 0.714 
(epoch: 118, iters: 976, time: 0.158, data: 0.000) loss: 0.291 
(epoch: 118, iters: 1056, time: 0.158, data: 0.008) loss: 0.339 
(epoch: 118, iters: 1136, time: 0.167, data: 0.005) loss: 0.400 
(epoch: 118, iters: 1216, time: 0.158, data: 0.000) loss: 0.424 
(epoch: 118, iters: 1296, time: 0.160, data: 0.000) loss: 0.259 
(epoch: 118, iters: 1376, time: 0.158, data: 0.000) loss: 0.315 
(epoch: 118, iters: 1456, time: 0.160, data: 0.016) loss: 0.324 
(epoch: 118, iters: 1536, time: 0.158, data: 0.000) loss: 0.576 
(epoch: 118, iters: 1616, time: 0.159, data: 0.031) loss: 0.174 
(epoch: 118, iters: 1696, time: 0.157, data: 0.000) loss: 0.209 
(epoch: 118, iters: 1776, time: 0.156, data: 0.024) loss: 0.229 
(epoch: 118, iters: 1856, time: 0.157, data: 0.000) loss: 0.129 
(epoch: 118, iters: 1936, time: 0.155, data: 0.000) loss: 0.346 
(epoch: 118, iters: 2016, time: 0.156, data: 0.005) loss: 0.760 
(epoch: 118, iters: 2096, time: 0.155, data: 0.005) loss: 0.141 
(epoch: 118, iters: 2176, time: 0.157, data: 0.006) loss: 0.155 
(epoch: 118, iters: 2256, time: 0.156, data: 0.005) loss: 0.148 
(epoch: 118, iters: 2336, time: 0.160, data: 0.008) loss: 0.737 
(epoch: 118, iters: 2416, time: 0.156, data: 0.000) loss: 0.374 
(epoch: 118, iters: 2496, time: 0.158, data: 0.011) loss: 1.215 
(epoch: 118, iters: 2576, time: 0.158, data: 0.000) loss: 0.150 
(epoch: 118, iters: 2656, time: 0.157, data: 0.000) loss: 0.482 
(epoch: 118, iters: 2736, time: 0.159, data: 0.009) loss: 0.175 
(epoch: 118, iters: 2816, time: 0.158, data: 0.008) loss: 0.536 
(epoch: 118, iters: 2896, time: 0.161, data: 0.000) loss: 0.303 
(epoch: 118, iters: 2976, time: 0.159, data: 0.009) loss: 0.355 
(epoch: 118, iters: 3056, time: 0.158, data: 0.000) loss: 0.350 
(epoch: 118, iters: 3136, time: 0.158, data: 0.018) loss: 0.615 
(epoch: 118, iters: 3216, time: 0.158, data: 0.000) loss: 0.388 
(epoch: 118, iters: 3296, time: 0.157, data: 0.011) loss: 0.366 
(epoch: 118, iters: 3376, time: 0.157, data: 0.000) loss: 0.578 
(epoch: 118, iters: 3456, time: 0.158, data: 0.017) loss: 0.636 
(epoch: 118, iters: 3536, time: 0.158, data: 0.000) loss: 0.323 
(epoch: 118, iters: 3616, time: 0.156, data: 0.023) loss: 0.221 
(epoch: 118, iters: 3696, time: 0.156, data: 0.000) loss: 0.203 
(epoch: 118, iters: 3776, time: 0.157, data: 0.000) loss: 0.811 
(epoch: 118, iters: 3856, time: 0.159, data: 0.006) loss: 0.162 
(epoch: 118, iters: 3936, time: 0.157, data: 0.000) loss: 0.386 
(epoch: 118, iters: 4016, time: 0.158, data: 0.028) loss: 0.576 
saving the latest model (epoch 118, total_steps 1196480)
(epoch: 118, iters: 4096, time: 0.158, data: 0.000) loss: 0.192 
(epoch: 118, iters: 4176, time: 0.157, data: 0.000) loss: 0.426 
(epoch: 118, iters: 4256, time: 0.158, data: 0.006) loss: 0.431 
(epoch: 118, iters: 4336, time: 0.158, data: 0.011) loss: 0.311 
(epoch: 118, iters: 4416, time: 0.157, data: 0.005) loss: 0.249 
(epoch: 118, iters: 4496, time: 0.157, data: 0.000) loss: 0.659 
(epoch: 118, iters: 4576, time: 0.158, data: 0.011) loss: 0.287 
(epoch: 118, iters: 4656, time: 0.164, data: 0.009) loss: 0.635 
(epoch: 118, iters: 4736, time: 0.157, data: 0.000) loss: 0.268 
(epoch: 118, iters: 4816, time: 0.157, data: 0.005) loss: 0.346 
(epoch: 118, iters: 4896, time: 0.159, data: 0.033) loss: 0.535 
(epoch: 118, iters: 4976, time: 0.159, data: 0.000) loss: 0.926 
(epoch: 118, iters: 5056, time: 0.163, data: 0.016) loss: 0.259 
(epoch: 118, iters: 5136, time: 0.158, data: 0.022) loss: 0.949 
(epoch: 118, iters: 5216, time: 0.161, data: 0.000) loss: 0.439 
(epoch: 118, iters: 5296, time: 0.158, data: 0.010) loss: 0.250 
(epoch: 118, iters: 5376, time: 0.159, data: 0.000) loss: 0.473 
(epoch: 118, iters: 5456, time: 0.159, data: 0.025) loss: 0.115 
(epoch: 118, iters: 5536, time: 0.157, data: 0.000) loss: 0.377 
(epoch: 118, iters: 5616, time: 0.159, data: 0.006) loss: 0.708 
(epoch: 118, iters: 5696, time: 0.158, data: 0.008) loss: 0.280 
(epoch: 118, iters: 5776, time: 0.159, data: 0.000) loss: 0.433 
(epoch: 118, iters: 5856, time: 0.159, data: 0.000) loss: 0.503 
(epoch: 118, iters: 5936, time: 0.157, data: 0.010) loss: 1.013 
(epoch: 118, iters: 6016, time: 0.158, data: 0.005) loss: 0.684 
(epoch: 118, iters: 6096, time: 0.156, data: 0.000) loss: 0.369 
(epoch: 118, iters: 6176, time: 0.156, data: 0.000) loss: 0.149 
(epoch: 118, iters: 6256, time: 0.154, data: 0.014) loss: 0.328 
(epoch: 118, iters: 6336, time: 0.158, data: 0.000) loss: 0.460 
(epoch: 118, iters: 6416, time: 0.157, data: 0.016) loss: 0.289 
(epoch: 118, iters: 6496, time: 0.157, data: 0.008) loss: 0.374 
(epoch: 118, iters: 6576, time: 0.157, data: 0.000) loss: 0.316 
(epoch: 118, iters: 6656, time: 0.158, data: 0.025) loss: 0.388 
(epoch: 118, iters: 6736, time: 0.158, data: 0.000) loss: 0.155 
(epoch: 118, iters: 6816, time: 0.159, data: 0.028) loss: 0.589 
(epoch: 118, iters: 6896, time: 0.159, data: 0.022) loss: 0.336 
(epoch: 118, iters: 6976, time: 0.156, data: 0.000) loss: 0.471 
(epoch: 118, iters: 7056, time: 0.159, data: 0.030) loss: 0.227 
(epoch: 118, iters: 7136, time: 0.157, data: 0.000) loss: 0.404 
(epoch: 118, iters: 7216, time: 0.159, data: 0.000) loss: 0.117 
(epoch: 118, iters: 7296, time: 0.157, data: 0.006) loss: 0.594 
(epoch: 118, iters: 7376, time: 0.159, data: 0.000) loss: 0.707 
(epoch: 118, iters: 7456, time: 0.159, data: 0.014) loss: 0.376 
(epoch: 118, iters: 7536, time: 0.160, data: 0.024) loss: 0.733 
(epoch: 118, iters: 7616, time: 0.158, data: 0.000) loss: 0.399 
(epoch: 118, iters: 7696, time: 0.158, data: 0.000) loss: 0.171 
(epoch: 118, iters: 7776, time: 0.159, data: 0.005) loss: 0.620 
(epoch: 118, iters: 7856, time: 0.158, data: 0.006) loss: 0.140 
(epoch: 118, iters: 7936, time: 0.157, data: 0.000) loss: 0.753 
(epoch: 118, iters: 8016, time: 0.157, data: 0.008) loss: 0.364 
saving the latest model (epoch 118, total_steps 1200480)
(epoch: 118, iters: 8096, time: 0.156, data: 0.000) loss: 0.371 
(epoch: 118, iters: 8176, time: 0.161, data: 0.017) loss: 0.393 
(epoch: 118, iters: 8256, time: 0.155, data: 0.000) loss: 0.779 
(epoch: 118, iters: 8336, time: 0.156, data: 0.024) loss: 1.018 
(epoch: 118, iters: 8416, time: 0.157, data: 0.000) loss: 0.456 
(epoch: 118, iters: 8496, time: 0.157, data: 0.000) loss: 0.905 
(epoch: 118, iters: 8576, time: 0.162, data: 0.008) loss: 0.209 
(epoch: 118, iters: 8656, time: 0.155, data: 0.023) loss: 0.641 
(epoch: 118, iters: 8736, time: 0.155, data: 0.000) loss: 0.394 
(epoch: 118, iters: 8816, time: 0.158, data: 0.005) loss: 0.725 
(epoch: 118, iters: 8896, time: 0.158, data: 0.000) loss: 0.611 
(epoch: 118, iters: 8976, time: 0.158, data: 0.000) loss: 0.480 
(epoch: 118, iters: 9056, time: 0.159, data: 0.018) loss: 0.574 
(epoch: 118, iters: 9136, time: 0.156, data: 0.008) loss: 0.319 
(epoch: 118, iters: 9216, time: 0.158, data: 0.009) loss: 1.024 
(epoch: 118, iters: 9296, time: 0.157, data: 0.020) loss: 0.373 
(epoch: 118, iters: 9376, time: 0.161, data: 0.000) loss: 0.563 
(epoch: 118, iters: 9456, time: 0.157, data: 0.006) loss: 0.783 
(epoch: 118, iters: 9536, time: 0.157, data: 0.000) loss: 0.635 
(epoch: 118, iters: 9616, time: 0.159, data: 0.000) loss: 0.305 
(epoch: 118, iters: 9696, time: 0.158, data: 0.009) loss: 0.395 
(epoch: 118, iters: 9776, time: 0.157, data: 0.000) loss: 0.534 
(epoch: 118, iters: 9856, time: 0.159, data: 0.000) loss: 0.671 
(epoch: 118, iters: 9936, time: 0.160, data: 0.000) loss: 0.558 
(epoch: 118, iters: 10016, time: 0.158, data: 0.000) loss: 0.260 
(epoch: 118, iters: 10096, time: 0.157, data: 0.005) loss: 0.248 
(epoch: 118, iters: 10176, time: 0.156, data: 0.009) loss: 0.422 
saving the model at the end of epoch 118, iters 1202656
End of epoch 118 / 200 	 Time Taken: 1617 sec
learning rate = 0.0001604
saving the latest model (epoch 119, total_steps 1202672)
(epoch: 119, iters: 64, time: 0.161, data: 0.000) loss: 0.486 
(epoch: 119, iters: 144, time: 0.159, data: 0.000) loss: 0.366 
(epoch: 119, iters: 224, time: 0.161, data: 0.000) loss: 0.651 
(epoch: 119, iters: 304, time: 0.156, data: 0.010) loss: 0.265 
(epoch: 119, iters: 384, time: 0.158, data: 0.018) loss: 0.591 
(epoch: 119, iters: 464, time: 0.158, data: 0.014) loss: 0.506 
(epoch: 119, iters: 544, time: 0.157, data: 0.000) loss: 0.241 
(epoch: 119, iters: 624, time: 0.157, data: 0.010) loss: 0.980 
(epoch: 119, iters: 704, time: 0.158, data: 0.000) loss: 0.373 
(epoch: 119, iters: 784, time: 0.158, data: 0.000) loss: 0.100 
(epoch: 119, iters: 864, time: 0.159, data: 0.000) loss: 0.270 
(epoch: 119, iters: 944, time: 0.159, data: 0.008) loss: 0.697 
(epoch: 119, iters: 1024, time: 0.157, data: 0.005) loss: 0.573 
(epoch: 119, iters: 1104, time: 0.156, data: 0.014) loss: 0.249 
(epoch: 119, iters: 1184, time: 0.157, data: 0.000) loss: 0.352 
(epoch: 119, iters: 1264, time: 0.158, data: 0.000) loss: 0.722 
(epoch: 119, iters: 1344, time: 0.157, data: 0.000) loss: 0.294 
(epoch: 119, iters: 1424, time: 0.158, data: 0.006) loss: 0.438 
(epoch: 119, iters: 1504, time: 0.161, data: 0.011) loss: 0.751 
(epoch: 119, iters: 1584, time: 0.158, data: 0.000) loss: 0.288 
(epoch: 119, iters: 1664, time: 0.157, data: 0.021) loss: 0.408 
(epoch: 119, iters: 1744, time: 0.158, data: 0.000) loss: 0.271 
(epoch: 119, iters: 1824, time: 0.159, data: 0.015) loss: 0.633 
(epoch: 119, iters: 1904, time: 0.159, data: 0.023) loss: 0.610 
(epoch: 119, iters: 1984, time: 0.160, data: 0.000) loss: 0.105 
(epoch: 119, iters: 2064, time: 0.160, data: 0.010) loss: 0.402 
(epoch: 119, iters: 2144, time: 0.158, data: 0.008) loss: 0.234 
(epoch: 119, iters: 2224, time: 0.159, data: 0.006) loss: 0.408 
(epoch: 119, iters: 2304, time: 0.160, data: 0.000) loss: 0.515 
(epoch: 119, iters: 2384, time: 0.159, data: 0.005) loss: 0.390 
(epoch: 119, iters: 2464, time: 0.158, data: 0.000) loss: 0.749 
(epoch: 119, iters: 2544, time: 0.157, data: 0.021) loss: 0.509 
(epoch: 119, iters: 2624, time: 0.160, data: 0.009) loss: 0.076 
(epoch: 119, iters: 2704, time: 0.160, data: 0.000) loss: 0.923 
(epoch: 119, iters: 2784, time: 0.158, data: 0.006) loss: 0.765 
(epoch: 119, iters: 2864, time: 0.157, data: 0.000) loss: 0.989 
(epoch: 119, iters: 2944, time: 0.158, data: 0.000) loss: 0.647 
(epoch: 119, iters: 3024, time: 0.157, data: 0.024) loss: 0.249 
(epoch: 119, iters: 3104, time: 0.156, data: 0.000) loss: 0.593 
(epoch: 119, iters: 3184, time: 0.161, data: 0.013) loss: 0.400 
(epoch: 119, iters: 3264, time: 0.160, data: 0.000) loss: 0.343 
(epoch: 119, iters: 3344, time: 0.158, data: 0.008) loss: 0.552 
(epoch: 119, iters: 3424, time: 0.161, data: 0.014) loss: 0.442 
(epoch: 119, iters: 3504, time: 0.159, data: 0.000) loss: 0.411 
(epoch: 119, iters: 3584, time: 0.161, data: 0.000) loss: 0.352 
(epoch: 119, iters: 3664, time: 0.162, data: 0.024) loss: 0.504 
(epoch: 119, iters: 3744, time: 0.161, data: 0.000) loss: 0.184 
(epoch: 119, iters: 3824, time: 0.160, data: 0.013) loss: 0.165 
(epoch: 119, iters: 3904, time: 0.157, data: 0.005) loss: 0.636 
(epoch: 119, iters: 3984, time: 0.159, data: 0.000) loss: 0.465 
saving the latest model (epoch 119, total_steps 1206672)
(epoch: 119, iters: 4064, time: 0.158, data: 0.009) loss: 0.546 
(epoch: 119, iters: 4144, time: 0.157, data: 0.000) loss: 0.649 
(epoch: 119, iters: 4224, time: 0.157, data: 0.021) loss: 0.298 
(epoch: 119, iters: 4304, time: 0.156, data: 0.000) loss: 0.467 
(epoch: 119, iters: 4384, time: 0.158, data: 0.000) loss: 0.404 
(epoch: 119, iters: 4464, time: 0.159, data: 0.000) loss: 1.140 
(epoch: 119, iters: 4544, time: 0.156, data: 0.008) loss: 0.658 
(epoch: 119, iters: 4624, time: 0.162, data: 0.000) loss: 0.214 
(epoch: 119, iters: 4704, time: 0.159, data: 0.000) loss: 0.308 
(epoch: 119, iters: 4784, time: 0.158, data: 0.005) loss: 0.614 
(epoch: 119, iters: 4864, time: 0.156, data: 0.000) loss: 0.614 
(epoch: 119, iters: 4944, time: 0.157, data: 0.005) loss: 0.809 
(epoch: 119, iters: 5024, time: 0.164, data: 0.000) loss: 1.053 
(epoch: 119, iters: 5104, time: 0.157, data: 0.000) loss: 0.595 
(epoch: 119, iters: 5184, time: 0.157, data: 0.000) loss: 0.527 
(epoch: 119, iters: 5264, time: 0.158, data: 0.000) loss: 0.457 
(epoch: 119, iters: 5344, time: 0.158, data: 0.000) loss: 0.475 
(epoch: 119, iters: 5424, time: 0.158, data: 0.005) loss: 0.307 
(epoch: 119, iters: 5504, time: 0.158, data: 0.000) loss: 0.777 
(epoch: 119, iters: 5584, time: 0.158, data: 0.000) loss: 0.771 
(epoch: 119, iters: 5664, time: 0.159, data: 0.006) loss: 0.388 
(epoch: 119, iters: 5744, time: 0.159, data: 0.024) loss: 0.141 
(epoch: 119, iters: 5824, time: 0.160, data: 0.000) loss: 0.411 
(epoch: 119, iters: 5904, time: 0.157, data: 0.033) loss: 0.341 
(epoch: 119, iters: 5984, time: 0.156, data: 0.000) loss: 0.280 
(epoch: 119, iters: 6064, time: 0.157, data: 0.011) loss: 0.064 
(epoch: 119, iters: 6144, time: 0.157, data: 0.000) loss: 0.085 
(epoch: 119, iters: 6224, time: 0.159, data: 0.021) loss: 0.140 
(epoch: 119, iters: 6304, time: 0.159, data: 0.000) loss: 0.495 
(epoch: 119, iters: 6384, time: 0.159, data: 0.008) loss: 0.158 
(epoch: 119, iters: 6464, time: 0.157, data: 0.000) loss: 0.860 
(epoch: 119, iters: 6544, time: 0.157, data: 0.006) loss: 0.352 
(epoch: 119, iters: 6624, time: 0.158, data: 0.019) loss: 0.388 
(epoch: 119, iters: 6704, time: 0.157, data: 0.000) loss: 0.147 
(epoch: 119, iters: 6784, time: 0.157, data: 0.000) loss: 0.239 
(epoch: 119, iters: 6864, time: 0.158, data: 0.005) loss: 0.721 
(epoch: 119, iters: 6944, time: 0.160, data: 0.042) loss: 0.696 
(epoch: 119, iters: 7024, time: 0.159, data: 0.000) loss: 0.116 
(epoch: 119, iters: 7104, time: 0.162, data: 0.024) loss: 0.502 
(epoch: 119, iters: 7184, time: 0.158, data: 0.014) loss: 0.361 
(epoch: 119, iters: 7264, time: 0.158, data: 0.005) loss: 0.394 
(epoch: 119, iters: 7344, time: 0.157, data: 0.000) loss: 1.084 
(epoch: 119, iters: 7424, time: 0.158, data: 0.031) loss: 0.412 
(epoch: 119, iters: 7504, time: 0.159, data: 0.000) loss: 0.227 
(epoch: 119, iters: 7584, time: 0.162, data: 0.000) loss: 0.386 
(epoch: 119, iters: 7664, time: 0.159, data: 0.005) loss: 0.268 
(epoch: 119, iters: 7744, time: 0.161, data: 0.011) loss: 0.621 
(epoch: 119, iters: 7824, time: 0.158, data: 0.000) loss: 0.229 
(epoch: 119, iters: 7904, time: 0.161, data: 0.000) loss: 0.559 
(epoch: 119, iters: 7984, time: 0.159, data: 0.005) loss: 0.292 
saving the latest model (epoch 119, total_steps 1210672)
(epoch: 119, iters: 8064, time: 0.157, data: 0.000) loss: 0.541 
(epoch: 119, iters: 8144, time: 0.163, data: 0.010) loss: 0.422 
(epoch: 119, iters: 8224, time: 0.160, data: 0.014) loss: 0.512 
(epoch: 119, iters: 8304, time: 0.157, data: 0.005) loss: 0.301 
(epoch: 119, iters: 8384, time: 0.157, data: 0.000) loss: 0.822 
(epoch: 119, iters: 8464, time: 0.157, data: 0.000) loss: 0.424 
(epoch: 119, iters: 8544, time: 0.159, data: 0.000) loss: 0.478 
(epoch: 119, iters: 8624, time: 0.158, data: 0.000) loss: 0.196 
(epoch: 119, iters: 8704, time: 0.156, data: 0.000) loss: 0.162 
(epoch: 119, iters: 8784, time: 0.161, data: 0.000) loss: 0.350 
(epoch: 119, iters: 8864, time: 0.159, data: 0.033) loss: 0.377 
(epoch: 119, iters: 8944, time: 0.161, data: 0.000) loss: 0.241 
(epoch: 119, iters: 9024, time: 0.162, data: 0.018) loss: 0.496 
(epoch: 119, iters: 9104, time: 0.158, data: 0.000) loss: 0.171 
(epoch: 119, iters: 9184, time: 0.160, data: 0.000) loss: 0.445 
(epoch: 119, iters: 9264, time: 0.159, data: 0.000) loss: 0.414 
(epoch: 119, iters: 9344, time: 0.160, data: 0.000) loss: 0.187 
(epoch: 119, iters: 9424, time: 0.159, data: 0.015) loss: 0.287 
(epoch: 119, iters: 9504, time: 0.160, data: 0.000) loss: 0.356 
(epoch: 119, iters: 9584, time: 0.158, data: 0.009) loss: 0.203 
(epoch: 119, iters: 9664, time: 0.158, data: 0.006) loss: 0.227 
(epoch: 119, iters: 9744, time: 0.159, data: 0.000) loss: 0.539 
(epoch: 119, iters: 9824, time: 0.158, data: 0.000) loss: 0.766 
(epoch: 119, iters: 9904, time: 0.157, data: 0.024) loss: 0.481 
(epoch: 119, iters: 9984, time: 0.160, data: 0.000) loss: 0.471 
(epoch: 119, iters: 10064, time: 0.159, data: 0.011) loss: 0.498 
(epoch: 119, iters: 10144, time: 0.159, data: 0.000) loss: 1.044 
saving the model at the end of epoch 119, iters 1212848
End of epoch 119 / 200 	 Time Taken: 1623 sec
learning rate = 0.0001584
saving the latest model (epoch 120, total_steps 1212864)
(epoch: 120, iters: 32, time: 0.169, data: 0.000) loss: 0.485 
(epoch: 120, iters: 112, time: 0.159, data: 0.000) loss: 0.280 
(epoch: 120, iters: 192, time: 0.160, data: 0.000) loss: 0.232 
(epoch: 120, iters: 272, time: 0.160, data: 0.005) loss: 0.432 
(epoch: 120, iters: 352, time: 0.158, data: 0.016) loss: 0.092 
(epoch: 120, iters: 432, time: 0.158, data: 0.000) loss: 0.636 
(epoch: 120, iters: 512, time: 0.158, data: 0.000) loss: 0.888 
(epoch: 120, iters: 592, time: 0.158, data: 0.007) loss: 0.728 
(epoch: 120, iters: 672, time: 0.164, data: 0.000) loss: 0.477 
(epoch: 120, iters: 752, time: 0.161, data: 0.016) loss: 0.786 
(epoch: 120, iters: 832, time: 0.160, data: 0.000) loss: 0.385 
(epoch: 120, iters: 912, time: 0.160, data: 0.032) loss: 0.389 
(epoch: 120, iters: 992, time: 0.160, data: 0.000) loss: 0.524 
(epoch: 120, iters: 1072, time: 0.161, data: 0.005) loss: 0.921 
(epoch: 120, iters: 1152, time: 0.160, data: 0.000) loss: 0.277 
(epoch: 120, iters: 1232, time: 0.160, data: 0.005) loss: 0.421 
(epoch: 120, iters: 1312, time: 0.162, data: 0.000) loss: 0.373 
(epoch: 120, iters: 1392, time: 0.161, data: 0.015) loss: 0.154 
(epoch: 120, iters: 1472, time: 0.157, data: 0.000) loss: 0.525 
(epoch: 120, iters: 1552, time: 0.157, data: 0.000) loss: 0.352 
(epoch: 120, iters: 1632, time: 0.159, data: 0.024) loss: 0.235 
(epoch: 120, iters: 1712, time: 0.159, data: 0.020) loss: 0.335 
(epoch: 120, iters: 1792, time: 0.159, data: 0.015) loss: 0.411 
(epoch: 120, iters: 1872, time: 0.158, data: 0.005) loss: 0.438 
(epoch: 120, iters: 1952, time: 0.160, data: 0.006) loss: 0.468 
(epoch: 120, iters: 2032, time: 0.159, data: 0.016) loss: 0.256 
(epoch: 120, iters: 2112, time: 0.160, data: 0.000) loss: 0.517 
(epoch: 120, iters: 2192, time: 0.159, data: 0.000) loss: 0.553 
(epoch: 120, iters: 2272, time: 0.159, data: 0.025) loss: 0.621 
(epoch: 120, iters: 2352, time: 0.158, data: 0.000) loss: 0.510 
(epoch: 120, iters: 2432, time: 0.159, data: 0.006) loss: 0.688 
(epoch: 120, iters: 2512, time: 0.158, data: 0.000) loss: 0.235 
(epoch: 120, iters: 2592, time: 0.160, data: 0.027) loss: 0.699 
(epoch: 120, iters: 2672, time: 0.158, data: 0.000) loss: 0.532 
(epoch: 120, iters: 2752, time: 0.158, data: 0.000) loss: 0.404 
(epoch: 120, iters: 2832, time: 0.159, data: 0.020) loss: 0.387 
(epoch: 120, iters: 2912, time: 0.157, data: 0.000) loss: 0.574 
(epoch: 120, iters: 2992, time: 0.158, data: 0.029) loss: 0.383 
(epoch: 120, iters: 3072, time: 0.159, data: 0.000) loss: 0.330 
(epoch: 120, iters: 3152, time: 0.157, data: 0.000) loss: 0.330 
(epoch: 120, iters: 3232, time: 0.155, data: 0.000) loss: 0.230 
(epoch: 120, iters: 3312, time: 0.158, data: 0.010) loss: 0.054 
(epoch: 120, iters: 3392, time: 0.165, data: 0.000) loss: 0.238 
(epoch: 120, iters: 3472, time: 0.158, data: 0.000) loss: 0.505 
(epoch: 120, iters: 3552, time: 0.157, data: 0.000) loss: 0.671 
(epoch: 120, iters: 3632, time: 0.158, data: 0.009) loss: 0.580 
(epoch: 120, iters: 3712, time: 0.158, data: 0.024) loss: 0.575 
(epoch: 120, iters: 3792, time: 0.164, data: 0.000) loss: 0.301 
(epoch: 120, iters: 3872, time: 0.159, data: 0.031) loss: 0.388 
(epoch: 120, iters: 3952, time: 0.158, data: 0.000) loss: 0.410 
saving the latest model (epoch 120, total_steps 1216864)
(epoch: 120, iters: 4032, time: 0.157, data: 0.005) loss: 0.423 
(epoch: 120, iters: 4112, time: 0.157, data: 0.000) loss: 0.800 
(epoch: 120, iters: 4192, time: 0.158, data: 0.008) loss: 0.642 
(epoch: 120, iters: 4272, time: 0.160, data: 0.014) loss: 0.313 
(epoch: 120, iters: 4352, time: 0.161, data: 0.000) loss: 0.120 
(epoch: 120, iters: 4432, time: 0.159, data: 0.013) loss: 0.128 
(epoch: 120, iters: 4512, time: 0.159, data: 0.000) loss: 0.498 
(epoch: 120, iters: 4592, time: 0.160, data: 0.000) loss: 0.533 
(epoch: 120, iters: 4672, time: 0.159, data: 0.000) loss: 0.402 
(epoch: 120, iters: 4752, time: 0.158, data: 0.008) loss: 0.381 
(epoch: 120, iters: 4832, time: 0.157, data: 0.011) loss: 0.478 
(epoch: 120, iters: 4912, time: 0.158, data: 0.006) loss: 0.514 
(epoch: 120, iters: 4992, time: 0.157, data: 0.000) loss: 0.319 
(epoch: 120, iters: 5072, time: 0.157, data: 0.000) loss: 0.292 
(epoch: 120, iters: 5152, time: 0.157, data: 0.022) loss: 0.597 
(epoch: 120, iters: 5232, time: 0.161, data: 0.000) loss: 0.255 
(epoch: 120, iters: 5312, time: 0.159, data: 0.017) loss: 0.890 
(epoch: 120, iters: 5392, time: 0.159, data: 0.016) loss: 0.256 
(epoch: 120, iters: 5472, time: 0.158, data: 0.020) loss: 0.350 
(epoch: 120, iters: 5552, time: 0.159, data: 0.000) loss: 0.348 
(epoch: 120, iters: 5632, time: 0.157, data: 0.008) loss: 0.354 
(epoch: 120, iters: 5712, time: 0.158, data: 0.024) loss: 0.788 
(epoch: 120, iters: 5792, time: 0.161, data: 0.000) loss: 0.101 
(epoch: 120, iters: 5872, time: 0.160, data: 0.000) loss: 0.902 
(epoch: 120, iters: 5952, time: 0.160, data: 0.000) loss: 0.852 
(epoch: 120, iters: 6032, time: 0.161, data: 0.011) loss: 0.019 
(epoch: 120, iters: 6112, time: 0.159, data: 0.000) loss: 0.470 
(epoch: 120, iters: 6192, time: 0.157, data: 0.024) loss: 0.321 
(epoch: 120, iters: 6272, time: 0.159, data: 0.000) loss: 0.534 
(epoch: 120, iters: 6352, time: 0.159, data: 0.000) loss: 0.202 
(epoch: 120, iters: 6432, time: 0.159, data: 0.000) loss: 0.858 
(epoch: 120, iters: 6512, time: 0.163, data: 0.037) loss: 0.992 
(epoch: 120, iters: 6592, time: 0.157, data: 0.000) loss: 0.301 
(epoch: 120, iters: 6672, time: 0.158, data: 0.014) loss: 1.166 
(epoch: 120, iters: 6752, time: 0.159, data: 0.000) loss: 0.875 
(epoch: 120, iters: 6832, time: 0.158, data: 0.021) loss: 0.495 
(epoch: 120, iters: 6912, time: 0.156, data: 0.014) loss: 0.205 
(epoch: 120, iters: 6992, time: 0.160, data: 0.000) loss: 0.385 
(epoch: 120, iters: 7072, time: 0.158, data: 0.005) loss: 0.177 
(epoch: 120, iters: 7152, time: 0.156, data: 0.010) loss: 0.351 
(epoch: 120, iters: 7232, time: 0.159, data: 0.000) loss: 0.170 
(epoch: 120, iters: 7312, time: 0.159, data: 0.011) loss: 0.286 
(epoch: 120, iters: 7392, time: 0.158, data: 0.000) loss: 0.060 
(epoch: 120, iters: 7472, time: 0.159, data: 0.000) loss: 0.527 
(epoch: 120, iters: 7552, time: 0.159, data: 0.015) loss: 0.504 
(epoch: 120, iters: 7632, time: 0.160, data: 0.000) loss: 0.808 
(epoch: 120, iters: 7712, time: 0.158, data: 0.000) loss: 0.296 
(epoch: 120, iters: 7792, time: 0.158, data: 0.006) loss: 0.422 
(epoch: 120, iters: 7872, time: 0.158, data: 0.000) loss: 0.274 
(epoch: 120, iters: 7952, time: 0.159, data: 0.025) loss: 0.217 
saving the latest model (epoch 120, total_steps 1220864)
(epoch: 120, iters: 8032, time: 0.161, data: 0.000) loss: 0.174 
(epoch: 120, iters: 8112, time: 0.159, data: 0.013) loss: 0.233 
(epoch: 120, iters: 8192, time: 0.158, data: 0.000) loss: 0.783 
(epoch: 120, iters: 8272, time: 0.160, data: 0.017) loss: 0.182 
(epoch: 120, iters: 8352, time: 0.159, data: 0.000) loss: 0.480 
(epoch: 120, iters: 8432, time: 0.158, data: 0.000) loss: 0.105 
(epoch: 120, iters: 8512, time: 0.158, data: 0.000) loss: 0.509 
(epoch: 120, iters: 8592, time: 0.159, data: 0.005) loss: 0.111 
(epoch: 120, iters: 8672, time: 0.159, data: 0.025) loss: 0.305 
(epoch: 120, iters: 8752, time: 0.159, data: 0.000) loss: 0.349 
(epoch: 120, iters: 8832, time: 0.161, data: 0.006) loss: 0.651 
(epoch: 120, iters: 8912, time: 0.160, data: 0.000) loss: 0.427 
(epoch: 120, iters: 8992, time: 0.160, data: 0.032) loss: 0.233 
(epoch: 120, iters: 9072, time: 0.158, data: 0.000) loss: 0.557 
(epoch: 120, iters: 9152, time: 0.157, data: 0.000) loss: 0.196 
(epoch: 120, iters: 9232, time: 0.168, data: 0.015) loss: 0.627 
(epoch: 120, iters: 9312, time: 0.159, data: 0.000) loss: 0.383 
(epoch: 120, iters: 9392, time: 0.158, data: 0.015) loss: 0.378 
(epoch: 120, iters: 9472, time: 0.159, data: 0.000) loss: 0.336 
(epoch: 120, iters: 9552, time: 0.161, data: 0.000) loss: 0.265 
(epoch: 120, iters: 9632, time: 0.165, data: 0.008) loss: 0.208 
(epoch: 120, iters: 9712, time: 0.159, data: 0.000) loss: 0.393 
(epoch: 120, iters: 9792, time: 0.158, data: 0.000) loss: 0.407 
(epoch: 120, iters: 9872, time: 0.158, data: 0.005) loss: 0.650 
(epoch: 120, iters: 9952, time: 0.157, data: 0.008) loss: 0.532 
(epoch: 120, iters: 10032, time: 0.158, data: 0.024) loss: 0.263 
(epoch: 120, iters: 10112, time: 0.159, data: 0.000) loss: 0.255 
(epoch: 120, iters: 10192, time: 0.096, data: 0.015) loss: 0.131 
saving the model at the end of epoch 120, iters 1223040
End of epoch 120 / 200 	 Time Taken: 1626 sec
learning rate = 0.0001564
saving the latest model (epoch 121, total_steps 1223056)
(epoch: 121, iters: 80, time: 0.162, data: 0.193) loss: 0.253 
(epoch: 121, iters: 160, time: 0.158, data: 0.000) loss: 0.469 
(epoch: 121, iters: 240, time: 0.159, data: 0.000) loss: 0.665 
(epoch: 121, iters: 320, time: 0.156, data: 0.007) loss: 0.080 
(epoch: 121, iters: 400, time: 0.157, data: 0.000) loss: 0.384 
(epoch: 121, iters: 480, time: 0.158, data: 0.021) loss: 0.697 
(epoch: 121, iters: 560, time: 0.156, data: 0.005) loss: 0.500 
(epoch: 121, iters: 640, time: 0.157, data: 0.000) loss: 1.000 
(epoch: 121, iters: 720, time: 0.159, data: 0.014) loss: 0.388 
(epoch: 121, iters: 800, time: 0.162, data: 0.000) loss: 0.196 
(epoch: 121, iters: 880, time: 0.158, data: 0.000) loss: 0.117 
(epoch: 121, iters: 960, time: 0.158, data: 0.005) loss: 0.369 
(epoch: 121, iters: 1040, time: 0.157, data: 0.000) loss: 0.467 
(epoch: 121, iters: 1120, time: 0.158, data: 0.029) loss: 0.255 
(epoch: 121, iters: 1200, time: 0.158, data: 0.013) loss: 0.229 
(epoch: 121, iters: 1280, time: 0.157, data: 0.000) loss: 0.323 
(epoch: 121, iters: 1360, time: 0.157, data: 0.006) loss: 0.889 
(epoch: 121, iters: 1440, time: 0.157, data: 0.000) loss: 0.543 
(epoch: 121, iters: 1520, time: 0.158, data: 0.005) loss: 0.445 
(epoch: 121, iters: 1600, time: 0.156, data: 0.000) loss: 0.219 
(epoch: 121, iters: 1680, time: 0.159, data: 0.000) loss: 0.841 
(epoch: 121, iters: 1760, time: 0.160, data: 0.000) loss: 0.386 
(epoch: 121, iters: 1840, time: 0.159, data: 0.005) loss: 0.623 
(epoch: 121, iters: 1920, time: 0.161, data: 0.008) loss: 0.217 
(epoch: 121, iters: 2000, time: 0.158, data: 0.009) loss: 0.265 
(epoch: 121, iters: 2080, time: 0.159, data: 0.000) loss: 0.414 
(epoch: 121, iters: 2160, time: 0.161, data: 0.022) loss: 0.311 
(epoch: 121, iters: 2240, time: 0.161, data: 0.000) loss: 0.197 
(epoch: 121, iters: 2320, time: 0.157, data: 0.000) loss: 0.324 
(epoch: 121, iters: 2400, time: 0.158, data: 0.000) loss: 0.350 
(epoch: 121, iters: 2480, time: 0.159, data: 0.005) loss: 0.590 
(epoch: 121, iters: 2560, time: 0.165, data: 0.000) loss: 0.078 
(epoch: 121, iters: 2640, time: 0.159, data: 0.005) loss: 0.800 
(epoch: 121, iters: 2720, time: 0.159, data: 0.000) loss: 0.393 
(epoch: 121, iters: 2800, time: 0.158, data: 0.021) loss: 0.349 
(epoch: 121, iters: 2880, time: 0.158, data: 0.005) loss: 0.528 
(epoch: 121, iters: 2960, time: 0.158, data: 0.034) loss: 0.237 
(epoch: 121, iters: 3040, time: 0.159, data: 0.000) loss: 0.219 
(epoch: 121, iters: 3120, time: 0.158, data: 0.000) loss: 0.384 
(epoch: 121, iters: 3200, time: 0.157, data: 0.026) loss: 0.831 
(epoch: 121, iters: 3280, time: 0.161, data: 0.000) loss: 0.931 
(epoch: 121, iters: 3360, time: 0.157, data: 0.000) loss: 0.121 
(epoch: 121, iters: 3440, time: 0.159, data: 0.000) loss: 0.593 
(epoch: 121, iters: 3520, time: 0.158, data: 0.000) loss: 0.105 
(epoch: 121, iters: 3600, time: 0.162, data: 0.000) loss: 0.360 
(epoch: 121, iters: 3680, time: 0.162, data: 0.030) loss: 0.326 
(epoch: 121, iters: 3760, time: 0.162, data: 0.000) loss: 0.543 
(epoch: 121, iters: 3840, time: 0.170, data: 0.010) loss: 0.349 
(epoch: 121, iters: 3920, time: 0.162, data: 0.000) loss: 0.536 
(epoch: 121, iters: 4000, time: 0.164, data: 0.000) loss: 0.402 
saving the latest model (epoch 121, total_steps 1227056)
(epoch: 121, iters: 4080, time: 0.164, data: 0.005) loss: 0.179 
(epoch: 121, iters: 4160, time: 0.162, data: 0.000) loss: 0.162 
(epoch: 121, iters: 4240, time: 0.162, data: 0.022) loss: 0.275 
(epoch: 121, iters: 4320, time: 0.162, data: 0.005) loss: 0.229 
(epoch: 121, iters: 4400, time: 0.164, data: 0.000) loss: 0.672 
(epoch: 121, iters: 4480, time: 0.166, data: 0.005) loss: 0.874 
(epoch: 121, iters: 4560, time: 0.161, data: 0.000) loss: 0.605 
(epoch: 121, iters: 4640, time: 0.163, data: 0.000) loss: 0.363 
(epoch: 121, iters: 4720, time: 0.161, data: 0.000) loss: 1.543 
(epoch: 121, iters: 4800, time: 0.163, data: 0.018) loss: 0.669 
(epoch: 121, iters: 4880, time: 0.164, data: 0.000) loss: 0.329 
(epoch: 121, iters: 4960, time: 0.162, data: 0.011) loss: 0.255 
(epoch: 121, iters: 5040, time: 0.162, data: 0.000) loss: 0.576 
(epoch: 121, iters: 5120, time: 0.160, data: 0.032) loss: 0.515 
(epoch: 121, iters: 5200, time: 0.161, data: 0.000) loss: 1.087 
(epoch: 121, iters: 5280, time: 0.159, data: 0.000) loss: 0.375 
(epoch: 121, iters: 5360, time: 0.164, data: 0.000) loss: 0.864 
(epoch: 121, iters: 5440, time: 0.161, data: 0.015) loss: 0.253 
(epoch: 121, iters: 5520, time: 0.163, data: 0.000) loss: 0.803 
(epoch: 121, iters: 5600, time: 0.164, data: 0.008) loss: 0.673 
(epoch: 121, iters: 5680, time: 0.163, data: 0.000) loss: 0.428 
(epoch: 121, iters: 5760, time: 0.163, data: 0.000) loss: 0.294 
(epoch: 121, iters: 5840, time: 0.162, data: 0.000) loss: 0.649 
(epoch: 121, iters: 5920, time: 0.162, data: 0.000) loss: 0.240 
(epoch: 121, iters: 6000, time: 0.166, data: 0.000) loss: 0.441 
(epoch: 121, iters: 6080, time: 0.161, data: 0.000) loss: 0.851 
(epoch: 121, iters: 6160, time: 0.163, data: 0.013) loss: 0.174 
(epoch: 121, iters: 6240, time: 0.161, data: 0.000) loss: 1.138 
(epoch: 121, iters: 6320, time: 0.164, data: 0.000) loss: 0.363 
(epoch: 121, iters: 6400, time: 0.163, data: 0.005) loss: 0.415 
(epoch: 121, iters: 6480, time: 0.161, data: 0.000) loss: 0.422 
(epoch: 121, iters: 6560, time: 0.163, data: 0.006) loss: 0.309 
(epoch: 121, iters: 6640, time: 0.162, data: 0.005) loss: 0.432 
(epoch: 121, iters: 6720, time: 0.162, data: 0.000) loss: 0.252 
(epoch: 121, iters: 6800, time: 0.163, data: 0.040) loss: 0.203 
(epoch: 121, iters: 6880, time: 0.161, data: 0.000) loss: 0.455 
(epoch: 121, iters: 6960, time: 0.161, data: 0.000) loss: 0.321 
(epoch: 121, iters: 7040, time: 0.163, data: 0.010) loss: 0.518 
(epoch: 121, iters: 7120, time: 0.161, data: 0.000) loss: 0.584 
(epoch: 121, iters: 7200, time: 0.163, data: 0.000) loss: 0.455 
(epoch: 121, iters: 7280, time: 0.163, data: 0.031) loss: 0.396 
(epoch: 121, iters: 7360, time: 0.161, data: 0.000) loss: 0.467 
(epoch: 121, iters: 7440, time: 0.166, data: 0.010) loss: 0.291 
(epoch: 121, iters: 7520, time: 0.162, data: 0.015) loss: 0.368 
(epoch: 121, iters: 7600, time: 0.163, data: 0.006) loss: 0.411 
(epoch: 121, iters: 7680, time: 0.164, data: 0.006) loss: 0.302 
(epoch: 121, iters: 7760, time: 0.163, data: 0.000) loss: 0.408 
(epoch: 121, iters: 7840, time: 0.160, data: 0.000) loss: 0.246 
(epoch: 121, iters: 7920, time: 0.166, data: 0.005) loss: 0.342 
(epoch: 121, iters: 8000, time: 0.162, data: 0.000) loss: 0.655 
saving the latest model (epoch 121, total_steps 1231056)
(epoch: 121, iters: 8080, time: 0.162, data: 0.000) loss: 0.204 
(epoch: 121, iters: 8160, time: 0.164, data: 0.000) loss: 1.018 
(epoch: 121, iters: 8240, time: 0.162, data: 0.011) loss: 0.097 
(epoch: 121, iters: 8320, time: 0.160, data: 0.009) loss: 0.466 
(epoch: 121, iters: 8400, time: 0.162, data: 0.013) loss: 0.207 
(epoch: 121, iters: 8480, time: 0.162, data: 0.008) loss: 0.180 
(epoch: 121, iters: 8560, time: 0.159, data: 0.000) loss: 0.820 
(epoch: 121, iters: 8640, time: 0.162, data: 0.008) loss: 0.295 
(epoch: 121, iters: 8720, time: 0.162, data: 0.000) loss: 0.238 
(epoch: 121, iters: 8800, time: 0.162, data: 0.008) loss: 0.322 
(epoch: 121, iters: 8880, time: 0.163, data: 0.000) loss: 0.509 
(epoch: 121, iters: 8960, time: 0.161, data: 0.000) loss: 0.361 
(epoch: 121, iters: 9040, time: 0.162, data: 0.000) loss: 0.282 
(epoch: 121, iters: 9120, time: 0.164, data: 0.006) loss: 0.465 
(epoch: 121, iters: 9200, time: 0.161, data: 0.000) loss: 0.178 
(epoch: 121, iters: 9280, time: 0.162, data: 0.014) loss: 1.048 
(epoch: 121, iters: 9360, time: 0.162, data: 0.017) loss: 0.751 
(epoch: 121, iters: 9440, time: 0.168, data: 0.000) loss: 0.088 
(epoch: 121, iters: 9520, time: 0.163, data: 0.000) loss: 0.272 
(epoch: 121, iters: 9600, time: 0.162, data: 0.015) loss: 0.469 
(epoch: 121, iters: 9680, time: 0.162, data: 0.014) loss: 0.695 
(epoch: 121, iters: 9760, time: 0.161, data: 0.000) loss: 0.358 
(epoch: 121, iters: 9840, time: 0.162, data: 0.000) loss: 0.781 
(epoch: 121, iters: 9920, time: 0.162, data: 0.000) loss: 0.343 
(epoch: 121, iters: 10000, time: 0.164, data: 0.000) loss: 0.136 
(epoch: 121, iters: 10080, time: 0.166, data: 0.017) loss: 0.552 
(epoch: 121, iters: 10160, time: 0.160, data: 0.014) loss: 0.127 
saving the model at the end of epoch 121, iters 1233232
End of epoch 121 / 200 	 Time Taken: 1648 sec
learning rate = 0.0001545
saving the latest model (epoch 122, total_steps 1233248)
(epoch: 122, iters: 48, time: 0.166, data: 0.005) loss: 0.770 
(epoch: 122, iters: 128, time: 0.159, data: 0.019) loss: 0.571 
(epoch: 122, iters: 208, time: 0.160, data: 0.000) loss: 0.584 
(epoch: 122, iters: 288, time: 0.163, data: 0.016) loss: 0.295 
(epoch: 122, iters: 368, time: 0.159, data: 0.008) loss: 0.521 
(epoch: 122, iters: 448, time: 0.160, data: 0.000) loss: 0.432 
(epoch: 122, iters: 528, time: 0.158, data: 0.000) loss: 0.323 
(epoch: 122, iters: 608, time: 0.159, data: 0.000) loss: 0.197 
(epoch: 122, iters: 688, time: 0.159, data: 0.000) loss: 0.302 
(epoch: 122, iters: 768, time: 0.160, data: 0.010) loss: 0.203 
(epoch: 122, iters: 848, time: 0.160, data: 0.000) loss: 0.725 
(epoch: 122, iters: 928, time: 0.159, data: 0.022) loss: 0.478 
(epoch: 122, iters: 1008, time: 0.158, data: 0.011) loss: 0.418 
(epoch: 122, iters: 1088, time: 0.157, data: 0.005) loss: 0.579 
(epoch: 122, iters: 1168, time: 0.168, data: 0.000) loss: 0.270 
(epoch: 122, iters: 1248, time: 0.161, data: 0.009) loss: 0.470 
(epoch: 122, iters: 1328, time: 0.160, data: 0.016) loss: 0.177 
(epoch: 122, iters: 1408, time: 0.158, data: 0.009) loss: 0.564 
(epoch: 122, iters: 1488, time: 0.161, data: 0.000) loss: 0.272 
(epoch: 122, iters: 1568, time: 0.165, data: 0.006) loss: 1.272 
(epoch: 122, iters: 1648, time: 0.159, data: 0.014) loss: 0.244 
(epoch: 122, iters: 1728, time: 0.158, data: 0.008) loss: 0.495 
(epoch: 122, iters: 1808, time: 0.160, data: 0.000) loss: 0.437 
(epoch: 122, iters: 1888, time: 0.159, data: 0.016) loss: 0.498 
(epoch: 122, iters: 1968, time: 0.160, data: 0.000) loss: 0.576 
(epoch: 122, iters: 2048, time: 0.159, data: 0.015) loss: 0.928 
(epoch: 122, iters: 2128, time: 0.156, data: 0.000) loss: 0.637 
(epoch: 122, iters: 2208, time: 0.159, data: 0.011) loss: 0.421 
(epoch: 122, iters: 2288, time: 0.157, data: 0.000) loss: 0.449 
(epoch: 122, iters: 2368, time: 0.157, data: 0.010) loss: 0.675 
(epoch: 122, iters: 2448, time: 0.156, data: 0.021) loss: 0.688 
(epoch: 122, iters: 2528, time: 0.156, data: 0.005) loss: 0.093 
(epoch: 122, iters: 2608, time: 0.157, data: 0.021) loss: 0.454 
(epoch: 122, iters: 2688, time: 0.158, data: 0.000) loss: 0.261 
(epoch: 122, iters: 2768, time: 0.156, data: 0.000) loss: 0.693 
(epoch: 122, iters: 2848, time: 0.157, data: 0.000) loss: 0.281 
(epoch: 122, iters: 2928, time: 0.158, data: 0.000) loss: 0.479 
(epoch: 122, iters: 3008, time: 0.157, data: 0.000) loss: 0.186 
(epoch: 122, iters: 3088, time: 0.157, data: 0.009) loss: 0.339 
(epoch: 122, iters: 3168, time: 0.159, data: 0.000) loss: 0.036 
(epoch: 122, iters: 3248, time: 0.160, data: 0.000) loss: 0.317 
(epoch: 122, iters: 3328, time: 0.157, data: 0.024) loss: 0.423 
(epoch: 122, iters: 3408, time: 0.160, data: 0.000) loss: 0.345 
(epoch: 122, iters: 3488, time: 0.156, data: 0.006) loss: 0.332 
(epoch: 122, iters: 3568, time: 0.158, data: 0.000) loss: 0.572 
(epoch: 122, iters: 3648, time: 0.160, data: 0.000) loss: 0.042 
(epoch: 122, iters: 3728, time: 0.158, data: 0.014) loss: 0.533 
(epoch: 122, iters: 3808, time: 0.158, data: 0.016) loss: 0.403 
(epoch: 122, iters: 3888, time: 0.157, data: 0.000) loss: 0.774 
(epoch: 122, iters: 3968, time: 0.157, data: 0.010) loss: 0.682 
saving the latest model (epoch 122, total_steps 1237248)
(epoch: 122, iters: 4048, time: 0.160, data: 0.000) loss: 0.123 
(epoch: 122, iters: 4128, time: 0.159, data: 0.011) loss: 0.419 
(epoch: 122, iters: 4208, time: 0.159, data: 0.000) loss: 0.688 
(epoch: 122, iters: 4288, time: 0.160, data: 0.000) loss: 0.336 
(epoch: 122, iters: 4368, time: 0.159, data: 0.000) loss: 0.804 
(epoch: 122, iters: 4448, time: 0.158, data: 0.000) loss: 0.469 
(epoch: 122, iters: 4528, time: 0.160, data: 0.000) loss: 0.195 
(epoch: 122, iters: 4608, time: 0.158, data: 0.000) loss: 0.704 
(epoch: 122, iters: 4688, time: 0.167, data: 0.000) loss: 0.378 
(epoch: 122, iters: 4768, time: 0.158, data: 0.034) loss: 0.668 
(epoch: 122, iters: 4848, time: 0.159, data: 0.000) loss: 0.771 
(epoch: 122, iters: 4928, time: 0.158, data: 0.000) loss: 0.737 
(epoch: 122, iters: 5008, time: 0.159, data: 0.000) loss: 0.555 
(epoch: 122, iters: 5088, time: 0.160, data: 0.000) loss: 0.841 
(epoch: 122, iters: 5168, time: 0.158, data: 0.008) loss: 0.550 
(epoch: 122, iters: 5248, time: 0.160, data: 0.014) loss: 0.276 
(epoch: 122, iters: 5328, time: 0.159, data: 0.019) loss: 0.207 
(epoch: 122, iters: 5408, time: 0.160, data: 0.000) loss: 0.471 
(epoch: 122, iters: 5488, time: 0.155, data: 0.015) loss: 0.448 
(epoch: 122, iters: 5568, time: 0.157, data: 0.000) loss: 0.254 
(epoch: 122, iters: 5648, time: 0.159, data: 0.005) loss: 0.706 
(epoch: 122, iters: 5728, time: 0.159, data: 0.025) loss: 0.277 
(epoch: 122, iters: 5808, time: 0.156, data: 0.000) loss: 0.359 
(epoch: 122, iters: 5888, time: 0.156, data: 0.000) loss: 0.616 
(epoch: 122, iters: 5968, time: 0.155, data: 0.000) loss: 0.624 
(epoch: 122, iters: 6048, time: 0.159, data: 0.015) loss: 0.288 
(epoch: 122, iters: 6128, time: 0.162, data: 0.010) loss: 0.490 
(epoch: 122, iters: 6208, time: 0.158, data: 0.008) loss: 0.294 
(epoch: 122, iters: 6288, time: 0.159, data: 0.005) loss: 0.183 
(epoch: 122, iters: 6368, time: 0.157, data: 0.008) loss: 0.335 
(epoch: 122, iters: 6448, time: 0.159, data: 0.005) loss: 0.666 
(epoch: 122, iters: 6528, time: 0.157, data: 0.010) loss: 1.062 
(epoch: 122, iters: 6608, time: 0.158, data: 0.005) loss: 0.097 
(epoch: 122, iters: 6688, time: 0.157, data: 0.006) loss: 0.548 
(epoch: 122, iters: 6768, time: 0.161, data: 0.000) loss: 0.382 
(epoch: 122, iters: 6848, time: 0.158, data: 0.025) loss: 0.479 
(epoch: 122, iters: 6928, time: 0.159, data: 0.000) loss: 0.106 
(epoch: 122, iters: 7008, time: 0.157, data: 0.000) loss: 0.208 
(epoch: 122, iters: 7088, time: 0.159, data: 0.005) loss: 0.371 
(epoch: 122, iters: 7168, time: 0.158, data: 0.005) loss: 0.303 
(epoch: 122, iters: 7248, time: 0.159, data: 0.000) loss: 0.957 
(epoch: 122, iters: 7328, time: 0.158, data: 0.022) loss: 0.453 
(epoch: 122, iters: 7408, time: 0.163, data: 0.000) loss: 0.052 
(epoch: 122, iters: 7488, time: 0.159, data: 0.000) loss: 0.994 
(epoch: 122, iters: 7568, time: 0.160, data: 0.020) loss: 0.289 
(epoch: 122, iters: 7648, time: 0.157, data: 0.010) loss: 0.483 
(epoch: 122, iters: 7728, time: 0.158, data: 0.000) loss: 0.172 
(epoch: 122, iters: 7808, time: 0.164, data: 0.000) loss: 0.562 
(epoch: 122, iters: 7888, time: 0.158, data: 0.000) loss: 0.515 
(epoch: 122, iters: 7968, time: 0.159, data: 0.010) loss: 0.855 
saving the latest model (epoch 122, total_steps 1241248)
(epoch: 122, iters: 8048, time: 0.156, data: 0.000) loss: 0.467 
(epoch: 122, iters: 8128, time: 0.158, data: 0.000) loss: 0.077 
(epoch: 122, iters: 8208, time: 0.158, data: 0.005) loss: 0.297 
(epoch: 122, iters: 8288, time: 0.157, data: 0.000) loss: 0.342 
(epoch: 122, iters: 8368, time: 0.158, data: 0.006) loss: 0.292 
(epoch: 122, iters: 8448, time: 0.156, data: 0.008) loss: 0.561 
(epoch: 122, iters: 8528, time: 0.159, data: 0.006) loss: 0.437 
(epoch: 122, iters: 8608, time: 0.162, data: 0.000) loss: 0.361 
(epoch: 122, iters: 8688, time: 0.157, data: 0.000) loss: 0.432 
(epoch: 122, iters: 8768, time: 0.157, data: 0.000) loss: 0.207 
(epoch: 122, iters: 8848, time: 0.158, data: 0.000) loss: 0.624 
(epoch: 122, iters: 8928, time: 0.158, data: 0.006) loss: 0.365 
(epoch: 122, iters: 9008, time: 0.160, data: 0.000) loss: 0.489 
(epoch: 122, iters: 9088, time: 0.160, data: 0.016) loss: 2.252 
(epoch: 122, iters: 9168, time: 0.160, data: 0.000) loss: 0.774 
(epoch: 122, iters: 9248, time: 0.159, data: 0.000) loss: 0.331 
(epoch: 122, iters: 9328, time: 0.157, data: 0.005) loss: 0.179 
(epoch: 122, iters: 9408, time: 0.159, data: 0.000) loss: 0.672 
(epoch: 122, iters: 9488, time: 0.159, data: 0.025) loss: 0.570 
(epoch: 122, iters: 9568, time: 0.161, data: 0.000) loss: 0.617 
(epoch: 122, iters: 9648, time: 0.158, data: 0.006) loss: 0.456 
(epoch: 122, iters: 9728, time: 0.159, data: 0.008) loss: 0.438 
(epoch: 122, iters: 9808, time: 0.158, data: 0.000) loss: 0.356 
(epoch: 122, iters: 9888, time: 0.159, data: 0.000) loss: 0.295 
(epoch: 122, iters: 9968, time: 0.159, data: 0.005) loss: 0.102 
(epoch: 122, iters: 10048, time: 0.159, data: 0.008) loss: 0.133 
(epoch: 122, iters: 10128, time: 0.158, data: 0.000) loss: 1.013 
saving the model at the end of epoch 122, iters 1243424
End of epoch 122 / 200 	 Time Taken: 1624 sec
learning rate = 0.0001525
(epoch: 123, iters: 16, time: 0.181, data: 0.000) loss: 0.278 
saving the latest model (epoch 123, total_steps 1243440)
(epoch: 123, iters: 96, time: 0.163, data: 0.000) loss: 0.690 
(epoch: 123, iters: 176, time: 0.162, data: 0.009) loss: 0.847 
(epoch: 123, iters: 256, time: 0.159, data: 0.016) loss: 0.443 
(epoch: 123, iters: 336, time: 0.165, data: 0.008) loss: 0.641 
(epoch: 123, iters: 416, time: 0.160, data: 0.008) loss: 0.366 
(epoch: 123, iters: 496, time: 0.160, data: 0.000) loss: 0.033 
(epoch: 123, iters: 576, time: 0.159, data: 0.009) loss: 0.465 
(epoch: 123, iters: 656, time: 0.160, data: 0.005) loss: 0.556 
(epoch: 123, iters: 736, time: 0.166, data: 0.024) loss: 0.193 
(epoch: 123, iters: 816, time: 0.161, data: 0.015) loss: 0.331 
(epoch: 123, iters: 896, time: 0.159, data: 0.022) loss: 0.387 
(epoch: 123, iters: 976, time: 0.159, data: 0.013) loss: 0.193 
(epoch: 123, iters: 1056, time: 0.159, data: 0.000) loss: 0.590 
(epoch: 123, iters: 1136, time: 0.159, data: 0.015) loss: 0.545 
(epoch: 123, iters: 1216, time: 0.159, data: 0.016) loss: 0.356 
(epoch: 123, iters: 1296, time: 0.160, data: 0.000) loss: 0.312 
(epoch: 123, iters: 1376, time: 0.159, data: 0.021) loss: 0.647 
(epoch: 123, iters: 1456, time: 0.159, data: 0.000) loss: 0.473 
(epoch: 123, iters: 1536, time: 0.160, data: 0.015) loss: 0.133 
(epoch: 123, iters: 1616, time: 0.159, data: 0.008) loss: 0.138 
(epoch: 123, iters: 1696, time: 0.161, data: 0.016) loss: 0.177 
(epoch: 123, iters: 1776, time: 0.158, data: 0.000) loss: 0.239 
(epoch: 123, iters: 1856, time: 0.159, data: 0.000) loss: 0.382 
(epoch: 123, iters: 1936, time: 0.159, data: 0.000) loss: 0.123 
(epoch: 123, iters: 2016, time: 0.159, data: 0.000) loss: 0.429 
(epoch: 123, iters: 2096, time: 0.159, data: 0.000) loss: 0.203 
(epoch: 123, iters: 2176, time: 0.161, data: 0.000) loss: 0.152 
(epoch: 123, iters: 2256, time: 0.160, data: 0.025) loss: 0.475 
(epoch: 123, iters: 2336, time: 0.162, data: 0.000) loss: 0.439 
(epoch: 123, iters: 2416, time: 0.158, data: 0.011) loss: 1.081 
(epoch: 123, iters: 2496, time: 0.158, data: 0.023) loss: 0.330 
(epoch: 123, iters: 2576, time: 0.160, data: 0.008) loss: 0.843 
(epoch: 123, iters: 2656, time: 0.159, data: 0.000) loss: 0.162 
(epoch: 123, iters: 2736, time: 0.158, data: 0.032) loss: 0.411 
(epoch: 123, iters: 2816, time: 0.160, data: 0.000) loss: 0.328 
(epoch: 123, iters: 2896, time: 0.160, data: 0.024) loss: 0.633 
(epoch: 123, iters: 2976, time: 0.159, data: 0.008) loss: 0.655 
(epoch: 123, iters: 3056, time: 0.165, data: 0.000) loss: 0.425 
(epoch: 123, iters: 3136, time: 0.157, data: 0.000) loss: 0.320 
(epoch: 123, iters: 3216, time: 0.160, data: 0.019) loss: 0.400 
(epoch: 123, iters: 3296, time: 0.162, data: 0.017) loss: 0.721 
(epoch: 123, iters: 3376, time: 0.161, data: 0.000) loss: 0.094 
(epoch: 123, iters: 3456, time: 0.161, data: 0.000) loss: 0.249 
(epoch: 123, iters: 3536, time: 0.160, data: 0.008) loss: 0.817 
(epoch: 123, iters: 3616, time: 0.160, data: 0.000) loss: 0.460 
(epoch: 123, iters: 3696, time: 0.162, data: 0.000) loss: 0.527 
(epoch: 123, iters: 3776, time: 0.160, data: 0.031) loss: 0.271 
(epoch: 123, iters: 3856, time: 0.159, data: 0.000) loss: 0.561 
(epoch: 123, iters: 3936, time: 0.158, data: 0.000) loss: 0.154 
(epoch: 123, iters: 4016, time: 0.159, data: 0.000) loss: 0.320 
saving the latest model (epoch 123, total_steps 1247440)
(epoch: 123, iters: 4096, time: 0.160, data: 0.025) loss: 0.229 
(epoch: 123, iters: 4176, time: 0.161, data: 0.000) loss: 0.797 
(epoch: 123, iters: 4256, time: 0.159, data: 0.005) loss: 0.586 
(epoch: 123, iters: 4336, time: 0.161, data: 0.000) loss: 0.302 
(epoch: 123, iters: 4416, time: 0.163, data: 0.010) loss: 0.505 
(epoch: 123, iters: 4496, time: 0.158, data: 0.000) loss: 0.678 
(epoch: 123, iters: 4576, time: 0.159, data: 0.000) loss: 0.302 
(epoch: 123, iters: 4656, time: 0.160, data: 0.000) loss: 0.327 
(epoch: 123, iters: 4736, time: 0.160, data: 0.005) loss: 0.523 
(epoch: 123, iters: 4816, time: 0.160, data: 0.000) loss: 0.104 
(epoch: 123, iters: 4896, time: 0.163, data: 0.000) loss: 0.067 
(epoch: 123, iters: 4976, time: 0.170, data: 0.000) loss: 0.536 
(epoch: 123, iters: 5056, time: 0.159, data: 0.008) loss: 0.675 
(epoch: 123, iters: 5136, time: 0.161, data: 0.005) loss: 0.652 
(epoch: 123, iters: 5216, time: 0.160, data: 0.027) loss: 0.781 
(epoch: 123, iters: 5296, time: 0.160, data: 0.000) loss: 0.516 
(epoch: 123, iters: 5376, time: 0.166, data: 0.014) loss: 0.644 
(epoch: 123, iters: 5456, time: 0.160, data: 0.000) loss: 0.522 
(epoch: 123, iters: 5536, time: 0.163, data: 0.021) loss: 0.467 
(epoch: 123, iters: 5616, time: 0.161, data: 0.009) loss: 0.557 
(epoch: 123, iters: 5696, time: 0.161, data: 0.000) loss: 0.205 
(epoch: 123, iters: 5776, time: 0.159, data: 0.018) loss: 0.663 
(epoch: 123, iters: 5856, time: 0.159, data: 0.021) loss: 0.355 
(epoch: 123, iters: 5936, time: 0.160, data: 0.000) loss: 0.503 
(epoch: 123, iters: 6016, time: 0.159, data: 0.000) loss: 0.090 
(epoch: 123, iters: 6096, time: 0.161, data: 0.000) loss: 0.729 
(epoch: 123, iters: 6176, time: 0.164, data: 0.020) loss: 0.653 
(epoch: 123, iters: 6256, time: 0.160, data: 0.000) loss: 1.003 
(epoch: 123, iters: 6336, time: 0.160, data: 0.028) loss: 0.232 
(epoch: 123, iters: 6416, time: 0.161, data: 0.000) loss: 0.317 
(epoch: 123, iters: 6496, time: 0.158, data: 0.005) loss: 0.636 
(epoch: 123, iters: 6576, time: 0.160, data: 0.005) loss: 0.846 
(epoch: 123, iters: 6656, time: 0.161, data: 0.000) loss: 0.249 
(epoch: 123, iters: 6736, time: 0.162, data: 0.017) loss: 0.253 
(epoch: 123, iters: 6816, time: 0.163, data: 0.000) loss: 0.614 
(epoch: 123, iters: 6896, time: 0.162, data: 0.005) loss: 0.443 
(epoch: 123, iters: 6976, time: 0.181, data: 0.017) loss: 0.617 
(epoch: 123, iters: 7056, time: 0.163, data: 0.008) loss: 0.811 
(epoch: 123, iters: 7136, time: 0.163, data: 0.000) loss: 0.355 
(epoch: 123, iters: 7216, time: 0.163, data: 0.000) loss: 0.651 
(epoch: 123, iters: 7296, time: 0.164, data: 0.000) loss: 0.192 
(epoch: 123, iters: 7376, time: 0.162, data: 0.000) loss: 0.275 
(epoch: 123, iters: 7456, time: 0.164, data: 0.000) loss: 0.403 
(epoch: 123, iters: 7536, time: 0.163, data: 0.000) loss: 0.506 
(epoch: 123, iters: 7616, time: 0.164, data: 0.006) loss: 0.209 
(epoch: 123, iters: 7696, time: 0.161, data: 0.000) loss: 0.372 
(epoch: 123, iters: 7776, time: 0.163, data: 0.000) loss: 0.555 
(epoch: 123, iters: 7856, time: 0.163, data: 0.005) loss: 0.266 
(epoch: 123, iters: 7936, time: 0.160, data: 0.000) loss: 0.507 
(epoch: 123, iters: 8016, time: 0.163, data: 0.006) loss: 0.533 
saving the latest model (epoch 123, total_steps 1251440)
(epoch: 123, iters: 8096, time: 0.161, data: 0.006) loss: 0.261 
(epoch: 123, iters: 8176, time: 0.163, data: 0.000) loss: 0.231 
(epoch: 123, iters: 8256, time: 0.162, data: 0.025) loss: 0.569 
(epoch: 123, iters: 8336, time: 0.163, data: 0.000) loss: 0.161 
(epoch: 123, iters: 8416, time: 0.164, data: 0.000) loss: 0.832 
(epoch: 123, iters: 8496, time: 0.161, data: 0.000) loss: 0.376 
(epoch: 123, iters: 8576, time: 0.160, data: 0.035) loss: 0.230 
(epoch: 123, iters: 8656, time: 0.157, data: 0.000) loss: 0.504 
(epoch: 123, iters: 8736, time: 0.158, data: 0.018) loss: 0.304 
(epoch: 123, iters: 8816, time: 0.165, data: 0.031) loss: 0.453 
(epoch: 123, iters: 8896, time: 0.161, data: 0.000) loss: 0.306 
(epoch: 123, iters: 8976, time: 0.161, data: 0.000) loss: 0.285 
(epoch: 123, iters: 9056, time: 0.160, data: 0.008) loss: 0.427 
(epoch: 123, iters: 9136, time: 0.161, data: 0.005) loss: 0.412 
(epoch: 123, iters: 9216, time: 0.163, data: 0.005) loss: 0.125 
(epoch: 123, iters: 9296, time: 0.162, data: 0.000) loss: 0.609 
(epoch: 123, iters: 9376, time: 0.159, data: 0.011) loss: 0.529 
(epoch: 123, iters: 9456, time: 0.160, data: 0.023) loss: 0.446 
(epoch: 123, iters: 9536, time: 0.163, data: 0.000) loss: 0.133 
(epoch: 123, iters: 9616, time: 0.162, data: 0.013) loss: 0.256 
(epoch: 123, iters: 9696, time: 0.164, data: 0.000) loss: 0.351 
(epoch: 123, iters: 9776, time: 0.163, data: 0.008) loss: 0.225 
(epoch: 123, iters: 9856, time: 0.163, data: 0.000) loss: 0.292 
(epoch: 123, iters: 9936, time: 0.162, data: 0.005) loss: 0.245 
(epoch: 123, iters: 10016, time: 0.163, data: 0.009) loss: 0.410 
(epoch: 123, iters: 10096, time: 0.162, data: 0.000) loss: 0.511 
(epoch: 123, iters: 10176, time: 0.161, data: 0.000) loss: 1.064 
saving the model at the end of epoch 123, iters 1253616
End of epoch 123 / 200 	 Time Taken: 1644 sec
learning rate = 0.0001505
saving the latest model (epoch 124, total_steps 1253632)
(epoch: 124, iters: 64, time: 0.161, data: 0.003) loss: 0.124 
(epoch: 124, iters: 144, time: 0.157, data: 0.000) loss: 0.140 
(epoch: 124, iters: 224, time: 0.160, data: 0.000) loss: 0.805 
(epoch: 124, iters: 304, time: 0.159, data: 0.010) loss: 0.545 
(epoch: 124, iters: 384, time: 0.159, data: 0.000) loss: 0.525 
(epoch: 124, iters: 464, time: 0.159, data: 0.000) loss: 0.230 
(epoch: 124, iters: 544, time: 0.168, data: 0.009) loss: 0.248 
(epoch: 124, iters: 624, time: 0.160, data: 0.000) loss: 0.656 
(epoch: 124, iters: 704, time: 0.159, data: 0.000) loss: 0.309 
(epoch: 124, iters: 784, time: 0.159, data: 0.020) loss: 0.133 
(epoch: 124, iters: 864, time: 0.158, data: 0.006) loss: 0.509 
(epoch: 124, iters: 944, time: 0.166, data: 0.000) loss: 0.504 
(epoch: 124, iters: 1024, time: 0.158, data: 0.000) loss: 0.381 
(epoch: 124, iters: 1104, time: 0.160, data: 0.027) loss: 0.448 
(epoch: 124, iters: 1184, time: 0.158, data: 0.000) loss: 0.535 
(epoch: 124, iters: 1264, time: 0.158, data: 0.000) loss: 0.628 
(epoch: 124, iters: 1344, time: 0.159, data: 0.000) loss: 0.137 
(epoch: 124, iters: 1424, time: 0.157, data: 0.008) loss: 0.826 
(epoch: 124, iters: 1504, time: 0.159, data: 0.005) loss: 0.590 
(epoch: 124, iters: 1584, time: 0.157, data: 0.010) loss: 0.539 
(epoch: 124, iters: 1664, time: 0.159, data: 0.000) loss: 0.481 
(epoch: 124, iters: 1744, time: 0.157, data: 0.015) loss: 0.495 
(epoch: 124, iters: 1824, time: 0.160, data: 0.000) loss: 0.252 
(epoch: 124, iters: 1904, time: 0.159, data: 0.016) loss: 0.637 
(epoch: 124, iters: 1984, time: 0.159, data: 0.000) loss: 0.447 
(epoch: 124, iters: 2064, time: 0.161, data: 0.000) loss: 0.283 
(epoch: 124, iters: 2144, time: 0.156, data: 0.008) loss: 0.282 
(epoch: 124, iters: 2224, time: 0.157, data: 0.000) loss: 0.209 
(epoch: 124, iters: 2304, time: 0.159, data: 0.000) loss: 0.713 
(epoch: 124, iters: 2384, time: 0.159, data: 0.017) loss: 0.353 
(epoch: 124, iters: 2464, time: 0.158, data: 0.031) loss: 0.485 
(epoch: 124, iters: 2544, time: 0.159, data: 0.000) loss: 0.464 
(epoch: 124, iters: 2624, time: 0.159, data: 0.012) loss: 0.432 
(epoch: 124, iters: 2704, time: 0.159, data: 0.015) loss: 0.678 
(epoch: 124, iters: 2784, time: 0.157, data: 0.005) loss: 0.304 
(epoch: 124, iters: 2864, time: 0.158, data: 0.013) loss: 0.250 
(epoch: 124, iters: 2944, time: 0.158, data: 0.005) loss: 0.345 
(epoch: 124, iters: 3024, time: 0.157, data: 0.000) loss: 0.705 
(epoch: 124, iters: 3104, time: 0.155, data: 0.011) loss: 0.302 
(epoch: 124, iters: 3184, time: 0.159, data: 0.000) loss: 0.438 
(epoch: 124, iters: 3264, time: 0.161, data: 0.006) loss: 0.218 
(epoch: 124, iters: 3344, time: 0.159, data: 0.010) loss: 0.069 
(epoch: 124, iters: 3424, time: 0.161, data: 0.000) loss: 0.609 
(epoch: 124, iters: 3504, time: 0.158, data: 0.023) loss: 0.432 
(epoch: 124, iters: 3584, time: 0.160, data: 0.000) loss: 0.430 
(epoch: 124, iters: 3664, time: 0.163, data: 0.013) loss: 0.502 
(epoch: 124, iters: 3744, time: 0.160, data: 0.000) loss: 0.383 
(epoch: 124, iters: 3824, time: 0.159, data: 0.024) loss: 0.445 
(epoch: 124, iters: 3904, time: 0.157, data: 0.000) loss: 0.575 
(epoch: 124, iters: 3984, time: 0.158, data: 0.010) loss: 0.949 
saving the latest model (epoch 124, total_steps 1257632)
(epoch: 124, iters: 4064, time: 0.157, data: 0.005) loss: 0.226 
(epoch: 124, iters: 4144, time: 0.159, data: 0.012) loss: 0.378 
(epoch: 124, iters: 4224, time: 0.161, data: 0.000) loss: 0.443 
(epoch: 124, iters: 4304, time: 0.159, data: 0.024) loss: 0.185 
(epoch: 124, iters: 4384, time: 0.160, data: 0.000) loss: 0.475 
(epoch: 124, iters: 4464, time: 0.160, data: 0.015) loss: 0.555 
(epoch: 124, iters: 4544, time: 0.159, data: 0.006) loss: 0.203 
(epoch: 124, iters: 4624, time: 0.159, data: 0.000) loss: 0.621 
(epoch: 124, iters: 4704, time: 0.161, data: 0.000) loss: 0.183 
(epoch: 124, iters: 4784, time: 0.158, data: 0.000) loss: 0.333 
(epoch: 124, iters: 4864, time: 0.159, data: 0.016) loss: 0.385 
(epoch: 124, iters: 4944, time: 0.158, data: 0.000) loss: 0.146 
(epoch: 124, iters: 5024, time: 0.158, data: 0.000) loss: 0.631 
(epoch: 124, iters: 5104, time: 0.159, data: 0.013) loss: 0.486 
(epoch: 124, iters: 5184, time: 0.158, data: 0.014) loss: 0.754 
(epoch: 124, iters: 5264, time: 0.160, data: 0.000) loss: 0.363 
(epoch: 124, iters: 5344, time: 0.161, data: 0.000) loss: 0.124 
(epoch: 124, iters: 5424, time: 0.160, data: 0.006) loss: 0.510 
(epoch: 124, iters: 5504, time: 0.159, data: 0.005) loss: 0.406 
(epoch: 124, iters: 5584, time: 0.160, data: 0.000) loss: 0.852 
(epoch: 124, iters: 5664, time: 0.161, data: 0.007) loss: 0.171 
(epoch: 124, iters: 5744, time: 0.160, data: 0.032) loss: 0.818 
(epoch: 124, iters: 5824, time: 0.160, data: 0.000) loss: 0.759 
(epoch: 124, iters: 5904, time: 0.162, data: 0.000) loss: 0.689 
(epoch: 124, iters: 5984, time: 0.161, data: 0.000) loss: 0.493 
(epoch: 124, iters: 6064, time: 0.159, data: 0.000) loss: 0.355 
(epoch: 124, iters: 6144, time: 0.160, data: 0.011) loss: 0.482 
(epoch: 124, iters: 6224, time: 0.157, data: 0.000) loss: 0.222 
(epoch: 124, iters: 6304, time: 0.160, data: 0.000) loss: 0.328 
(epoch: 124, iters: 6384, time: 0.166, data: 0.000) loss: 0.272 
(epoch: 124, iters: 6464, time: 0.159, data: 0.005) loss: 0.104 
(epoch: 124, iters: 6544, time: 0.159, data: 0.013) loss: 0.158 
(epoch: 124, iters: 6624, time: 0.160, data: 0.000) loss: 0.048 
(epoch: 124, iters: 6704, time: 0.159, data: 0.024) loss: 0.138 
(epoch: 124, iters: 6784, time: 0.158, data: 0.000) loss: 0.488 
(epoch: 124, iters: 6864, time: 0.160, data: 0.011) loss: 0.262 
(epoch: 124, iters: 6944, time: 0.158, data: 0.000) loss: 0.435 
(epoch: 124, iters: 7024, time: 0.159, data: 0.000) loss: 0.444 
(epoch: 124, iters: 7104, time: 0.159, data: 0.008) loss: 0.416 
(epoch: 124, iters: 7184, time: 0.160, data: 0.000) loss: 0.284 
(epoch: 124, iters: 7264, time: 0.158, data: 0.023) loss: 0.785 
(epoch: 124, iters: 7344, time: 0.159, data: 0.025) loss: 0.363 
(epoch: 124, iters: 7424, time: 0.158, data: 0.005) loss: 0.674 
(epoch: 124, iters: 7504, time: 0.157, data: 0.005) loss: 0.528 
(epoch: 124, iters: 7584, time: 0.159, data: 0.008) loss: 0.484 
(epoch: 124, iters: 7664, time: 0.159, data: 0.000) loss: 0.669 
(epoch: 124, iters: 7744, time: 0.158, data: 0.000) loss: 0.216 
(epoch: 124, iters: 7824, time: 0.156, data: 0.015) loss: 0.625 
(epoch: 124, iters: 7904, time: 0.157, data: 0.000) loss: 0.334 
(epoch: 124, iters: 7984, time: 0.157, data: 0.023) loss: 0.568 
saving the latest model (epoch 124, total_steps 1261632)
(epoch: 124, iters: 8064, time: 0.158, data: 0.000) loss: 0.379 
(epoch: 124, iters: 8144, time: 0.158, data: 0.000) loss: 0.231 
(epoch: 124, iters: 8224, time: 0.160, data: 0.005) loss: 0.496 
(epoch: 124, iters: 8304, time: 0.158, data: 0.015) loss: 0.305 
(epoch: 124, iters: 8384, time: 0.156, data: 0.008) loss: 0.437 
(epoch: 124, iters: 8464, time: 0.157, data: 0.010) loss: 0.488 
(epoch: 124, iters: 8544, time: 0.159, data: 0.000) loss: 0.175 
(epoch: 124, iters: 8624, time: 0.158, data: 0.000) loss: 0.617 
(epoch: 124, iters: 8704, time: 0.158, data: 0.000) loss: 0.182 
(epoch: 124, iters: 8784, time: 0.158, data: 0.000) loss: 0.167 
(epoch: 124, iters: 8864, time: 0.160, data: 0.006) loss: 0.488 
(epoch: 124, iters: 8944, time: 0.158, data: 0.024) loss: 0.184 
(epoch: 124, iters: 9024, time: 0.158, data: 0.000) loss: 0.328 
(epoch: 124, iters: 9104, time: 0.165, data: 0.014) loss: 0.890 
(epoch: 124, iters: 9184, time: 0.159, data: 0.000) loss: 0.268 
(epoch: 124, iters: 9264, time: 0.158, data: 0.027) loss: 0.572 
(epoch: 124, iters: 9344, time: 0.158, data: 0.021) loss: 0.439 
(epoch: 124, iters: 9424, time: 0.162, data: 0.000) loss: 0.691 
(epoch: 124, iters: 9504, time: 0.165, data: 0.000) loss: 0.199 
(epoch: 124, iters: 9584, time: 0.162, data: 0.032) loss: 0.334 
(epoch: 124, iters: 9664, time: 0.158, data: 0.000) loss: 0.685 
(epoch: 124, iters: 9744, time: 0.159, data: 0.000) loss: 0.592 
(epoch: 124, iters: 9824, time: 0.160, data: 0.000) loss: 0.722 
(epoch: 124, iters: 9904, time: 0.157, data: 0.006) loss: 0.685 
(epoch: 124, iters: 9984, time: 0.160, data: 0.014) loss: 0.225 
(epoch: 124, iters: 10064, time: 0.161, data: 0.000) loss: 0.571 
(epoch: 124, iters: 10144, time: 0.160, data: 0.000) loss: 0.181 
saving the model at the end of epoch 124, iters 1263808
End of epoch 124 / 200 	 Time Taken: 1629 sec
learning rate = 0.0001485
saving the latest model (epoch 125, total_steps 1263824)
(epoch: 125, iters: 32, time: 0.167, data: 0.000) loss: 0.434 
(epoch: 125, iters: 112, time: 0.161, data: 0.019) loss: 0.235 
(epoch: 125, iters: 192, time: 0.160, data: 0.009) loss: 0.937 
(epoch: 125, iters: 272, time: 0.158, data: 0.000) loss: 0.277 
(epoch: 125, iters: 352, time: 0.161, data: 0.000) loss: 0.487 
(epoch: 125, iters: 432, time: 0.160, data: 0.009) loss: 0.909 
(epoch: 125, iters: 512, time: 0.160, data: 0.005) loss: 0.532 
(epoch: 125, iters: 592, time: 0.158, data: 0.015) loss: 0.390 
(epoch: 125, iters: 672, time: 0.158, data: 0.000) loss: 0.236 
(epoch: 125, iters: 752, time: 0.157, data: 0.008) loss: 0.259 
(epoch: 125, iters: 832, time: 0.158, data: 0.005) loss: 0.312 
(epoch: 125, iters: 912, time: 0.156, data: 0.000) loss: 0.961 
(epoch: 125, iters: 992, time: 0.159, data: 0.017) loss: 0.369 
(epoch: 125, iters: 1072, time: 0.158, data: 0.000) loss: 0.140 
(epoch: 125, iters: 1152, time: 0.157, data: 0.000) loss: 0.194 
(epoch: 125, iters: 1232, time: 0.158, data: 0.005) loss: 0.124 
(epoch: 125, iters: 1312, time: 0.157, data: 0.000) loss: 0.754 
(epoch: 125, iters: 1392, time: 0.159, data: 0.000) loss: 0.545 
(epoch: 125, iters: 1472, time: 0.158, data: 0.006) loss: 0.082 
(epoch: 125, iters: 1552, time: 0.154, data: 0.000) loss: 0.369 
(epoch: 125, iters: 1632, time: 0.158, data: 0.000) loss: 0.503 
(epoch: 125, iters: 1712, time: 0.162, data: 0.008) loss: 0.165 
(epoch: 125, iters: 1792, time: 0.158, data: 0.014) loss: 0.791 
(epoch: 125, iters: 1872, time: 0.158, data: 0.000) loss: 0.448 
(epoch: 125, iters: 1952, time: 0.157, data: 0.031) loss: 0.437 
(epoch: 125, iters: 2032, time: 0.160, data: 0.000) loss: 0.753 
(epoch: 125, iters: 2112, time: 0.157, data: 0.000) loss: 0.806 
(epoch: 125, iters: 2192, time: 0.159, data: 0.000) loss: 0.281 
(epoch: 125, iters: 2272, time: 0.157, data: 0.009) loss: 0.416 
(epoch: 125, iters: 2352, time: 0.158, data: 0.000) loss: 0.480 
(epoch: 125, iters: 2432, time: 0.159, data: 0.013) loss: 0.546 
(epoch: 125, iters: 2512, time: 0.158, data: 0.000) loss: 0.362 
(epoch: 125, iters: 2592, time: 0.160, data: 0.011) loss: 0.113 
(epoch: 125, iters: 2672, time: 0.159, data: 0.000) loss: 0.321 
(epoch: 125, iters: 2752, time: 0.158, data: 0.009) loss: 0.310 
(epoch: 125, iters: 2832, time: 0.156, data: 0.000) loss: 0.131 
(epoch: 125, iters: 2912, time: 0.157, data: 0.026) loss: 0.309 
(epoch: 125, iters: 2992, time: 0.160, data: 0.000) loss: 0.141 
(epoch: 125, iters: 3072, time: 0.158, data: 0.023) loss: 0.671 
(epoch: 125, iters: 3152, time: 0.160, data: 0.000) loss: 0.210 
(epoch: 125, iters: 3232, time: 0.159, data: 0.000) loss: 0.452 
(epoch: 125, iters: 3312, time: 0.159, data: 0.000) loss: 0.292 
(epoch: 125, iters: 3392, time: 0.161, data: 0.017) loss: 0.471 
(epoch: 125, iters: 3472, time: 0.160, data: 0.006) loss: 0.323 
(epoch: 125, iters: 3552, time: 0.160, data: 0.015) loss: 0.182 
(epoch: 125, iters: 3632, time: 0.160, data: 0.000) loss: 0.365 
(epoch: 125, iters: 3712, time: 0.160, data: 0.000) loss: 0.439 
(epoch: 125, iters: 3792, time: 0.158, data: 0.000) loss: 0.590 
(epoch: 125, iters: 3872, time: 0.160, data: 0.020) loss: 0.239 
(epoch: 125, iters: 3952, time: 0.161, data: 0.000) loss: 0.724 
saving the latest model (epoch 125, total_steps 1267824)
(epoch: 125, iters: 4032, time: 0.162, data: 0.000) loss: 0.696 
(epoch: 125, iters: 4112, time: 0.158, data: 0.000) loss: 0.100 
(epoch: 125, iters: 4192, time: 0.162, data: 0.000) loss: 0.632 
(epoch: 125, iters: 4272, time: 0.161, data: 0.000) loss: 0.262 
(epoch: 125, iters: 4352, time: 0.164, data: 0.000) loss: 0.220 
(epoch: 125, iters: 4432, time: 0.162, data: 0.000) loss: 1.071 
(epoch: 125, iters: 4512, time: 0.157, data: 0.016) loss: 0.337 
(epoch: 125, iters: 4592, time: 0.157, data: 0.008) loss: 0.178 
(epoch: 125, iters: 4672, time: 0.160, data: 0.000) loss: 0.277 
(epoch: 125, iters: 4752, time: 0.166, data: 0.014) loss: 0.416 
(epoch: 125, iters: 4832, time: 0.161, data: 0.029) loss: 0.615 
(epoch: 125, iters: 4912, time: 0.161, data: 0.000) loss: 0.367 
(epoch: 125, iters: 4992, time: 0.158, data: 0.017) loss: 0.290 
(epoch: 125, iters: 5072, time: 0.160, data: 0.018) loss: 0.225 
(epoch: 125, iters: 5152, time: 0.161, data: 0.000) loss: 0.279 
(epoch: 125, iters: 5232, time: 0.162, data: 0.017) loss: 0.776 
(epoch: 125, iters: 5312, time: 0.158, data: 0.006) loss: 0.432 
(epoch: 125, iters: 5392, time: 0.158, data: 0.000) loss: 0.290 
(epoch: 125, iters: 5472, time: 0.157, data: 0.000) loss: 0.181 
(epoch: 125, iters: 5552, time: 0.160, data: 0.011) loss: 0.777 
(epoch: 125, iters: 5632, time: 0.161, data: 0.000) loss: 0.283 
(epoch: 125, iters: 5712, time: 0.157, data: 0.005) loss: 0.553 
(epoch: 125, iters: 5792, time: 0.159, data: 0.013) loss: 0.142 
(epoch: 125, iters: 5872, time: 0.159, data: 0.000) loss: 0.528 
(epoch: 125, iters: 5952, time: 0.159, data: 0.010) loss: 0.569 
(epoch: 125, iters: 6032, time: 0.160, data: 0.000) loss: 0.346 
(epoch: 125, iters: 6112, time: 0.161, data: 0.025) loss: 0.367 
(epoch: 125, iters: 6192, time: 0.158, data: 0.000) loss: 0.237 
(epoch: 125, iters: 6272, time: 0.159, data: 0.006) loss: 0.591 
(epoch: 125, iters: 6352, time: 0.161, data: 0.009) loss: 0.660 
(epoch: 125, iters: 6432, time: 0.159, data: 0.000) loss: 0.923 
(epoch: 125, iters: 6512, time: 0.159, data: 0.000) loss: 0.666 
(epoch: 125, iters: 6592, time: 0.161, data: 0.014) loss: 0.519 
(epoch: 125, iters: 6672, time: 0.167, data: 0.000) loss: 0.798 
(epoch: 125, iters: 6752, time: 0.161, data: 0.000) loss: 0.124 
(epoch: 125, iters: 6832, time: 0.159, data: 0.018) loss: 0.557 
(epoch: 125, iters: 6912, time: 0.158, data: 0.000) loss: 0.412 
(epoch: 125, iters: 6992, time: 0.160, data: 0.005) loss: 0.223 
(epoch: 125, iters: 7072, time: 0.167, data: 0.000) loss: 0.342 
(epoch: 125, iters: 7152, time: 0.162, data: 0.023) loss: 0.389 
(epoch: 125, iters: 7232, time: 0.160, data: 0.000) loss: 1.044 
(epoch: 125, iters: 7312, time: 0.160, data: 0.000) loss: 0.270 
(epoch: 125, iters: 7392, time: 0.162, data: 0.000) loss: 0.631 
(epoch: 125, iters: 7472, time: 0.161, data: 0.000) loss: 0.344 
(epoch: 125, iters: 7552, time: 0.162, data: 0.000) loss: 0.425 
(epoch: 125, iters: 7632, time: 0.160, data: 0.000) loss: 0.223 
(epoch: 125, iters: 7712, time: 0.161, data: 0.011) loss: 0.429 
(epoch: 125, iters: 7792, time: 0.158, data: 0.000) loss: 0.400 
(epoch: 125, iters: 7872, time: 0.160, data: 0.000) loss: 0.093 
(epoch: 125, iters: 7952, time: 0.160, data: 0.000) loss: 0.195 
saving the latest model (epoch 125, total_steps 1271824)
(epoch: 125, iters: 8032, time: 0.159, data: 0.017) loss: 0.660 
(epoch: 125, iters: 8112, time: 0.158, data: 0.000) loss: 0.240 
(epoch: 125, iters: 8192, time: 0.158, data: 0.034) loss: 0.141 
(epoch: 125, iters: 8272, time: 0.160, data: 0.000) loss: 0.496 
(epoch: 125, iters: 8352, time: 0.158, data: 0.000) loss: 0.235 
(epoch: 125, iters: 8432, time: 0.159, data: 0.000) loss: 0.508 
(epoch: 125, iters: 8512, time: 0.158, data: 0.022) loss: 0.600 
(epoch: 125, iters: 8592, time: 0.158, data: 0.000) loss: 0.150 
(epoch: 125, iters: 8672, time: 0.159, data: 0.011) loss: 0.786 
(epoch: 125, iters: 8752, time: 0.161, data: 0.000) loss: 0.181 
(epoch: 125, iters: 8832, time: 0.159, data: 0.005) loss: 0.932 
(epoch: 125, iters: 8912, time: 0.161, data: 0.000) loss: 0.149 
(epoch: 125, iters: 8992, time: 0.162, data: 0.028) loss: 0.584 
(epoch: 125, iters: 9072, time: 0.158, data: 0.000) loss: 0.291 
(epoch: 125, iters: 9152, time: 0.160, data: 0.010) loss: 0.599 
(epoch: 125, iters: 9232, time: 0.161, data: 0.008) loss: 0.711 
(epoch: 125, iters: 9312, time: 0.161, data: 0.000) loss: 0.564 
(epoch: 125, iters: 9392, time: 0.165, data: 0.010) loss: 0.749 
(epoch: 125, iters: 9472, time: 0.161, data: 0.000) loss: 0.282 
(epoch: 125, iters: 9552, time: 0.161, data: 0.009) loss: 0.347 
(epoch: 125, iters: 9632, time: 0.161, data: 0.005) loss: 0.514 
(epoch: 125, iters: 9712, time: 0.160, data: 0.006) loss: 0.240 
(epoch: 125, iters: 9792, time: 0.160, data: 0.023) loss: 0.405 
(epoch: 125, iters: 9872, time: 0.160, data: 0.000) loss: 0.559 
(epoch: 125, iters: 9952, time: 0.161, data: 0.010) loss: 0.665 
(epoch: 125, iters: 10032, time: 0.159, data: 0.000) loss: 0.178 
(epoch: 125, iters: 10112, time: 0.158, data: 0.014) loss: 0.728 
(epoch: 125, iters: 10192, time: 0.094, data: 0.000) loss: 0.415 
saving the model at the end of epoch 125, iters 1274000
End of epoch 125 / 200 	 Time Taken: 1633 sec
learning rate = 0.0001465
saving the latest model (epoch 126, total_steps 1274016)
(epoch: 126, iters: 80, time: 0.158, data: 0.174) loss: 1.117 
(epoch: 126, iters: 160, time: 0.160, data: 0.000) loss: 0.465 
(epoch: 126, iters: 240, time: 0.157, data: 0.008) loss: 0.821 
(epoch: 126, iters: 320, time: 0.156, data: 0.000) loss: 0.235 
(epoch: 126, iters: 400, time: 0.158, data: 0.000) loss: 0.484 
(epoch: 126, iters: 480, time: 0.156, data: 0.005) loss: 0.308 
(epoch: 126, iters: 560, time: 0.157, data: 0.005) loss: 0.388 
(epoch: 126, iters: 640, time: 0.157, data: 0.000) loss: 0.125 
(epoch: 126, iters: 720, time: 0.157, data: 0.000) loss: 0.582 
(epoch: 126, iters: 800, time: 0.158, data: 0.000) loss: 0.154 
(epoch: 126, iters: 880, time: 0.156, data: 0.000) loss: 0.551 
(epoch: 126, iters: 960, time: 0.158, data: 0.008) loss: 0.285 
(epoch: 126, iters: 1040, time: 0.158, data: 0.028) loss: 0.521 
(epoch: 126, iters: 1120, time: 0.157, data: 0.000) loss: 0.635 
(epoch: 126, iters: 1200, time: 0.158, data: 0.005) loss: 0.408 
(epoch: 126, iters: 1280, time: 0.159, data: 0.000) loss: 0.437 
(epoch: 126, iters: 1360, time: 0.157, data: 0.000) loss: 0.191 
(epoch: 126, iters: 1440, time: 0.158, data: 0.005) loss: 0.199 
(epoch: 126, iters: 1520, time: 0.162, data: 0.000) loss: 0.936 
(epoch: 126, iters: 1600, time: 0.204, data: 0.023) loss: 0.788 
(epoch: 126, iters: 1680, time: 0.151, data: 0.000) loss: 0.831 
(epoch: 126, iters: 1760, time: 0.160, data: 0.000) loss: 0.692 
(epoch: 126, iters: 1840, time: 0.158, data: 0.005) loss: 0.409 
(epoch: 126, iters: 1920, time: 0.158, data: 0.000) loss: 0.292 
(epoch: 126, iters: 2000, time: 0.158, data: 0.000) loss: 0.399 
(epoch: 126, iters: 2080, time: 0.157, data: 0.008) loss: 0.395 
(epoch: 126, iters: 2160, time: 0.156, data: 0.000) loss: 0.225 
(epoch: 126, iters: 2240, time: 0.160, data: 0.024) loss: 0.177 
(epoch: 126, iters: 2320, time: 0.160, data: 0.000) loss: 0.297 
(epoch: 126, iters: 2400, time: 0.165, data: 0.011) loss: 0.718 
(epoch: 126, iters: 2480, time: 0.163, data: 0.015) loss: 0.273 
(epoch: 126, iters: 2560, time: 0.157, data: 0.005) loss: 0.432 
(epoch: 126, iters: 2640, time: 0.164, data: 0.000) loss: 0.242 
(epoch: 126, iters: 2720, time: 0.152, data: 0.043) loss: 0.602 
(epoch: 126, iters: 2800, time: 0.152, data: 0.000) loss: 0.763 
(epoch: 126, iters: 2880, time: 0.152, data: 0.032) loss: 0.166 
(epoch: 126, iters: 2960, time: 0.152, data: 0.000) loss: 0.551 
(epoch: 126, iters: 3040, time: 0.153, data: 0.024) loss: 0.236 
(epoch: 126, iters: 3120, time: 0.152, data: 0.005) loss: 0.397 
(epoch: 126, iters: 3200, time: 0.153, data: 0.005) loss: 0.569 
(epoch: 126, iters: 3280, time: 0.151, data: 0.019) loss: 0.254 
(epoch: 126, iters: 3360, time: 0.155, data: 0.000) loss: 0.464 
(epoch: 126, iters: 3440, time: 0.153, data: 0.000) loss: 0.106 
(epoch: 126, iters: 3520, time: 0.154, data: 0.000) loss: 0.277 
(epoch: 126, iters: 3600, time: 0.151, data: 0.000) loss: 0.634 
(epoch: 126, iters: 3680, time: 0.150, data: 0.015) loss: 0.282 
(epoch: 126, iters: 3760, time: 0.152, data: 0.000) loss: 0.338 
(epoch: 126, iters: 3840, time: 0.153, data: 0.000) loss: 0.327 
(epoch: 126, iters: 3920, time: 0.154, data: 0.011) loss: 0.373 
(epoch: 126, iters: 4000, time: 0.153, data: 0.000) loss: 0.405 
saving the latest model (epoch 126, total_steps 1278016)
(epoch: 126, iters: 4080, time: 0.155, data: 0.000) loss: 0.412 
(epoch: 126, iters: 4160, time: 0.155, data: 0.021) loss: 0.609 
(epoch: 126, iters: 4240, time: 0.154, data: 0.000) loss: 0.139 
(epoch: 126, iters: 4320, time: 0.175, data: 0.000) loss: 0.446 
(epoch: 126, iters: 4400, time: 0.148, data: 0.000) loss: 0.183 
(epoch: 126, iters: 4480, time: 0.159, data: 0.005) loss: 0.708 
(epoch: 126, iters: 4560, time: 0.195, data: 0.006) loss: 0.165 
(epoch: 126, iters: 4640, time: 0.164, data: 0.000) loss: 0.798 
(epoch: 126, iters: 4720, time: 0.164, data: 0.006) loss: 0.231 
(epoch: 126, iters: 4800, time: 0.165, data: 0.027) loss: 0.435 
(epoch: 126, iters: 4880, time: 0.177, data: 0.005) loss: 0.480 
(epoch: 126, iters: 4960, time: 0.166, data: 0.039) loss: 0.323 
(epoch: 126, iters: 5040, time: 0.168, data: 0.000) loss: 0.269 
(epoch: 126, iters: 5120, time: 0.169, data: 0.000) loss: 0.733 
(epoch: 126, iters: 5200, time: 0.205, data: 0.013) loss: 0.299 
(epoch: 126, iters: 5280, time: 0.256, data: 0.000) loss: 0.070 
(epoch: 126, iters: 5360, time: 0.167, data: 0.000) loss: 0.371 
(epoch: 126, iters: 5440, time: 0.165, data: 0.011) loss: 0.586 
(epoch: 126, iters: 5520, time: 0.182, data: 0.023) loss: 0.197 
(epoch: 126, iters: 5600, time: 0.205, data: 0.000) loss: 0.580 
(epoch: 126, iters: 5680, time: 0.208, data: 0.008) loss: 0.260 
(epoch: 126, iters: 5760, time: 0.210, data: 0.009) loss: 0.472 
(epoch: 126, iters: 5840, time: 0.166, data: 0.000) loss: 0.506 
(epoch: 126, iters: 5920, time: 0.166, data: 0.005) loss: 0.098 
(epoch: 126, iters: 6000, time: 0.225, data: 0.005) loss: 0.188 
(epoch: 126, iters: 6080, time: 0.247, data: 0.000) loss: 0.232 
(epoch: 126, iters: 6160, time: 0.242, data: 0.038) loss: 0.569 
(epoch: 126, iters: 6240, time: 0.234, data: 0.000) loss: 0.281 
(epoch: 126, iters: 6320, time: 0.170, data: 0.000) loss: 0.515 
(epoch: 126, iters: 6400, time: 0.188, data: 0.006) loss: 0.505 
(epoch: 126, iters: 6480, time: 0.218, data: 0.028) loss: 0.615 
(epoch: 126, iters: 6560, time: 0.227, data: 0.000) loss: 0.732 
(epoch: 126, iters: 6640, time: 0.212, data: 0.000) loss: 0.638 
(epoch: 126, iters: 6720, time: 0.223, data: 0.047) loss: 0.483 
(epoch: 126, iters: 6800, time: 0.360, data: 0.000) loss: 0.660 
(epoch: 126, iters: 6880, time: 0.184, data: 0.028) loss: 0.811 
(epoch: 126, iters: 6960, time: 0.214, data: 0.000) loss: 0.118 
(epoch: 126, iters: 7040, time: 0.461, data: 0.016) loss: 0.243 
(epoch: 126, iters: 7120, time: 0.271, data: 0.031) loss: 0.232 
(epoch: 126, iters: 7200, time: 0.187, data: 0.011) loss: 0.452 
(epoch: 126, iters: 7280, time: 0.244, data: 0.000) loss: 0.258 
(epoch: 126, iters: 7360, time: 0.289, data: 0.009) loss: 0.163 
(epoch: 126, iters: 7440, time: 0.509, data: 0.000) loss: 0.522 
(epoch: 126, iters: 7520, time: 0.268, data: 0.020) loss: 0.365 
(epoch: 126, iters: 7600, time: 0.241, data: 0.000) loss: 0.487 
(epoch: 126, iters: 7680, time: 0.174, data: 0.010) loss: 0.604 
(epoch: 126, iters: 7760, time: 0.183, data: 0.000) loss: 0.338 
(epoch: 126, iters: 7840, time: 0.252, data: 0.000) loss: 0.611 
(epoch: 126, iters: 7920, time: 0.268, data: 0.000) loss: 0.706 
(epoch: 126, iters: 8000, time: 0.194, data: 0.010) loss: 0.202 
saving the latest model (epoch 126, total_steps 1282016)
(epoch: 126, iters: 8080, time: 0.279, data: 0.000) loss: 0.567 
(epoch: 126, iters: 8160, time: 0.218, data: 0.034) loss: 0.488 
(epoch: 126, iters: 8240, time: 0.237, data: 0.000) loss: 0.627 
(epoch: 126, iters: 8320, time: 0.251, data: 0.009) loss: 0.377 
(epoch: 126, iters: 8400, time: 0.222, data: 0.000) loss: 0.262 
(epoch: 126, iters: 8480, time: 0.264, data: 0.067) loss: 0.765 
(epoch: 126, iters: 8560, time: 0.489, data: 0.000) loss: 0.427 
(epoch: 126, iters: 8640, time: 0.519, data: 0.000) loss: 0.466 
(epoch: 126, iters: 8720, time: 0.391, data: 0.000) loss: 0.431 
(epoch: 126, iters: 8800, time: 0.452, data: 0.000) loss: 0.634 
(epoch: 126, iters: 8880, time: 0.266, data: 0.025) loss: 0.181 
(epoch: 126, iters: 8960, time: 0.458, data: 0.007) loss: 0.600 
(epoch: 126, iters: 9040, time: 0.599, data: 0.000) loss: 0.077 
(epoch: 126, iters: 9120, time: 0.371, data: 0.000) loss: 0.220 
(epoch: 126, iters: 9200, time: 0.292, data: 0.000) loss: 0.359 
(epoch: 126, iters: 9280, time: 0.281, data: 0.000) loss: 0.598 
(epoch: 126, iters: 9360, time: 0.699, data: 0.000) loss: 0.241 
(epoch: 126, iters: 9440, time: 0.589, data: 0.005) loss: 0.340 
(epoch: 126, iters: 9520, time: 0.548, data: 0.000) loss: 0.565 
(epoch: 126, iters: 9600, time: 0.308, data: 0.000) loss: 0.304 
(epoch: 126, iters: 9680, time: 0.330, data: 0.000) loss: 0.627 
(epoch: 126, iters: 9760, time: 0.889, data: 0.000) loss: 0.808 
(epoch: 126, iters: 9840, time: 0.276, data: 0.062) loss: 0.262 
(epoch: 126, iters: 9920, time: 0.396, data: 0.000) loss: 0.569 
(epoch: 126, iters: 10000, time: 0.673, data: 0.022) loss: 0.744 
(epoch: 126, iters: 10080, time: 0.220, data: 0.076) loss: 0.488 
(epoch: 126, iters: 10160, time: 0.165, data: 0.000) loss: 0.518 
saving the model at the end of epoch 126, iters 1284192
End of epoch 126 / 200 	 Time Taken: 2388 sec
learning rate = 0.0001446
saving the latest model (epoch 127, total_steps 1284208)
(epoch: 127, iters: 48, time: 0.171, data: 0.008) loss: 0.331 
(epoch: 127, iters: 128, time: 0.267, data: 0.016) loss: 0.336 
(epoch: 127, iters: 208, time: 0.712, data: 0.000) loss: 0.291 
(epoch: 127, iters: 288, time: 0.235, data: 0.011) loss: 0.647 
(epoch: 127, iters: 368, time: 0.469, data: 0.018) loss: 0.121 
(epoch: 127, iters: 448, time: 0.411, data: 0.000) loss: 0.593 
(epoch: 127, iters: 528, time: 0.281, data: 0.000) loss: 0.593 
(epoch: 127, iters: 608, time: 0.642, data: 0.000) loss: 0.667 
(epoch: 127, iters: 688, time: 0.342, data: 0.000) loss: 0.601 
(epoch: 127, iters: 768, time: 0.423, data: 0.009) loss: 0.267 
(epoch: 127, iters: 848, time: 0.438, data: 0.000) loss: 0.441 
(epoch: 127, iters: 928, time: 0.169, data: 0.000) loss: 0.411 
(epoch: 127, iters: 1008, time: 0.230, data: 0.000) loss: 0.987 
(epoch: 127, iters: 1088, time: 0.445, data: 0.009) loss: 0.945 
(epoch: 127, iters: 1168, time: 0.287, data: 0.000) loss: 0.304 
(epoch: 127, iters: 1248, time: 0.266, data: 0.010) loss: 0.564 
(epoch: 127, iters: 1328, time: 0.307, data: 0.021) loss: 0.317 
(epoch: 127, iters: 1408, time: 0.335, data: 0.000) loss: 0.265 
(epoch: 127, iters: 1488, time: 0.179, data: 0.018) loss: 0.270 
(epoch: 127, iters: 1568, time: 0.250, data: 0.000) loss: 0.692 
(epoch: 127, iters: 1648, time: 0.258, data: 0.000) loss: 0.289 
(epoch: 127, iters: 1728, time: 0.255, data: 0.000) loss: 0.319 
(epoch: 127, iters: 1808, time: 0.185, data: 0.007) loss: 0.422 
(epoch: 127, iters: 1888, time: 0.167, data: 0.000) loss: 0.388 
(epoch: 127, iters: 1968, time: 0.165, data: 0.009) loss: 0.896 
(epoch: 127, iters: 2048, time: 0.166, data: 0.000) loss: 0.884 
(epoch: 127, iters: 2128, time: 0.167, data: 0.009) loss: 0.329 
(epoch: 127, iters: 2208, time: 0.166, data: 0.000) loss: 0.256 
(epoch: 127, iters: 2288, time: 0.167, data: 0.005) loss: 0.388 
(epoch: 127, iters: 2368, time: 0.169, data: 0.000) loss: 0.159 
(epoch: 127, iters: 2448, time: 0.166, data: 0.000) loss: 0.370 
(epoch: 127, iters: 2528, time: 0.166, data: 0.000) loss: 0.085 
(epoch: 127, iters: 2608, time: 0.166, data: 0.009) loss: 0.229 
(epoch: 127, iters: 2688, time: 0.171, data: 0.014) loss: 0.297 
(epoch: 127, iters: 2768, time: 0.167, data: 0.008) loss: 0.421 
(epoch: 127, iters: 2848, time: 0.167, data: 0.000) loss: 0.066 
(epoch: 127, iters: 2928, time: 0.167, data: 0.000) loss: 0.479 
(epoch: 127, iters: 3008, time: 0.167, data: 0.000) loss: 0.398 
(epoch: 127, iters: 3088, time: 0.166, data: 0.005) loss: 0.084 
(epoch: 127, iters: 3168, time: 0.167, data: 0.006) loss: 0.306 
(epoch: 127, iters: 3248, time: 0.166, data: 0.000) loss: 0.358 
(epoch: 127, iters: 3328, time: 0.167, data: 0.006) loss: 0.082 
(epoch: 127, iters: 3408, time: 0.164, data: 0.016) loss: 0.430 
(epoch: 127, iters: 3488, time: 0.167, data: 0.000) loss: 0.192 
(epoch: 127, iters: 3568, time: 0.168, data: 0.015) loss: 0.097 
(epoch: 127, iters: 3648, time: 0.167, data: 0.028) loss: 0.113 
(epoch: 127, iters: 3728, time: 0.165, data: 0.009) loss: 0.199 
(epoch: 127, iters: 3808, time: 0.172, data: 0.000) loss: 0.274 
(epoch: 127, iters: 3888, time: 0.167, data: 0.033) loss: 0.216 
(epoch: 127, iters: 3968, time: 0.166, data: 0.000) loss: 0.552 
saving the latest model (epoch 127, total_steps 1288208)
(epoch: 127, iters: 4048, time: 0.164, data: 0.000) loss: 0.163 
(epoch: 127, iters: 4128, time: 0.167, data: 0.032) loss: 0.371 
(epoch: 127, iters: 4208, time: 0.167, data: 0.000) loss: 0.242 
(epoch: 127, iters: 4288, time: 0.166, data: 0.000) loss: 0.598 
(epoch: 127, iters: 4368, time: 0.164, data: 0.000) loss: 0.563 
(epoch: 127, iters: 4448, time: 0.166, data: 0.000) loss: 0.173 
(epoch: 127, iters: 4528, time: 0.165, data: 0.000) loss: 0.670 
(epoch: 127, iters: 4608, time: 0.167, data: 0.005) loss: 0.268 
(epoch: 127, iters: 4688, time: 0.166, data: 0.007) loss: 0.392 
(epoch: 127, iters: 4768, time: 0.166, data: 0.006) loss: 0.251 
(epoch: 127, iters: 4848, time: 0.166, data: 0.000) loss: 0.537 
(epoch: 127, iters: 4928, time: 0.172, data: 0.000) loss: 0.444 
(epoch: 127, iters: 5008, time: 0.167, data: 0.000) loss: 0.495 
(epoch: 127, iters: 5088, time: 0.165, data: 0.016) loss: 0.423 
(epoch: 127, iters: 5168, time: 0.166, data: 0.000) loss: 0.927 
(epoch: 127, iters: 5248, time: 0.165, data: 0.000) loss: 0.230 
(epoch: 127, iters: 5328, time: 0.166, data: 0.000) loss: 0.151 
(epoch: 127, iters: 5408, time: 0.166, data: 0.000) loss: 0.354 
(epoch: 127, iters: 5488, time: 0.166, data: 0.000) loss: 0.366 
(epoch: 127, iters: 5568, time: 0.166, data: 0.008) loss: 1.024 
(epoch: 127, iters: 5648, time: 0.165, data: 0.000) loss: 0.637 
(epoch: 127, iters: 5728, time: 0.163, data: 0.000) loss: 0.103 
(epoch: 127, iters: 5808, time: 0.166, data: 0.000) loss: 0.305 
(epoch: 127, iters: 5888, time: 0.165, data: 0.008) loss: 0.197 
(epoch: 127, iters: 5968, time: 0.165, data: 0.020) loss: 0.305 
(epoch: 127, iters: 6048, time: 0.170, data: 0.005) loss: 0.317 
(epoch: 127, iters: 6128, time: 0.165, data: 0.000) loss: 0.372 
(epoch: 127, iters: 6208, time: 0.231, data: 0.006) loss: 0.398 
(epoch: 127, iters: 6288, time: 0.180, data: 0.000) loss: 0.345 
(epoch: 127, iters: 6368, time: 0.175, data: 0.016) loss: 0.301 
(epoch: 127, iters: 6448, time: 0.165, data: 0.000) loss: 0.443 
(epoch: 127, iters: 6528, time: 0.170, data: 0.000) loss: 0.227 
(epoch: 127, iters: 6608, time: 0.178, data: 0.022) loss: 0.466 
(epoch: 127, iters: 6688, time: 0.179, data: 0.000) loss: 0.386 
(epoch: 127, iters: 6768, time: 0.189, data: 0.000) loss: 0.531 
(epoch: 127, iters: 6848, time: 0.229, data: 0.023) loss: 0.627 
(epoch: 127, iters: 6928, time: 0.168, data: 0.000) loss: 0.640 
(epoch: 127, iters: 7008, time: 0.172, data: 0.010) loss: 0.237 
(epoch: 127, iters: 7088, time: 0.194, data: 0.000) loss: 0.173 
(epoch: 127, iters: 7168, time: 0.166, data: 0.006) loss: 0.306 
(epoch: 127, iters: 7248, time: 0.167, data: 0.006) loss: 0.226 
(epoch: 127, iters: 7328, time: 0.182, data: 0.000) loss: 0.311 
(epoch: 127, iters: 7408, time: 0.167, data: 0.000) loss: 0.230 
(epoch: 127, iters: 7488, time: 0.162, data: 0.015) loss: 0.163 
(epoch: 127, iters: 7568, time: 0.170, data: 0.000) loss: 0.144 
(epoch: 127, iters: 7648, time: 0.162, data: 0.010) loss: 0.288 
(epoch: 127, iters: 7728, time: 0.165, data: 0.022) loss: 0.225 
(epoch: 127, iters: 7808, time: 0.207, data: 0.000) loss: 0.238 
(epoch: 127, iters: 7888, time: 0.201, data: 0.018) loss: 0.783 
(epoch: 127, iters: 7968, time: 0.204, data: 0.000) loss: 0.081 
saving the latest model (epoch 127, total_steps 1292208)
(epoch: 127, iters: 8048, time: 0.202, data: 0.012) loss: 0.178 
(epoch: 127, iters: 8128, time: 0.170, data: 0.000) loss: 0.344 
(epoch: 127, iters: 8208, time: 0.190, data: 0.000) loss: 0.575 
(epoch: 127, iters: 8288, time: 0.242, data: 0.030) loss: 0.223 
(epoch: 127, iters: 8368, time: 0.216, data: 0.000) loss: 0.166 
(epoch: 127, iters: 8448, time: 0.283, data: 0.000) loss: 0.487 
(epoch: 127, iters: 8528, time: 0.190, data: 0.012) loss: 0.443 
(epoch: 127, iters: 8608, time: 0.182, data: 0.023) loss: 0.097 
(epoch: 127, iters: 8688, time: 0.169, data: 0.008) loss: 0.345 
(epoch: 127, iters: 8768, time: 0.167, data: 0.000) loss: 0.250 
(epoch: 127, iters: 8848, time: 0.173, data: 0.000) loss: 0.639 
(epoch: 127, iters: 8928, time: 0.168, data: 0.000) loss: 0.219 
(epoch: 127, iters: 9008, time: 0.170, data: 0.000) loss: 0.143 
(epoch: 127, iters: 9088, time: 0.171, data: 0.000) loss: 0.415 
(epoch: 127, iters: 9168, time: 0.172, data: 0.010) loss: 0.736 
(epoch: 127, iters: 9248, time: 0.166, data: 0.000) loss: 0.731 
(epoch: 127, iters: 9328, time: 0.176, data: 0.021) loss: 0.534 
(epoch: 127, iters: 9408, time: 0.203, data: 0.000) loss: 0.518 
(epoch: 127, iters: 9488, time: 0.167, data: 0.009) loss: 0.561 
(epoch: 127, iters: 9568, time: 0.184, data: 0.000) loss: 0.250 
(epoch: 127, iters: 9648, time: 0.167, data: 0.000) loss: 0.326 
(epoch: 127, iters: 9728, time: 0.165, data: 0.011) loss: 0.879 
(epoch: 127, iters: 9808, time: 0.195, data: 0.008) loss: 0.142 
(epoch: 127, iters: 9888, time: 0.264, data: 0.000) loss: 0.539 
(epoch: 127, iters: 9968, time: 0.253, data: 0.028) loss: 0.889 
(epoch: 127, iters: 10048, time: 0.264, data: 0.000) loss: 0.515 
(epoch: 127, iters: 10128, time: 0.172, data: 0.000) loss: 0.274 
saving the model at the end of epoch 127, iters 1294384
End of epoch 127 / 200 	 Time Taken: 2125 sec
learning rate = 0.0001426
(epoch: 128, iters: 16, time: 0.191, data: 0.016) loss: 0.446 
saving the latest model (epoch 128, total_steps 1294400)
(epoch: 128, iters: 96, time: 0.208, data: 0.000) loss: 0.470 
(epoch: 128, iters: 176, time: 0.259, data: 0.010) loss: 0.325 
(epoch: 128, iters: 256, time: 0.283, data: 0.015) loss: 0.230 
(epoch: 128, iters: 336, time: 0.207, data: 0.000) loss: 0.306 
(epoch: 128, iters: 416, time: 0.185, data: 0.009) loss: 0.586 
(epoch: 128, iters: 496, time: 0.307, data: 0.000) loss: 0.289 
(epoch: 128, iters: 576, time: 0.250, data: 0.041) loss: 0.232 
(epoch: 128, iters: 656, time: 0.262, data: 0.000) loss: 0.238 
(epoch: 128, iters: 736, time: 0.204, data: 0.000) loss: 0.137 
(epoch: 128, iters: 816, time: 0.363, data: 0.000) loss: 0.355 
(epoch: 128, iters: 896, time: 0.374, data: 0.000) loss: 0.186 
(epoch: 128, iters: 976, time: 0.233, data: 0.000) loss: 0.378 
(epoch: 128, iters: 1056, time: 0.202, data: 0.033) loss: 0.273 
(epoch: 128, iters: 1136, time: 0.313, data: 0.000) loss: 0.291 
(epoch: 128, iters: 1216, time: 0.284, data: 0.009) loss: 0.408 
(epoch: 128, iters: 1296, time: 0.252, data: 0.000) loss: 0.306 
(epoch: 128, iters: 1376, time: 0.178, data: 0.032) loss: 0.557 
(epoch: 128, iters: 1456, time: 0.177, data: 0.000) loss: 0.101 
(epoch: 128, iters: 1536, time: 0.252, data: 0.000) loss: 0.620 
(epoch: 128, iters: 1616, time: 0.247, data: 0.000) loss: 0.595 
(epoch: 128, iters: 1696, time: 0.256, data: 0.022) loss: 0.378 
(epoch: 128, iters: 1776, time: 0.169, data: 0.000) loss: 0.221 
(epoch: 128, iters: 1856, time: 0.176, data: 0.016) loss: 0.209 
(epoch: 128, iters: 1936, time: 0.248, data: 0.025) loss: 0.390 
(epoch: 128, iters: 2016, time: 0.225, data: 0.000) loss: 0.299 
(epoch: 128, iters: 2096, time: 0.262, data: 0.010) loss: 0.498 
(epoch: 128, iters: 2176, time: 0.176, data: 0.026) loss: 0.516 
(epoch: 128, iters: 2256, time: 0.184, data: 0.000) loss: 0.284 
(epoch: 128, iters: 2336, time: 0.263, data: 0.017) loss: 0.280 
(epoch: 128, iters: 2416, time: 0.228, data: 0.026) loss: 0.315 
(epoch: 128, iters: 2496, time: 0.254, data: 0.000) loss: 0.225 
(epoch: 128, iters: 2576, time: 0.172, data: 0.025) loss: 0.214 
(epoch: 128, iters: 2656, time: 0.168, data: 0.017) loss: 0.502 
(epoch: 128, iters: 2736, time: 0.182, data: 0.005) loss: 0.331 
(epoch: 128, iters: 2816, time: 0.168, data: 0.000) loss: 0.164 
(epoch: 128, iters: 2896, time: 0.183, data: 0.000) loss: 0.453 
(epoch: 128, iters: 2976, time: 0.164, data: 0.000) loss: 0.158 
(epoch: 128, iters: 3056, time: 0.165, data: 0.000) loss: 0.779 
(epoch: 128, iters: 3136, time: 0.173, data: 0.000) loss: 0.847 
(epoch: 128, iters: 3216, time: 0.165, data: 0.000) loss: 0.629 
(epoch: 128, iters: 3296, time: 0.163, data: 0.000) loss: 0.196 
(epoch: 128, iters: 3376, time: 0.162, data: 0.009) loss: 0.045 
(epoch: 128, iters: 3456, time: 0.173, data: 0.000) loss: 0.458 
(epoch: 128, iters: 3536, time: 0.176, data: 0.000) loss: 0.500 
(epoch: 128, iters: 3616, time: 0.179, data: 0.000) loss: 0.488 
(epoch: 128, iters: 3696, time: 0.183, data: 0.000) loss: 0.044 
(epoch: 128, iters: 3776, time: 0.175, data: 0.000) loss: 0.452 
(epoch: 128, iters: 3856, time: 0.165, data: 0.009) loss: 0.669 
(epoch: 128, iters: 3936, time: 0.163, data: 0.000) loss: 0.309 
(epoch: 128, iters: 4016, time: 0.167, data: 0.011) loss: 0.681 
saving the latest model (epoch 128, total_steps 1298400)
(epoch: 128, iters: 4096, time: 0.165, data: 0.008) loss: 0.453 
(epoch: 128, iters: 4176, time: 0.170, data: 0.000) loss: 0.286 
(epoch: 128, iters: 4256, time: 0.167, data: 0.008) loss: 0.752 
(epoch: 128, iters: 4336, time: 0.165, data: 0.000) loss: 0.259 
(epoch: 128, iters: 4416, time: 0.214, data: 0.000) loss: 0.206 
(epoch: 128, iters: 4496, time: 0.172, data: 0.000) loss: 0.328 
(epoch: 128, iters: 4576, time: 0.210, data: 0.000) loss: 0.495 
(epoch: 128, iters: 4656, time: 0.210, data: 0.008) loss: 0.718 
(epoch: 128, iters: 4736, time: 0.236, data: 0.000) loss: 0.520 
(epoch: 128, iters: 4816, time: 0.176, data: 0.010) loss: 0.412 
(epoch: 128, iters: 4896, time: 0.181, data: 0.024) loss: 0.664 
(epoch: 128, iters: 4976, time: 0.173, data: 0.000) loss: 0.836 
(epoch: 128, iters: 5056, time: 0.180, data: 0.000) loss: 0.567 
(epoch: 128, iters: 5136, time: 0.167, data: 0.008) loss: 0.078 
(epoch: 128, iters: 5216, time: 0.180, data: 0.000) loss: 0.663 
(epoch: 128, iters: 5296, time: 0.170, data: 0.018) loss: 0.278 
(epoch: 128, iters: 5376, time: 0.178, data: 0.021) loss: 0.142 
(epoch: 128, iters: 5456, time: 0.710, data: 0.000) loss: 0.155 
(epoch: 128, iters: 5536, time: 0.322, data: 0.032) loss: 0.483 
(epoch: 128, iters: 5616, time: 0.249, data: 0.011) loss: 0.261 
(epoch: 128, iters: 5696, time: 0.295, data: 0.020) loss: 0.717 
(epoch: 128, iters: 5776, time: 0.421, data: 0.000) loss: 0.305 
(epoch: 128, iters: 5856, time: 0.231, data: 0.000) loss: 0.521 
(epoch: 128, iters: 5936, time: 0.283, data: 0.021) loss: 0.393 
(epoch: 128, iters: 6016, time: 0.213, data: 0.009) loss: 0.371 
(epoch: 128, iters: 6096, time: 0.651, data: 0.000) loss: 0.134 
(epoch: 128, iters: 6176, time: 0.370, data: 0.000) loss: 0.563 
(epoch: 128, iters: 6256, time: 0.185, data: 0.017) loss: 0.286 
(epoch: 128, iters: 6336, time: 0.252, data: 0.000) loss: 0.420 
(epoch: 128, iters: 6416, time: 0.264, data: 0.006) loss: 0.453 
(epoch: 128, iters: 6496, time: 0.274, data: 0.000) loss: 0.524 
(epoch: 128, iters: 6576, time: 0.170, data: 0.029) loss: 0.342 
(epoch: 128, iters: 6656, time: 0.199, data: 0.033) loss: 0.152 
(epoch: 128, iters: 6736, time: 0.276, data: 0.000) loss: 0.371 
(epoch: 128, iters: 6816, time: 0.219, data: 0.000) loss: 0.612 
(epoch: 128, iters: 6896, time: 0.293, data: 0.022) loss: 0.646 
(epoch: 128, iters: 6976, time: 0.175, data: 0.000) loss: 0.213 
(epoch: 128, iters: 7056, time: 0.167, data: 0.018) loss: 0.324 
(epoch: 128, iters: 7136, time: 0.167, data: 0.013) loss: 0.243 
(epoch: 128, iters: 7216, time: 0.166, data: 0.008) loss: 0.509 
(epoch: 128, iters: 7296, time: 0.169, data: 0.015) loss: 0.235 
(epoch: 128, iters: 7376, time: 0.166, data: 0.000) loss: 0.619 
(epoch: 128, iters: 7456, time: 0.166, data: 0.006) loss: 0.297 
(epoch: 128, iters: 7536, time: 0.166, data: 0.000) loss: 0.268 
(epoch: 128, iters: 7616, time: 0.165, data: 0.000) loss: 0.089 
(epoch: 128, iters: 7696, time: 0.184, data: 0.000) loss: 0.306 
(epoch: 128, iters: 7776, time: 0.165, data: 0.025) loss: 0.256 
(epoch: 128, iters: 7856, time: 0.165, data: 0.000) loss: 0.361 
(epoch: 128, iters: 7936, time: 0.167, data: 0.005) loss: 0.397 
(epoch: 128, iters: 8016, time: 0.174, data: 0.004) loss: 0.214 
saving the latest model (epoch 128, total_steps 1302400)
(epoch: 128, iters: 8096, time: 0.168, data: 0.000) loss: 0.497 
(epoch: 128, iters: 8176, time: 0.166, data: 0.000) loss: 0.632 
(epoch: 128, iters: 8256, time: 0.165, data: 0.006) loss: 0.136 
(epoch: 128, iters: 8336, time: 0.167, data: 0.005) loss: 0.392 
(epoch: 128, iters: 8416, time: 0.169, data: 0.000) loss: 0.097 
(epoch: 128, iters: 8496, time: 0.167, data: 0.000) loss: 0.237 
(epoch: 128, iters: 8576, time: 0.166, data: 0.009) loss: 0.427 
(epoch: 128, iters: 8656, time: 0.165, data: 0.000) loss: 0.280 
(epoch: 128, iters: 8736, time: 0.166, data: 0.000) loss: 0.574 
(epoch: 128, iters: 8816, time: 0.168, data: 0.026) loss: 0.122 
(epoch: 128, iters: 8896, time: 0.167, data: 0.008) loss: 0.363 
(epoch: 128, iters: 8976, time: 0.166, data: 0.000) loss: 0.628 
(epoch: 128, iters: 9056, time: 0.168, data: 0.005) loss: 0.177 
(epoch: 128, iters: 9136, time: 0.171, data: 0.008) loss: 0.123 
(epoch: 128, iters: 9216, time: 0.166, data: 0.000) loss: 0.494 
(epoch: 128, iters: 9296, time: 0.168, data: 0.000) loss: 0.065 
(epoch: 128, iters: 9376, time: 0.167, data: 0.006) loss: 0.427 
(epoch: 128, iters: 9456, time: 0.166, data: 0.008) loss: 0.296 
(epoch: 128, iters: 9536, time: 0.169, data: 0.000) loss: 0.507 
(epoch: 128, iters: 9616, time: 0.167, data: 0.023) loss: 0.615 
(epoch: 128, iters: 9696, time: 0.168, data: 0.000) loss: 0.935 
(epoch: 128, iters: 9776, time: 0.166, data: 0.000) loss: 0.740 
(epoch: 128, iters: 9856, time: 0.166, data: 0.006) loss: 0.048 
(epoch: 128, iters: 9936, time: 0.166, data: 0.000) loss: 0.394 
(epoch: 128, iters: 10016, time: 0.165, data: 0.000) loss: 0.288 
(epoch: 128, iters: 10096, time: 0.166, data: 0.008) loss: 0.301 
(epoch: 128, iters: 10176, time: 0.190, data: 0.000) loss: 0.249 
saving the model at the end of epoch 128, iters 1304576
End of epoch 128 / 200 	 Time Taken: 2135 sec
learning rate = 0.0001406
saving the latest model (epoch 129, total_steps 1304592)
(epoch: 129, iters: 64, time: 0.169, data: 0.003) loss: 0.127 
(epoch: 129, iters: 144, time: 0.166, data: 0.031) loss: 0.156 
(epoch: 129, iters: 224, time: 0.166, data: 0.009) loss: 0.234 
(epoch: 129, iters: 304, time: 0.164, data: 0.000) loss: 0.585 
(epoch: 129, iters: 384, time: 0.170, data: 0.015) loss: 0.324 
(epoch: 129, iters: 464, time: 0.166, data: 0.005) loss: 0.220 
(epoch: 129, iters: 544, time: 0.166, data: 0.000) loss: 0.354 
(epoch: 129, iters: 624, time: 0.168, data: 0.012) loss: 0.422 
(epoch: 129, iters: 704, time: 0.167, data: 0.000) loss: 0.208 
(epoch: 129, iters: 784, time: 0.166, data: 0.005) loss: 0.289 
(epoch: 129, iters: 864, time: 0.167, data: 0.025) loss: 0.265 
(epoch: 129, iters: 944, time: 0.165, data: 0.000) loss: 0.369 
(epoch: 129, iters: 1024, time: 0.166, data: 0.020) loss: 0.427 
(epoch: 129, iters: 1104, time: 0.166, data: 0.000) loss: 0.204 
(epoch: 129, iters: 1184, time: 0.166, data: 0.000) loss: 0.263 
(epoch: 129, iters: 1264, time: 0.169, data: 0.005) loss: 0.144 
(epoch: 129, iters: 1344, time: 0.171, data: 0.000) loss: 0.690 
(epoch: 129, iters: 1424, time: 0.168, data: 0.000) loss: 0.465 
(epoch: 129, iters: 1504, time: 0.165, data: 0.010) loss: 0.508 
(epoch: 129, iters: 1584, time: 0.169, data: 0.000) loss: 0.488 
(epoch: 129, iters: 1664, time: 0.166, data: 0.000) loss: 0.051 
(epoch: 129, iters: 1744, time: 0.164, data: 0.005) loss: 0.768 
(epoch: 129, iters: 1824, time: 0.167, data: 0.000) loss: 0.264 
(epoch: 129, iters: 1904, time: 0.170, data: 0.009) loss: 0.215 
(epoch: 129, iters: 1984, time: 0.167, data: 0.000) loss: 0.271 
(epoch: 129, iters: 2064, time: 0.174, data: 0.005) loss: 0.537 
(epoch: 129, iters: 2144, time: 0.168, data: 0.000) loss: 0.377 
(epoch: 129, iters: 2224, time: 0.166, data: 0.000) loss: 0.166 
(epoch: 129, iters: 2304, time: 0.164, data: 0.000) loss: 0.663 
(epoch: 129, iters: 2384, time: 0.165, data: 0.000) loss: 0.490 
(epoch: 129, iters: 2464, time: 0.167, data: 0.020) loss: 0.365 
(epoch: 129, iters: 2544, time: 0.165, data: 0.024) loss: 0.128 
(epoch: 129, iters: 2624, time: 0.171, data: 0.005) loss: 0.483 
(epoch: 129, iters: 2704, time: 0.165, data: 0.016) loss: 0.188 
(epoch: 129, iters: 2784, time: 0.166, data: 0.009) loss: 0.643 
(epoch: 129, iters: 2864, time: 0.164, data: 0.000) loss: 0.252 
(epoch: 129, iters: 2944, time: 0.166, data: 0.000) loss: 0.401 
(epoch: 129, iters: 3024, time: 0.171, data: 0.000) loss: 0.165 
(epoch: 129, iters: 3104, time: 0.180, data: 0.005) loss: 0.540 
(epoch: 129, iters: 3184, time: 0.218, data: 0.017) loss: 0.512 
(epoch: 129, iters: 3264, time: 0.222, data: 0.009) loss: 0.125 
(epoch: 129, iters: 3344, time: 0.235, data: 0.000) loss: 0.642 
(epoch: 129, iters: 3424, time: 0.166, data: 0.023) loss: 0.093 
(epoch: 129, iters: 3504, time: 0.185, data: 0.005) loss: 0.208 
(epoch: 129, iters: 3584, time: 0.263, data: 0.000) loss: 0.082 
(epoch: 129, iters: 3664, time: 0.251, data: 0.006) loss: 0.493 
(epoch: 129, iters: 3744, time: 0.248, data: 0.000) loss: 0.229 
(epoch: 129, iters: 3824, time: 0.176, data: 0.017) loss: 0.360 
(epoch: 129, iters: 3904, time: 0.172, data: 0.000) loss: 0.392 
(epoch: 129, iters: 3984, time: 0.175, data: 0.007) loss: 0.356 
saving the latest model (epoch 129, total_steps 1308592)
(epoch: 129, iters: 4064, time: 0.250, data: 0.000) loss: 0.793 
(epoch: 129, iters: 4144, time: 0.249, data: 0.006) loss: 0.325 
(epoch: 129, iters: 4224, time: 0.258, data: 0.009) loss: 0.473 
(epoch: 129, iters: 4304, time: 0.166, data: 0.019) loss: 0.167 
(epoch: 129, iters: 4384, time: 0.165, data: 0.000) loss: 0.145 
(epoch: 129, iters: 4464, time: 0.167, data: 0.000) loss: 0.305 
(epoch: 129, iters: 4544, time: 0.166, data: 0.015) loss: 0.149 
(epoch: 129, iters: 4624, time: 0.169, data: 0.000) loss: 0.482 
(epoch: 129, iters: 4704, time: 0.167, data: 0.010) loss: 0.518 
(epoch: 129, iters: 4784, time: 0.166, data: 0.000) loss: 0.385 
(epoch: 129, iters: 4864, time: 0.165, data: 0.000) loss: 0.390 
(epoch: 129, iters: 4944, time: 0.167, data: 0.027) loss: 0.734 
(epoch: 129, iters: 5024, time: 0.168, data: 0.000) loss: 0.368 
(epoch: 129, iters: 5104, time: 0.167, data: 0.000) loss: 0.262 
(epoch: 129, iters: 5184, time: 0.168, data: 0.000) loss: 0.123 
(epoch: 129, iters: 5264, time: 0.176, data: 0.011) loss: 0.601 
(epoch: 129, iters: 5344, time: 0.166, data: 0.000) loss: 0.111 
(epoch: 129, iters: 5424, time: 0.168, data: 0.007) loss: 0.233 
(epoch: 129, iters: 5504, time: 0.165, data: 0.000) loss: 0.443 
(epoch: 129, iters: 5584, time: 0.165, data: 0.000) loss: 0.498 
(epoch: 129, iters: 5664, time: 0.165, data: 0.000) loss: 0.703 
(epoch: 129, iters: 5744, time: 0.168, data: 0.008) loss: 0.295 
(epoch: 129, iters: 5824, time: 0.165, data: 0.013) loss: 0.521 
(epoch: 129, iters: 5904, time: 0.166, data: 0.000) loss: 0.370 
(epoch: 129, iters: 5984, time: 0.167, data: 0.000) loss: 0.332 
(epoch: 129, iters: 6064, time: 0.166, data: 0.020) loss: 0.287 
(epoch: 129, iters: 6144, time: 0.165, data: 0.020) loss: 0.555 
(epoch: 129, iters: 6224, time: 0.165, data: 0.006) loss: 0.332 
(epoch: 129, iters: 6304, time: 0.167, data: 0.000) loss: 0.304 
(epoch: 129, iters: 6384, time: 0.170, data: 0.010) loss: 0.621 
(epoch: 129, iters: 6464, time: 0.164, data: 0.000) loss: 0.723 
(epoch: 129, iters: 6544, time: 0.165, data: 0.025) loss: 0.386 
(epoch: 129, iters: 6624, time: 0.168, data: 0.000) loss: 0.457 
(epoch: 129, iters: 6704, time: 0.166, data: 0.000) loss: 0.300 
(epoch: 129, iters: 6784, time: 0.167, data: 0.041) loss: 0.306 
(epoch: 129, iters: 6864, time: 0.166, data: 0.000) loss: 0.432 
(epoch: 129, iters: 6944, time: 0.164, data: 0.000) loss: 0.155 
(epoch: 129, iters: 7024, time: 0.167, data: 0.000) loss: 0.453 
(epoch: 129, iters: 7104, time: 0.167, data: 0.000) loss: 0.286 
(epoch: 129, iters: 7184, time: 0.166, data: 0.000) loss: 0.429 
(epoch: 129, iters: 7264, time: 0.166, data: 0.000) loss: 0.461 
(epoch: 129, iters: 7344, time: 0.166, data: 0.009) loss: 0.543 
(epoch: 129, iters: 7424, time: 0.166, data: 0.000) loss: 0.984 
(epoch: 129, iters: 7504, time: 0.170, data: 0.011) loss: 0.207 
(epoch: 129, iters: 7584, time: 0.166, data: 0.000) loss: 0.219 
(epoch: 129, iters: 7664, time: 0.170, data: 0.024) loss: 0.304 
(epoch: 129, iters: 7744, time: 0.167, data: 0.000) loss: 0.148 
(epoch: 129, iters: 7824, time: 0.165, data: 0.005) loss: 0.375 
(epoch: 129, iters: 7904, time: 0.167, data: 0.000) loss: 0.108 
(epoch: 129, iters: 7984, time: 0.165, data: 0.000) loss: 0.751 
saving the latest model (epoch 129, total_steps 1312592)
(epoch: 129, iters: 8064, time: 0.168, data: 0.010) loss: 0.687 
(epoch: 129, iters: 8144, time: 0.170, data: 0.000) loss: 0.418 
(epoch: 129, iters: 8224, time: 0.168, data: 0.021) loss: 0.533 
(epoch: 129, iters: 8304, time: 0.166, data: 0.008) loss: 0.662 
(epoch: 129, iters: 8384, time: 0.166, data: 0.000) loss: 0.086 
(epoch: 129, iters: 8464, time: 0.165, data: 0.000) loss: 0.807 
(epoch: 129, iters: 8544, time: 0.165, data: 0.040) loss: 0.241 
(epoch: 129, iters: 8624, time: 0.165, data: 0.000) loss: 0.284 
(epoch: 129, iters: 8704, time: 0.167, data: 0.013) loss: 0.157 
(epoch: 129, iters: 8784, time: 0.164, data: 0.000) loss: 0.335 
(epoch: 129, iters: 8864, time: 0.169, data: 0.019) loss: 0.524 
(epoch: 129, iters: 8944, time: 0.165, data: 0.000) loss: 0.076 
(epoch: 129, iters: 9024, time: 0.167, data: 0.006) loss: 0.245 
(epoch: 129, iters: 9104, time: 0.167, data: 0.000) loss: 0.434 
(epoch: 129, iters: 9184, time: 0.165, data: 0.000) loss: 0.107 
(epoch: 129, iters: 9264, time: 0.167, data: 0.006) loss: 0.639 
(epoch: 129, iters: 9344, time: 0.166, data: 0.000) loss: 0.933 
(epoch: 129, iters: 9424, time: 0.164, data: 0.013) loss: 0.980 
(epoch: 129, iters: 9504, time: 0.165, data: 0.000) loss: 0.495 
(epoch: 129, iters: 9584, time: 0.166, data: 0.005) loss: 0.281 
(epoch: 129, iters: 9664, time: 0.165, data: 0.000) loss: 0.162 
(epoch: 129, iters: 9744, time: 0.171, data: 0.022) loss: 0.583 
(epoch: 129, iters: 9824, time: 0.165, data: 0.000) loss: 0.381 
(epoch: 129, iters: 9904, time: 0.165, data: 0.006) loss: 0.778 
(epoch: 129, iters: 9984, time: 0.166, data: 0.000) loss: 0.370 
(epoch: 129, iters: 10064, time: 0.169, data: 0.005) loss: 0.471 
(epoch: 129, iters: 10144, time: 0.166, data: 0.000) loss: 0.384 
saving the model at the end of epoch 129, iters 1314768
End of epoch 129 / 200 	 Time Taken: 1763 sec
learning rate = 0.0001386
saving the latest model (epoch 130, total_steps 1314784)
(epoch: 130, iters: 32, time: 0.167, data: 0.000) loss: 0.070 
(epoch: 130, iters: 112, time: 0.165, data: 0.000) loss: 0.266 
(epoch: 130, iters: 192, time: 0.166, data: 0.005) loss: 0.309 
(epoch: 130, iters: 272, time: 0.166, data: 0.000) loss: 0.341 
(epoch: 130, iters: 352, time: 0.167, data: 0.000) loss: 0.455 
(epoch: 130, iters: 432, time: 0.166, data: 0.006) loss: 0.332 
(epoch: 130, iters: 512, time: 0.169, data: 0.032) loss: 0.497 
(epoch: 130, iters: 592, time: 0.165, data: 0.000) loss: 0.276 
(epoch: 130, iters: 672, time: 0.168, data: 0.013) loss: 0.396 
(epoch: 130, iters: 752, time: 0.167, data: 0.000) loss: 0.210 
(epoch: 130, iters: 832, time: 0.168, data: 0.000) loss: 0.397 
(epoch: 130, iters: 912, time: 0.236, data: 0.005) loss: 0.611 
(epoch: 130, iters: 992, time: 0.159, data: 0.000) loss: 0.218 
(epoch: 130, iters: 1072, time: 0.164, data: 0.008) loss: 0.718 
(epoch: 130, iters: 1152, time: 0.168, data: 0.020) loss: 0.486 
(epoch: 130, iters: 1232, time: 0.165, data: 0.000) loss: 0.375 
(epoch: 130, iters: 1312, time: 0.163, data: 0.000) loss: 0.270 
(epoch: 130, iters: 1392, time: 0.171, data: 0.013) loss: 0.242 
(epoch: 130, iters: 1472, time: 0.165, data: 0.000) loss: 0.334 
(epoch: 130, iters: 1552, time: 0.163, data: 0.008) loss: 0.229 
(epoch: 130, iters: 1632, time: 0.163, data: 0.000) loss: 0.275 
(epoch: 130, iters: 1712, time: 0.163, data: 0.022) loss: 0.429 
(epoch: 130, iters: 1792, time: 0.163, data: 0.000) loss: 0.159 
(epoch: 130, iters: 1872, time: 0.168, data: 0.000) loss: 0.448 
(epoch: 130, iters: 1952, time: 0.165, data: 0.006) loss: 0.281 
(epoch: 130, iters: 2032, time: 0.163, data: 0.000) loss: 0.232 
(epoch: 130, iters: 2112, time: 0.163, data: 0.015) loss: 0.460 
(epoch: 130, iters: 2192, time: 0.161, data: 0.000) loss: 0.240 
(epoch: 130, iters: 2272, time: 0.162, data: 0.011) loss: 0.664 
(epoch: 130, iters: 2352, time: 0.162, data: 0.000) loss: 0.447 
(epoch: 130, iters: 2432, time: 0.163, data: 0.000) loss: 0.192 
(epoch: 130, iters: 2512, time: 0.162, data: 0.000) loss: 0.217 
(epoch: 130, iters: 2592, time: 0.162, data: 0.030) loss: 0.266 
(epoch: 130, iters: 2672, time: 0.169, data: 0.000) loss: 0.211 
(epoch: 130, iters: 2752, time: 0.167, data: 0.000) loss: 0.424 
(epoch: 130, iters: 2832, time: 0.165, data: 0.005) loss: 0.064 
(epoch: 130, iters: 2912, time: 0.172, data: 0.000) loss: 0.234 
(epoch: 130, iters: 2992, time: 0.165, data: 0.005) loss: 0.272 
(epoch: 130, iters: 3072, time: 0.166, data: 0.017) loss: 0.232 
(epoch: 130, iters: 3152, time: 0.168, data: 0.000) loss: 0.422 
(epoch: 130, iters: 3232, time: 0.168, data: 0.006) loss: 0.478 
(epoch: 130, iters: 3312, time: 0.166, data: 0.006) loss: 0.138 
(epoch: 130, iters: 3392, time: 0.166, data: 0.000) loss: 0.437 
(epoch: 130, iters: 3472, time: 0.165, data: 0.000) loss: 0.091 
(epoch: 130, iters: 3552, time: 0.165, data: 0.009) loss: 0.165 
(epoch: 130, iters: 3632, time: 0.165, data: 0.000) loss: 0.371 
(epoch: 130, iters: 3712, time: 0.166, data: 0.014) loss: 0.252 
(epoch: 130, iters: 3792, time: 0.167, data: 0.000) loss: 0.311 
(epoch: 130, iters: 3872, time: 0.165, data: 0.025) loss: 0.428 
(epoch: 130, iters: 3952, time: 0.166, data: 0.000) loss: 0.382 
saving the latest model (epoch 130, total_steps 1318784)
(epoch: 130, iters: 4032, time: 0.166, data: 0.005) loss: 0.832 
(epoch: 130, iters: 4112, time: 0.165, data: 0.000) loss: 0.262 
(epoch: 130, iters: 4192, time: 0.165, data: 0.006) loss: 0.408 
(epoch: 130, iters: 4272, time: 0.168, data: 0.005) loss: 0.645 
(epoch: 130, iters: 4352, time: 0.166, data: 0.000) loss: 0.548 
(epoch: 130, iters: 4432, time: 0.166, data: 0.014) loss: 0.264 
(epoch: 130, iters: 4512, time: 0.167, data: 0.006) loss: 0.516 
(epoch: 130, iters: 4592, time: 0.166, data: 0.000) loss: 0.192 
(epoch: 130, iters: 4672, time: 0.165, data: 0.011) loss: 0.349 
(epoch: 130, iters: 4752, time: 0.167, data: 0.000) loss: 0.358 
(epoch: 130, iters: 4832, time: 0.167, data: 0.025) loss: 0.098 
(epoch: 130, iters: 4912, time: 0.166, data: 0.000) loss: 0.266 
(epoch: 130, iters: 4992, time: 0.166, data: 0.000) loss: 0.212 
(epoch: 130, iters: 5072, time: 0.165, data: 0.008) loss: 0.369 
(epoch: 130, iters: 5152, time: 0.165, data: 0.005) loss: 0.228 
(epoch: 130, iters: 5232, time: 0.167, data: 0.005) loss: 0.827 
(epoch: 130, iters: 5312, time: 0.167, data: 0.000) loss: 0.234 
(epoch: 130, iters: 5392, time: 0.167, data: 0.032) loss: 0.657 
(epoch: 130, iters: 5472, time: 0.166, data: 0.000) loss: 0.409 
(epoch: 130, iters: 5552, time: 0.167, data: 0.024) loss: 0.622 
(epoch: 130, iters: 5632, time: 0.167, data: 0.000) loss: 0.315 
(epoch: 130, iters: 5712, time: 0.167, data: 0.032) loss: 0.409 
(epoch: 130, iters: 5792, time: 0.166, data: 0.000) loss: 0.351 
(epoch: 130, iters: 5872, time: 0.166, data: 0.033) loss: 0.163 
(epoch: 130, iters: 5952, time: 0.166, data: 0.000) loss: 0.344 
(epoch: 130, iters: 6032, time: 0.167, data: 0.000) loss: 0.782 
(epoch: 130, iters: 6112, time: 0.165, data: 0.021) loss: 0.333 
(epoch: 130, iters: 6192, time: 0.166, data: 0.000) loss: 0.497 
(epoch: 130, iters: 6272, time: 0.165, data: 0.000) loss: 0.786 
(epoch: 130, iters: 6352, time: 0.165, data: 0.006) loss: 0.734 
(epoch: 130, iters: 6432, time: 0.164, data: 0.019) loss: 0.451 
(epoch: 130, iters: 6512, time: 0.167, data: 0.000) loss: 0.637 
(epoch: 130, iters: 6592, time: 0.165, data: 0.000) loss: 0.412 
(epoch: 130, iters: 6672, time: 0.167, data: 0.000) loss: 0.878 
(epoch: 130, iters: 6752, time: 0.166, data: 0.015) loss: 0.468 
(epoch: 130, iters: 6832, time: 0.166, data: 0.005) loss: 0.589 
(epoch: 130, iters: 6912, time: 0.167, data: 0.032) loss: 0.552 
(epoch: 130, iters: 6992, time: 0.173, data: 0.000) loss: 0.749 
(epoch: 130, iters: 7072, time: 0.167, data: 0.000) loss: 0.411 
(epoch: 130, iters: 7152, time: 0.166, data: 0.010) loss: 0.634 
(epoch: 130, iters: 7232, time: 0.168, data: 0.005) loss: 0.249 
(epoch: 130, iters: 7312, time: 0.167, data: 0.020) loss: 0.273 
(epoch: 130, iters: 7392, time: 0.167, data: 0.000) loss: 0.341 
(epoch: 130, iters: 7472, time: 0.168, data: 0.020) loss: 0.485 
(epoch: 130, iters: 7552, time: 0.166, data: 0.015) loss: 0.656 
(epoch: 130, iters: 7632, time: 0.167, data: 0.000) loss: 0.298 
(epoch: 130, iters: 7712, time: 0.166, data: 0.024) loss: 0.528 
(epoch: 130, iters: 7792, time: 0.166, data: 0.000) loss: 0.470 
(epoch: 130, iters: 7872, time: 0.168, data: 0.009) loss: 0.235 
(epoch: 130, iters: 7952, time: 0.164, data: 0.018) loss: 0.518 
saving the latest model (epoch 130, total_steps 1322784)
(epoch: 130, iters: 8032, time: 0.164, data: 0.000) loss: 0.359 
(epoch: 130, iters: 8112, time: 0.172, data: 0.000) loss: 0.562 
(epoch: 130, iters: 8192, time: 0.165, data: 0.000) loss: 0.503 
(epoch: 130, iters: 8272, time: 0.168, data: 0.000) loss: 0.598 
(epoch: 130, iters: 8352, time: 0.166, data: 0.000) loss: 0.393 
(epoch: 130, iters: 8432, time: 0.166, data: 0.005) loss: 0.367 
(epoch: 130, iters: 8512, time: 0.166, data: 0.000) loss: 0.407 
(epoch: 130, iters: 8592, time: 0.165, data: 0.000) loss: 0.648 
(epoch: 130, iters: 8672, time: 0.166, data: 0.000) loss: 0.422 
(epoch: 130, iters: 8752, time: 0.170, data: 0.037) loss: 0.396 
(epoch: 130, iters: 8832, time: 0.168, data: 0.000) loss: 0.543 
(epoch: 130, iters: 8912, time: 0.169, data: 0.000) loss: 0.829 
(epoch: 130, iters: 8992, time: 0.165, data: 0.005) loss: 0.291 
(epoch: 130, iters: 9072, time: 0.167, data: 0.000) loss: 0.258 
(epoch: 130, iters: 9152, time: 0.166, data: 0.024) loss: 0.295 
(epoch: 130, iters: 9232, time: 0.173, data: 0.005) loss: 0.103 
(epoch: 130, iters: 9312, time: 0.166, data: 0.005) loss: 0.590 
(epoch: 130, iters: 9392, time: 0.169, data: 0.000) loss: 0.159 
(epoch: 130, iters: 9472, time: 0.165, data: 0.010) loss: 0.598 
(epoch: 130, iters: 9552, time: 0.164, data: 0.014) loss: 0.404 
(epoch: 130, iters: 9632, time: 0.166, data: 0.006) loss: 0.329 
(epoch: 130, iters: 9712, time: 0.168, data: 0.000) loss: 0.458 
(epoch: 130, iters: 9792, time: 0.165, data: 0.006) loss: 0.453 
(epoch: 130, iters: 9872, time: 0.165, data: 0.000) loss: 0.386 
(epoch: 130, iters: 9952, time: 0.169, data: 0.000) loss: 0.712 
(epoch: 130, iters: 10032, time: 0.164, data: 0.000) loss: 0.453 
(epoch: 130, iters: 10112, time: 0.166, data: 0.006) loss: 0.388 
(epoch: 130, iters: 10192, time: 0.100, data: 0.000) loss: 0.854 
saving the model at the end of epoch 130, iters 1324960
End of epoch 130 / 200 	 Time Taken: 1701 sec
learning rate = 0.0001366
saving the latest model (epoch 131, total_steps 1324976)
(epoch: 131, iters: 80, time: 0.165, data: 0.193) loss: 0.192 
(epoch: 131, iters: 160, time: 0.166, data: 0.000) loss: 0.382 
(epoch: 131, iters: 240, time: 0.166, data: 0.024) loss: 0.187 
(epoch: 131, iters: 320, time: 0.165, data: 0.000) loss: 0.258 
(epoch: 131, iters: 400, time: 0.165, data: 0.000) loss: 0.768 
(epoch: 131, iters: 480, time: 0.165, data: 0.000) loss: 0.200 
(epoch: 131, iters: 560, time: 0.166, data: 0.000) loss: 0.247 
(epoch: 131, iters: 640, time: 0.166, data: 0.008) loss: 0.257 
(epoch: 131, iters: 720, time: 0.167, data: 0.000) loss: 0.342 
(epoch: 131, iters: 800, time: 0.165, data: 0.016) loss: 0.489 
(epoch: 131, iters: 880, time: 0.165, data: 0.006) loss: 0.206 
(epoch: 131, iters: 960, time: 0.168, data: 0.019) loss: 0.390 
(epoch: 131, iters: 1040, time: 0.167, data: 0.000) loss: 0.566 
(epoch: 131, iters: 1120, time: 0.165, data: 0.000) loss: 0.485 
(epoch: 131, iters: 1200, time: 0.165, data: 0.027) loss: 0.271 
(epoch: 131, iters: 1280, time: 0.170, data: 0.000) loss: 0.573 
(epoch: 131, iters: 1360, time: 0.165, data: 0.023) loss: 0.613 
(epoch: 131, iters: 1440, time: 0.166, data: 0.000) loss: 0.374 
(epoch: 131, iters: 1520, time: 0.168, data: 0.005) loss: 0.139 
(epoch: 131, iters: 1600, time: 0.167, data: 0.000) loss: 0.455 
(epoch: 131, iters: 1680, time: 0.165, data: 0.013) loss: 0.500 
(epoch: 131, iters: 1760, time: 0.167, data: 0.006) loss: 0.678 
(epoch: 131, iters: 1840, time: 0.166, data: 0.025) loss: 0.218 
(epoch: 131, iters: 1920, time: 0.166, data: 0.000) loss: 0.536 
(epoch: 131, iters: 2000, time: 0.169, data: 0.000) loss: 0.219 
(epoch: 131, iters: 2080, time: 0.167, data: 0.005) loss: 0.108 
(epoch: 131, iters: 2160, time: 0.165, data: 0.000) loss: 0.315 
(epoch: 131, iters: 2240, time: 0.164, data: 0.000) loss: 0.189 
(epoch: 131, iters: 2320, time: 0.167, data: 0.000) loss: 0.410 
(epoch: 131, iters: 2400, time: 0.164, data: 0.005) loss: 0.500 
(epoch: 131, iters: 2480, time: 0.166, data: 0.000) loss: 0.270 
(epoch: 131, iters: 2560, time: 0.167, data: 0.000) loss: 0.264 
(epoch: 131, iters: 2640, time: 0.165, data: 0.019) loss: 0.311 
(epoch: 131, iters: 2720, time: 0.167, data: 0.024) loss: 0.573 
(epoch: 131, iters: 2800, time: 0.165, data: 0.000) loss: 0.333 
(epoch: 131, iters: 2880, time: 0.167, data: 0.005) loss: 0.127 
(epoch: 131, iters: 2960, time: 0.164, data: 0.011) loss: 0.319 
(epoch: 131, iters: 3040, time: 0.167, data: 0.000) loss: 0.256 
(epoch: 131, iters: 3120, time: 0.164, data: 0.025) loss: 0.277 
(epoch: 131, iters: 3200, time: 0.164, data: 0.000) loss: 0.383 
(epoch: 131, iters: 3280, time: 0.165, data: 0.032) loss: 0.626 
(epoch: 131, iters: 3360, time: 0.166, data: 0.000) loss: 0.234 
(epoch: 131, iters: 3440, time: 0.166, data: 0.000) loss: 0.573 
(epoch: 131, iters: 3520, time: 0.167, data: 0.011) loss: 0.066 
(epoch: 131, iters: 3600, time: 0.166, data: 0.000) loss: 0.562 
(epoch: 131, iters: 3680, time: 0.167, data: 0.009) loss: 0.237 
(epoch: 131, iters: 3760, time: 0.167, data: 0.000) loss: 0.178 
(epoch: 131, iters: 3840, time: 0.168, data: 0.000) loss: 0.510 
(epoch: 131, iters: 3920, time: 0.163, data: 0.005) loss: 0.220 
(epoch: 131, iters: 4000, time: 0.164, data: 0.000) loss: 0.255 
saving the latest model (epoch 131, total_steps 1328976)
(epoch: 131, iters: 4080, time: 0.165, data: 0.009) loss: 0.422 
(epoch: 131, iters: 4160, time: 0.165, data: 0.015) loss: 0.602 
(epoch: 131, iters: 4240, time: 0.165, data: 0.000) loss: 0.208 
(epoch: 131, iters: 4320, time: 0.166, data: 0.029) loss: 0.197 
(epoch: 131, iters: 4400, time: 0.165, data: 0.000) loss: 0.311 
(epoch: 131, iters: 4480, time: 0.164, data: 0.000) loss: 0.532 
(epoch: 131, iters: 4560, time: 0.166, data: 0.008) loss: 0.298 
(epoch: 131, iters: 4640, time: 0.165, data: 0.005) loss: 0.388 
(epoch: 131, iters: 4720, time: 0.164, data: 0.021) loss: 0.389 
(epoch: 131, iters: 4800, time: 0.165, data: 0.000) loss: 0.367 
(epoch: 131, iters: 4880, time: 0.169, data: 0.031) loss: 0.353 
(epoch: 131, iters: 4960, time: 0.165, data: 0.000) loss: 0.523 
(epoch: 131, iters: 5040, time: 0.165, data: 0.000) loss: 0.208 
(epoch: 131, iters: 5120, time: 0.166, data: 0.000) loss: 0.765 
(epoch: 131, iters: 5200, time: 0.165, data: 0.008) loss: 0.135 
(epoch: 131, iters: 5280, time: 0.166, data: 0.000) loss: 0.204 
(epoch: 131, iters: 5360, time: 0.167, data: 0.009) loss: 0.545 
(epoch: 131, iters: 5440, time: 0.166, data: 0.000) loss: 0.935 
(epoch: 131, iters: 5520, time: 0.165, data: 0.005) loss: 0.107 
(epoch: 131, iters: 5600, time: 0.166, data: 0.000) loss: 0.694 
(epoch: 131, iters: 5680, time: 0.164, data: 0.005) loss: 0.707 
(epoch: 131, iters: 5760, time: 0.165, data: 0.000) loss: 0.344 
(epoch: 131, iters: 5840, time: 0.165, data: 0.006) loss: 0.158 
(epoch: 131, iters: 5920, time: 0.166, data: 0.025) loss: 0.200 
(epoch: 131, iters: 6000, time: 0.165, data: 0.000) loss: 0.119 
(epoch: 131, iters: 6080, time: 0.165, data: 0.000) loss: 0.297 
(epoch: 131, iters: 6160, time: 0.164, data: 0.005) loss: 0.514 
(epoch: 131, iters: 6240, time: 0.166, data: 0.000) loss: 0.803 
(epoch: 131, iters: 6320, time: 0.164, data: 0.032) loss: 0.694 
(epoch: 131, iters: 6400, time: 0.164, data: 0.000) loss: 0.362 
(epoch: 131, iters: 6480, time: 0.164, data: 0.000) loss: 0.643 
(epoch: 131, iters: 6560, time: 0.167, data: 0.006) loss: 0.312 
(epoch: 131, iters: 6640, time: 0.164, data: 0.038) loss: 0.192 
(epoch: 131, iters: 6720, time: 0.165, data: 0.000) loss: 0.382 
(epoch: 131, iters: 6800, time: 0.165, data: 0.018) loss: 0.100 
(epoch: 131, iters: 6880, time: 0.169, data: 0.008) loss: 0.589 
(epoch: 131, iters: 6960, time: 0.166, data: 0.000) loss: 0.143 
(epoch: 131, iters: 7040, time: 0.166, data: 0.018) loss: 0.248 
(epoch: 131, iters: 7120, time: 0.165, data: 0.000) loss: 0.245 
(epoch: 131, iters: 7200, time: 0.165, data: 0.018) loss: 0.604 
(epoch: 131, iters: 7280, time: 0.165, data: 0.000) loss: 0.460 
(epoch: 131, iters: 7360, time: 0.166, data: 0.000) loss: 0.666 
(epoch: 131, iters: 7440, time: 0.166, data: 0.000) loss: 0.108 
(epoch: 131, iters: 7520, time: 0.166, data: 0.005) loss: 0.578 
(epoch: 131, iters: 7600, time: 0.164, data: 0.009) loss: 0.312 
(epoch: 131, iters: 7680, time: 0.164, data: 0.000) loss: 0.094 
(epoch: 131, iters: 7760, time: 0.165, data: 0.005) loss: 0.375 
(epoch: 131, iters: 7840, time: 0.163, data: 0.000) loss: 0.578 
(epoch: 131, iters: 7920, time: 0.164, data: 0.000) loss: 0.558 
(epoch: 131, iters: 8000, time: 0.171, data: 0.000) loss: 0.331 
saving the latest model (epoch 131, total_steps 1332976)
(epoch: 131, iters: 8080, time: 0.167, data: 0.000) loss: 0.293 
(epoch: 131, iters: 8160, time: 0.165, data: 0.009) loss: 0.439 
(epoch: 131, iters: 8240, time: 0.165, data: 0.000) loss: 0.189 
(epoch: 131, iters: 8320, time: 0.165, data: 0.016) loss: 0.380 
(epoch: 131, iters: 8400, time: 0.164, data: 0.009) loss: 0.287 
(epoch: 131, iters: 8480, time: 0.167, data: 0.000) loss: 0.265 
(epoch: 131, iters: 8560, time: 0.166, data: 0.017) loss: 0.150 
(epoch: 131, iters: 8640, time: 0.165, data: 0.022) loss: 0.498 
(epoch: 131, iters: 8720, time: 0.164, data: 0.014) loss: 0.329 
(epoch: 131, iters: 8800, time: 0.166, data: 0.024) loss: 0.400 
(epoch: 131, iters: 8880, time: 0.166, data: 0.000) loss: 0.773 
(epoch: 131, iters: 8960, time: 0.166, data: 0.005) loss: 0.410 
(epoch: 131, iters: 9040, time: 0.165, data: 0.000) loss: 0.879 
(epoch: 131, iters: 9120, time: 0.172, data: 0.000) loss: 0.328 
(epoch: 131, iters: 9200, time: 0.165, data: 0.000) loss: 0.748 
(epoch: 131, iters: 9280, time: 0.164, data: 0.015) loss: 0.826 
(epoch: 131, iters: 9360, time: 0.166, data: 0.027) loss: 0.075 
(epoch: 131, iters: 9440, time: 0.169, data: 0.000) loss: 0.136 
(epoch: 131, iters: 9520, time: 0.165, data: 0.000) loss: 0.745 
(epoch: 131, iters: 9600, time: 0.164, data: 0.008) loss: 0.339 
(epoch: 131, iters: 9680, time: 0.165, data: 0.000) loss: 0.249 
(epoch: 131, iters: 9760, time: 0.164, data: 0.005) loss: 0.748 
(epoch: 131, iters: 9840, time: 0.167, data: 0.006) loss: 0.875 
(epoch: 131, iters: 9920, time: 0.164, data: 0.000) loss: 0.344 
(epoch: 131, iters: 10000, time: 0.166, data: 0.000) loss: 0.529 
(epoch: 131, iters: 10080, time: 0.164, data: 0.000) loss: 0.354 
(epoch: 131, iters: 10160, time: 0.167, data: 0.014) loss: 0.187 
saving the model at the end of epoch 131, iters 1335152
End of epoch 131 / 200 	 Time Taken: 1695 sec
learning rate = 0.0001347
saving the latest model (epoch 132, total_steps 1335168)
(epoch: 132, iters: 48, time: 0.172, data: 0.005) loss: 0.500 
(epoch: 132, iters: 128, time: 0.166, data: 0.010) loss: 0.254 
(epoch: 132, iters: 208, time: 0.165, data: 0.000) loss: 0.353 
(epoch: 132, iters: 288, time: 0.164, data: 0.015) loss: 0.240 
(epoch: 132, iters: 368, time: 0.165, data: 0.000) loss: 0.578 
(epoch: 132, iters: 448, time: 0.163, data: 0.006) loss: 0.280 
(epoch: 132, iters: 528, time: 0.165, data: 0.000) loss: 0.357 
(epoch: 132, iters: 608, time: 0.165, data: 0.000) loss: 0.473 
(epoch: 132, iters: 688, time: 0.164, data: 0.000) loss: 0.339 
(epoch: 132, iters: 768, time: 0.165, data: 0.016) loss: 0.275 
(epoch: 132, iters: 848, time: 0.163, data: 0.013) loss: 0.231 
(epoch: 132, iters: 928, time: 0.166, data: 0.013) loss: 0.308 
(epoch: 132, iters: 1008, time: 0.169, data: 0.000) loss: 0.476 
(epoch: 132, iters: 1088, time: 0.166, data: 0.008) loss: 0.697 
(epoch: 132, iters: 1168, time: 0.169, data: 0.000) loss: 0.139 
(epoch: 132, iters: 1248, time: 0.166, data: 0.000) loss: 0.505 
(epoch: 132, iters: 1328, time: 0.166, data: 0.019) loss: 0.328 
(epoch: 132, iters: 1408, time: 0.166, data: 0.000) loss: 0.740 
(epoch: 132, iters: 1488, time: 0.163, data: 0.000) loss: 0.328 
(epoch: 132, iters: 1568, time: 0.168, data: 0.000) loss: 0.499 
(epoch: 132, iters: 1648, time: 0.167, data: 0.000) loss: 0.163 
(epoch: 132, iters: 1728, time: 0.165, data: 0.000) loss: 0.470 
(epoch: 132, iters: 1808, time: 0.166, data: 0.008) loss: 0.116 
(epoch: 132, iters: 1888, time: 0.166, data: 0.000) loss: 0.490 
(epoch: 132, iters: 1968, time: 0.166, data: 0.005) loss: 0.515 
(epoch: 132, iters: 2048, time: 0.165, data: 0.008) loss: 0.127 
(epoch: 132, iters: 2128, time: 0.168, data: 0.000) loss: 0.229 
(epoch: 132, iters: 2208, time: 0.167, data: 0.000) loss: 0.872 
(epoch: 132, iters: 2288, time: 0.172, data: 0.000) loss: 0.472 
(epoch: 132, iters: 2368, time: 0.164, data: 0.026) loss: 0.456 
(epoch: 132, iters: 2448, time: 0.163, data: 0.000) loss: 0.307 
(epoch: 132, iters: 2528, time: 0.165, data: 0.041) loss: 0.401 
(epoch: 132, iters: 2608, time: 0.166, data: 0.000) loss: 0.115 
(epoch: 132, iters: 2688, time: 0.164, data: 0.000) loss: 0.213 
(epoch: 132, iters: 2768, time: 0.166, data: 0.000) loss: 0.396 
(epoch: 132, iters: 2848, time: 0.167, data: 0.000) loss: 0.361 
(epoch: 132, iters: 2928, time: 0.166, data: 0.005) loss: 0.902 
(epoch: 132, iters: 3008, time: 0.166, data: 0.000) loss: 0.266 
(epoch: 132, iters: 3088, time: 0.165, data: 0.000) loss: 0.455 
(epoch: 132, iters: 3168, time: 0.165, data: 0.000) loss: 0.694 
(epoch: 132, iters: 3248, time: 0.165, data: 0.000) loss: 0.384 
(epoch: 132, iters: 3328, time: 0.165, data: 0.000) loss: 0.151 
(epoch: 132, iters: 3408, time: 0.170, data: 0.000) loss: 0.161 
(epoch: 132, iters: 3488, time: 0.165, data: 0.000) loss: 0.237 
(epoch: 132, iters: 3568, time: 0.163, data: 0.020) loss: 0.901 
(epoch: 132, iters: 3648, time: 0.165, data: 0.000) loss: 0.418 
(epoch: 132, iters: 3728, time: 0.173, data: 0.000) loss: 0.110 
(epoch: 132, iters: 3808, time: 0.167, data: 0.000) loss: 0.278 
(epoch: 132, iters: 3888, time: 0.165, data: 0.024) loss: 0.563 
(epoch: 132, iters: 3968, time: 0.164, data: 0.000) loss: 0.265 
saving the latest model (epoch 132, total_steps 1339168)
(epoch: 132, iters: 4048, time: 0.165, data: 0.000) loss: 0.573 
(epoch: 132, iters: 4128, time: 0.166, data: 0.000) loss: 0.590 
(epoch: 132, iters: 4208, time: 0.165, data: 0.005) loss: 0.251 
(epoch: 132, iters: 4288, time: 0.166, data: 0.017) loss: 0.389 
(epoch: 132, iters: 4368, time: 0.164, data: 0.005) loss: 0.912 
(epoch: 132, iters: 4448, time: 0.165, data: 0.000) loss: 0.443 
(epoch: 132, iters: 4528, time: 0.168, data: 0.035) loss: 0.172 
(epoch: 132, iters: 4608, time: 0.168, data: 0.000) loss: 0.489 
(epoch: 132, iters: 4688, time: 0.165, data: 0.033) loss: 0.419 
(epoch: 132, iters: 4768, time: 0.166, data: 0.000) loss: 0.246 
(epoch: 132, iters: 4848, time: 0.165, data: 0.000) loss: 1.316 
(epoch: 132, iters: 4928, time: 0.166, data: 0.008) loss: 0.225 
(epoch: 132, iters: 5008, time: 0.165, data: 0.025) loss: 0.270 
(epoch: 132, iters: 5088, time: 0.166, data: 0.000) loss: 0.251 
(epoch: 132, iters: 5168, time: 0.166, data: 0.024) loss: 0.329 
(epoch: 132, iters: 5248, time: 0.162, data: 0.000) loss: 0.127 
(epoch: 132, iters: 5328, time: 0.169, data: 0.000) loss: 0.748 
(epoch: 132, iters: 5408, time: 0.164, data: 0.000) loss: 0.290 
(epoch: 132, iters: 5488, time: 0.165, data: 0.000) loss: 0.247 
(epoch: 132, iters: 5568, time: 0.166, data: 0.009) loss: 0.354 
(epoch: 132, iters: 5648, time: 0.172, data: 0.000) loss: 0.177 
(epoch: 132, iters: 5728, time: 0.165, data: 0.018) loss: 0.500 
(epoch: 132, iters: 5808, time: 0.168, data: 0.000) loss: 0.237 
(epoch: 132, iters: 5888, time: 0.167, data: 0.009) loss: 0.335 
(epoch: 132, iters: 5968, time: 0.165, data: 0.000) loss: 0.269 
(epoch: 132, iters: 6048, time: 0.167, data: 0.024) loss: 0.245 
(epoch: 132, iters: 6128, time: 0.165, data: 0.000) loss: 0.395 
(epoch: 132, iters: 6208, time: 0.164, data: 0.000) loss: 0.563 
(epoch: 132, iters: 6288, time: 0.165, data: 0.008) loss: 0.234 
(epoch: 132, iters: 6368, time: 0.165, data: 0.000) loss: 0.387 
(epoch: 132, iters: 6448, time: 0.163, data: 0.017) loss: 0.314 
(epoch: 132, iters: 6528, time: 0.167, data: 0.015) loss: 0.551 
(epoch: 132, iters: 6608, time: 0.165, data: 0.041) loss: 0.424 
(epoch: 132, iters: 6688, time: 0.164, data: 0.000) loss: 0.244 
(epoch: 132, iters: 6768, time: 0.172, data: 0.000) loss: 0.319 
(epoch: 132, iters: 6848, time: 0.166, data: 0.008) loss: 0.138 
(epoch: 132, iters: 6928, time: 0.167, data: 0.000) loss: 0.298 
(epoch: 132, iters: 7008, time: 0.165, data: 0.000) loss: 0.915 
(epoch: 132, iters: 7088, time: 0.165, data: 0.000) loss: 0.417 
(epoch: 132, iters: 7168, time: 0.165, data: 0.000) loss: 0.198 
(epoch: 132, iters: 7248, time: 0.165, data: 0.000) loss: 0.148 
(epoch: 132, iters: 7328, time: 0.166, data: 0.000) loss: 0.283 
(epoch: 132, iters: 7408, time: 0.166, data: 0.020) loss: 0.310 
(epoch: 132, iters: 7488, time: 0.165, data: 0.032) loss: 0.353 
(epoch: 132, iters: 7568, time: 0.166, data: 0.000) loss: 0.327 
(epoch: 132, iters: 7648, time: 0.165, data: 0.005) loss: 0.095 
(epoch: 132, iters: 7728, time: 0.165, data: 0.000) loss: 0.477 
(epoch: 132, iters: 7808, time: 0.164, data: 0.000) loss: 0.142 
(epoch: 132, iters: 7888, time: 0.169, data: 0.009) loss: 0.303 
(epoch: 132, iters: 7968, time: 0.166, data: 0.000) loss: 0.182 
saving the latest model (epoch 132, total_steps 1343168)
(epoch: 132, iters: 8048, time: 0.167, data: 0.005) loss: 0.705 
(epoch: 132, iters: 8128, time: 0.165, data: 0.000) loss: 0.272 
(epoch: 132, iters: 8208, time: 0.165, data: 0.008) loss: 0.282 
(epoch: 132, iters: 8288, time: 0.165, data: 0.005) loss: 1.133 
(epoch: 132, iters: 8368, time: 0.166, data: 0.000) loss: 0.411 
(epoch: 132, iters: 8448, time: 0.163, data: 0.008) loss: 0.327 
(epoch: 132, iters: 8528, time: 0.166, data: 0.006) loss: 0.459 
(epoch: 132, iters: 8608, time: 0.165, data: 0.014) loss: 0.087 
(epoch: 132, iters: 8688, time: 0.166, data: 0.000) loss: 0.269 
(epoch: 132, iters: 8768, time: 0.166, data: 0.000) loss: 0.473 
(epoch: 132, iters: 8848, time: 0.164, data: 0.008) loss: 0.660 
(epoch: 132, iters: 8928, time: 0.166, data: 0.000) loss: 0.768 
(epoch: 132, iters: 9008, time: 0.171, data: 0.008) loss: 0.207 
(epoch: 132, iters: 9088, time: 0.164, data: 0.000) loss: 0.265 
(epoch: 132, iters: 9168, time: 0.163, data: 0.006) loss: 0.974 
(epoch: 132, iters: 9248, time: 0.167, data: 0.000) loss: 0.450 
(epoch: 132, iters: 9328, time: 0.166, data: 0.015) loss: 0.599 
(epoch: 132, iters: 9408, time: 0.166, data: 0.000) loss: 0.204 
(epoch: 132, iters: 9488, time: 0.165, data: 0.000) loss: 0.783 
(epoch: 132, iters: 9568, time: 0.164, data: 0.005) loss: 0.140 
(epoch: 132, iters: 9648, time: 0.164, data: 0.006) loss: 0.459 
(epoch: 132, iters: 9728, time: 0.166, data: 0.016) loss: 0.391 
(epoch: 132, iters: 9808, time: 0.164, data: 0.000) loss: 0.328 
(epoch: 132, iters: 9888, time: 0.163, data: 0.006) loss: 0.526 
(epoch: 132, iters: 9968, time: 0.166, data: 0.000) loss: 0.617 
(epoch: 132, iters: 10048, time: 0.162, data: 0.000) loss: 0.730 
(epoch: 132, iters: 10128, time: 0.167, data: 0.008) loss: 1.071 
saving the model at the end of epoch 132, iters 1345344
End of epoch 132 / 200 	 Time Taken: 1695 sec
learning rate = 0.0001327
(epoch: 133, iters: 16, time: 0.180, data: 0.011) loss: 0.178 
saving the latest model (epoch 133, total_steps 1345360)
(epoch: 133, iters: 96, time: 0.165, data: 0.023) loss: 0.178 
(epoch: 133, iters: 176, time: 0.165, data: 0.009) loss: 0.256 
(epoch: 133, iters: 256, time: 0.165, data: 0.000) loss: 0.361 
(epoch: 133, iters: 336, time: 0.165, data: 0.011) loss: 0.423 
(epoch: 133, iters: 416, time: 0.166, data: 0.000) loss: 0.380 
(epoch: 133, iters: 496, time: 0.166, data: 0.000) loss: 0.666 
(epoch: 133, iters: 576, time: 0.165, data: 0.000) loss: 0.260 
(epoch: 133, iters: 656, time: 0.166, data: 0.000) loss: 0.674 
(epoch: 133, iters: 736, time: 0.168, data: 0.000) loss: 0.280 
(epoch: 133, iters: 816, time: 0.167, data: 0.030) loss: 0.186 
(epoch: 133, iters: 896, time: 0.166, data: 0.023) loss: 0.530 
(epoch: 133, iters: 976, time: 0.168, data: 0.000) loss: 0.505 
(epoch: 133, iters: 1056, time: 0.171, data: 0.021) loss: 0.129 
(epoch: 133, iters: 1136, time: 0.168, data: 0.000) loss: 0.291 
(epoch: 133, iters: 1216, time: 0.164, data: 0.026) loss: 0.117 
(epoch: 133, iters: 1296, time: 0.165, data: 0.000) loss: 0.193 
(epoch: 133, iters: 1376, time: 0.167, data: 0.000) loss: 0.887 
(epoch: 133, iters: 1456, time: 0.167, data: 0.015) loss: 0.112 
(epoch: 133, iters: 1536, time: 0.167, data: 0.014) loss: 0.391 
(epoch: 133, iters: 1616, time: 0.169, data: 0.000) loss: 0.469 
(epoch: 133, iters: 1696, time: 0.168, data: 0.025) loss: 0.241 
(epoch: 133, iters: 1776, time: 0.165, data: 0.000) loss: 0.137 
(epoch: 133, iters: 1856, time: 0.168, data: 0.000) loss: 0.750 
(epoch: 133, iters: 1936, time: 0.166, data: 0.014) loss: 0.194 
(epoch: 133, iters: 2016, time: 0.163, data: 0.000) loss: 0.173 
(epoch: 133, iters: 2096, time: 0.164, data: 0.000) loss: 0.712 
(epoch: 133, iters: 2176, time: 0.165, data: 0.014) loss: 0.220 
(epoch: 133, iters: 2256, time: 0.165, data: 0.005) loss: 0.693 
(epoch: 133, iters: 2336, time: 0.165, data: 0.000) loss: 1.003 
(epoch: 133, iters: 2416, time: 0.165, data: 0.005) loss: 0.480 
(epoch: 133, iters: 2496, time: 0.166, data: 0.005) loss: 0.468 
(epoch: 133, iters: 2576, time: 0.165, data: 0.000) loss: 0.428 
(epoch: 133, iters: 2656, time: 0.165, data: 0.000) loss: 1.071 
(epoch: 133, iters: 2736, time: 0.171, data: 0.009) loss: 0.138 
(epoch: 133, iters: 2816, time: 0.164, data: 0.000) loss: 0.202 
(epoch: 133, iters: 2896, time: 0.167, data: 0.015) loss: 0.360 
(epoch: 133, iters: 2976, time: 0.167, data: 0.000) loss: 0.445 
(epoch: 133, iters: 3056, time: 0.168, data: 0.000) loss: 1.254 
(epoch: 133, iters: 3136, time: 0.167, data: 0.008) loss: 0.057 
(epoch: 133, iters: 3216, time: 0.166, data: 0.005) loss: 0.241 
(epoch: 133, iters: 3296, time: 0.166, data: 0.000) loss: 0.330 
(epoch: 133, iters: 3376, time: 0.164, data: 0.000) loss: 0.298 
(epoch: 133, iters: 3456, time: 0.167, data: 0.000) loss: 0.534 
(epoch: 133, iters: 3536, time: 0.166, data: 0.031) loss: 0.217 
(epoch: 133, iters: 3616, time: 0.164, data: 0.000) loss: 0.440 
(epoch: 133, iters: 3696, time: 0.165, data: 0.000) loss: 0.360 
(epoch: 133, iters: 3776, time: 0.164, data: 0.018) loss: 0.486 
(epoch: 133, iters: 3856, time: 0.165, data: 0.000) loss: 0.099 
(epoch: 133, iters: 3936, time: 0.165, data: 0.000) loss: 0.173 
(epoch: 133, iters: 4016, time: 0.164, data: 0.009) loss: 0.246 
saving the latest model (epoch 133, total_steps 1349360)
(epoch: 133, iters: 4096, time: 0.164, data: 0.000) loss: 0.441 
(epoch: 133, iters: 4176, time: 0.167, data: 0.025) loss: 0.148 
(epoch: 133, iters: 4256, time: 0.204, data: 0.000) loss: 0.125 
(epoch: 133, iters: 4336, time: 0.161, data: 0.009) loss: 0.218 
(epoch: 133, iters: 4416, time: 0.161, data: 0.000) loss: 0.328 
(epoch: 133, iters: 4496, time: 0.161, data: 0.000) loss: 0.423 
(epoch: 133, iters: 4576, time: 0.164, data: 0.017) loss: 0.333 
(epoch: 133, iters: 4656, time: 0.164, data: 0.000) loss: 0.541 
(epoch: 133, iters: 4736, time: 0.161, data: 0.011) loss: 0.946 
(epoch: 133, iters: 4816, time: 0.165, data: 0.021) loss: 0.184 
(epoch: 133, iters: 4896, time: 0.164, data: 0.000) loss: 0.561 
(epoch: 133, iters: 4976, time: 0.163, data: 0.000) loss: 0.278 
(epoch: 133, iters: 5056, time: 0.163, data: 0.008) loss: 0.558 
(epoch: 133, iters: 5136, time: 0.168, data: 0.008) loss: 0.257 
(epoch: 133, iters: 5216, time: 0.166, data: 0.000) loss: 0.563 
(epoch: 133, iters: 5296, time: 0.159, data: 0.000) loss: 0.381 
(epoch: 133, iters: 5376, time: 0.164, data: 0.000) loss: 0.501 
(epoch: 133, iters: 5456, time: 0.164, data: 0.008) loss: 0.382 
(epoch: 133, iters: 5536, time: 0.161, data: 0.000) loss: 0.455 
(epoch: 133, iters: 5616, time: 0.161, data: 0.000) loss: 0.085 
(epoch: 133, iters: 5696, time: 0.161, data: 0.005) loss: 0.657 
(epoch: 133, iters: 5776, time: 0.161, data: 0.000) loss: 0.540 
(epoch: 133, iters: 5856, time: 0.162, data: 0.000) loss: 0.189 
(epoch: 133, iters: 5936, time: 0.162, data: 0.011) loss: 0.522 
(epoch: 133, iters: 6016, time: 0.161, data: 0.000) loss: 0.123 
(epoch: 133, iters: 6096, time: 0.165, data: 0.000) loss: 0.422 
(epoch: 133, iters: 6176, time: 0.167, data: 0.006) loss: 0.617 
(epoch: 133, iters: 6256, time: 0.164, data: 0.000) loss: 0.125 
(epoch: 133, iters: 6336, time: 0.165, data: 0.000) loss: 0.192 
(epoch: 133, iters: 6416, time: 0.165, data: 0.009) loss: 0.305 
(epoch: 133, iters: 6496, time: 0.165, data: 0.015) loss: 0.201 
(epoch: 133, iters: 6576, time: 0.166, data: 0.000) loss: 0.231 
(epoch: 133, iters: 6656, time: 0.166, data: 0.014) loss: 0.349 
(epoch: 133, iters: 6736, time: 0.167, data: 0.000) loss: 0.534 
(epoch: 133, iters: 6816, time: 0.166, data: 0.008) loss: 0.322 
(epoch: 133, iters: 6896, time: 0.165, data: 0.005) loss: 0.172 
(epoch: 133, iters: 6976, time: 0.165, data: 0.033) loss: 0.240 
(epoch: 133, iters: 7056, time: 0.166, data: 0.000) loss: 0.494 
(epoch: 133, iters: 7136, time: 0.165, data: 0.000) loss: 0.101 
(epoch: 133, iters: 7216, time: 0.164, data: 0.000) loss: 0.278 
(epoch: 133, iters: 7296, time: 0.166, data: 0.000) loss: 0.241 
(epoch: 133, iters: 7376, time: 0.166, data: 0.000) loss: 0.486 
(epoch: 133, iters: 7456, time: 0.166, data: 0.005) loss: 0.308 
(epoch: 133, iters: 7536, time: 0.168, data: 0.000) loss: 0.229 
(epoch: 133, iters: 7616, time: 0.165, data: 0.015) loss: 0.540 
(epoch: 133, iters: 7696, time: 0.165, data: 0.011) loss: 0.187 
(epoch: 133, iters: 7776, time: 0.168, data: 0.015) loss: 0.567 
(epoch: 133, iters: 7856, time: 0.167, data: 0.024) loss: 0.381 
(epoch: 133, iters: 7936, time: 0.167, data: 0.000) loss: 0.368 
(epoch: 133, iters: 8016, time: 0.166, data: 0.024) loss: 0.222 
saving the latest model (epoch 133, total_steps 1353360)
(epoch: 133, iters: 8096, time: 0.168, data: 0.000) loss: 0.042 
(epoch: 133, iters: 8176, time: 0.165, data: 0.000) loss: 0.882 
(epoch: 133, iters: 8256, time: 0.166, data: 0.000) loss: 0.318 
(epoch: 133, iters: 8336, time: 0.166, data: 0.005) loss: 0.192 
(epoch: 133, iters: 8416, time: 0.170, data: 0.009) loss: 0.451 
(epoch: 133, iters: 8496, time: 0.166, data: 0.005) loss: 0.554 
(epoch: 133, iters: 8576, time: 0.166, data: 0.000) loss: 0.448 
(epoch: 133, iters: 8656, time: 0.164, data: 0.034) loss: 0.425 
(epoch: 133, iters: 8736, time: 0.167, data: 0.000) loss: 0.157 
(epoch: 133, iters: 8816, time: 0.165, data: 0.033) loss: 0.619 
(epoch: 133, iters: 8896, time: 0.168, data: 0.000) loss: 0.538 
(epoch: 133, iters: 8976, time: 0.165, data: 0.005) loss: 0.526 
(epoch: 133, iters: 9056, time: 0.166, data: 0.009) loss: 0.215 
(epoch: 133, iters: 9136, time: 0.165, data: 0.000) loss: 0.759 
(epoch: 133, iters: 9216, time: 0.166, data: 0.008) loss: 0.234 
(epoch: 133, iters: 9296, time: 0.164, data: 0.000) loss: 0.243 
(epoch: 133, iters: 9376, time: 0.167, data: 0.023) loss: 0.342 
(epoch: 133, iters: 9456, time: 0.165, data: 0.021) loss: 0.140 
(epoch: 133, iters: 9536, time: 0.166, data: 0.000) loss: 0.471 
(epoch: 133, iters: 9616, time: 0.167, data: 0.011) loss: 0.150 
(epoch: 133, iters: 9696, time: 0.165, data: 0.000) loss: 0.285 
(epoch: 133, iters: 9776, time: 0.168, data: 0.000) loss: 0.157 
(epoch: 133, iters: 9856, time: 0.165, data: 0.008) loss: 0.125 
(epoch: 133, iters: 9936, time: 0.167, data: 0.000) loss: 0.274 
(epoch: 133, iters: 10016, time: 0.166, data: 0.005) loss: 0.246 
(epoch: 133, iters: 10096, time: 0.166, data: 0.000) loss: 0.354 
(epoch: 133, iters: 10176, time: 0.165, data: 0.018) loss: 0.403 
saving the model at the end of epoch 133, iters 1355536
End of epoch 133 / 200 	 Time Taken: 1698 sec
learning rate = 0.0001307
saving the latest model (epoch 134, total_steps 1355552)
(epoch: 134, iters: 64, time: 0.165, data: 0.003) loss: 0.472 
(epoch: 134, iters: 144, time: 0.167, data: 0.000) loss: 0.568 
(epoch: 134, iters: 224, time: 0.166, data: 0.000) loss: 0.508 
(epoch: 134, iters: 304, time: 0.168, data: 0.000) loss: 0.364 
(epoch: 134, iters: 384, time: 0.167, data: 0.000) loss: 0.079 
(epoch: 134, iters: 464, time: 0.167, data: 0.000) loss: 0.133 
(epoch: 134, iters: 544, time: 0.167, data: 0.005) loss: 0.485 
(epoch: 134, iters: 624, time: 0.167, data: 0.000) loss: 0.616 
(epoch: 134, iters: 704, time: 0.166, data: 0.005) loss: 0.163 
(epoch: 134, iters: 784, time: 0.166, data: 0.005) loss: 0.592 
(epoch: 134, iters: 864, time: 0.165, data: 0.000) loss: 0.219 
(epoch: 134, iters: 944, time: 0.165, data: 0.005) loss: 0.380 
(epoch: 134, iters: 1024, time: 0.166, data: 0.000) loss: 0.441 
(epoch: 134, iters: 1104, time: 0.166, data: 0.005) loss: 0.158 
(epoch: 134, iters: 1184, time: 0.166, data: 0.024) loss: 0.417 
(epoch: 134, iters: 1264, time: 0.167, data: 0.000) loss: 0.400 
(epoch: 134, iters: 1344, time: 0.166, data: 0.011) loss: 0.535 
(epoch: 134, iters: 1424, time: 0.167, data: 0.005) loss: 0.193 
(epoch: 134, iters: 1504, time: 0.168, data: 0.017) loss: 0.433 
(epoch: 134, iters: 1584, time: 0.168, data: 0.000) loss: 0.315 
(epoch: 134, iters: 1664, time: 0.173, data: 0.000) loss: 0.158 
(epoch: 134, iters: 1744, time: 0.167, data: 0.005) loss: 0.287 
(epoch: 134, iters: 1824, time: 0.167, data: 0.000) loss: 0.474 
(epoch: 134, iters: 1904, time: 0.166, data: 0.025) loss: 0.324 
(epoch: 134, iters: 1984, time: 0.167, data: 0.000) loss: 1.271 
(epoch: 134, iters: 2064, time: 0.168, data: 0.000) loss: 0.317 
(epoch: 134, iters: 2144, time: 0.165, data: 0.005) loss: 0.360 
(epoch: 134, iters: 2224, time: 0.166, data: 0.015) loss: 0.721 
(epoch: 134, iters: 2304, time: 0.167, data: 0.032) loss: 0.303 
(epoch: 134, iters: 2384, time: 0.166, data: 0.000) loss: 0.053 
(epoch: 134, iters: 2464, time: 0.167, data: 0.000) loss: 0.693 
(epoch: 134, iters: 2544, time: 0.164, data: 0.005) loss: 0.154 
(epoch: 134, iters: 2624, time: 0.166, data: 0.000) loss: 0.378 
(epoch: 134, iters: 2704, time: 0.165, data: 0.006) loss: 0.664 
(epoch: 134, iters: 2784, time: 0.170, data: 0.000) loss: 0.451 
(epoch: 134, iters: 2864, time: 0.165, data: 0.016) loss: 0.306 
(epoch: 134, iters: 2944, time: 0.167, data: 0.000) loss: 0.508 
(epoch: 134, iters: 3024, time: 0.168, data: 0.005) loss: 0.151 
(epoch: 134, iters: 3104, time: 0.166, data: 0.000) loss: 0.079 
(epoch: 134, iters: 3184, time: 0.168, data: 0.000) loss: 0.545 
(epoch: 134, iters: 3264, time: 0.164, data: 0.000) loss: 0.146 
(epoch: 134, iters: 3344, time: 0.167, data: 0.000) loss: 0.128 
(epoch: 134, iters: 3424, time: 0.167, data: 0.006) loss: 0.275 
(epoch: 134, iters: 3504, time: 0.166, data: 0.013) loss: 0.240 
(epoch: 134, iters: 3584, time: 0.166, data: 0.000) loss: 0.200 
(epoch: 134, iters: 3664, time: 0.165, data: 0.021) loss: 0.284 
(epoch: 134, iters: 3744, time: 0.165, data: 0.000) loss: 0.257 
(epoch: 134, iters: 3824, time: 0.166, data: 0.000) loss: 0.233 
(epoch: 134, iters: 3904, time: 0.173, data: 0.000) loss: 0.181 
(epoch: 134, iters: 3984, time: 0.165, data: 0.014) loss: 0.365 
saving the latest model (epoch 134, total_steps 1359552)
(epoch: 134, iters: 4064, time: 0.166, data: 0.000) loss: 0.338 
(epoch: 134, iters: 4144, time: 0.166, data: 0.025) loss: 0.377 
(epoch: 134, iters: 4224, time: 0.165, data: 0.000) loss: 0.300 
(epoch: 134, iters: 4304, time: 0.166, data: 0.000) loss: 0.243 
(epoch: 134, iters: 4384, time: 0.168, data: 0.000) loss: 0.209 
(epoch: 134, iters: 4464, time: 0.166, data: 0.019) loss: 0.327 
(epoch: 134, iters: 4544, time: 0.165, data: 0.000) loss: 0.234 
(epoch: 134, iters: 4624, time: 0.166, data: 0.000) loss: 0.515 
(epoch: 134, iters: 4704, time: 0.166, data: 0.016) loss: 0.452 
(epoch: 134, iters: 4784, time: 0.166, data: 0.000) loss: 0.306 
(epoch: 134, iters: 4864, time: 0.166, data: 0.024) loss: 0.249 
(epoch: 134, iters: 4944, time: 0.166, data: 0.005) loss: 0.120 
(epoch: 134, iters: 5024, time: 0.165, data: 0.018) loss: 0.530 
(epoch: 134, iters: 5104, time: 0.166, data: 0.000) loss: 0.359 
(epoch: 134, iters: 5184, time: 0.166, data: 0.006) loss: 0.043 
(epoch: 134, iters: 5264, time: 0.165, data: 0.005) loss: 0.152 
(epoch: 134, iters: 5344, time: 0.167, data: 0.025) loss: 0.449 
(epoch: 134, iters: 5424, time: 0.165, data: 0.000) loss: 0.276 
(epoch: 134, iters: 5504, time: 0.166, data: 0.029) loss: 0.344 
(epoch: 134, iters: 5584, time: 0.168, data: 0.018) loss: 0.231 
(epoch: 134, iters: 5664, time: 0.165, data: 0.033) loss: 0.333 
(epoch: 134, iters: 5744, time: 0.167, data: 0.000) loss: 0.601 
(epoch: 134, iters: 5824, time: 0.167, data: 0.032) loss: 0.501 
(epoch: 134, iters: 5904, time: 0.166, data: 0.000) loss: 0.412 
(epoch: 134, iters: 5984, time: 0.164, data: 0.024) loss: 0.644 
(epoch: 134, iters: 6064, time: 0.166, data: 0.000) loss: 0.244 
(epoch: 134, iters: 6144, time: 0.164, data: 0.016) loss: 0.159 
(epoch: 134, iters: 6224, time: 0.165, data: 0.000) loss: 0.306 
(epoch: 134, iters: 6304, time: 0.165, data: 0.000) loss: 0.142 
(epoch: 134, iters: 6384, time: 0.167, data: 0.006) loss: 0.070 
(epoch: 134, iters: 6464, time: 0.166, data: 0.016) loss: 0.366 
(epoch: 134, iters: 6544, time: 0.169, data: 0.011) loss: 0.293 
(epoch: 134, iters: 6624, time: 0.166, data: 0.009) loss: 0.370 
(epoch: 134, iters: 6704, time: 0.168, data: 0.000) loss: 0.597 
(epoch: 134, iters: 6784, time: 0.168, data: 0.000) loss: 0.371 
(epoch: 134, iters: 6864, time: 0.172, data: 0.027) loss: 0.317 
(epoch: 134, iters: 6944, time: 0.166, data: 0.000) loss: 0.391 
(epoch: 134, iters: 7024, time: 0.167, data: 0.000) loss: 0.571 
(epoch: 134, iters: 7104, time: 0.166, data: 0.005) loss: 0.735 
(epoch: 134, iters: 7184, time: 0.168, data: 0.014) loss: 0.439 
(epoch: 134, iters: 7264, time: 0.168, data: 0.005) loss: 0.683 
(epoch: 134, iters: 7344, time: 0.165, data: 0.000) loss: 1.011 
(epoch: 134, iters: 7424, time: 0.167, data: 0.027) loss: 0.131 
(epoch: 134, iters: 7504, time: 0.166, data: 0.000) loss: 0.632 
(epoch: 134, iters: 7584, time: 0.165, data: 0.000) loss: 0.404 
(epoch: 134, iters: 7664, time: 0.169, data: 0.005) loss: 0.161 
(epoch: 134, iters: 7744, time: 0.168, data: 0.005) loss: 0.400 
(epoch: 134, iters: 7824, time: 0.168, data: 0.000) loss: 0.239 
(epoch: 134, iters: 7904, time: 0.166, data: 0.006) loss: 0.244 
(epoch: 134, iters: 7984, time: 0.175, data: 0.005) loss: 0.631 
saving the latest model (epoch 134, total_steps 1363552)
(epoch: 134, iters: 8064, time: 0.167, data: 0.000) loss: 0.480 
(epoch: 134, iters: 8144, time: 0.168, data: 0.033) loss: 0.483 
(epoch: 134, iters: 8224, time: 0.167, data: 0.000) loss: 0.087 
(epoch: 134, iters: 8304, time: 0.166, data: 0.006) loss: 0.331 
(epoch: 134, iters: 8384, time: 0.167, data: 0.009) loss: 0.234 
(epoch: 134, iters: 8464, time: 0.165, data: 0.005) loss: 0.348 
(epoch: 134, iters: 8544, time: 0.168, data: 0.024) loss: 0.430 
(epoch: 134, iters: 8624, time: 0.167, data: 0.000) loss: 0.255 
(epoch: 134, iters: 8704, time: 0.166, data: 0.009) loss: 0.266 
(epoch: 134, iters: 8784, time: 0.165, data: 0.000) loss: 0.209 
(epoch: 134, iters: 8864, time: 0.165, data: 0.000) loss: 0.616 
(epoch: 134, iters: 8944, time: 0.165, data: 0.000) loss: 0.180 
(epoch: 134, iters: 9024, time: 0.167, data: 0.000) loss: 0.410 
(epoch: 134, iters: 9104, time: 0.172, data: 0.005) loss: 0.096 
(epoch: 134, iters: 9184, time: 0.165, data: 0.013) loss: 0.375 
(epoch: 134, iters: 9264, time: 0.168, data: 0.000) loss: 0.586 
(epoch: 134, iters: 9344, time: 0.165, data: 0.006) loss: 0.459 
(epoch: 134, iters: 9424, time: 0.164, data: 0.000) loss: 0.234 
(epoch: 134, iters: 9504, time: 0.168, data: 0.000) loss: 0.441 
(epoch: 134, iters: 9584, time: 0.167, data: 0.000) loss: 0.352 
(epoch: 134, iters: 9664, time: 0.166, data: 0.000) loss: 0.608 
(epoch: 134, iters: 9744, time: 0.166, data: 0.000) loss: 0.346 
(epoch: 134, iters: 9824, time: 0.166, data: 0.014) loss: 0.396 
(epoch: 134, iters: 9904, time: 0.167, data: 0.000) loss: 0.353 
(epoch: 134, iters: 9984, time: 0.167, data: 0.000) loss: 0.143 
(epoch: 134, iters: 10064, time: 0.164, data: 0.000) loss: 0.154 
(epoch: 134, iters: 10144, time: 0.164, data: 0.008) loss: 0.680 
saving the model at the end of epoch 134, iters 1365728
End of epoch 134 / 200 	 Time Taken: 1701 sec
learning rate = 0.0001287
saving the latest model (epoch 135, total_steps 1365744)
(epoch: 135, iters: 32, time: 0.171, data: 0.005) loss: 0.252 
(epoch: 135, iters: 112, time: 0.164, data: 0.000) loss: 0.425 
(epoch: 135, iters: 192, time: 0.165, data: 0.020) loss: 0.158 
(epoch: 135, iters: 272, time: 0.164, data: 0.017) loss: 0.388 
(epoch: 135, iters: 352, time: 0.166, data: 0.006) loss: 0.115 
(epoch: 135, iters: 432, time: 0.166, data: 0.000) loss: 0.198 
(epoch: 135, iters: 512, time: 0.167, data: 0.027) loss: 0.157 
(epoch: 135, iters: 592, time: 0.165, data: 0.000) loss: 0.097 
(epoch: 135, iters: 672, time: 0.165, data: 0.009) loss: 0.312 
(epoch: 135, iters: 752, time: 0.164, data: 0.000) loss: 0.191 
(epoch: 135, iters: 832, time: 0.164, data: 0.016) loss: 0.595 
(epoch: 135, iters: 912, time: 0.167, data: 0.000) loss: 0.103 
(epoch: 135, iters: 992, time: 0.167, data: 0.017) loss: 0.166 
(epoch: 135, iters: 1072, time: 0.169, data: 0.000) loss: 0.218 
(epoch: 135, iters: 1152, time: 0.168, data: 0.031) loss: 0.336 
(epoch: 135, iters: 1232, time: 0.170, data: 0.000) loss: 0.477 
(epoch: 135, iters: 1312, time: 0.166, data: 0.006) loss: 0.426 
(epoch: 135, iters: 1392, time: 0.167, data: 0.000) loss: 0.223 
(epoch: 135, iters: 1472, time: 0.166, data: 0.000) loss: 0.383 
(epoch: 135, iters: 1552, time: 0.167, data: 0.000) loss: 0.430 
(epoch: 135, iters: 1632, time: 0.167, data: 0.005) loss: 0.098 
(epoch: 135, iters: 1712, time: 0.169, data: 0.000) loss: 0.396 
(epoch: 135, iters: 1792, time: 0.167, data: 0.017) loss: 0.480 
(epoch: 135, iters: 1872, time: 0.175, data: 0.000) loss: 0.523 
(epoch: 135, iters: 1952, time: 0.165, data: 0.017) loss: 0.463 
(epoch: 135, iters: 2032, time: 0.164, data: 0.005) loss: 0.403 
(epoch: 135, iters: 2112, time: 0.166, data: 0.005) loss: 0.199 
(epoch: 135, iters: 2192, time: 0.165, data: 0.005) loss: 0.277 
(epoch: 135, iters: 2272, time: 0.166, data: 0.000) loss: 0.078 
(epoch: 135, iters: 2352, time: 0.167, data: 0.000) loss: 0.332 
(epoch: 135, iters: 2432, time: 0.166, data: 0.000) loss: 0.342 
(epoch: 135, iters: 2512, time: 0.165, data: 0.000) loss: 0.088 
(epoch: 135, iters: 2592, time: 0.166, data: 0.006) loss: 0.463 
(epoch: 135, iters: 2672, time: 0.167, data: 0.005) loss: 0.299 
(epoch: 135, iters: 2752, time: 0.166, data: 0.013) loss: 0.760 
(epoch: 135, iters: 2832, time: 0.165, data: 0.016) loss: 0.325 
(epoch: 135, iters: 2912, time: 0.166, data: 0.000) loss: 0.060 
(epoch: 135, iters: 2992, time: 0.171, data: 0.033) loss: 0.417 
(epoch: 135, iters: 3072, time: 0.167, data: 0.000) loss: 0.388 
(epoch: 135, iters: 3152, time: 0.165, data: 0.014) loss: 0.325 
(epoch: 135, iters: 3232, time: 0.166, data: 0.008) loss: 0.353 
(epoch: 135, iters: 3312, time: 0.165, data: 0.000) loss: 0.352 
(epoch: 135, iters: 3392, time: 0.168, data: 0.005) loss: 0.172 
(epoch: 135, iters: 3472, time: 0.167, data: 0.000) loss: 0.569 
(epoch: 135, iters: 3552, time: 0.167, data: 0.006) loss: 0.683 
(epoch: 135, iters: 3632, time: 0.166, data: 0.000) loss: 0.495 
(epoch: 135, iters: 3712, time: 0.168, data: 0.000) loss: 0.235 
(epoch: 135, iters: 3792, time: 0.167, data: 0.018) loss: 0.213 
(epoch: 135, iters: 3872, time: 0.166, data: 0.024) loss: 0.455 
(epoch: 135, iters: 3952, time: 0.165, data: 0.000) loss: 0.695 
saving the latest model (epoch 135, total_steps 1369744)
(epoch: 135, iters: 4032, time: 0.166, data: 0.000) loss: 0.405 
(epoch: 135, iters: 4112, time: 0.172, data: 0.010) loss: 0.611 
(epoch: 135, iters: 4192, time: 0.166, data: 0.000) loss: 0.336 
(epoch: 135, iters: 4272, time: 0.165, data: 0.000) loss: 0.862 
(epoch: 135, iters: 4352, time: 0.165, data: 0.009) loss: 0.588 
(epoch: 135, iters: 4432, time: 0.166, data: 0.000) loss: 0.187 
(epoch: 135, iters: 4512, time: 0.166, data: 0.000) loss: 0.296 
(epoch: 135, iters: 4592, time: 0.167, data: 0.000) loss: 0.206 
(epoch: 135, iters: 4672, time: 0.165, data: 0.000) loss: 0.049 
(epoch: 135, iters: 4752, time: 0.167, data: 0.005) loss: 0.837 
(epoch: 135, iters: 4832, time: 0.166, data: 0.005) loss: 0.120 
(epoch: 135, iters: 4912, time: 0.166, data: 0.008) loss: 0.313 
(epoch: 135, iters: 4992, time: 0.164, data: 0.000) loss: 0.262 
(epoch: 135, iters: 5072, time: 0.165, data: 0.000) loss: 0.150 
(epoch: 135, iters: 5152, time: 0.167, data: 0.027) loss: 0.227 
(epoch: 135, iters: 5232, time: 0.167, data: 0.000) loss: 0.692 
(epoch: 135, iters: 5312, time: 0.165, data: 0.000) loss: 0.226 
(epoch: 135, iters: 5392, time: 0.164, data: 0.006) loss: 0.203 
(epoch: 135, iters: 5472, time: 0.168, data: 0.021) loss: 0.195 
(epoch: 135, iters: 5552, time: 0.166, data: 0.019) loss: 0.226 
(epoch: 135, iters: 5632, time: 0.168, data: 0.000) loss: 0.275 
(epoch: 135, iters: 5712, time: 0.170, data: 0.000) loss: 0.268 
(epoch: 135, iters: 5792, time: 0.164, data: 0.016) loss: 0.311 
(epoch: 135, iters: 5872, time: 0.165, data: 0.000) loss: 0.848 
(epoch: 135, iters: 5952, time: 0.169, data: 0.024) loss: 0.420 
(epoch: 135, iters: 6032, time: 0.166, data: 0.000) loss: 0.675 
(epoch: 135, iters: 6112, time: 0.166, data: 0.011) loss: 0.098 
(epoch: 135, iters: 6192, time: 0.168, data: 0.000) loss: 0.234 
(epoch: 135, iters: 6272, time: 0.165, data: 0.012) loss: 0.212 
(epoch: 135, iters: 6352, time: 0.165, data: 0.000) loss: 0.350 
(epoch: 135, iters: 6432, time: 0.165, data: 0.000) loss: 0.641 
(epoch: 135, iters: 6512, time: 0.166, data: 0.000) loss: 0.276 
(epoch: 135, iters: 6592, time: 0.166, data: 0.010) loss: 0.216 
(epoch: 135, iters: 6672, time: 0.166, data: 0.000) loss: 0.172 
(epoch: 135, iters: 6752, time: 0.167, data: 0.005) loss: 0.241 
(epoch: 135, iters: 6832, time: 0.167, data: 0.015) loss: 0.188 
(epoch: 135, iters: 6912, time: 0.165, data: 0.000) loss: 0.371 
(epoch: 135, iters: 6992, time: 0.165, data: 0.006) loss: 0.178 
(epoch: 135, iters: 7072, time: 0.172, data: 0.000) loss: 0.617 
(epoch: 135, iters: 7152, time: 0.166, data: 0.000) loss: 0.372 
(epoch: 135, iters: 7232, time: 0.166, data: 0.024) loss: 0.482 
(epoch: 135, iters: 7312, time: 0.167, data: 0.000) loss: 0.176 
(epoch: 135, iters: 7392, time: 0.166, data: 0.000) loss: 0.348 
(epoch: 135, iters: 7472, time: 0.166, data: 0.017) loss: 0.298 
(epoch: 135, iters: 7552, time: 0.167, data: 0.019) loss: 0.277 
(epoch: 135, iters: 7632, time: 0.168, data: 0.000) loss: 0.166 
(epoch: 135, iters: 7712, time: 0.167, data: 0.005) loss: 0.236 
(epoch: 135, iters: 7792, time: 0.168, data: 0.000) loss: 0.309 
(epoch: 135, iters: 7872, time: 0.167, data: 0.000) loss: 0.617 
(epoch: 135, iters: 7952, time: 0.166, data: 0.005) loss: 0.395 
saving the latest model (epoch 135, total_steps 1373744)
(epoch: 135, iters: 8032, time: 0.166, data: 0.000) loss: 0.263 
(epoch: 135, iters: 8112, time: 0.167, data: 0.015) loss: 0.972 
(epoch: 135, iters: 8192, time: 0.173, data: 0.010) loss: 0.445 
(epoch: 135, iters: 8272, time: 0.167, data: 0.000) loss: 0.059 
(epoch: 135, iters: 8352, time: 0.165, data: 0.000) loss: 0.633 
(epoch: 135, iters: 8432, time: 0.166, data: 0.005) loss: 0.398 
(epoch: 135, iters: 8512, time: 0.166, data: 0.000) loss: 0.260 
(epoch: 135, iters: 8592, time: 0.164, data: 0.005) loss: 0.200 
(epoch: 135, iters: 8672, time: 0.166, data: 0.005) loss: 0.664 
(epoch: 135, iters: 8752, time: 0.165, data: 0.010) loss: 0.498 
(epoch: 135, iters: 8832, time: 0.165, data: 0.000) loss: 0.387 
(epoch: 135, iters: 8912, time: 0.166, data: 0.000) loss: 0.682 
(epoch: 135, iters: 8992, time: 0.163, data: 0.000) loss: 0.465 
(epoch: 135, iters: 9072, time: 0.167, data: 0.005) loss: 0.407 
(epoch: 135, iters: 9152, time: 0.166, data: 0.000) loss: 0.577 
(epoch: 135, iters: 9232, time: 0.166, data: 0.006) loss: 0.381 
(epoch: 135, iters: 9312, time: 0.172, data: 0.000) loss: 0.903 
(epoch: 135, iters: 9392, time: 0.167, data: 0.017) loss: 0.276 
(epoch: 135, iters: 9472, time: 0.166, data: 0.000) loss: 0.597 
(epoch: 135, iters: 9552, time: 0.167, data: 0.011) loss: 0.261 
(epoch: 135, iters: 9632, time: 0.165, data: 0.021) loss: 0.231 
(epoch: 135, iters: 9712, time: 0.167, data: 0.000) loss: 0.456 
(epoch: 135, iters: 9792, time: 0.166, data: 0.000) loss: 0.338 
(epoch: 135, iters: 9872, time: 0.165, data: 0.000) loss: 0.335 
(epoch: 135, iters: 9952, time: 0.166, data: 0.006) loss: 0.560 
(epoch: 135, iters: 10032, time: 0.165, data: 0.008) loss: 0.271 
(epoch: 135, iters: 10112, time: 0.166, data: 0.008) loss: 0.180 
(epoch: 135, iters: 10192, time: 0.101, data: 0.000) loss: 0.339 
saving the model at the end of epoch 135, iters 1375920
End of epoch 135 / 200 	 Time Taken: 1701 sec
learning rate = 0.0001267
saving the latest model (epoch 136, total_steps 1375936)
(epoch: 136, iters: 80, time: 0.168, data: 0.184) loss: 0.343 
(epoch: 136, iters: 160, time: 0.168, data: 0.033) loss: 0.353 
(epoch: 136, iters: 240, time: 0.171, data: 0.000) loss: 0.039 
(epoch: 136, iters: 320, time: 0.164, data: 0.000) loss: 0.814 
(epoch: 136, iters: 400, time: 0.167, data: 0.000) loss: 0.160 
(epoch: 136, iters: 480, time: 0.164, data: 0.009) loss: 0.303 
(epoch: 136, iters: 560, time: 0.164, data: 0.005) loss: 0.281 
(epoch: 136, iters: 640, time: 0.165, data: 0.000) loss: 0.486 
(epoch: 136, iters: 720, time: 0.163, data: 0.006) loss: 0.121 
(epoch: 136, iters: 800, time: 0.166, data: 0.000) loss: 0.474 
(epoch: 136, iters: 880, time: 0.165, data: 0.020) loss: 0.707 
(epoch: 136, iters: 960, time: 0.165, data: 0.000) loss: 0.209 
(epoch: 136, iters: 1040, time: 0.167, data: 0.000) loss: 0.300 
(epoch: 136, iters: 1120, time: 0.165, data: 0.032) loss: 0.392 
(epoch: 136, iters: 1200, time: 0.168, data: 0.000) loss: 0.506 
(epoch: 136, iters: 1280, time: 0.167, data: 0.000) loss: 0.238 
(epoch: 136, iters: 1360, time: 0.171, data: 0.005) loss: 0.991 
(epoch: 136, iters: 1440, time: 0.165, data: 0.005) loss: 0.438 
(epoch: 136, iters: 1520, time: 0.165, data: 0.018) loss: 0.592 
(epoch: 136, iters: 1600, time: 0.166, data: 0.000) loss: 0.544 
(epoch: 136, iters: 1680, time: 0.165, data: 0.005) loss: 0.527 
(epoch: 136, iters: 1760, time: 0.162, data: 0.000) loss: 0.229 
(epoch: 136, iters: 1840, time: 0.165, data: 0.024) loss: 0.194 
(epoch: 136, iters: 1920, time: 0.166, data: 0.000) loss: 0.410 
(epoch: 136, iters: 2000, time: 0.165, data: 0.005) loss: 0.928 
(epoch: 136, iters: 2080, time: 0.167, data: 0.000) loss: 0.576 
(epoch: 136, iters: 2160, time: 0.169, data: 0.013) loss: 0.209 
(epoch: 136, iters: 2240, time: 0.168, data: 0.000) loss: 0.308 
(epoch: 136, iters: 2320, time: 0.167, data: 0.006) loss: 0.439 
(epoch: 136, iters: 2400, time: 0.166, data: 0.006) loss: 0.314 
(epoch: 136, iters: 2480, time: 0.172, data: 0.030) loss: 0.207 
(epoch: 136, iters: 2560, time: 0.165, data: 0.000) loss: 0.121 
(epoch: 136, iters: 2640, time: 0.165, data: 0.000) loss: 0.604 
(epoch: 136, iters: 2720, time: 0.164, data: 0.000) loss: 0.264 
(epoch: 136, iters: 2800, time: 0.166, data: 0.026) loss: 0.361 
(epoch: 136, iters: 2880, time: 0.166, data: 0.000) loss: 0.301 
(epoch: 136, iters: 2960, time: 0.168, data: 0.005) loss: 0.291 
(epoch: 136, iters: 3040, time: 0.165, data: 0.000) loss: 0.585 
(epoch: 136, iters: 3120, time: 0.165, data: 0.010) loss: 0.340 
(epoch: 136, iters: 3200, time: 0.165, data: 0.000) loss: 0.057 
(epoch: 136, iters: 3280, time: 0.165, data: 0.000) loss: 0.309 
(epoch: 136, iters: 3360, time: 0.165, data: 0.000) loss: 0.393 
(epoch: 136, iters: 3440, time: 0.166, data: 0.000) loss: 0.466 
(epoch: 136, iters: 3520, time: 0.163, data: 0.005) loss: 0.708 
(epoch: 136, iters: 3600, time: 0.170, data: 0.000) loss: 0.589 
(epoch: 136, iters: 3680, time: 0.164, data: 0.000) loss: 0.320 
(epoch: 136, iters: 3760, time: 0.166, data: 0.014) loss: 0.376 
(epoch: 136, iters: 3840, time: 0.163, data: 0.000) loss: 0.655 
(epoch: 136, iters: 3920, time: 0.163, data: 0.000) loss: 0.279 
(epoch: 136, iters: 4000, time: 0.164, data: 0.000) loss: 0.356 
saving the latest model (epoch 136, total_steps 1379936)
(epoch: 136, iters: 4080, time: 0.165, data: 0.024) loss: 0.290 
(epoch: 136, iters: 4160, time: 0.168, data: 0.000) loss: 0.428 
(epoch: 136, iters: 4240, time: 0.166, data: 0.006) loss: 0.283 
(epoch: 136, iters: 4320, time: 0.165, data: 0.000) loss: 0.219 
(epoch: 136, iters: 4400, time: 0.164, data: 0.000) loss: 0.764 
(epoch: 136, iters: 4480, time: 0.165, data: 0.000) loss: 0.381 
(epoch: 136, iters: 4560, time: 0.166, data: 0.000) loss: 0.477 
(epoch: 136, iters: 4640, time: 0.166, data: 0.000) loss: 0.173 
(epoch: 136, iters: 4720, time: 0.173, data: 0.000) loss: 0.176 
(epoch: 136, iters: 4800, time: 0.165, data: 0.000) loss: 0.394 
(epoch: 136, iters: 4880, time: 0.164, data: 0.000) loss: 0.244 
(epoch: 136, iters: 4960, time: 0.168, data: 0.000) loss: 0.423 
(epoch: 136, iters: 5040, time: 0.165, data: 0.006) loss: 0.290 
(epoch: 136, iters: 5120, time: 0.164, data: 0.000) loss: 0.457 
(epoch: 136, iters: 5200, time: 0.165, data: 0.011) loss: 0.363 
(epoch: 136, iters: 5280, time: 0.166, data: 0.000) loss: 0.444 
(epoch: 136, iters: 5360, time: 0.165, data: 0.024) loss: 0.393 
(epoch: 136, iters: 5440, time: 0.165, data: 0.000) loss: 0.238 
(epoch: 136, iters: 5520, time: 0.165, data: 0.000) loss: 0.396 
(epoch: 136, iters: 5600, time: 0.164, data: 0.000) loss: 0.444 
(epoch: 136, iters: 5680, time: 0.164, data: 0.000) loss: 0.173 
(epoch: 136, iters: 5760, time: 0.165, data: 0.026) loss: 0.344 
(epoch: 136, iters: 5840, time: 0.167, data: 0.000) loss: 0.210 
(epoch: 136, iters: 5920, time: 0.163, data: 0.000) loss: 0.130 
(epoch: 136, iters: 6000, time: 0.165, data: 0.000) loss: 0.198 
(epoch: 136, iters: 6080, time: 0.167, data: 0.000) loss: 0.866 
(epoch: 136, iters: 6160, time: 0.167, data: 0.000) loss: 0.786 
(epoch: 136, iters: 6240, time: 0.166, data: 0.010) loss: 0.319 
(epoch: 136, iters: 6320, time: 0.168, data: 0.000) loss: 0.561 
(epoch: 136, iters: 6400, time: 0.165, data: 0.031) loss: 0.556 
(epoch: 136, iters: 6480, time: 0.165, data: 0.000) loss: 0.224 
(epoch: 136, iters: 6560, time: 0.163, data: 0.000) loss: 0.317 
(epoch: 136, iters: 6640, time: 0.164, data: 0.005) loss: 0.162 
(epoch: 136, iters: 6720, time: 0.168, data: 0.005) loss: 0.162 
(epoch: 136, iters: 6800, time: 0.164, data: 0.000) loss: 0.787 
(epoch: 136, iters: 6880, time: 0.165, data: 0.018) loss: 0.063 
(epoch: 136, iters: 6960, time: 0.164, data: 0.000) loss: 0.823 
(epoch: 136, iters: 7040, time: 0.168, data: 0.000) loss: 0.220 
(epoch: 136, iters: 7120, time: 0.168, data: 0.000) loss: 0.524 
(epoch: 136, iters: 7200, time: 0.166, data: 0.005) loss: 0.275 
(epoch: 136, iters: 7280, time: 0.165, data: 0.000) loss: 0.073 
(epoch: 136, iters: 7360, time: 0.165, data: 0.010) loss: 0.142 
(epoch: 136, iters: 7440, time: 0.168, data: 0.005) loss: 0.212 
(epoch: 136, iters: 7520, time: 0.165, data: 0.014) loss: 0.158 
(epoch: 136, iters: 7600, time: 0.166, data: 0.020) loss: 1.085 
(epoch: 136, iters: 7680, time: 0.165, data: 0.000) loss: 0.059 
(epoch: 136, iters: 7760, time: 0.165, data: 0.000) loss: 0.218 
(epoch: 136, iters: 7840, time: 0.163, data: 0.006) loss: 0.448 
(epoch: 136, iters: 7920, time: 0.167, data: 0.008) loss: 0.465 
(epoch: 136, iters: 8000, time: 0.163, data: 0.021) loss: 0.378 
saving the latest model (epoch 136, total_steps 1383936)
(epoch: 136, iters: 8080, time: 0.166, data: 0.000) loss: 0.054 
(epoch: 136, iters: 8160, time: 0.162, data: 0.000) loss: 0.111 
(epoch: 136, iters: 8240, time: 0.163, data: 0.006) loss: 0.055 
(epoch: 136, iters: 8320, time: 0.165, data: 0.000) loss: 0.444 
(epoch: 136, iters: 8400, time: 0.166, data: 0.013) loss: 0.352 
(epoch: 136, iters: 8480, time: 0.165, data: 0.005) loss: 0.171 
(epoch: 136, iters: 8560, time: 0.165, data: 0.000) loss: 0.267 
(epoch: 136, iters: 8640, time: 0.164, data: 0.013) loss: 0.231 
(epoch: 136, iters: 8720, time: 0.167, data: 0.015) loss: 0.124 
(epoch: 136, iters: 8800, time: 0.165, data: 0.024) loss: 0.315 
(epoch: 136, iters: 8880, time: 0.165, data: 0.000) loss: 0.500 
(epoch: 136, iters: 8960, time: 0.164, data: 0.000) loss: 0.483 
(epoch: 136, iters: 9040, time: 0.164, data: 0.000) loss: 0.622 
(epoch: 136, iters: 9120, time: 0.167, data: 0.037) loss: 0.475 
(epoch: 136, iters: 9200, time: 0.167, data: 0.000) loss: 0.441 
(epoch: 136, iters: 9280, time: 0.165, data: 0.030) loss: 0.434 
(epoch: 136, iters: 9360, time: 0.166, data: 0.000) loss: 0.229 
(epoch: 136, iters: 9440, time: 0.167, data: 0.000) loss: 0.435 
(epoch: 136, iters: 9520, time: 0.165, data: 0.000) loss: 0.235 
(epoch: 136, iters: 9600, time: 0.164, data: 0.013) loss: 0.446 
(epoch: 136, iters: 9680, time: 0.164, data: 0.010) loss: 0.299 
(epoch: 136, iters: 9760, time: 0.166, data: 0.008) loss: 0.357 
(epoch: 136, iters: 9840, time: 0.165, data: 0.014) loss: 0.477 
(epoch: 136, iters: 9920, time: 0.166, data: 0.000) loss: 0.165 
(epoch: 136, iters: 10000, time: 0.163, data: 0.020) loss: 0.655 
(epoch: 136, iters: 10080, time: 0.167, data: 0.009) loss: 0.312 
(epoch: 136, iters: 10160, time: 0.165, data: 0.009) loss: 0.593 
saving the model at the end of epoch 136, iters 1386112
End of epoch 136 / 200 	 Time Taken: 1692 sec
learning rate = 0.0001248
saving the latest model (epoch 137, total_steps 1386128)
(epoch: 137, iters: 48, time: 0.169, data: 0.000) loss: 0.592 
(epoch: 137, iters: 128, time: 0.165, data: 0.017) loss: 0.183 
(epoch: 137, iters: 208, time: 0.167, data: 0.000) loss: 0.510 
(epoch: 137, iters: 288, time: 0.167, data: 0.022) loss: 0.320 
(epoch: 137, iters: 368, time: 0.168, data: 0.021) loss: 0.437 
(epoch: 137, iters: 448, time: 0.167, data: 0.000) loss: 0.160 
(epoch: 137, iters: 528, time: 0.169, data: 0.032) loss: 0.729 
(epoch: 137, iters: 608, time: 0.165, data: 0.000) loss: 0.210 
(epoch: 137, iters: 688, time: 0.166, data: 0.000) loss: 0.512 
(epoch: 137, iters: 768, time: 0.166, data: 0.000) loss: 0.400 
(epoch: 137, iters: 848, time: 0.168, data: 0.000) loss: 0.423 
(epoch: 137, iters: 928, time: 0.166, data: 0.018) loss: 0.340 
(epoch: 137, iters: 1008, time: 0.166, data: 0.000) loss: 0.433 
(epoch: 137, iters: 1088, time: 0.166, data: 0.000) loss: 0.197 
(epoch: 137, iters: 1168, time: 0.166, data: 0.017) loss: 0.509 
(epoch: 137, iters: 1248, time: 0.166, data: 0.000) loss: 0.332 
(epoch: 137, iters: 1328, time: 0.167, data: 0.000) loss: 0.103 
(epoch: 137, iters: 1408, time: 0.165, data: 0.016) loss: 0.198 
(epoch: 137, iters: 1488, time: 0.170, data: 0.000) loss: 0.780 
(epoch: 137, iters: 1568, time: 0.166, data: 0.018) loss: 0.240 
(epoch: 137, iters: 1648, time: 0.166, data: 0.010) loss: 1.024 
(epoch: 137, iters: 1728, time: 0.165, data: 0.000) loss: 0.506 
(epoch: 137, iters: 1808, time: 0.165, data: 0.000) loss: 0.266 
(epoch: 137, iters: 1888, time: 0.163, data: 0.015) loss: 0.085 
(epoch: 137, iters: 1968, time: 0.165, data: 0.023) loss: 0.317 
(epoch: 137, iters: 2048, time: 0.167, data: 0.000) loss: 0.260 
(epoch: 137, iters: 2128, time: 0.167, data: 0.000) loss: 0.344 
(epoch: 137, iters: 2208, time: 0.165, data: 0.008) loss: 0.232 
(epoch: 137, iters: 2288, time: 0.164, data: 0.000) loss: 0.252 
(epoch: 137, iters: 2368, time: 0.164, data: 0.000) loss: 0.453 
(epoch: 137, iters: 2448, time: 0.166, data: 0.000) loss: 0.539 
(epoch: 137, iters: 2528, time: 0.163, data: 0.013) loss: 0.546 
(epoch: 137, iters: 2608, time: 0.166, data: 0.000) loss: 0.324 
(epoch: 137, iters: 2688, time: 0.167, data: 0.035) loss: 0.154 
(epoch: 137, iters: 2768, time: 0.166, data: 0.000) loss: 0.146 
(epoch: 137, iters: 2848, time: 0.164, data: 0.031) loss: 0.189 
(epoch: 137, iters: 2928, time: 0.164, data: 0.000) loss: 0.096 
(epoch: 137, iters: 3008, time: 0.162, data: 0.000) loss: 0.165 
(epoch: 137, iters: 3088, time: 0.164, data: 0.016) loss: 1.076 
(epoch: 137, iters: 3168, time: 0.167, data: 0.000) loss: 0.292 
(epoch: 137, iters: 3248, time: 0.165, data: 0.000) loss: 0.090 
(epoch: 137, iters: 3328, time: 0.166, data: 0.000) loss: 0.140 
(epoch: 137, iters: 3408, time: 0.165, data: 0.010) loss: 0.417 
(epoch: 137, iters: 3488, time: 0.167, data: 0.000) loss: 0.437 
(epoch: 137, iters: 3568, time: 0.166, data: 0.000) loss: 0.308 
(epoch: 137, iters: 3648, time: 0.166, data: 0.015) loss: 0.291 
(epoch: 137, iters: 3728, time: 0.165, data: 0.018) loss: 0.249 
(epoch: 137, iters: 3808, time: 0.165, data: 0.000) loss: 0.602 
(epoch: 137, iters: 3888, time: 0.165, data: 0.000) loss: 0.492 
(epoch: 137, iters: 3968, time: 0.162, data: 0.024) loss: 0.371 
saving the latest model (epoch 137, total_steps 1390128)
(epoch: 137, iters: 4048, time: 0.165, data: 0.000) loss: 0.310 
(epoch: 137, iters: 4128, time: 0.167, data: 0.000) loss: 0.338 
(epoch: 137, iters: 4208, time: 0.165, data: 0.014) loss: 0.517 
(epoch: 137, iters: 4288, time: 0.164, data: 0.009) loss: 0.164 
(epoch: 137, iters: 4368, time: 0.166, data: 0.005) loss: 0.371 
(epoch: 137, iters: 4448, time: 0.165, data: 0.005) loss: 0.208 
(epoch: 137, iters: 4528, time: 0.166, data: 0.008) loss: 0.304 
(epoch: 137, iters: 4608, time: 0.170, data: 0.000) loss: 0.522 
(epoch: 137, iters: 4688, time: 0.164, data: 0.021) loss: 0.550 
(epoch: 137, iters: 4768, time: 0.166, data: 0.014) loss: 0.658 
(epoch: 137, iters: 4848, time: 0.166, data: 0.000) loss: 0.486 
(epoch: 137, iters: 4928, time: 0.165, data: 0.028) loss: 0.386 
(epoch: 137, iters: 5008, time: 0.165, data: 0.000) loss: 0.576 
(epoch: 137, iters: 5088, time: 0.165, data: 0.032) loss: 0.113 
(epoch: 137, iters: 5168, time: 0.164, data: 0.000) loss: 0.831 
(epoch: 137, iters: 5248, time: 0.167, data: 0.013) loss: 0.395 
(epoch: 137, iters: 5328, time: 0.167, data: 0.006) loss: 0.641 
(epoch: 137, iters: 5408, time: 0.166, data: 0.000) loss: 0.269 
(epoch: 137, iters: 5488, time: 0.167, data: 0.008) loss: 0.761 
(epoch: 137, iters: 5568, time: 0.169, data: 0.000) loss: 0.406 
(epoch: 137, iters: 5648, time: 0.165, data: 0.000) loss: 0.650 
(epoch: 137, iters: 5728, time: 0.166, data: 0.006) loss: 0.417 
(epoch: 137, iters: 5808, time: 0.165, data: 0.033) loss: 0.282 
(epoch: 137, iters: 5888, time: 0.162, data: 0.000) loss: 0.511 
(epoch: 137, iters: 5968, time: 0.166, data: 0.000) loss: 0.570 
(epoch: 137, iters: 6048, time: 0.165, data: 0.014) loss: 0.155 
(epoch: 137, iters: 6128, time: 0.165, data: 0.000) loss: 0.457 
(epoch: 137, iters: 6208, time: 0.165, data: 0.000) loss: 0.423 
(epoch: 137, iters: 6288, time: 0.165, data: 0.017) loss: 0.322 
(epoch: 137, iters: 6368, time: 0.161, data: 0.008) loss: 0.536 
(epoch: 137, iters: 6448, time: 0.165, data: 0.000) loss: 0.463 
(epoch: 137, iters: 6528, time: 0.172, data: 0.008) loss: 0.431 
(epoch: 137, iters: 6608, time: 0.162, data: 0.000) loss: 0.299 
(epoch: 137, iters: 6688, time: 0.159, data: 0.000) loss: 0.181 
(epoch: 137, iters: 6768, time: 0.165, data: 0.019) loss: 0.245 
(epoch: 137, iters: 6848, time: 0.160, data: 0.000) loss: 0.292 
(epoch: 137, iters: 6928, time: 0.164, data: 0.017) loss: 0.191 
(epoch: 137, iters: 7008, time: 0.165, data: 0.005) loss: 0.460 
(epoch: 137, iters: 7088, time: 0.162, data: 0.000) loss: 0.296 
(epoch: 137, iters: 7168, time: 0.163, data: 0.005) loss: 0.182 
(epoch: 137, iters: 7248, time: 0.168, data: 0.000) loss: 0.106 
(epoch: 137, iters: 7328, time: 0.161, data: 0.006) loss: 0.264 
(epoch: 137, iters: 7408, time: 0.163, data: 0.000) loss: 0.282 
(epoch: 137, iters: 7488, time: 0.165, data: 0.000) loss: 0.178 
(epoch: 137, iters: 7568, time: 0.163, data: 0.022) loss: 0.306 
(epoch: 137, iters: 7648, time: 0.165, data: 0.000) loss: 0.508 
(epoch: 137, iters: 7728, time: 0.163, data: 0.016) loss: 0.317 
(epoch: 137, iters: 7808, time: 0.165, data: 0.000) loss: 0.224 
(epoch: 137, iters: 7888, time: 0.164, data: 0.000) loss: 0.779 
(epoch: 137, iters: 7968, time: 0.162, data: 0.013) loss: 0.156 
saving the latest model (epoch 137, total_steps 1394128)
(epoch: 137, iters: 8048, time: 0.162, data: 0.000) loss: 0.461 
(epoch: 137, iters: 8128, time: 0.163, data: 0.000) loss: 0.547 
(epoch: 137, iters: 8208, time: 0.164, data: 0.026) loss: 0.204 
(epoch: 137, iters: 8288, time: 0.163, data: 0.000) loss: 0.243 
(epoch: 137, iters: 8368, time: 0.168, data: 0.000) loss: 0.439 
(epoch: 137, iters: 8448, time: 0.165, data: 0.008) loss: 0.588 
(epoch: 137, iters: 8528, time: 0.167, data: 0.000) loss: 0.479 
(epoch: 137, iters: 8608, time: 0.167, data: 0.000) loss: 0.291 
(epoch: 137, iters: 8688, time: 0.165, data: 0.000) loss: 0.423 
(epoch: 137, iters: 8768, time: 0.165, data: 0.005) loss: 0.482 
(epoch: 137, iters: 8848, time: 0.164, data: 0.023) loss: 0.223 
(epoch: 137, iters: 8928, time: 0.166, data: 0.000) loss: 0.764 
(epoch: 137, iters: 9008, time: 0.166, data: 0.000) loss: 0.429 
(epoch: 137, iters: 9088, time: 0.167, data: 0.015) loss: 0.446 
(epoch: 137, iters: 9168, time: 0.166, data: 0.032) loss: 0.581 
(epoch: 137, iters: 9248, time: 0.164, data: 0.000) loss: 0.346 
(epoch: 137, iters: 9328, time: 0.167, data: 0.000) loss: 0.362 
(epoch: 137, iters: 9408, time: 0.166, data: 0.000) loss: 0.196 
(epoch: 137, iters: 9488, time: 0.166, data: 0.006) loss: 0.214 
(epoch: 137, iters: 9568, time: 0.166, data: 0.006) loss: 0.383 
(epoch: 137, iters: 9648, time: 0.167, data: 0.021) loss: 0.398 
(epoch: 137, iters: 9728, time: 0.166, data: 0.000) loss: 0.437 
(epoch: 137, iters: 9808, time: 0.165, data: 0.010) loss: 0.480 
(epoch: 137, iters: 9888, time: 0.166, data: 0.022) loss: 0.386 
(epoch: 137, iters: 9968, time: 0.166, data: 0.000) loss: 0.258 
(epoch: 137, iters: 10048, time: 0.166, data: 0.000) loss: 0.518 
(epoch: 137, iters: 10128, time: 0.166, data: 0.020) loss: 0.314 
saving the model at the end of epoch 137, iters 1396304
End of epoch 137 / 200 	 Time Taken: 1693 sec
learning rate = 0.0001228
(epoch: 138, iters: 16, time: 0.180, data: 0.007) loss: 0.348 
saving the latest model (epoch 138, total_steps 1396320)
(epoch: 138, iters: 96, time: 0.166, data: 0.000) loss: 0.341 
(epoch: 138, iters: 176, time: 0.166, data: 0.007) loss: 0.299 
(epoch: 138, iters: 256, time: 0.168, data: 0.006) loss: 0.381 
(epoch: 138, iters: 336, time: 0.167, data: 0.000) loss: 0.143 
(epoch: 138, iters: 416, time: 0.166, data: 0.000) loss: 0.256 
(epoch: 138, iters: 496, time: 0.167, data: 0.018) loss: 0.432 
(epoch: 138, iters: 576, time: 0.167, data: 0.000) loss: 0.593 
(epoch: 138, iters: 656, time: 0.169, data: 0.009) loss: 0.122 
(epoch: 138, iters: 736, time: 0.166, data: 0.000) loss: 0.053 
(epoch: 138, iters: 816, time: 0.169, data: 0.017) loss: 0.237 
(epoch: 138, iters: 896, time: 0.168, data: 0.025) loss: 0.429 
(epoch: 138, iters: 976, time: 0.166, data: 0.000) loss: 0.289 
(epoch: 138, iters: 1056, time: 0.166, data: 0.013) loss: 0.712 
(epoch: 138, iters: 1136, time: 0.166, data: 0.000) loss: 0.390 
(epoch: 138, iters: 1216, time: 0.165, data: 0.018) loss: 0.323 
(epoch: 138, iters: 1296, time: 0.166, data: 0.000) loss: 0.131 
(epoch: 138, iters: 1376, time: 0.166, data: 0.015) loss: 0.583 
(epoch: 138, iters: 1456, time: 0.169, data: 0.023) loss: 0.190 
(epoch: 138, iters: 1536, time: 0.169, data: 0.000) loss: 0.228 
(epoch: 138, iters: 1616, time: 0.166, data: 0.000) loss: 0.177 
(epoch: 138, iters: 1696, time: 0.167, data: 0.000) loss: 0.225 
(epoch: 138, iters: 1776, time: 0.167, data: 0.000) loss: 0.480 
(epoch: 138, iters: 1856, time: 0.160, data: 0.005) loss: 0.120 
(epoch: 138, iters: 1936, time: 0.160, data: 0.000) loss: 1.182 
(epoch: 138, iters: 2016, time: 0.161, data: 0.000) loss: 0.337 
(epoch: 138, iters: 2096, time: 0.161, data: 0.006) loss: 0.366 
(epoch: 138, iters: 2176, time: 0.159, data: 0.000) loss: 0.139 
(epoch: 138, iters: 2256, time: 0.161, data: 0.016) loss: 0.356 
(epoch: 138, iters: 2336, time: 0.160, data: 0.014) loss: 0.377 
(epoch: 138, iters: 2416, time: 0.159, data: 0.010) loss: 0.647 
(epoch: 138, iters: 2496, time: 0.163, data: 0.006) loss: 0.383 
(epoch: 138, iters: 2576, time: 0.161, data: 0.000) loss: 0.372 
(epoch: 138, iters: 2656, time: 0.161, data: 0.005) loss: 0.093 
(epoch: 138, iters: 2736, time: 0.159, data: 0.000) loss: 0.163 
(epoch: 138, iters: 2816, time: 0.160, data: 0.020) loss: 0.850 
(epoch: 138, iters: 2896, time: 0.160, data: 0.029) loss: 0.469 
(epoch: 138, iters: 2976, time: 0.160, data: 0.000) loss: 0.142 
(epoch: 138, iters: 3056, time: 0.159, data: 0.000) loss: 0.449 
(epoch: 138, iters: 3136, time: 0.160, data: 0.013) loss: 0.234 
(epoch: 138, iters: 3216, time: 0.162, data: 0.000) loss: 0.571 
(epoch: 138, iters: 3296, time: 0.160, data: 0.015) loss: 0.436 
(epoch: 138, iters: 3376, time: 0.161, data: 0.000) loss: 0.461 
(epoch: 138, iters: 3456, time: 0.161, data: 0.000) loss: 0.143 
(epoch: 138, iters: 3536, time: 0.160, data: 0.005) loss: 0.268 
(epoch: 138, iters: 3616, time: 0.162, data: 0.000) loss: 0.308 
(epoch: 138, iters: 3696, time: 0.159, data: 0.000) loss: 0.223 
(epoch: 138, iters: 3776, time: 0.160, data: 0.000) loss: 0.123 
(epoch: 138, iters: 3856, time: 0.160, data: 0.007) loss: 0.389 
(epoch: 138, iters: 3936, time: 0.161, data: 0.008) loss: 0.269 
(epoch: 138, iters: 4016, time: 0.162, data: 0.000) loss: 0.172 
saving the latest model (epoch 138, total_steps 1400320)
(epoch: 138, iters: 4096, time: 0.160, data: 0.024) loss: 0.372 
(epoch: 138, iters: 4176, time: 0.161, data: 0.000) loss: 0.151 
(epoch: 138, iters: 4256, time: 0.162, data: 0.032) loss: 0.620 
(epoch: 138, iters: 4336, time: 0.161, data: 0.000) loss: 0.120 
(epoch: 138, iters: 4416, time: 0.160, data: 0.012) loss: 0.363 
(epoch: 138, iters: 4496, time: 0.162, data: 0.000) loss: 0.174 
(epoch: 138, iters: 4576, time: 0.159, data: 0.000) loss: 1.250 
(epoch: 138, iters: 4656, time: 0.160, data: 0.015) loss: 0.287 
(epoch: 138, iters: 4736, time: 0.160, data: 0.000) loss: 0.265 
(epoch: 138, iters: 4816, time: 0.160, data: 0.000) loss: 0.567 
(epoch: 138, iters: 4896, time: 0.160, data: 0.000) loss: 0.113 
(epoch: 138, iters: 4976, time: 0.159, data: 0.000) loss: 0.447 
(epoch: 138, iters: 5056, time: 0.159, data: 0.000) loss: 0.047 
(epoch: 138, iters: 5136, time: 0.164, data: 0.000) loss: 0.131 
(epoch: 138, iters: 5216, time: 0.165, data: 0.000) loss: 0.421 
(epoch: 138, iters: 5296, time: 0.162, data: 0.026) loss: 0.449 
(epoch: 138, iters: 5376, time: 0.163, data: 0.000) loss: 0.470 
(epoch: 138, iters: 5456, time: 0.164, data: 0.000) loss: 0.455 
(epoch: 138, iters: 5536, time: 0.162, data: 0.000) loss: 0.520 
(epoch: 138, iters: 5616, time: 0.163, data: 0.000) loss: 0.442 
(epoch: 138, iters: 5696, time: 0.164, data: 0.000) loss: 0.358 
(epoch: 138, iters: 5776, time: 0.160, data: 0.014) loss: 0.410 
(epoch: 138, iters: 5856, time: 0.163, data: 0.005) loss: 0.188 
(epoch: 138, iters: 5936, time: 0.171, data: 0.000) loss: 0.152 
(epoch: 138, iters: 6016, time: 0.166, data: 0.014) loss: 0.409 
(epoch: 138, iters: 6096, time: 0.155, data: 0.000) loss: 0.543 
(epoch: 138, iters: 6176, time: 0.180, data: 0.000) loss: 0.363 
(epoch: 138, iters: 6256, time: 0.152, data: 0.000) loss: 0.427 
(epoch: 138, iters: 6336, time: 0.152, data: 0.000) loss: 0.534 
(epoch: 138, iters: 6416, time: 0.154, data: 0.000) loss: 0.318 
(epoch: 138, iters: 6496, time: 0.153, data: 0.008) loss: 0.463 
(epoch: 138, iters: 6576, time: 0.150, data: 0.000) loss: 0.286 
(epoch: 138, iters: 6656, time: 0.154, data: 0.008) loss: 0.681 
(epoch: 138, iters: 6736, time: 0.159, data: 0.005) loss: 0.192 
(epoch: 138, iters: 6816, time: 0.154, data: 0.000) loss: 0.152 
(epoch: 138, iters: 6896, time: 0.153, data: 0.000) loss: 0.704 
(epoch: 138, iters: 6976, time: 0.153, data: 0.024) loss: 0.233 
(epoch: 138, iters: 7056, time: 0.154, data: 0.008) loss: 0.298 
(epoch: 138, iters: 7136, time: 0.162, data: 0.025) loss: 0.327 
(epoch: 138, iters: 7216, time: 0.154, data: 0.000) loss: 0.146 
(epoch: 138, iters: 7296, time: 0.152, data: 0.000) loss: 0.458 
(epoch: 138, iters: 7376, time: 0.154, data: 0.005) loss: 0.309 
(epoch: 138, iters: 7456, time: 0.155, data: 0.010) loss: 0.080 
(epoch: 138, iters: 7536, time: 0.161, data: 0.000) loss: 0.315 
(epoch: 138, iters: 7616, time: 0.153, data: 0.014) loss: 0.310 
(epoch: 138, iters: 7696, time: 0.154, data: 0.000) loss: 0.599 
(epoch: 138, iters: 7776, time: 0.154, data: 0.008) loss: 0.575 
(epoch: 138, iters: 7856, time: 0.156, data: 0.005) loss: 0.578 
(epoch: 138, iters: 7936, time: 0.161, data: 0.000) loss: 0.460 
(epoch: 138, iters: 8016, time: 0.153, data: 0.000) loss: 0.129 
saving the latest model (epoch 138, total_steps 1404320)
(epoch: 138, iters: 8096, time: 0.151, data: 0.000) loss: 0.564 
(epoch: 138, iters: 8176, time: 0.152, data: 0.005) loss: 0.226 
(epoch: 138, iters: 8256, time: 0.154, data: 0.014) loss: 0.666 
(epoch: 138, iters: 8336, time: 0.159, data: 0.000) loss: 0.350 
(epoch: 138, iters: 8416, time: 0.153, data: 0.000) loss: 0.196 
(epoch: 138, iters: 8496, time: 0.153, data: 0.000) loss: 0.286 
(epoch: 138, iters: 8576, time: 0.156, data: 0.000) loss: 0.291 
(epoch: 138, iters: 8656, time: 0.154, data: 0.010) loss: 0.357 
(epoch: 138, iters: 8736, time: 0.159, data: 0.005) loss: 0.701 
(epoch: 138, iters: 8816, time: 0.153, data: 0.000) loss: 0.322 
(epoch: 138, iters: 8896, time: 0.153, data: 0.006) loss: 0.130 
(epoch: 138, iters: 8976, time: 0.152, data: 0.035) loss: 0.264 
(epoch: 138, iters: 9056, time: 0.155, data: 0.000) loss: 0.252 
(epoch: 138, iters: 9136, time: 0.158, data: 0.000) loss: 0.511 
(epoch: 138, iters: 9216, time: 0.152, data: 0.000) loss: 0.480 
(epoch: 138, iters: 9296, time: 0.152, data: 0.008) loss: 0.553 
(epoch: 138, iters: 9376, time: 0.154, data: 0.005) loss: 0.335 
(epoch: 138, iters: 9456, time: 0.153, data: 0.014) loss: 0.239 
(epoch: 138, iters: 9536, time: 0.155, data: 0.021) loss: 0.652 
(epoch: 138, iters: 9616, time: 0.153, data: 0.008) loss: 0.421 
(epoch: 138, iters: 9696, time: 0.154, data: 0.000) loss: 0.401 
(epoch: 138, iters: 9776, time: 0.157, data: 0.005) loss: 0.156 
(epoch: 138, iters: 9856, time: 0.151, data: 0.000) loss: 0.419 
(epoch: 138, iters: 9936, time: 0.154, data: 0.000) loss: 0.412 
(epoch: 138, iters: 10016, time: 0.153, data: 0.025) loss: 0.233 
(epoch: 138, iters: 10096, time: 0.152, data: 0.008) loss: 0.596 
(epoch: 138, iters: 10176, time: 0.156, data: 0.005) loss: 0.201 
saving the model at the end of epoch 138, iters 1406496
End of epoch 138 / 200 	 Time Taken: 1628 sec
learning rate = 0.0001208
saving the latest model (epoch 139, total_steps 1406512)
(epoch: 139, iters: 64, time: 0.164, data: 0.000) loss: 0.147 
(epoch: 139, iters: 144, time: 0.165, data: 0.000) loss: 0.478 
(epoch: 139, iters: 224, time: 0.159, data: 0.008) loss: 0.449 
(epoch: 139, iters: 304, time: 0.161, data: 0.000) loss: 0.672 
(epoch: 139, iters: 384, time: 0.163, data: 0.006) loss: 0.154 
(epoch: 139, iters: 464, time: 0.161, data: 0.014) loss: 0.173 
(epoch: 139, iters: 544, time: 0.161, data: 0.000) loss: 0.119 
(epoch: 139, iters: 624, time: 0.161, data: 0.014) loss: 0.444 
(epoch: 139, iters: 704, time: 0.161, data: 0.000) loss: 0.693 
(epoch: 139, iters: 784, time: 0.177, data: 0.000) loss: 0.663 
(epoch: 139, iters: 864, time: 0.158, data: 0.000) loss: 0.146 
(epoch: 139, iters: 944, time: 0.160, data: 0.005) loss: 0.471 
(epoch: 139, iters: 1024, time: 0.159, data: 0.000) loss: 0.219 
(epoch: 139, iters: 1104, time: 0.160, data: 0.019) loss: 0.883 
(epoch: 139, iters: 1184, time: 0.160, data: 0.029) loss: 0.214 
(epoch: 139, iters: 1264, time: 0.162, data: 0.000) loss: 0.061 
(epoch: 139, iters: 1344, time: 0.159, data: 0.000) loss: 0.395 
(epoch: 139, iters: 1424, time: 0.160, data: 0.022) loss: 0.551 
(epoch: 139, iters: 1504, time: 0.158, data: 0.000) loss: 0.292 
(epoch: 139, iters: 1584, time: 0.159, data: 0.000) loss: 0.347 
(epoch: 139, iters: 1664, time: 0.160, data: 0.006) loss: 0.673 
(epoch: 139, iters: 1744, time: 0.159, data: 0.025) loss: 0.390 
(epoch: 139, iters: 1824, time: 0.164, data: 0.000) loss: 0.795 
(epoch: 139, iters: 1904, time: 0.159, data: 0.011) loss: 0.133 
(epoch: 139, iters: 1984, time: 0.160, data: 0.006) loss: 0.309 
(epoch: 139, iters: 2064, time: 0.163, data: 0.018) loss: 0.507 
(epoch: 139, iters: 2144, time: 0.164, data: 0.000) loss: 0.294 
(epoch: 139, iters: 2224, time: 0.164, data: 0.011) loss: 0.344 
(epoch: 139, iters: 2304, time: 0.163, data: 0.000) loss: 0.260 
(epoch: 139, iters: 2384, time: 0.162, data: 0.000) loss: 0.357 
(epoch: 139, iters: 2464, time: 0.166, data: 0.000) loss: 0.031 
(epoch: 139, iters: 2544, time: 0.171, data: 0.005) loss: 0.314 
(epoch: 139, iters: 2624, time: 0.162, data: 0.011) loss: 0.285 
(epoch: 139, iters: 2704, time: 0.163, data: 0.000) loss: 0.500 
(epoch: 139, iters: 2784, time: 0.162, data: 0.000) loss: 0.209 
(epoch: 139, iters: 2864, time: 0.162, data: 0.006) loss: 0.636 
(epoch: 139, iters: 2944, time: 0.161, data: 0.000) loss: 0.060 
(epoch: 139, iters: 3024, time: 0.161, data: 0.006) loss: 0.081 
(epoch: 139, iters: 3104, time: 0.162, data: 0.000) loss: 0.221 
(epoch: 139, iters: 3184, time: 0.162, data: 0.014) loss: 0.715 
(epoch: 139, iters: 3264, time: 0.162, data: 0.005) loss: 0.188 
(epoch: 139, iters: 3344, time: 0.162, data: 0.009) loss: 0.462 
(epoch: 139, iters: 3424, time: 0.162, data: 0.008) loss: 0.560 
(epoch: 139, iters: 3504, time: 0.164, data: 0.023) loss: 0.382 
(epoch: 139, iters: 3584, time: 0.162, data: 0.000) loss: 0.142 
(epoch: 139, iters: 3664, time: 0.164, data: 0.000) loss: 0.460 
(epoch: 139, iters: 3744, time: 0.162, data: 0.000) loss: 0.270 
(epoch: 139, iters: 3824, time: 0.163, data: 0.005) loss: 0.379 
(epoch: 139, iters: 3904, time: 0.161, data: 0.000) loss: 0.315 
(epoch: 139, iters: 3984, time: 0.169, data: 0.000) loss: 0.416 
saving the latest model (epoch 139, total_steps 1410512)
(epoch: 139, iters: 4064, time: 0.163, data: 0.000) loss: 0.464 
(epoch: 139, iters: 4144, time: 0.166, data: 0.008) loss: 0.447 
(epoch: 139, iters: 4224, time: 0.162, data: 0.005) loss: 0.102 
(epoch: 139, iters: 4304, time: 0.162, data: 0.000) loss: 0.175 
(epoch: 139, iters: 4384, time: 0.165, data: 0.000) loss: 0.076 
(epoch: 139, iters: 4464, time: 0.161, data: 0.018) loss: 0.321 
(epoch: 139, iters: 4544, time: 0.163, data: 0.000) loss: 0.197 
(epoch: 139, iters: 4624, time: 0.163, data: 0.000) loss: 0.296 
(epoch: 139, iters: 4704, time: 0.161, data: 0.008) loss: 0.230 
(epoch: 139, iters: 4784, time: 0.163, data: 0.044) loss: 0.219 
(epoch: 139, iters: 4864, time: 0.165, data: 0.000) loss: 0.515 
(epoch: 139, iters: 4944, time: 0.162, data: 0.016) loss: 0.181 
(epoch: 139, iters: 5024, time: 0.161, data: 0.000) loss: 0.608 
(epoch: 139, iters: 5104, time: 0.161, data: 0.006) loss: 0.094 
(epoch: 139, iters: 5184, time: 0.162, data: 0.000) loss: 0.412 
(epoch: 139, iters: 5264, time: 0.161, data: 0.021) loss: 0.058 
(epoch: 139, iters: 5344, time: 0.161, data: 0.005) loss: 0.114 
(epoch: 139, iters: 5424, time: 0.163, data: 0.026) loss: 0.103 
(epoch: 139, iters: 5504, time: 0.167, data: 0.000) loss: 0.559 
(epoch: 139, iters: 5584, time: 0.163, data: 0.000) loss: 0.391 
(epoch: 139, iters: 5664, time: 0.162, data: 0.000) loss: 0.167 
(epoch: 139, iters: 5744, time: 0.161, data: 0.000) loss: 0.279 
(epoch: 139, iters: 5824, time: 0.161, data: 0.027) loss: 0.867 
(epoch: 139, iters: 5904, time: 0.165, data: 0.000) loss: 0.556 
(epoch: 139, iters: 5984, time: 0.163, data: 0.014) loss: 0.277 
(epoch: 139, iters: 6064, time: 0.162, data: 0.006) loss: 0.357 
(epoch: 139, iters: 6144, time: 0.162, data: 0.000) loss: 0.668 
(epoch: 139, iters: 6224, time: 0.163, data: 0.014) loss: 0.425 
(epoch: 139, iters: 6304, time: 0.161, data: 0.016) loss: 0.179 
(epoch: 139, iters: 6384, time: 0.163, data: 0.000) loss: 0.287 
(epoch: 139, iters: 6464, time: 0.164, data: 0.005) loss: 0.147 
(epoch: 139, iters: 6544, time: 0.161, data: 0.000) loss: 0.433 
(epoch: 139, iters: 6624, time: 0.162, data: 0.024) loss: 0.216 
(epoch: 139, iters: 6704, time: 0.162, data: 0.000) loss: 0.140 
(epoch: 139, iters: 6784, time: 0.162, data: 0.014) loss: 0.627 
(epoch: 139, iters: 6864, time: 0.161, data: 0.000) loss: 0.140 
(epoch: 139, iters: 6944, time: 0.161, data: 0.000) loss: 0.040 
(epoch: 139, iters: 7024, time: 0.160, data: 0.000) loss: 0.809 
(epoch: 139, iters: 7104, time: 0.160, data: 0.034) loss: 0.082 
(epoch: 139, iters: 7184, time: 0.161, data: 0.000) loss: 0.397 
(epoch: 139, iters: 7264, time: 0.161, data: 0.028) loss: 0.197 
(epoch: 139, iters: 7344, time: 0.163, data: 0.000) loss: 0.092 
(epoch: 139, iters: 7424, time: 0.166, data: 0.000) loss: 0.378 
(epoch: 139, iters: 7504, time: 0.161, data: 0.006) loss: 0.182 
(epoch: 139, iters: 7584, time: 0.162, data: 0.005) loss: 0.327 
(epoch: 139, iters: 7664, time: 0.163, data: 0.000) loss: 0.498 
(epoch: 139, iters: 7744, time: 0.163, data: 0.018) loss: 0.120 
(epoch: 139, iters: 7824, time: 0.161, data: 0.000) loss: 0.251 
(epoch: 139, iters: 7904, time: 0.163, data: 0.000) loss: 0.275 
(epoch: 139, iters: 7984, time: 0.162, data: 0.005) loss: 0.226 
saving the latest model (epoch 139, total_steps 1414512)
(epoch: 139, iters: 8064, time: 0.161, data: 0.000) loss: 0.240 
(epoch: 139, iters: 8144, time: 0.161, data: 0.005) loss: 0.636 
(epoch: 139, iters: 8224, time: 0.162, data: 0.005) loss: 0.351 
(epoch: 139, iters: 8304, time: 0.162, data: 0.014) loss: 0.175 
(epoch: 139, iters: 8384, time: 0.160, data: 0.000) loss: 0.122 
(epoch: 139, iters: 8464, time: 0.165, data: 0.000) loss: 0.296 
(epoch: 139, iters: 8544, time: 0.161, data: 0.014) loss: 0.366 
(epoch: 139, iters: 8624, time: 0.163, data: 0.005) loss: 0.705 
(epoch: 139, iters: 8704, time: 0.161, data: 0.000) loss: 0.115 
(epoch: 139, iters: 8784, time: 0.163, data: 0.006) loss: 0.724 
(epoch: 139, iters: 8864, time: 0.161, data: 0.000) loss: 0.582 
(epoch: 139, iters: 8944, time: 0.162, data: 0.000) loss: 0.303 
(epoch: 139, iters: 9024, time: 0.162, data: 0.005) loss: 0.495 
(epoch: 139, iters: 9104, time: 0.161, data: 0.000) loss: 0.301 
(epoch: 139, iters: 9184, time: 0.162, data: 0.000) loss: 0.316 
(epoch: 139, iters: 9264, time: 0.163, data: 0.000) loss: 0.828 
(epoch: 139, iters: 9344, time: 0.169, data: 0.000) loss: 0.467 
(epoch: 139, iters: 9424, time: 0.162, data: 0.000) loss: 0.125 
(epoch: 139, iters: 9504, time: 0.163, data: 0.000) loss: 0.265 
(epoch: 139, iters: 9584, time: 0.162, data: 0.005) loss: 0.145 
(epoch: 139, iters: 9664, time: 0.161, data: 0.000) loss: 0.218 
(epoch: 139, iters: 9744, time: 0.161, data: 0.000) loss: 0.264 
(epoch: 139, iters: 9824, time: 0.162, data: 0.000) loss: 0.355 
(epoch: 139, iters: 9904, time: 0.162, data: 0.000) loss: 0.475 
(epoch: 139, iters: 9984, time: 0.161, data: 0.015) loss: 0.247 
(epoch: 139, iters: 10064, time: 0.162, data: 0.005) loss: 0.229 
(epoch: 139, iters: 10144, time: 0.163, data: 0.013) loss: 0.254 
saving the model at the end of epoch 139, iters 1416688
End of epoch 139 / 200 	 Time Taken: 1654 sec
learning rate = 0.0001188
saving the latest model (epoch 140, total_steps 1416704)
(epoch: 140, iters: 32, time: 0.170, data: 0.011) loss: 0.209 
(epoch: 140, iters: 112, time: 0.163, data: 0.000) loss: 0.324 
(epoch: 140, iters: 192, time: 0.160, data: 0.031) loss: 0.045 
(epoch: 140, iters: 272, time: 0.159, data: 0.000) loss: 0.410 
(epoch: 140, iters: 352, time: 0.160, data: 0.000) loss: 0.094 
(epoch: 140, iters: 432, time: 0.161, data: 0.000) loss: 0.250 
(epoch: 140, iters: 512, time: 0.162, data: 0.000) loss: 0.354 
(epoch: 140, iters: 592, time: 0.160, data: 0.008) loss: 0.519 
(epoch: 140, iters: 672, time: 0.163, data: 0.000) loss: 0.307 
(epoch: 140, iters: 752, time: 0.163, data: 0.008) loss: 0.170 
(epoch: 140, iters: 832, time: 0.161, data: 0.008) loss: 0.269 
(epoch: 140, iters: 912, time: 0.161, data: 0.005) loss: 0.300 
(epoch: 140, iters: 992, time: 0.162, data: 0.000) loss: 0.237 
(epoch: 140, iters: 1072, time: 0.161, data: 0.000) loss: 0.188 
(epoch: 140, iters: 1152, time: 0.162, data: 0.000) loss: 0.279 
(epoch: 140, iters: 1232, time: 0.161, data: 0.005) loss: 0.339 
(epoch: 140, iters: 1312, time: 0.160, data: 0.005) loss: 0.457 
(epoch: 140, iters: 1392, time: 0.159, data: 0.040) loss: 0.334 
(epoch: 140, iters: 1472, time: 0.160, data: 0.000) loss: 0.394 
(epoch: 140, iters: 1552, time: 0.162, data: 0.000) loss: 0.672 
(epoch: 140, iters: 1632, time: 0.161, data: 0.000) loss: 0.141 
(epoch: 140, iters: 1712, time: 0.160, data: 0.000) loss: 0.557 
(epoch: 140, iters: 1792, time: 0.160, data: 0.009) loss: 0.095 
(epoch: 140, iters: 1872, time: 0.163, data: 0.006) loss: 0.335 
(epoch: 140, iters: 1952, time: 0.161, data: 0.000) loss: 0.512 
(epoch: 140, iters: 2032, time: 0.161, data: 0.000) loss: 0.157 
(epoch: 140, iters: 2112, time: 0.161, data: 0.010) loss: 0.310 
(epoch: 140, iters: 2192, time: 0.158, data: 0.000) loss: 0.360 
(epoch: 140, iters: 2272, time: 0.161, data: 0.000) loss: 0.306 
(epoch: 140, iters: 2352, time: 0.160, data: 0.024) loss: 0.502 
(epoch: 140, iters: 2432, time: 0.161, data: 0.000) loss: 0.156 
(epoch: 140, iters: 2512, time: 0.159, data: 0.000) loss: 0.730 
(epoch: 140, iters: 2592, time: 0.168, data: 0.000) loss: 0.378 
(epoch: 140, iters: 2672, time: 0.159, data: 0.021) loss: 0.623 
(epoch: 140, iters: 2752, time: 0.160, data: 0.031) loss: 0.290 
(epoch: 140, iters: 2832, time: 0.159, data: 0.000) loss: 0.298 
(epoch: 140, iters: 2912, time: 0.161, data: 0.006) loss: 0.319 
(epoch: 140, iters: 2992, time: 0.166, data: 0.000) loss: 0.595 
(epoch: 140, iters: 3072, time: 0.161, data: 0.000) loss: 0.831 
(epoch: 140, iters: 3152, time: 0.160, data: 0.008) loss: 0.529 
(epoch: 140, iters: 3232, time: 0.161, data: 0.005) loss: 0.576 
(epoch: 140, iters: 3312, time: 0.161, data: 0.039) loss: 0.343 
(epoch: 140, iters: 3392, time: 0.161, data: 0.000) loss: 0.283 
(epoch: 140, iters: 3472, time: 0.161, data: 0.000) loss: 0.477 
(epoch: 140, iters: 3552, time: 0.161, data: 0.000) loss: 0.908 
(epoch: 140, iters: 3632, time: 0.161, data: 0.000) loss: 0.120 
(epoch: 140, iters: 3712, time: 0.159, data: 0.000) loss: 0.801 
(epoch: 140, iters: 3792, time: 0.160, data: 0.029) loss: 0.613 
(epoch: 140, iters: 3872, time: 0.162, data: 0.000) loss: 0.180 
(epoch: 140, iters: 3952, time: 0.162, data: 0.000) loss: 0.257 
saving the latest model (epoch 140, total_steps 1420704)
(epoch: 140, iters: 4032, time: 0.160, data: 0.000) loss: 0.501 
(epoch: 140, iters: 4112, time: 0.160, data: 0.000) loss: 0.238 
(epoch: 140, iters: 4192, time: 0.160, data: 0.000) loss: 0.643 
(epoch: 140, iters: 4272, time: 0.160, data: 0.006) loss: 0.106 
(epoch: 140, iters: 4352, time: 0.158, data: 0.032) loss: 0.368 
(epoch: 140, iters: 4432, time: 0.162, data: 0.000) loss: 0.139 
(epoch: 140, iters: 4512, time: 0.161, data: 0.006) loss: 0.395 
(epoch: 140, iters: 4592, time: 0.161, data: 0.000) loss: 0.347 
(epoch: 140, iters: 4672, time: 0.161, data: 0.012) loss: 0.056 
(epoch: 140, iters: 4752, time: 0.161, data: 0.000) loss: 0.208 
(epoch: 140, iters: 4832, time: 0.160, data: 0.032) loss: 0.468 
(epoch: 140, iters: 4912, time: 0.166, data: 0.000) loss: 0.114 
(epoch: 140, iters: 4992, time: 0.159, data: 0.000) loss: 0.508 
(epoch: 140, iters: 5072, time: 0.160, data: 0.000) loss: 0.286 
(epoch: 140, iters: 5152, time: 0.162, data: 0.009) loss: 0.290 
(epoch: 140, iters: 5232, time: 0.160, data: 0.000) loss: 0.347 
(epoch: 140, iters: 5312, time: 0.159, data: 0.005) loss: 0.347 
(epoch: 140, iters: 5392, time: 0.159, data: 0.008) loss: 0.251 
(epoch: 140, iters: 5472, time: 0.162, data: 0.000) loss: 0.230 
(epoch: 140, iters: 5552, time: 0.162, data: 0.031) loss: 0.091 
(epoch: 140, iters: 5632, time: 0.160, data: 0.000) loss: 0.734 
(epoch: 140, iters: 5712, time: 0.158, data: 0.032) loss: 0.484 
(epoch: 140, iters: 5792, time: 0.159, data: 0.000) loss: 0.241 
(epoch: 140, iters: 5872, time: 0.160, data: 0.018) loss: 0.257 
(epoch: 140, iters: 5952, time: 0.160, data: 0.000) loss: 0.200 
(epoch: 140, iters: 6032, time: 0.159, data: 0.008) loss: 0.372 
(epoch: 140, iters: 6112, time: 0.158, data: 0.005) loss: 0.408 
(epoch: 140, iters: 6192, time: 0.158, data: 0.000) loss: 0.628 
(epoch: 140, iters: 6272, time: 0.160, data: 0.009) loss: 0.373 
(epoch: 140, iters: 6352, time: 0.158, data: 0.005) loss: 0.260 
(epoch: 140, iters: 6432, time: 0.158, data: 0.000) loss: 0.305 
(epoch: 140, iters: 6512, time: 0.158, data: 0.000) loss: 0.304 
(epoch: 140, iters: 6592, time: 0.159, data: 0.015) loss: 0.144 
(epoch: 140, iters: 6672, time: 0.160, data: 0.025) loss: 0.297 
(epoch: 140, iters: 6752, time: 0.164, data: 0.000) loss: 0.287 
(epoch: 140, iters: 6832, time: 0.165, data: 0.005) loss: 0.257 
(epoch: 140, iters: 6912, time: 0.161, data: 0.006) loss: 0.419 
(epoch: 140, iters: 6992, time: 0.162, data: 0.000) loss: 0.262 
(epoch: 140, iters: 7072, time: 0.160, data: 0.004) loss: 0.315 
(epoch: 140, iters: 7152, time: 0.160, data: 0.027) loss: 0.460 
(epoch: 140, iters: 7232, time: 0.160, data: 0.000) loss: 0.592 
(epoch: 140, iters: 7312, time: 0.161, data: 0.015) loss: 0.297 
(epoch: 140, iters: 7392, time: 0.160, data: 0.014) loss: 0.105 
(epoch: 140, iters: 7472, time: 0.161, data: 0.000) loss: 0.397 
(epoch: 140, iters: 7552, time: 0.159, data: 0.000) loss: 0.668 
(epoch: 140, iters: 7632, time: 0.161, data: 0.000) loss: 0.626 
(epoch: 140, iters: 7712, time: 0.160, data: 0.017) loss: 0.123 
(epoch: 140, iters: 7792, time: 0.161, data: 0.011) loss: 0.077 
(epoch: 140, iters: 7872, time: 0.161, data: 0.000) loss: 0.619 
(epoch: 140, iters: 7952, time: 0.160, data: 0.005) loss: 0.267 
saving the latest model (epoch 140, total_steps 1424704)
(epoch: 140, iters: 8032, time: 0.160, data: 0.017) loss: 0.790 
(epoch: 140, iters: 8112, time: 0.159, data: 0.000) loss: 0.622 
(epoch: 140, iters: 8192, time: 0.159, data: 0.029) loss: 0.540 
(epoch: 140, iters: 8272, time: 0.160, data: 0.000) loss: 0.516 
(epoch: 140, iters: 8352, time: 0.159, data: 0.000) loss: 0.153 
(epoch: 140, iters: 8432, time: 0.159, data: 0.020) loss: 0.131 
(epoch: 140, iters: 8512, time: 0.160, data: 0.000) loss: 0.340 
(epoch: 140, iters: 8592, time: 0.159, data: 0.000) loss: 0.407 
(epoch: 140, iters: 8672, time: 0.159, data: 0.000) loss: 0.139 
(epoch: 140, iters: 8752, time: 0.164, data: 0.005) loss: 0.256 
(epoch: 140, iters: 8832, time: 0.159, data: 0.005) loss: 0.311 
(epoch: 140, iters: 8912, time: 0.159, data: 0.008) loss: 0.304 
(epoch: 140, iters: 8992, time: 0.160, data: 0.000) loss: 0.149 
(epoch: 140, iters: 9072, time: 0.160, data: 0.000) loss: 0.405 
(epoch: 140, iters: 9152, time: 0.160, data: 0.015) loss: 0.284 
(epoch: 140, iters: 9232, time: 0.160, data: 0.012) loss: 0.630 
(epoch: 140, iters: 9312, time: 0.159, data: 0.000) loss: 0.779 
(epoch: 140, iters: 9392, time: 0.162, data: 0.028) loss: 0.173 
(epoch: 140, iters: 9472, time: 0.160, data: 0.008) loss: 0.315 
(epoch: 140, iters: 9552, time: 0.161, data: 0.017) loss: 0.453 
(epoch: 140, iters: 9632, time: 0.160, data: 0.022) loss: 0.535 
(epoch: 140, iters: 9712, time: 0.160, data: 0.000) loss: 0.730 
(epoch: 140, iters: 9792, time: 0.159, data: 0.000) loss: 0.527 
(epoch: 140, iters: 9872, time: 0.159, data: 0.000) loss: 0.736 
(epoch: 140, iters: 9952, time: 0.160, data: 0.009) loss: 0.363 
(epoch: 140, iters: 10032, time: 0.160, data: 0.005) loss: 0.439 
(epoch: 140, iters: 10112, time: 0.159, data: 0.005) loss: 0.370 
(epoch: 140, iters: 10192, time: 0.097, data: 0.008) loss: 0.413 
saving the model at the end of epoch 140, iters 1426880
End of epoch 140 / 200 	 Time Taken: 1640 sec
learning rate = 0.0001168
saving the latest model (epoch 141, total_steps 1426896)
(epoch: 141, iters: 80, time: 0.165, data: 0.179) loss: 0.369 
(epoch: 141, iters: 160, time: 0.161, data: 0.000) loss: 0.105 
(epoch: 141, iters: 240, time: 0.160, data: 0.017) loss: 0.354 
(epoch: 141, iters: 320, time: 0.164, data: 0.000) loss: 0.542 
(epoch: 141, iters: 400, time: 0.162, data: 0.024) loss: 0.455 
(epoch: 141, iters: 480, time: 0.166, data: 0.000) loss: 0.232 
(epoch: 141, iters: 560, time: 0.161, data: 0.000) loss: 0.590 
(epoch: 141, iters: 640, time: 0.161, data: 0.013) loss: 0.603 
(epoch: 141, iters: 720, time: 0.162, data: 0.015) loss: 0.380 
(epoch: 141, iters: 800, time: 0.162, data: 0.009) loss: 0.096 
(epoch: 141, iters: 880, time: 0.161, data: 0.008) loss: 0.293 
(epoch: 141, iters: 960, time: 0.160, data: 0.000) loss: 0.215 
(epoch: 141, iters: 1040, time: 0.158, data: 0.000) loss: 0.665 
(epoch: 141, iters: 1120, time: 0.159, data: 0.000) loss: 0.127 
(epoch: 141, iters: 1200, time: 0.161, data: 0.008) loss: 0.194 
(epoch: 141, iters: 1280, time: 0.161, data: 0.034) loss: 0.276 
(epoch: 141, iters: 1360, time: 0.161, data: 0.000) loss: 0.236 
(epoch: 141, iters: 1440, time: 0.162, data: 0.000) loss: 0.240 
(epoch: 141, iters: 1520, time: 0.160, data: 0.022) loss: 0.746 
(epoch: 141, iters: 1600, time: 0.161, data: 0.013) loss: 0.567 
(epoch: 141, iters: 1680, time: 0.159, data: 0.000) loss: 0.273 
(epoch: 141, iters: 1760, time: 0.161, data: 0.013) loss: 0.139 
(epoch: 141, iters: 1840, time: 0.163, data: 0.000) loss: 0.187 
(epoch: 141, iters: 1920, time: 0.160, data: 0.010) loss: 0.254 
(epoch: 141, iters: 2000, time: 0.162, data: 0.000) loss: 0.292 
(epoch: 141, iters: 2080, time: 0.160, data: 0.016) loss: 0.049 
(epoch: 141, iters: 2160, time: 0.162, data: 0.000) loss: 0.256 
(epoch: 141, iters: 2240, time: 0.160, data: 0.000) loss: 0.507 
(epoch: 141, iters: 2320, time: 0.160, data: 0.010) loss: 0.297 
(epoch: 141, iters: 2400, time: 0.162, data: 0.000) loss: 0.101 
(epoch: 141, iters: 2480, time: 0.160, data: 0.008) loss: 0.429 
(epoch: 141, iters: 2560, time: 0.161, data: 0.000) loss: 0.409 
(epoch: 141, iters: 2640, time: 0.160, data: 0.016) loss: 0.360 
(epoch: 141, iters: 2720, time: 0.162, data: 0.000) loss: 0.184 
(epoch: 141, iters: 2800, time: 0.164, data: 0.021) loss: 0.361 
(epoch: 141, iters: 2880, time: 0.160, data: 0.000) loss: 0.254 
(epoch: 141, iters: 2960, time: 0.162, data: 0.005) loss: 0.299 
(epoch: 141, iters: 3040, time: 0.161, data: 0.000) loss: 0.557 
(epoch: 141, iters: 3120, time: 0.161, data: 0.012) loss: 0.198 
(epoch: 141, iters: 3200, time: 0.161, data: 0.000) loss: 0.108 
(epoch: 141, iters: 3280, time: 0.161, data: 0.023) loss: 0.185 
(epoch: 141, iters: 3360, time: 0.164, data: 0.006) loss: 0.189 
(epoch: 141, iters: 3440, time: 0.162, data: 0.000) loss: 0.446 
(epoch: 141, iters: 3520, time: 0.162, data: 0.005) loss: 0.499 
(epoch: 141, iters: 3600, time: 0.160, data: 0.000) loss: 0.293 
(epoch: 141, iters: 3680, time: 0.161, data: 0.000) loss: 0.492 
(epoch: 141, iters: 3760, time: 0.160, data: 0.014) loss: 0.398 
(epoch: 141, iters: 3840, time: 0.158, data: 0.005) loss: 0.405 
(epoch: 141, iters: 3920, time: 0.162, data: 0.000) loss: 0.283 
(epoch: 141, iters: 4000, time: 0.162, data: 0.008) loss: 0.476 
saving the latest model (epoch 141, total_steps 1430896)
(epoch: 141, iters: 4080, time: 0.161, data: 0.000) loss: 0.347 
(epoch: 141, iters: 4160, time: 0.161, data: 0.000) loss: 0.156 
(epoch: 141, iters: 4240, time: 0.161, data: 0.000) loss: 0.422 
(epoch: 141, iters: 4320, time: 0.168, data: 0.000) loss: 0.299 
(epoch: 141, iters: 4400, time: 0.159, data: 0.000) loss: 0.350 
(epoch: 141, iters: 4480, time: 0.160, data: 0.006) loss: 0.149 
(epoch: 141, iters: 4560, time: 0.162, data: 0.000) loss: 0.176 
(epoch: 141, iters: 4640, time: 0.162, data: 0.000) loss: 0.148 
(epoch: 141, iters: 4720, time: 0.158, data: 0.009) loss: 0.532 
(epoch: 141, iters: 4800, time: 0.159, data: 0.012) loss: 0.485 
(epoch: 141, iters: 4880, time: 0.161, data: 0.000) loss: 0.218 
(epoch: 141, iters: 4960, time: 0.161, data: 0.000) loss: 0.243 
(epoch: 141, iters: 5040, time: 0.159, data: 0.005) loss: 0.278 
(epoch: 141, iters: 5120, time: 0.160, data: 0.000) loss: 0.185 
(epoch: 141, iters: 5200, time: 0.160, data: 0.000) loss: 0.363 
(epoch: 141, iters: 5280, time: 0.161, data: 0.015) loss: 0.437 
(epoch: 141, iters: 5360, time: 0.160, data: 0.040) loss: 0.326 
(epoch: 141, iters: 5440, time: 0.160, data: 0.000) loss: 0.141 
(epoch: 141, iters: 5520, time: 0.159, data: 0.019) loss: 0.275 
(epoch: 141, iters: 5600, time: 0.159, data: 0.000) loss: 0.673 
(epoch: 141, iters: 5680, time: 0.160, data: 0.000) loss: 0.302 
(epoch: 141, iters: 5760, time: 0.159, data: 0.006) loss: 0.377 
(epoch: 141, iters: 5840, time: 0.161, data: 0.000) loss: 0.451 
(epoch: 141, iters: 5920, time: 0.159, data: 0.013) loss: 0.484 
(epoch: 141, iters: 6000, time: 0.160, data: 0.000) loss: 0.446 
(epoch: 141, iters: 6080, time: 0.165, data: 0.000) loss: 0.146 
(epoch: 141, iters: 6160, time: 0.160, data: 0.000) loss: 0.296 
(epoch: 141, iters: 6240, time: 0.160, data: 0.005) loss: 0.492 
(epoch: 141, iters: 6320, time: 0.160, data: 0.000) loss: 0.496 
(epoch: 141, iters: 6400, time: 0.160, data: 0.000) loss: 0.512 
(epoch: 141, iters: 6480, time: 0.161, data: 0.005) loss: 0.482 
(epoch: 141, iters: 6560, time: 0.160, data: 0.006) loss: 0.692 
(epoch: 141, iters: 6640, time: 0.164, data: 0.024) loss: 0.409 
(epoch: 141, iters: 6720, time: 0.160, data: 0.000) loss: 0.170 
(epoch: 141, iters: 6800, time: 0.158, data: 0.000) loss: 0.170 
(epoch: 141, iters: 6880, time: 0.161, data: 0.006) loss: 0.112 
(epoch: 141, iters: 6960, time: 0.158, data: 0.011) loss: 0.205 
(epoch: 141, iters: 7040, time: 0.165, data: 0.000) loss: 0.249 
(epoch: 141, iters: 7120, time: 0.159, data: 0.000) loss: 0.135 
(epoch: 141, iters: 7200, time: 0.161, data: 0.015) loss: 0.425 
(epoch: 141, iters: 7280, time: 0.159, data: 0.000) loss: 0.160 
(epoch: 141, iters: 7360, time: 0.158, data: 0.000) loss: 0.225 
(epoch: 141, iters: 7440, time: 0.162, data: 0.006) loss: 0.790 
(epoch: 141, iters: 7520, time: 0.161, data: 0.017) loss: 0.696 
(epoch: 141, iters: 7600, time: 0.161, data: 0.000) loss: 0.151 
(epoch: 141, iters: 7680, time: 0.160, data: 0.000) loss: 0.528 
(epoch: 141, iters: 7760, time: 0.160, data: 0.000) loss: 0.143 
(epoch: 141, iters: 7840, time: 0.160, data: 0.008) loss: 0.135 
(epoch: 141, iters: 7920, time: 0.159, data: 0.000) loss: 0.158 
(epoch: 141, iters: 8000, time: 0.161, data: 0.000) loss: 1.654 
saving the latest model (epoch 141, total_steps 1434896)
(epoch: 141, iters: 8080, time: 0.160, data: 0.000) loss: 0.431 
(epoch: 141, iters: 8160, time: 0.163, data: 0.000) loss: 0.351 
(epoch: 141, iters: 8240, time: 0.163, data: 0.000) loss: 0.667 
(epoch: 141, iters: 8320, time: 0.160, data: 0.005) loss: 0.502 
(epoch: 141, iters: 8400, time: 0.160, data: 0.000) loss: 0.250 
(epoch: 141, iters: 8480, time: 0.159, data: 0.000) loss: 0.124 
(epoch: 141, iters: 8560, time: 0.160, data: 0.006) loss: 0.783 
(epoch: 141, iters: 8640, time: 0.160, data: 0.000) loss: 0.111 
(epoch: 141, iters: 8720, time: 0.161, data: 0.000) loss: 0.257 
(epoch: 141, iters: 8800, time: 0.159, data: 0.000) loss: 0.318 
(epoch: 141, iters: 8880, time: 0.160, data: 0.005) loss: 0.180 
(epoch: 141, iters: 8960, time: 0.167, data: 0.005) loss: 0.410 
(epoch: 141, iters: 9040, time: 0.162, data: 0.000) loss: 0.529 
(epoch: 141, iters: 9120, time: 0.162, data: 0.000) loss: 0.630 
(epoch: 141, iters: 9200, time: 0.160, data: 0.000) loss: 0.236 
(epoch: 141, iters: 9280, time: 0.161, data: 0.000) loss: 0.579 
(epoch: 141, iters: 9360, time: 0.161, data: 0.000) loss: 0.108 
(epoch: 141, iters: 9440, time: 0.159, data: 0.000) loss: 0.222 
(epoch: 141, iters: 9520, time: 0.160, data: 0.000) loss: 0.232 
(epoch: 141, iters: 9600, time: 0.162, data: 0.015) loss: 0.146 
(epoch: 141, iters: 9680, time: 0.161, data: 0.005) loss: 0.228 
(epoch: 141, iters: 9760, time: 0.160, data: 0.000) loss: 0.394 
(epoch: 141, iters: 9840, time: 0.160, data: 0.000) loss: 0.194 
(epoch: 141, iters: 9920, time: 0.162, data: 0.000) loss: 0.426 
(epoch: 141, iters: 10000, time: 0.160, data: 0.015) loss: 0.203 
(epoch: 141, iters: 10080, time: 0.159, data: 0.008) loss: 0.633 
(epoch: 141, iters: 10160, time: 0.161, data: 0.000) loss: 0.169 
saving the model at the end of epoch 141, iters 1437072
End of epoch 141 / 200 	 Time Taken: 1643 sec
learning rate = 0.0001149
saving the latest model (epoch 142, total_steps 1437088)
(epoch: 142, iters: 48, time: 0.165, data: 0.005) loss: 0.102 
(epoch: 142, iters: 128, time: 0.164, data: 0.010) loss: 0.281 
(epoch: 142, iters: 208, time: 0.162, data: 0.000) loss: 0.293 
(epoch: 142, iters: 288, time: 0.164, data: 0.009) loss: 0.384 
(epoch: 142, iters: 368, time: 0.160, data: 0.000) loss: 0.059 
(epoch: 142, iters: 448, time: 0.163, data: 0.025) loss: 0.191 
(epoch: 142, iters: 528, time: 0.161, data: 0.000) loss: 0.461 
(epoch: 142, iters: 608, time: 0.161, data: 0.000) loss: 0.162 
(epoch: 142, iters: 688, time: 0.164, data: 0.000) loss: 0.432 
(epoch: 142, iters: 768, time: 0.160, data: 0.000) loss: 0.096 
(epoch: 142, iters: 848, time: 0.160, data: 0.000) loss: 0.326 
(epoch: 142, iters: 928, time: 0.162, data: 0.000) loss: 0.371 
(epoch: 142, iters: 1008, time: 0.159, data: 0.000) loss: 0.142 
(epoch: 142, iters: 1088, time: 0.161, data: 0.015) loss: 0.429 
(epoch: 142, iters: 1168, time: 0.159, data: 0.000) loss: 0.132 
(epoch: 142, iters: 1248, time: 0.161, data: 0.034) loss: 0.248 
(epoch: 142, iters: 1328, time: 0.160, data: 0.000) loss: 0.193 
(epoch: 142, iters: 1408, time: 0.160, data: 0.000) loss: 0.478 
(epoch: 142, iters: 1488, time: 0.159, data: 0.000) loss: 0.139 
(epoch: 142, iters: 1568, time: 0.160, data: 0.005) loss: 0.466 
(epoch: 142, iters: 1648, time: 0.160, data: 0.000) loss: 0.222 
(epoch: 142, iters: 1728, time: 0.162, data: 0.000) loss: 0.237 
(epoch: 142, iters: 1808, time: 0.160, data: 0.008) loss: 0.165 
(epoch: 142, iters: 1888, time: 0.160, data: 0.014) loss: 0.071 
(epoch: 142, iters: 1968, time: 0.161, data: 0.005) loss: 0.319 
(epoch: 142, iters: 2048, time: 0.162, data: 0.000) loss: 0.080 
(epoch: 142, iters: 2128, time: 0.158, data: 0.009) loss: 0.184 
(epoch: 142, iters: 2208, time: 0.162, data: 0.000) loss: 0.209 
(epoch: 142, iters: 2288, time: 0.159, data: 0.009) loss: 0.214 
(epoch: 142, iters: 2368, time: 0.159, data: 0.000) loss: 0.155 
(epoch: 142, iters: 2448, time: 0.160, data: 0.000) loss: 0.089 
(epoch: 142, iters: 2528, time: 0.161, data: 0.006) loss: 0.167 
(epoch: 142, iters: 2608, time: 0.165, data: 0.016) loss: 0.545 
(epoch: 142, iters: 2688, time: 0.160, data: 0.000) loss: 0.253 
(epoch: 142, iters: 2768, time: 0.160, data: 0.000) loss: 1.252 
(epoch: 142, iters: 2848, time: 0.161, data: 0.010) loss: 1.126 
(epoch: 142, iters: 2928, time: 0.162, data: 0.000) loss: 0.425 
(epoch: 142, iters: 3008, time: 0.159, data: 0.014) loss: 0.378 
(epoch: 142, iters: 3088, time: 0.159, data: 0.032) loss: 0.168 
(epoch: 142, iters: 3168, time: 0.160, data: 0.000) loss: 0.246 
(epoch: 142, iters: 3248, time: 0.158, data: 0.005) loss: 0.577 
(epoch: 142, iters: 3328, time: 0.160, data: 0.000) loss: 0.160 
(epoch: 142, iters: 3408, time: 0.159, data: 0.018) loss: 0.234 
(epoch: 142, iters: 3488, time: 0.159, data: 0.000) loss: 0.647 
(epoch: 142, iters: 3568, time: 0.157, data: 0.000) loss: 0.057 
(epoch: 142, iters: 3648, time: 0.158, data: 0.016) loss: 0.042 
(epoch: 142, iters: 3728, time: 0.160, data: 0.000) loss: 0.673 
(epoch: 142, iters: 3808, time: 0.159, data: 0.005) loss: 0.151 
(epoch: 142, iters: 3888, time: 0.161, data: 0.000) loss: 0.469 
(epoch: 142, iters: 3968, time: 0.159, data: 0.017) loss: 0.323 
saving the latest model (epoch 142, total_steps 1441088)
(epoch: 142, iters: 4048, time: 0.161, data: 0.011) loss: 0.119 
(epoch: 142, iters: 4128, time: 0.160, data: 0.017) loss: 0.594 
(epoch: 142, iters: 4208, time: 0.158, data: 0.005) loss: 0.279 
(epoch: 142, iters: 4288, time: 0.157, data: 0.005) loss: 0.530 
(epoch: 142, iters: 4368, time: 0.159, data: 0.011) loss: 0.378 
(epoch: 142, iters: 4448, time: 0.158, data: 0.000) loss: 0.215 
(epoch: 142, iters: 4528, time: 0.158, data: 0.025) loss: 0.575 
(epoch: 142, iters: 4608, time: 0.158, data: 0.000) loss: 0.438 
(epoch: 142, iters: 4688, time: 0.157, data: 0.000) loss: 0.300 
(epoch: 142, iters: 4768, time: 0.158, data: 0.025) loss: 0.314 
(epoch: 142, iters: 4848, time: 0.157, data: 0.000) loss: 0.394 
(epoch: 142, iters: 4928, time: 0.164, data: 0.010) loss: 0.284 
(epoch: 142, iters: 5008, time: 0.160, data: 0.011) loss: 0.198 
(epoch: 142, iters: 5088, time: 0.160, data: 0.000) loss: 0.054 
(epoch: 142, iters: 5168, time: 0.159, data: 0.024) loss: 0.662 
(epoch: 142, iters: 5248, time: 0.158, data: 0.000) loss: 0.389 
(epoch: 142, iters: 5328, time: 0.160, data: 0.000) loss: 0.434 
(epoch: 142, iters: 5408, time: 0.159, data: 0.000) loss: 0.296 
(epoch: 142, iters: 5488, time: 0.161, data: 0.000) loss: 0.501 
(epoch: 142, iters: 5568, time: 0.160, data: 0.005) loss: 0.224 
(epoch: 142, iters: 5648, time: 0.159, data: 0.018) loss: 0.299 
(epoch: 142, iters: 5728, time: 0.159, data: 0.000) loss: 0.394 
(epoch: 142, iters: 5808, time: 0.158, data: 0.005) loss: 0.467 
(epoch: 142, iters: 5888, time: 0.159, data: 0.005) loss: 0.175 
(epoch: 142, iters: 5968, time: 0.160, data: 0.000) loss: 0.848 
(epoch: 142, iters: 6048, time: 0.161, data: 0.005) loss: 0.201 
(epoch: 142, iters: 6128, time: 0.159, data: 0.024) loss: 0.572 
(epoch: 142, iters: 6208, time: 0.160, data: 0.000) loss: 0.640 
(epoch: 142, iters: 6288, time: 0.159, data: 0.000) loss: 0.310 
(epoch: 142, iters: 6368, time: 0.162, data: 0.000) loss: 0.303 
(epoch: 142, iters: 6448, time: 0.160, data: 0.008) loss: 0.336 
(epoch: 142, iters: 6528, time: 0.160, data: 0.015) loss: 0.901 
(epoch: 142, iters: 6608, time: 0.161, data: 0.000) loss: 0.864 
(epoch: 142, iters: 6688, time: 0.159, data: 0.000) loss: 0.763 
(epoch: 142, iters: 6768, time: 0.161, data: 0.000) loss: 0.213 
(epoch: 142, iters: 6848, time: 0.160, data: 0.016) loss: 0.140 
(epoch: 142, iters: 6928, time: 0.160, data: 0.000) loss: 0.754 
(epoch: 142, iters: 7008, time: 0.158, data: 0.008) loss: 0.574 
(epoch: 142, iters: 7088, time: 0.162, data: 0.000) loss: 0.715 
(epoch: 142, iters: 7168, time: 0.159, data: 0.000) loss: 0.159 
(epoch: 142, iters: 7248, time: 0.163, data: 0.000) loss: 0.116 
(epoch: 142, iters: 7328, time: 0.159, data: 0.000) loss: 0.227 
(epoch: 142, iters: 7408, time: 0.160, data: 0.020) loss: 0.363 
(epoch: 142, iters: 7488, time: 0.161, data: 0.008) loss: 0.186 
(epoch: 142, iters: 7568, time: 0.160, data: 0.000) loss: 0.539 
(epoch: 142, iters: 7648, time: 0.160, data: 0.000) loss: 0.243 
(epoch: 142, iters: 7728, time: 0.159, data: 0.015) loss: 0.096 
(epoch: 142, iters: 7808, time: 0.159, data: 0.000) loss: 0.255 
(epoch: 142, iters: 7888, time: 0.161, data: 0.005) loss: 0.106 
(epoch: 142, iters: 7968, time: 0.162, data: 0.014) loss: 0.608 
saving the latest model (epoch 142, total_steps 1445088)
(epoch: 142, iters: 8048, time: 0.160, data: 0.000) loss: 0.258 
(epoch: 142, iters: 8128, time: 0.163, data: 0.006) loss: 0.237 
(epoch: 142, iters: 8208, time: 0.161, data: 0.000) loss: 0.549 
(epoch: 142, iters: 8288, time: 0.159, data: 0.000) loss: 0.208 
(epoch: 142, iters: 8368, time: 0.160, data: 0.000) loss: 0.811 
(epoch: 142, iters: 8448, time: 0.160, data: 0.008) loss: 0.251 
(epoch: 142, iters: 8528, time: 0.160, data: 0.000) loss: 0.185 
(epoch: 142, iters: 8608, time: 0.158, data: 0.005) loss: 0.300 
(epoch: 142, iters: 8688, time: 0.160, data: 0.005) loss: 0.523 
(epoch: 142, iters: 8768, time: 0.162, data: 0.000) loss: 0.484 
(epoch: 142, iters: 8848, time: 0.160, data: 0.000) loss: 0.440 
(epoch: 142, iters: 8928, time: 0.158, data: 0.009) loss: 0.455 
(epoch: 142, iters: 9008, time: 0.158, data: 0.000) loss: 0.353 
(epoch: 142, iters: 9088, time: 0.160, data: 0.021) loss: 0.711 
(epoch: 142, iters: 9168, time: 0.160, data: 0.008) loss: 0.341 
(epoch: 142, iters: 9248, time: 0.159, data: 0.000) loss: 0.582 
(epoch: 142, iters: 9328, time: 0.161, data: 0.000) loss: 0.153 
(epoch: 142, iters: 9408, time: 0.161, data: 0.000) loss: 0.648 
(epoch: 142, iters: 9488, time: 0.160, data: 0.006) loss: 0.293 
(epoch: 142, iters: 9568, time: 0.163, data: 0.000) loss: 0.708 
(epoch: 142, iters: 9648, time: 0.158, data: 0.008) loss: 0.330 
(epoch: 142, iters: 9728, time: 0.162, data: 0.005) loss: 1.141 
(epoch: 142, iters: 9808, time: 0.162, data: 0.008) loss: 0.374 
(epoch: 142, iters: 9888, time: 0.160, data: 0.000) loss: 0.223 
(epoch: 142, iters: 9968, time: 0.161, data: 0.000) loss: 0.620 
(epoch: 142, iters: 10048, time: 0.159, data: 0.005) loss: 0.080 
(epoch: 142, iters: 10128, time: 0.159, data: 0.000) loss: 0.323 
saving the model at the end of epoch 142, iters 1447264
End of epoch 142 / 200 	 Time Taken: 1635 sec
learning rate = 0.0001129
(epoch: 143, iters: 16, time: 0.178, data: 0.012) loss: 0.290 
saving the latest model (epoch 143, total_steps 1447280)
(epoch: 143, iters: 96, time: 0.161, data: 0.000) loss: 0.776 
(epoch: 143, iters: 176, time: 0.161, data: 0.000) loss: 0.422 
(epoch: 143, iters: 256, time: 0.158, data: 0.016) loss: 0.257 
(epoch: 143, iters: 336, time: 0.159, data: 0.000) loss: 0.389 
(epoch: 143, iters: 416, time: 0.159, data: 0.000) loss: 0.180 
(epoch: 143, iters: 496, time: 0.160, data: 0.005) loss: 0.380 
(epoch: 143, iters: 576, time: 0.159, data: 0.000) loss: 0.056 
(epoch: 143, iters: 656, time: 0.159, data: 0.012) loss: 0.387 
(epoch: 143, iters: 736, time: 0.158, data: 0.000) loss: 0.108 
(epoch: 143, iters: 816, time: 0.160, data: 0.012) loss: 0.234 
(epoch: 143, iters: 896, time: 0.159, data: 0.000) loss: 0.658 
(epoch: 143, iters: 976, time: 0.160, data: 0.005) loss: 0.141 
(epoch: 143, iters: 1056, time: 0.159, data: 0.018) loss: 0.183 
(epoch: 143, iters: 1136, time: 0.159, data: 0.000) loss: 0.424 
(epoch: 143, iters: 1216, time: 0.161, data: 0.000) loss: 0.279 
(epoch: 143, iters: 1296, time: 0.160, data: 0.000) loss: 0.331 
(epoch: 143, iters: 1376, time: 0.159, data: 0.008) loss: 0.270 
(epoch: 143, iters: 1456, time: 0.160, data: 0.000) loss: 0.503 
(epoch: 143, iters: 1536, time: 0.162, data: 0.014) loss: 0.341 
(epoch: 143, iters: 1616, time: 0.160, data: 0.000) loss: 0.217 
(epoch: 143, iters: 1696, time: 0.166, data: 0.000) loss: 0.092 
(epoch: 143, iters: 1776, time: 0.161, data: 0.008) loss: 0.375 
(epoch: 143, iters: 1856, time: 0.159, data: 0.000) loss: 0.810 
(epoch: 143, iters: 1936, time: 0.162, data: 0.005) loss: 0.028 
(epoch: 143, iters: 2016, time: 0.161, data: 0.000) loss: 0.638 
(epoch: 143, iters: 2096, time: 0.163, data: 0.005) loss: 0.080 
(epoch: 143, iters: 2176, time: 0.160, data: 0.000) loss: 0.078 
(epoch: 143, iters: 2256, time: 0.163, data: 0.005) loss: 0.181 
(epoch: 143, iters: 2336, time: 0.161, data: 0.000) loss: 0.115 
(epoch: 143, iters: 2416, time: 0.161, data: 0.000) loss: 0.312 
(epoch: 143, iters: 2496, time: 0.161, data: 0.010) loss: 0.468 
(epoch: 143, iters: 2576, time: 0.157, data: 0.000) loss: 0.762 
(epoch: 143, iters: 2656, time: 0.159, data: 0.000) loss: 0.487 
(epoch: 143, iters: 2736, time: 0.159, data: 0.031) loss: 0.738 
(epoch: 143, iters: 2816, time: 0.158, data: 0.000) loss: 0.084 
(epoch: 143, iters: 2896, time: 0.160, data: 0.000) loss: 0.258 
(epoch: 143, iters: 2976, time: 0.161, data: 0.000) loss: 0.538 
(epoch: 143, iters: 3056, time: 0.160, data: 0.009) loss: 0.191 
(epoch: 143, iters: 3136, time: 0.160, data: 0.000) loss: 0.350 
(epoch: 143, iters: 3216, time: 0.161, data: 0.000) loss: 0.084 
(epoch: 143, iters: 3296, time: 0.159, data: 0.005) loss: 0.267 
(epoch: 143, iters: 3376, time: 0.159, data: 0.005) loss: 1.073 
(epoch: 143, iters: 3456, time: 0.160, data: 0.000) loss: 0.378 
(epoch: 143, iters: 3536, time: 0.163, data: 0.000) loss: 0.632 
(epoch: 143, iters: 3616, time: 0.159, data: 0.016) loss: 0.286 
(epoch: 143, iters: 3696, time: 0.160, data: 0.000) loss: 0.449 
(epoch: 143, iters: 3776, time: 0.160, data: 0.016) loss: 0.410 
(epoch: 143, iters: 3856, time: 0.158, data: 0.000) loss: 0.188 
(epoch: 143, iters: 3936, time: 0.157, data: 0.009) loss: 0.403 
(epoch: 143, iters: 4016, time: 0.158, data: 0.017) loss: 0.439 
saving the latest model (epoch 143, total_steps 1451280)
(epoch: 143, iters: 4096, time: 0.158, data: 0.000) loss: 0.623 
(epoch: 143, iters: 4176, time: 0.158, data: 0.000) loss: 0.375 
(epoch: 143, iters: 4256, time: 0.160, data: 0.005) loss: 0.220 
(epoch: 143, iters: 4336, time: 0.161, data: 0.005) loss: 0.482 
(epoch: 143, iters: 4416, time: 0.157, data: 0.000) loss: 0.275 
(epoch: 143, iters: 4496, time: 0.160, data: 0.000) loss: 0.289 
(epoch: 143, iters: 4576, time: 0.158, data: 0.018) loss: 0.324 
(epoch: 143, iters: 4656, time: 0.160, data: 0.020) loss: 0.580 
(epoch: 143, iters: 4736, time: 0.160, data: 0.000) loss: 0.422 
(epoch: 143, iters: 4816, time: 0.159, data: 0.000) loss: 0.057 
(epoch: 143, iters: 4896, time: 0.157, data: 0.014) loss: 0.178 
(epoch: 143, iters: 4976, time: 0.160, data: 0.014) loss: 0.435 
(epoch: 143, iters: 5056, time: 0.162, data: 0.005) loss: 0.304 
(epoch: 143, iters: 5136, time: 0.158, data: 0.006) loss: 0.253 
(epoch: 143, iters: 5216, time: 0.158, data: 0.010) loss: 0.466 
(epoch: 143, iters: 5296, time: 0.157, data: 0.000) loss: 0.212 
(epoch: 143, iters: 5376, time: 0.158, data: 0.026) loss: 0.210 
(epoch: 143, iters: 5456, time: 0.159, data: 0.000) loss: 0.471 
(epoch: 143, iters: 5536, time: 0.158, data: 0.000) loss: 0.310 
(epoch: 143, iters: 5616, time: 0.158, data: 0.000) loss: 0.367 
(epoch: 143, iters: 5696, time: 0.160, data: 0.008) loss: 0.414 
(epoch: 143, iters: 5776, time: 0.158, data: 0.005) loss: 0.205 
(epoch: 143, iters: 5856, time: 0.158, data: 0.000) loss: 0.602 
(epoch: 143, iters: 5936, time: 0.159, data: 0.008) loss: 0.880 
(epoch: 143, iters: 6016, time: 0.160, data: 0.000) loss: 0.705 
(epoch: 143, iters: 6096, time: 0.159, data: 0.000) loss: 0.296 
(epoch: 143, iters: 6176, time: 0.165, data: 0.021) loss: 0.506 
(epoch: 143, iters: 6256, time: 0.159, data: 0.024) loss: 0.173 
(epoch: 143, iters: 6336, time: 0.159, data: 0.000) loss: 0.341 
(epoch: 143, iters: 6416, time: 0.158, data: 0.000) loss: 0.245 
(epoch: 143, iters: 6496, time: 0.160, data: 0.000) loss: 0.134 
(epoch: 143, iters: 6576, time: 0.165, data: 0.006) loss: 0.258 
(epoch: 143, iters: 6656, time: 0.161, data: 0.000) loss: 0.214 
(epoch: 143, iters: 6736, time: 0.160, data: 0.000) loss: 0.217 
(epoch: 143, iters: 6816, time: 0.158, data: 0.000) loss: 0.365 
(epoch: 143, iters: 6896, time: 0.160, data: 0.011) loss: 0.326 
(epoch: 143, iters: 6976, time: 0.160, data: 0.000) loss: 0.250 
(epoch: 143, iters: 7056, time: 0.159, data: 0.000) loss: 0.134 
(epoch: 143, iters: 7136, time: 0.159, data: 0.000) loss: 0.518 
(epoch: 143, iters: 7216, time: 0.161, data: 0.005) loss: 0.572 
(epoch: 143, iters: 7296, time: 0.158, data: 0.013) loss: 0.417 
(epoch: 143, iters: 7376, time: 0.161, data: 0.000) loss: 0.437 
(epoch: 143, iters: 7456, time: 0.159, data: 0.006) loss: 0.221 
(epoch: 143, iters: 7536, time: 0.159, data: 0.005) loss: 0.365 
(epoch: 143, iters: 7616, time: 0.160, data: 0.030) loss: 0.616 
(epoch: 143, iters: 7696, time: 0.160, data: 0.000) loss: 0.390 
(epoch: 143, iters: 7776, time: 0.160, data: 0.000) loss: 0.541 
(epoch: 143, iters: 7856, time: 0.159, data: 0.023) loss: 0.077 
(epoch: 143, iters: 7936, time: 0.159, data: 0.000) loss: 0.522 
(epoch: 143, iters: 8016, time: 0.160, data: 0.000) loss: 0.099 
saving the latest model (epoch 143, total_steps 1455280)
(epoch: 143, iters: 8096, time: 0.160, data: 0.000) loss: 0.556 
(epoch: 143, iters: 8176, time: 0.162, data: 0.014) loss: 0.627 
(epoch: 143, iters: 8256, time: 0.158, data: 0.005) loss: 0.300 
(epoch: 143, iters: 8336, time: 0.159, data: 0.000) loss: 0.215 
(epoch: 143, iters: 8416, time: 0.159, data: 0.005) loss: 0.801 
(epoch: 143, iters: 8496, time: 0.159, data: 0.014) loss: 0.304 
(epoch: 143, iters: 8576, time: 0.158, data: 0.000) loss: 0.628 
(epoch: 143, iters: 8656, time: 0.158, data: 0.019) loss: 0.192 
(epoch: 143, iters: 8736, time: 0.157, data: 0.005) loss: 0.214 
(epoch: 143, iters: 8816, time: 0.159, data: 0.010) loss: 0.191 
(epoch: 143, iters: 8896, time: 0.163, data: 0.000) loss: 0.504 
(epoch: 143, iters: 8976, time: 0.157, data: 0.000) loss: 0.601 
(epoch: 143, iters: 9056, time: 0.160, data: 0.000) loss: 0.517 
(epoch: 143, iters: 9136, time: 0.160, data: 0.012) loss: 0.131 
(epoch: 143, iters: 9216, time: 0.158, data: 0.006) loss: 1.092 
(epoch: 143, iters: 9296, time: 0.160, data: 0.006) loss: 0.517 
(epoch: 143, iters: 9376, time: 0.159, data: 0.000) loss: 0.576 
(epoch: 143, iters: 9456, time: 0.158, data: 0.000) loss: 0.455 
(epoch: 143, iters: 9536, time: 0.158, data: 0.000) loss: 0.067 
(epoch: 143, iters: 9616, time: 0.158, data: 0.034) loss: 0.343 
(epoch: 143, iters: 9696, time: 0.158, data: 0.000) loss: 0.589 
(epoch: 143, iters: 9776, time: 0.159, data: 0.000) loss: 0.521 
(epoch: 143, iters: 9856, time: 0.160, data: 0.000) loss: 0.459 
(epoch: 143, iters: 9936, time: 0.161, data: 0.008) loss: 0.463 
(epoch: 143, iters: 10016, time: 0.160, data: 0.015) loss: 0.339 
(epoch: 143, iters: 10096, time: 0.163, data: 0.005) loss: 0.343 
(epoch: 143, iters: 10176, time: 0.160, data: 0.000) loss: 0.541 
saving the model at the end of epoch 143, iters 1457456
End of epoch 143 / 200 	 Time Taken: 1629 sec
learning rate = 0.0001109
saving the latest model (epoch 144, total_steps 1457472)
(epoch: 144, iters: 64, time: 0.162, data: 0.000) loss: 0.419 
(epoch: 144, iters: 144, time: 0.161, data: 0.000) loss: 0.145 
(epoch: 144, iters: 224, time: 0.161, data: 0.022) loss: 0.159 
(epoch: 144, iters: 304, time: 0.159, data: 0.000) loss: 0.364 
(epoch: 144, iters: 384, time: 0.159, data: 0.025) loss: 0.393 
(epoch: 144, iters: 464, time: 0.158, data: 0.000) loss: 0.763 
(epoch: 144, iters: 544, time: 0.160, data: 0.000) loss: 0.188 
(epoch: 144, iters: 624, time: 0.159, data: 0.000) loss: 0.204 
(epoch: 144, iters: 704, time: 0.159, data: 0.008) loss: 0.203 
(epoch: 144, iters: 784, time: 0.158, data: 0.000) loss: 0.160 
(epoch: 144, iters: 864, time: 0.160, data: 0.018) loss: 0.116 
(epoch: 144, iters: 944, time: 0.161, data: 0.000) loss: 0.370 
(epoch: 144, iters: 1024, time: 0.168, data: 0.000) loss: 0.233 
(epoch: 144, iters: 1104, time: 0.158, data: 0.000) loss: 0.453 
(epoch: 144, iters: 1184, time: 0.160, data: 0.000) loss: 0.571 
(epoch: 144, iters: 1264, time: 0.161, data: 0.009) loss: 0.233 
(epoch: 144, iters: 1344, time: 0.159, data: 0.000) loss: 0.420 
(epoch: 144, iters: 1424, time: 0.159, data: 0.005) loss: 0.373 
(epoch: 144, iters: 1504, time: 0.159, data: 0.000) loss: 0.168 
(epoch: 144, iters: 1584, time: 0.159, data: 0.005) loss: 0.283 
(epoch: 144, iters: 1664, time: 0.160, data: 0.006) loss: 0.124 
(epoch: 144, iters: 1744, time: 0.161, data: 0.006) loss: 0.148 
(epoch: 144, iters: 1824, time: 0.162, data: 0.000) loss: 0.389 
(epoch: 144, iters: 1904, time: 0.159, data: 0.000) loss: 0.371 
(epoch: 144, iters: 1984, time: 0.161, data: 0.000) loss: 0.244 
(epoch: 144, iters: 2064, time: 0.159, data: 0.000) loss: 0.169 
(epoch: 144, iters: 2144, time: 0.159, data: 0.006) loss: 0.521 
(epoch: 144, iters: 2224, time: 0.159, data: 0.000) loss: 0.228 
(epoch: 144, iters: 2304, time: 0.160, data: 0.006) loss: 0.172 
(epoch: 144, iters: 2384, time: 0.159, data: 0.005) loss: 0.232 
(epoch: 144, iters: 2464, time: 0.161, data: 0.000) loss: 0.175 
(epoch: 144, iters: 2544, time: 0.158, data: 0.006) loss: 0.336 
(epoch: 144, iters: 2624, time: 0.156, data: 0.018) loss: 0.058 
(epoch: 144, iters: 2704, time: 0.161, data: 0.000) loss: 0.462 
(epoch: 144, iters: 2784, time: 0.159, data: 0.000) loss: 0.154 
(epoch: 144, iters: 2864, time: 0.159, data: 0.005) loss: 0.204 
(epoch: 144, iters: 2944, time: 0.159, data: 0.000) loss: 0.379 
(epoch: 144, iters: 3024, time: 0.160, data: 0.000) loss: 0.368 
(epoch: 144, iters: 3104, time: 0.159, data: 0.000) loss: 0.454 
(epoch: 144, iters: 3184, time: 0.159, data: 0.005) loss: 0.154 
(epoch: 144, iters: 3264, time: 0.159, data: 0.000) loss: 0.489 
(epoch: 144, iters: 3344, time: 0.166, data: 0.041) loss: 0.503 
(epoch: 144, iters: 3424, time: 0.159, data: 0.000) loss: 0.618 
(epoch: 144, iters: 3504, time: 0.158, data: 0.000) loss: 0.489 
(epoch: 144, iters: 3584, time: 0.162, data: 0.020) loss: 0.765 
(epoch: 144, iters: 3664, time: 0.158, data: 0.000) loss: 0.205 
(epoch: 144, iters: 3744, time: 0.166, data: 0.000) loss: 0.420 
(epoch: 144, iters: 3824, time: 0.159, data: 0.008) loss: 0.785 
(epoch: 144, iters: 3904, time: 0.160, data: 0.005) loss: 0.295 
(epoch: 144, iters: 3984, time: 0.161, data: 0.000) loss: 0.345 
saving the latest model (epoch 144, total_steps 1461472)
(epoch: 144, iters: 4064, time: 0.161, data: 0.000) loss: 0.405 
(epoch: 144, iters: 4144, time: 0.160, data: 0.022) loss: 0.228 
(epoch: 144, iters: 4224, time: 0.158, data: 0.000) loss: 0.292 
(epoch: 144, iters: 4304, time: 0.159, data: 0.027) loss: 0.280 
(epoch: 144, iters: 4384, time: 0.159, data: 0.000) loss: 0.376 
(epoch: 144, iters: 4464, time: 0.160, data: 0.000) loss: 0.173 
(epoch: 144, iters: 4544, time: 0.160, data: 0.000) loss: 0.224 
(epoch: 144, iters: 4624, time: 0.159, data: 0.000) loss: 0.426 
(epoch: 144, iters: 4704, time: 0.159, data: 0.000) loss: 0.094 
(epoch: 144, iters: 4784, time: 0.159, data: 0.016) loss: 0.697 
(epoch: 144, iters: 4864, time: 0.164, data: 0.009) loss: 0.346 
(epoch: 144, iters: 4944, time: 0.159, data: 0.000) loss: 0.204 
(epoch: 144, iters: 5024, time: 0.159, data: 0.000) loss: 0.259 
(epoch: 144, iters: 5104, time: 0.159, data: 0.010) loss: 0.212 
(epoch: 144, iters: 5184, time: 0.159, data: 0.000) loss: 0.438 
(epoch: 144, iters: 5264, time: 0.158, data: 0.000) loss: 0.172 
(epoch: 144, iters: 5344, time: 0.159, data: 0.006) loss: 0.121 
(epoch: 144, iters: 5424, time: 0.158, data: 0.014) loss: 0.531 
(epoch: 144, iters: 5504, time: 0.160, data: 0.000) loss: 0.149 
(epoch: 144, iters: 5584, time: 0.160, data: 0.000) loss: 0.134 
(epoch: 144, iters: 5664, time: 0.158, data: 0.000) loss: 0.668 
(epoch: 144, iters: 5744, time: 0.160, data: 0.000) loss: 0.272 
(epoch: 144, iters: 5824, time: 0.160, data: 0.021) loss: 0.618 
(epoch: 144, iters: 5904, time: 0.159, data: 0.005) loss: 0.795 
(epoch: 144, iters: 5984, time: 0.159, data: 0.000) loss: 0.399 
(epoch: 144, iters: 6064, time: 0.162, data: 0.000) loss: 0.411 
(epoch: 144, iters: 6144, time: 0.159, data: 0.000) loss: 0.541 
(epoch: 144, iters: 6224, time: 0.158, data: 0.016) loss: 0.348 
(epoch: 144, iters: 6304, time: 0.159, data: 0.000) loss: 0.248 
(epoch: 144, iters: 6384, time: 0.159, data: 0.000) loss: 0.579 
(epoch: 144, iters: 6464, time: 0.162, data: 0.005) loss: 0.432 
(epoch: 144, iters: 6544, time: 0.158, data: 0.019) loss: 0.413 
(epoch: 144, iters: 6624, time: 0.159, data: 0.000) loss: 0.568 
(epoch: 144, iters: 6704, time: 0.158, data: 0.008) loss: 0.707 
(epoch: 144, iters: 6784, time: 0.159, data: 0.000) loss: 0.617 
(epoch: 144, iters: 6864, time: 0.159, data: 0.000) loss: 0.245 
(epoch: 144, iters: 6944, time: 0.161, data: 0.015) loss: 0.225 
(epoch: 144, iters: 7024, time: 0.158, data: 0.000) loss: 0.339 
(epoch: 144, iters: 7104, time: 0.160, data: 0.000) loss: 0.553 
(epoch: 144, iters: 7184, time: 0.159, data: 0.008) loss: 0.146 
(epoch: 144, iters: 7264, time: 0.160, data: 0.005) loss: 0.094 
(epoch: 144, iters: 7344, time: 0.161, data: 0.000) loss: 0.198 
(epoch: 144, iters: 7424, time: 0.157, data: 0.018) loss: 0.160 
(epoch: 144, iters: 7504, time: 0.158, data: 0.000) loss: 0.381 
(epoch: 144, iters: 7584, time: 0.160, data: 0.000) loss: 0.163 
(epoch: 144, iters: 7664, time: 0.157, data: 0.000) loss: 0.485 
(epoch: 144, iters: 7744, time: 0.159, data: 0.000) loss: 0.074 
(epoch: 144, iters: 7824, time: 0.160, data: 0.000) loss: 0.265 
(epoch: 144, iters: 7904, time: 0.159, data: 0.000) loss: 0.574 
(epoch: 144, iters: 7984, time: 0.159, data: 0.000) loss: 0.408 
saving the latest model (epoch 144, total_steps 1465472)
(epoch: 144, iters: 8064, time: 0.159, data: 0.000) loss: 0.479 
(epoch: 144, iters: 8144, time: 0.161, data: 0.000) loss: 0.205 
(epoch: 144, iters: 8224, time: 0.159, data: 0.020) loss: 0.519 
(epoch: 144, iters: 8304, time: 0.159, data: 0.000) loss: 0.311 
(epoch: 144, iters: 8384, time: 0.158, data: 0.011) loss: 0.292 
(epoch: 144, iters: 8464, time: 0.158, data: 0.000) loss: 0.357 
(epoch: 144, iters: 8544, time: 0.159, data: 0.000) loss: 0.489 
(epoch: 144, iters: 8624, time: 0.158, data: 0.000) loss: 0.683 
(epoch: 144, iters: 8704, time: 0.157, data: 0.009) loss: 0.356 
(epoch: 144, iters: 8784, time: 0.160, data: 0.000) loss: 0.235 
(epoch: 144, iters: 8864, time: 0.157, data: 0.008) loss: 0.725 
(epoch: 144, iters: 8944, time: 0.158, data: 0.000) loss: 0.246 
(epoch: 144, iters: 9024, time: 0.157, data: 0.005) loss: 0.453 
(epoch: 144, iters: 9104, time: 0.162, data: 0.000) loss: 0.639 
(epoch: 144, iters: 9184, time: 0.157, data: 0.041) loss: 0.661 
(epoch: 144, iters: 9264, time: 0.160, data: 0.000) loss: 0.281 
(epoch: 144, iters: 9344, time: 0.157, data: 0.032) loss: 0.355 
(epoch: 144, iters: 9424, time: 0.158, data: 0.000) loss: 0.622 
(epoch: 144, iters: 9504, time: 0.157, data: 0.022) loss: 0.170 
(epoch: 144, iters: 9584, time: 0.159, data: 0.000) loss: 0.453 
(epoch: 144, iters: 9664, time: 0.158, data: 0.000) loss: 0.540 
(epoch: 144, iters: 9744, time: 0.162, data: 0.009) loss: 0.224 
(epoch: 144, iters: 9824, time: 0.160, data: 0.005) loss: 0.697 
(epoch: 144, iters: 9904, time: 0.158, data: 0.000) loss: 0.125 
(epoch: 144, iters: 9984, time: 0.160, data: 0.005) loss: 0.504 
(epoch: 144, iters: 10064, time: 0.158, data: 0.000) loss: 1.186 
(epoch: 144, iters: 10144, time: 0.159, data: 0.008) loss: 0.287 
saving the model at the end of epoch 144, iters 1467648
End of epoch 144 / 200 	 Time Taken: 1628 sec
learning rate = 0.0001089
saving the latest model (epoch 145, total_steps 1467664)
(epoch: 145, iters: 32, time: 0.167, data: 0.004) loss: 0.197 
(epoch: 145, iters: 112, time: 0.161, data: 0.000) loss: 0.312 
(epoch: 145, iters: 192, time: 0.160, data: 0.000) loss: 0.166 
(epoch: 145, iters: 272, time: 0.159, data: 0.009) loss: 0.187 
(epoch: 145, iters: 352, time: 0.159, data: 0.006) loss: 0.532 
(epoch: 145, iters: 432, time: 0.159, data: 0.000) loss: 0.354 
(epoch: 145, iters: 512, time: 0.160, data: 0.000) loss: 0.518 
(epoch: 145, iters: 592, time: 0.157, data: 0.000) loss: 0.497 
(epoch: 145, iters: 672, time: 0.158, data: 0.023) loss: 0.108 
(epoch: 145, iters: 752, time: 0.159, data: 0.000) loss: 0.073 
(epoch: 145, iters: 832, time: 0.160, data: 0.000) loss: 0.149 
(epoch: 145, iters: 912, time: 0.160, data: 0.000) loss: 0.210 
(epoch: 145, iters: 992, time: 0.160, data: 0.000) loss: 0.133 
(epoch: 145, iters: 1072, time: 0.159, data: 0.006) loss: 0.470 
(epoch: 145, iters: 1152, time: 0.161, data: 0.000) loss: 0.285 
(epoch: 145, iters: 1232, time: 0.159, data: 0.000) loss: 0.131 
(epoch: 145, iters: 1312, time: 0.166, data: 0.000) loss: 0.131 
(epoch: 145, iters: 1392, time: 0.159, data: 0.011) loss: 0.161 
(epoch: 145, iters: 1472, time: 0.158, data: 0.000) loss: 0.200 
(epoch: 145, iters: 1552, time: 0.157, data: 0.000) loss: 0.639 
(epoch: 145, iters: 1632, time: 0.157, data: 0.000) loss: 0.068 
(epoch: 145, iters: 1712, time: 0.164, data: 0.000) loss: 0.533 
(epoch: 145, iters: 1792, time: 0.159, data: 0.000) loss: 0.340 
(epoch: 145, iters: 1872, time: 0.160, data: 0.000) loss: 0.372 
(epoch: 145, iters: 1952, time: 0.160, data: 0.005) loss: 0.127 
(epoch: 145, iters: 2032, time: 0.164, data: 0.008) loss: 0.207 
(epoch: 145, iters: 2112, time: 0.159, data: 0.008) loss: 0.184 
(epoch: 145, iters: 2192, time: 0.159, data: 0.000) loss: 0.456 
(epoch: 145, iters: 2272, time: 0.159, data: 0.020) loss: 0.218 
(epoch: 145, iters: 2352, time: 0.159, data: 0.016) loss: 0.290 
(epoch: 145, iters: 2432, time: 0.157, data: 0.005) loss: 0.284 
(epoch: 145, iters: 2512, time: 0.159, data: 0.000) loss: 0.462 
(epoch: 145, iters: 2592, time: 0.161, data: 0.009) loss: 0.266 
(epoch: 145, iters: 2672, time: 0.159, data: 0.000) loss: 0.393 
(epoch: 145, iters: 2752, time: 0.158, data: 0.000) loss: 0.219 
(epoch: 145, iters: 2832, time: 0.158, data: 0.008) loss: 0.213 
(epoch: 145, iters: 2912, time: 0.161, data: 0.031) loss: 0.105 
(epoch: 145, iters: 2992, time: 0.160, data: 0.000) loss: 0.148 
(epoch: 145, iters: 3072, time: 0.159, data: 0.000) loss: 0.304 
(epoch: 145, iters: 3152, time: 0.158, data: 0.000) loss: 0.173 
(epoch: 145, iters: 3232, time: 0.159, data: 0.000) loss: 0.032 
(epoch: 145, iters: 3312, time: 0.158, data: 0.000) loss: 0.337 
(epoch: 145, iters: 3392, time: 0.160, data: 0.006) loss: 0.200 
(epoch: 145, iters: 3472, time: 0.159, data: 0.006) loss: 0.295 
(epoch: 145, iters: 3552, time: 0.158, data: 0.028) loss: 0.213 
(epoch: 145, iters: 3632, time: 0.157, data: 0.017) loss: 0.184 
(epoch: 145, iters: 3712, time: 0.157, data: 0.000) loss: 0.587 
(epoch: 145, iters: 3792, time: 0.159, data: 0.023) loss: 0.738 
(epoch: 145, iters: 3872, time: 0.157, data: 0.000) loss: 0.132 
(epoch: 145, iters: 3952, time: 0.158, data: 0.000) loss: 0.729 
saving the latest model (epoch 145, total_steps 1471664)
(epoch: 145, iters: 4032, time: 0.168, data: 0.000) loss: 0.574 
(epoch: 145, iters: 4112, time: 0.159, data: 0.000) loss: 0.231 
(epoch: 145, iters: 4192, time: 0.159, data: 0.009) loss: 0.560 
(epoch: 145, iters: 4272, time: 0.159, data: 0.000) loss: 0.464 
(epoch: 145, iters: 4352, time: 0.158, data: 0.008) loss: 0.176 
(epoch: 145, iters: 4432, time: 0.165, data: 0.000) loss: 0.213 
(epoch: 145, iters: 4512, time: 0.158, data: 0.000) loss: 0.213 
(epoch: 145, iters: 4592, time: 0.157, data: 0.018) loss: 0.215 
(epoch: 145, iters: 4672, time: 0.160, data: 0.000) loss: 0.040 
(epoch: 145, iters: 4752, time: 0.159, data: 0.010) loss: 0.203 
(epoch: 145, iters: 4832, time: 0.160, data: 0.015) loss: 0.296 
(epoch: 145, iters: 4912, time: 0.158, data: 0.008) loss: 0.400 
(epoch: 145, iters: 4992, time: 0.158, data: 0.008) loss: 0.369 
(epoch: 145, iters: 5072, time: 0.158, data: 0.000) loss: 0.153 
(epoch: 145, iters: 5152, time: 0.158, data: 0.019) loss: 0.278 
(epoch: 145, iters: 5232, time: 0.158, data: 0.000) loss: 0.334 
(epoch: 145, iters: 5312, time: 0.158, data: 0.000) loss: 0.297 
(epoch: 145, iters: 5392, time: 0.157, data: 0.000) loss: 0.107 
(epoch: 145, iters: 5472, time: 0.157, data: 0.005) loss: 0.178 
(epoch: 145, iters: 5552, time: 0.160, data: 0.016) loss: 0.109 
(epoch: 145, iters: 5632, time: 0.160, data: 0.000) loss: 0.127 
(epoch: 145, iters: 5712, time: 0.157, data: 0.036) loss: 0.174 
(epoch: 145, iters: 5792, time: 0.162, data: 0.000) loss: 0.122 
(epoch: 145, iters: 5872, time: 0.158, data: 0.000) loss: 0.756 
(epoch: 145, iters: 5952, time: 0.161, data: 0.015) loss: 0.176 
(epoch: 145, iters: 6032, time: 0.162, data: 0.005) loss: 0.595 
(epoch: 145, iters: 6112, time: 0.161, data: 0.006) loss: 0.110 
(epoch: 145, iters: 6192, time: 0.161, data: 0.024) loss: 0.160 
(epoch: 145, iters: 6272, time: 0.161, data: 0.000) loss: 0.297 
(epoch: 145, iters: 6352, time: 0.164, data: 0.016) loss: 0.471 
(epoch: 145, iters: 6432, time: 0.163, data: 0.008) loss: 0.548 
(epoch: 145, iters: 6512, time: 0.160, data: 0.005) loss: 0.345 
(epoch: 145, iters: 6592, time: 0.161, data: 0.000) loss: 0.246 
(epoch: 145, iters: 6672, time: 0.162, data: 0.015) loss: 0.383 
(epoch: 145, iters: 6752, time: 0.164, data: 0.023) loss: 0.244 
(epoch: 145, iters: 6832, time: 0.163, data: 0.000) loss: 0.023 
(epoch: 145, iters: 6912, time: 0.161, data: 0.000) loss: 0.452 
(epoch: 145, iters: 6992, time: 0.163, data: 0.015) loss: 0.288 
(epoch: 145, iters: 7072, time: 0.161, data: 0.000) loss: 0.288 
(epoch: 145, iters: 7152, time: 0.159, data: 0.008) loss: 0.289 
(epoch: 145, iters: 7232, time: 0.161, data: 0.024) loss: 0.132 
(epoch: 145, iters: 7312, time: 0.161, data: 0.000) loss: 0.361 
(epoch: 145, iters: 7392, time: 0.161, data: 0.005) loss: 0.097 
(epoch: 145, iters: 7472, time: 0.161, data: 0.008) loss: 0.031 
(epoch: 145, iters: 7552, time: 0.161, data: 0.000) loss: 0.644 
(epoch: 145, iters: 7632, time: 0.164, data: 0.020) loss: 0.445 
(epoch: 145, iters: 7712, time: 0.163, data: 0.000) loss: 0.145 
(epoch: 145, iters: 7792, time: 0.161, data: 0.000) loss: 0.417 
(epoch: 145, iters: 7872, time: 0.161, data: 0.021) loss: 0.245 
(epoch: 145, iters: 7952, time: 0.164, data: 0.000) loss: 0.254 
saving the latest model (epoch 145, total_steps 1475664)
(epoch: 145, iters: 8032, time: 0.162, data: 0.000) loss: 0.160 
(epoch: 145, iters: 8112, time: 0.161, data: 0.000) loss: 0.222 
(epoch: 145, iters: 8192, time: 0.161, data: 0.000) loss: 0.236 
(epoch: 145, iters: 8272, time: 0.167, data: 0.000) loss: 0.291 
(epoch: 145, iters: 8352, time: 0.162, data: 0.020) loss: 0.106 
(epoch: 145, iters: 8432, time: 0.161, data: 0.000) loss: 0.401 
(epoch: 145, iters: 8512, time: 0.166, data: 0.013) loss: 1.046 
(epoch: 145, iters: 8592, time: 0.162, data: 0.000) loss: 0.061 
(epoch: 145, iters: 8672, time: 0.162, data: 0.000) loss: 0.273 
(epoch: 145, iters: 8752, time: 0.164, data: 0.006) loss: 0.083 
(epoch: 145, iters: 8832, time: 0.162, data: 0.000) loss: 0.624 
(epoch: 145, iters: 8912, time: 0.162, data: 0.000) loss: 1.149 
(epoch: 145, iters: 8992, time: 0.162, data: 0.006) loss: 0.084 
(epoch: 145, iters: 9072, time: 0.161, data: 0.009) loss: 0.509 
(epoch: 145, iters: 9152, time: 0.162, data: 0.000) loss: 0.731 
(epoch: 145, iters: 9232, time: 0.163, data: 0.016) loss: 0.655 
(epoch: 145, iters: 9312, time: 0.164, data: 0.000) loss: 0.359 
(epoch: 145, iters: 9392, time: 0.163, data: 0.005) loss: 0.206 
(epoch: 145, iters: 9472, time: 0.163, data: 0.000) loss: 0.168 
(epoch: 145, iters: 9552, time: 0.164, data: 0.005) loss: 0.159 
(epoch: 145, iters: 9632, time: 0.162, data: 0.000) loss: 0.504 
(epoch: 145, iters: 9712, time: 0.162, data: 0.000) loss: 0.032 
(epoch: 145, iters: 9792, time: 0.164, data: 0.008) loss: 0.309 
(epoch: 145, iters: 9872, time: 0.163, data: 0.000) loss: 0.174 
(epoch: 145, iters: 9952, time: 0.162, data: 0.006) loss: 0.346 
(epoch: 145, iters: 10032, time: 0.162, data: 0.000) loss: 0.454 
(epoch: 145, iters: 10112, time: 0.163, data: 0.014) loss: 0.384 
(epoch: 145, iters: 10192, time: 0.101, data: 0.000) loss: 0.565 
saving the model at the end of epoch 145, iters 1477840
End of epoch 145 / 200 	 Time Taken: 1638 sec
learning rate = 0.0001069
saving the latest model (epoch 146, total_steps 1477856)
(epoch: 146, iters: 80, time: 0.164, data: 0.174) loss: 0.171 
(epoch: 146, iters: 160, time: 0.162, data: 0.037) loss: 0.169 
(epoch: 146, iters: 240, time: 0.163, data: 0.008) loss: 0.374 
(epoch: 146, iters: 320, time: 0.160, data: 0.000) loss: 0.643 
(epoch: 146, iters: 400, time: 0.160, data: 0.005) loss: 0.292 
(epoch: 146, iters: 480, time: 0.162, data: 0.000) loss: 0.264 
(epoch: 146, iters: 560, time: 0.162, data: 0.005) loss: 0.609 
(epoch: 146, iters: 640, time: 0.160, data: 0.000) loss: 0.658 
(epoch: 146, iters: 720, time: 0.160, data: 0.000) loss: 0.666 
(epoch: 146, iters: 800, time: 0.161, data: 0.000) loss: 0.223 
(epoch: 146, iters: 880, time: 0.162, data: 0.015) loss: 0.539 
(epoch: 146, iters: 960, time: 0.160, data: 0.011) loss: 0.217 
(epoch: 146, iters: 1040, time: 0.161, data: 0.000) loss: 0.626 
(epoch: 146, iters: 1120, time: 0.159, data: 0.005) loss: 0.206 
(epoch: 146, iters: 1200, time: 0.161, data: 0.014) loss: 0.257 
(epoch: 146, iters: 1280, time: 0.159, data: 0.000) loss: 0.247 
(epoch: 146, iters: 1360, time: 0.159, data: 0.022) loss: 0.448 
(epoch: 146, iters: 1440, time: 0.158, data: 0.040) loss: 0.487 
(epoch: 146, iters: 1520, time: 0.161, data: 0.000) loss: 0.037 
(epoch: 146, iters: 1600, time: 0.161, data: 0.000) loss: 0.156 
(epoch: 146, iters: 1680, time: 0.161, data: 0.000) loss: 0.874 
(epoch: 146, iters: 1760, time: 0.161, data: 0.006) loss: 0.406 
(epoch: 146, iters: 1840, time: 0.162, data: 0.000) loss: 0.090 
(epoch: 146, iters: 1920, time: 0.162, data: 0.000) loss: 0.432 
(epoch: 146, iters: 2000, time: 0.160, data: 0.005) loss: 0.197 
(epoch: 146, iters: 2080, time: 0.162, data: 0.000) loss: 0.430 
(epoch: 146, iters: 2160, time: 0.161, data: 0.008) loss: 0.236 
(epoch: 146, iters: 2240, time: 0.158, data: 0.000) loss: 0.239 
(epoch: 146, iters: 2320, time: 0.160, data: 0.026) loss: 0.481 
(epoch: 146, iters: 2400, time: 0.163, data: 0.000) loss: 0.441 
(epoch: 146, iters: 2480, time: 0.161, data: 0.000) loss: 0.423 
(epoch: 146, iters: 2560, time: 0.161, data: 0.005) loss: 0.138 
(epoch: 146, iters: 2640, time: 0.161, data: 0.005) loss: 0.282 
(epoch: 146, iters: 2720, time: 0.160, data: 0.005) loss: 0.110 
(epoch: 146, iters: 2800, time: 0.160, data: 0.000) loss: 0.538 
(epoch: 146, iters: 2880, time: 0.160, data: 0.005) loss: 0.258 
(epoch: 146, iters: 2960, time: 0.161, data: 0.000) loss: 0.254 
(epoch: 146, iters: 3040, time: 0.160, data: 0.005) loss: 0.210 
(epoch: 146, iters: 3120, time: 0.157, data: 0.000) loss: 0.853 
(epoch: 146, iters: 3200, time: 0.160, data: 0.034) loss: 0.265 
(epoch: 146, iters: 3280, time: 0.160, data: 0.000) loss: 0.498 
(epoch: 146, iters: 3360, time: 0.160, data: 0.000) loss: 0.112 
(epoch: 146, iters: 3440, time: 0.159, data: 0.028) loss: 0.251 
(epoch: 146, iters: 3520, time: 0.160, data: 0.023) loss: 0.696 
(epoch: 146, iters: 3600, time: 0.159, data: 0.000) loss: 0.431 
(epoch: 146, iters: 3680, time: 0.160, data: 0.023) loss: 0.236 
(epoch: 146, iters: 3760, time: 0.161, data: 0.005) loss: 0.154 
(epoch: 146, iters: 3840, time: 0.160, data: 0.018) loss: 0.336 
(epoch: 146, iters: 3920, time: 0.161, data: 0.000) loss: 0.196 
(epoch: 146, iters: 4000, time: 0.160, data: 0.027) loss: 0.302 
saving the latest model (epoch 146, total_steps 1481856)
(epoch: 146, iters: 4080, time: 0.162, data: 0.000) loss: 0.378 
(epoch: 146, iters: 4160, time: 0.161, data: 0.025) loss: 0.440 
(epoch: 146, iters: 4240, time: 0.161, data: 0.000) loss: 0.198 
(epoch: 146, iters: 4320, time: 0.160, data: 0.013) loss: 0.073 
(epoch: 146, iters: 4400, time: 0.160, data: 0.000) loss: 0.311 
(epoch: 146, iters: 4480, time: 0.161, data: 0.019) loss: 0.271 
(epoch: 146, iters: 4560, time: 0.162, data: 0.000) loss: 0.655 
(epoch: 146, iters: 4640, time: 0.160, data: 0.006) loss: 0.495 
(epoch: 146, iters: 4720, time: 0.162, data: 0.000) loss: 0.525 
(epoch: 146, iters: 4800, time: 0.161, data: 0.000) loss: 0.187 
(epoch: 146, iters: 4880, time: 0.159, data: 0.005) loss: 0.254 
(epoch: 146, iters: 4960, time: 0.160, data: 0.019) loss: 0.320 
(epoch: 146, iters: 5040, time: 0.161, data: 0.000) loss: 0.320 
(epoch: 146, iters: 5120, time: 0.160, data: 0.000) loss: 0.199 
(epoch: 146, iters: 5200, time: 0.159, data: 0.000) loss: 0.662 
(epoch: 146, iters: 5280, time: 0.159, data: 0.005) loss: 0.229 
(epoch: 146, iters: 5360, time: 0.160, data: 0.000) loss: 0.286 
(epoch: 146, iters: 5440, time: 0.161, data: 0.006) loss: 0.242 
(epoch: 146, iters: 5520, time: 0.160, data: 0.000) loss: 0.195 
(epoch: 146, iters: 5600, time: 0.162, data: 0.000) loss: 0.336 
(epoch: 146, iters: 5680, time: 0.160, data: 0.008) loss: 0.340 
(epoch: 146, iters: 5760, time: 0.161, data: 0.000) loss: 0.537 
(epoch: 146, iters: 5840, time: 0.160, data: 0.000) loss: 0.434 
(epoch: 146, iters: 5920, time: 0.159, data: 0.000) loss: 0.190 
(epoch: 146, iters: 6000, time: 0.162, data: 0.016) loss: 0.601 
(epoch: 146, iters: 6080, time: 0.159, data: 0.000) loss: 0.622 
(epoch: 146, iters: 6160, time: 0.160, data: 0.013) loss: 0.204 
(epoch: 146, iters: 6240, time: 0.158, data: 0.000) loss: 0.144 
(epoch: 146, iters: 6320, time: 0.159, data: 0.014) loss: 1.483 
(epoch: 146, iters: 6400, time: 0.160, data: 0.000) loss: 0.357 
(epoch: 146, iters: 6480, time: 0.161, data: 0.005) loss: 0.383 
(epoch: 146, iters: 6560, time: 0.159, data: 0.000) loss: 0.483 
(epoch: 146, iters: 6640, time: 0.159, data: 0.015) loss: 0.390 
(epoch: 146, iters: 6720, time: 0.161, data: 0.005) loss: 0.346 
(epoch: 146, iters: 6800, time: 0.159, data: 0.010) loss: 0.255 
(epoch: 146, iters: 6880, time: 0.158, data: 0.000) loss: 0.363 
(epoch: 146, iters: 6960, time: 0.159, data: 0.000) loss: 0.178 
(epoch: 146, iters: 7040, time: 0.161, data: 0.000) loss: 0.115 
(epoch: 146, iters: 7120, time: 0.159, data: 0.000) loss: 0.894 
(epoch: 146, iters: 7200, time: 0.160, data: 0.019) loss: 0.340 
(epoch: 146, iters: 7280, time: 0.161, data: 0.000) loss: 0.252 
(epoch: 146, iters: 7360, time: 0.161, data: 0.010) loss: 0.750 
(epoch: 146, iters: 7440, time: 0.159, data: 0.006) loss: 0.275 
(epoch: 146, iters: 7520, time: 0.162, data: 0.000) loss: 0.443 
(epoch: 146, iters: 7600, time: 0.160, data: 0.000) loss: 0.519 
(epoch: 146, iters: 7680, time: 0.162, data: 0.005) loss: 0.101 
(epoch: 146, iters: 7760, time: 0.161, data: 0.000) loss: 0.466 
(epoch: 146, iters: 7840, time: 0.161, data: 0.019) loss: 0.411 
(epoch: 146, iters: 7920, time: 0.160, data: 0.000) loss: 0.337 
(epoch: 146, iters: 8000, time: 0.161, data: 0.014) loss: 0.207 
saving the latest model (epoch 146, total_steps 1485856)
(epoch: 146, iters: 8080, time: 0.161, data: 0.006) loss: 0.475 
(epoch: 146, iters: 8160, time: 0.164, data: 0.000) loss: 0.367 
(epoch: 146, iters: 8240, time: 0.162, data: 0.013) loss: 0.160 
(epoch: 146, iters: 8320, time: 0.160, data: 0.005) loss: 0.094 
(epoch: 146, iters: 8400, time: 0.160, data: 0.000) loss: 0.583 
(epoch: 146, iters: 8480, time: 0.160, data: 0.000) loss: 0.395 
(epoch: 146, iters: 8560, time: 0.163, data: 0.010) loss: 0.540 
(epoch: 146, iters: 8640, time: 0.163, data: 0.006) loss: 0.262 
(epoch: 146, iters: 8720, time: 0.159, data: 0.000) loss: 0.235 
(epoch: 146, iters: 8800, time: 0.160, data: 0.000) loss: 0.231 
(epoch: 146, iters: 8880, time: 0.158, data: 0.016) loss: 0.331 
(epoch: 146, iters: 8960, time: 0.159, data: 0.000) loss: 0.264 
(epoch: 146, iters: 9040, time: 0.159, data: 0.008) loss: 0.350 
(epoch: 146, iters: 9120, time: 0.160, data: 0.000) loss: 0.227 
(epoch: 146, iters: 9200, time: 0.160, data: 0.008) loss: 0.463 
(epoch: 146, iters: 9280, time: 0.159, data: 0.005) loss: 0.305 
(epoch: 146, iters: 9360, time: 0.159, data: 0.000) loss: 0.224 
(epoch: 146, iters: 9440, time: 0.162, data: 0.000) loss: 0.155 
(epoch: 146, iters: 9520, time: 0.160, data: 0.006) loss: 0.428 
(epoch: 146, iters: 9600, time: 0.160, data: 0.020) loss: 0.050 
(epoch: 146, iters: 9680, time: 0.161, data: 0.000) loss: 0.520 
(epoch: 146, iters: 9760, time: 0.159, data: 0.019) loss: 0.131 
(epoch: 146, iters: 9840, time: 0.160, data: 0.005) loss: 0.179 
(epoch: 146, iters: 9920, time: 0.160, data: 0.000) loss: 0.328 
(epoch: 146, iters: 10000, time: 0.159, data: 0.022) loss: 0.411 
(epoch: 146, iters: 10080, time: 0.161, data: 0.000) loss: 0.345 
(epoch: 146, iters: 10160, time: 0.161, data: 0.032) loss: 0.112 
saving the model at the end of epoch 146, iters 1488032
End of epoch 146 / 200 	 Time Taken: 1638 sec
learning rate = 0.0001050
saving the latest model (epoch 147, total_steps 1488048)
(epoch: 147, iters: 48, time: 0.166, data: 0.000) loss: 0.148 
(epoch: 147, iters: 128, time: 0.163, data: 0.012) loss: 0.140 
(epoch: 147, iters: 208, time: 0.164, data: 0.000) loss: 0.266 
(epoch: 147, iters: 288, time: 0.162, data: 0.000) loss: 0.670 
(epoch: 147, iters: 368, time: 0.162, data: 0.011) loss: 0.534 
(epoch: 147, iters: 448, time: 0.161, data: 0.000) loss: 0.425 
(epoch: 147, iters: 528, time: 0.164, data: 0.000) loss: 0.771 
(epoch: 147, iters: 608, time: 0.160, data: 0.000) loss: 0.290 
(epoch: 147, iters: 688, time: 0.158, data: 0.021) loss: 0.177 
(epoch: 147, iters: 768, time: 0.161, data: 0.000) loss: 0.273 
(epoch: 147, iters: 848, time: 0.159, data: 0.000) loss: 0.058 
(epoch: 147, iters: 928, time: 0.160, data: 0.006) loss: 0.629 
(epoch: 147, iters: 1008, time: 0.160, data: 0.000) loss: 0.204 
(epoch: 147, iters: 1088, time: 0.160, data: 0.000) loss: 0.585 
(epoch: 147, iters: 1168, time: 0.163, data: 0.005) loss: 0.271 
(epoch: 147, iters: 1248, time: 0.162, data: 0.000) loss: 0.269 
(epoch: 147, iters: 1328, time: 0.160, data: 0.008) loss: 0.213 
(epoch: 147, iters: 1408, time: 0.160, data: 0.000) loss: 0.636 
(epoch: 147, iters: 1488, time: 0.158, data: 0.000) loss: 0.149 
(epoch: 147, iters: 1568, time: 0.160, data: 0.035) loss: 0.239 
(epoch: 147, iters: 1648, time: 0.162, data: 0.000) loss: 0.365 
(epoch: 147, iters: 1728, time: 0.163, data: 0.000) loss: 0.203 
(epoch: 147, iters: 1808, time: 0.161, data: 0.000) loss: 0.109 
(epoch: 147, iters: 1888, time: 0.161, data: 0.011) loss: 0.841 
(epoch: 147, iters: 1968, time: 0.160, data: 0.000) loss: 0.223 
(epoch: 147, iters: 2048, time: 0.163, data: 0.005) loss: 0.329 
(epoch: 147, iters: 2128, time: 0.161, data: 0.006) loss: 0.144 
(epoch: 147, iters: 2208, time: 0.160, data: 0.000) loss: 0.634 
(epoch: 147, iters: 2288, time: 0.159, data: 0.000) loss: 0.202 
(epoch: 147, iters: 2368, time: 0.159, data: 0.005) loss: 0.143 
(epoch: 147, iters: 2448, time: 0.159, data: 0.025) loss: 0.593 
(epoch: 147, iters: 2528, time: 0.162, data: 0.000) loss: 0.227 
(epoch: 147, iters: 2608, time: 0.161, data: 0.032) loss: 0.778 
(epoch: 147, iters: 2688, time: 0.160, data: 0.000) loss: 0.290 
(epoch: 147, iters: 2768, time: 0.160, data: 0.000) loss: 0.427 
(epoch: 147, iters: 2848, time: 0.160, data: 0.000) loss: 0.184 
(epoch: 147, iters: 2928, time: 0.161, data: 0.006) loss: 0.111 
(epoch: 147, iters: 3008, time: 0.160, data: 0.000) loss: 0.303 
(epoch: 147, iters: 3088, time: 0.160, data: 0.000) loss: 0.507 
(epoch: 147, iters: 3168, time: 0.162, data: 0.005) loss: 0.381 
(epoch: 147, iters: 3248, time: 0.163, data: 0.025) loss: 0.098 
(epoch: 147, iters: 3328, time: 0.161, data: 0.026) loss: 0.226 
(epoch: 147, iters: 3408, time: 0.161, data: 0.013) loss: 0.184 
(epoch: 147, iters: 3488, time: 0.161, data: 0.008) loss: 0.241 
(epoch: 147, iters: 3568, time: 0.162, data: 0.024) loss: 0.164 
(epoch: 147, iters: 3648, time: 0.161, data: 0.000) loss: 0.162 
(epoch: 147, iters: 3728, time: 0.162, data: 0.032) loss: 0.450 
(epoch: 147, iters: 3808, time: 0.161, data: 0.000) loss: 0.302 
(epoch: 147, iters: 3888, time: 0.162, data: 0.000) loss: 0.358 
(epoch: 147, iters: 3968, time: 0.160, data: 0.008) loss: 0.281 
saving the latest model (epoch 147, total_steps 1492048)
(epoch: 147, iters: 4048, time: 0.161, data: 0.000) loss: 0.316 
(epoch: 147, iters: 4128, time: 0.160, data: 0.000) loss: 0.143 
(epoch: 147, iters: 4208, time: 0.161, data: 0.005) loss: 0.614 
(epoch: 147, iters: 4288, time: 0.160, data: 0.009) loss: 0.730 
(epoch: 147, iters: 4368, time: 0.163, data: 0.000) loss: 0.114 
(epoch: 147, iters: 4448, time: 0.160, data: 0.006) loss: 0.252 
(epoch: 147, iters: 4528, time: 0.159, data: 0.000) loss: 0.181 
(epoch: 147, iters: 4608, time: 0.159, data: 0.023) loss: 0.496 
(epoch: 147, iters: 4688, time: 0.160, data: 0.000) loss: 0.475 
(epoch: 147, iters: 4768, time: 0.159, data: 0.000) loss: 0.342 
(epoch: 147, iters: 4848, time: 0.160, data: 0.000) loss: 0.246 
(epoch: 147, iters: 4928, time: 0.159, data: 0.005) loss: 0.127 
(epoch: 147, iters: 5008, time: 0.158, data: 0.000) loss: 0.142 
(epoch: 147, iters: 5088, time: 0.157, data: 0.005) loss: 0.318 
(epoch: 147, iters: 5168, time: 0.158, data: 0.000) loss: 0.250 
(epoch: 147, iters: 5248, time: 0.158, data: 0.000) loss: 0.407 
(epoch: 147, iters: 5328, time: 0.160, data: 0.016) loss: 0.669 
(epoch: 147, iters: 5408, time: 0.158, data: 0.000) loss: 0.251 
(epoch: 147, iters: 5488, time: 0.159, data: 0.032) loss: 0.248 
(epoch: 147, iters: 5568, time: 0.160, data: 0.000) loss: 0.156 
(epoch: 147, iters: 5648, time: 0.161, data: 0.000) loss: 0.297 
(epoch: 147, iters: 5728, time: 0.162, data: 0.014) loss: 0.352 
(epoch: 147, iters: 5808, time: 0.160, data: 0.005) loss: 0.274 
(epoch: 147, iters: 5888, time: 0.158, data: 0.020) loss: 0.375 
(epoch: 147, iters: 5968, time: 0.158, data: 0.005) loss: 0.193 
(epoch: 147, iters: 6048, time: 0.162, data: 0.000) loss: 0.250 
(epoch: 147, iters: 6128, time: 0.162, data: 0.024) loss: 0.287 
(epoch: 147, iters: 6208, time: 0.158, data: 0.000) loss: 0.280 
(epoch: 147, iters: 6288, time: 0.162, data: 0.000) loss: 0.066 
(epoch: 147, iters: 6368, time: 0.162, data: 0.024) loss: 0.419 
(epoch: 147, iters: 6448, time: 0.163, data: 0.000) loss: 0.083 
(epoch: 147, iters: 6528, time: 0.162, data: 0.005) loss: 0.467 
(epoch: 147, iters: 6608, time: 0.163, data: 0.000) loss: 0.379 
(epoch: 147, iters: 6688, time: 0.163, data: 0.006) loss: 0.563 
(epoch: 147, iters: 6768, time: 0.163, data: 0.000) loss: 0.491 
(epoch: 147, iters: 6848, time: 0.161, data: 0.009) loss: 0.295 
(epoch: 147, iters: 6928, time: 0.163, data: 0.000) loss: 0.404 
(epoch: 147, iters: 7008, time: 0.163, data: 0.006) loss: 0.202 
(epoch: 147, iters: 7088, time: 0.162, data: 0.000) loss: 0.312 
(epoch: 147, iters: 7168, time: 0.166, data: 0.005) loss: 0.170 
(epoch: 147, iters: 7248, time: 0.161, data: 0.000) loss: 0.868 
(epoch: 147, iters: 7328, time: 0.163, data: 0.000) loss: 0.357 
(epoch: 147, iters: 7408, time: 0.163, data: 0.000) loss: 0.627 
(epoch: 147, iters: 7488, time: 0.162, data: 0.005) loss: 0.771 
(epoch: 147, iters: 7568, time: 0.163, data: 0.011) loss: 0.319 
(epoch: 147, iters: 7648, time: 0.164, data: 0.000) loss: 0.228 
(epoch: 147, iters: 7728, time: 0.164, data: 0.006) loss: 0.213 
(epoch: 147, iters: 7808, time: 0.161, data: 0.000) loss: 0.156 
(epoch: 147, iters: 7888, time: 0.162, data: 0.032) loss: 0.354 
(epoch: 147, iters: 7968, time: 0.164, data: 0.000) loss: 0.221 
saving the latest model (epoch 147, total_steps 1496048)
(epoch: 147, iters: 8048, time: 0.163, data: 0.000) loss: 0.083 
(epoch: 147, iters: 8128, time: 0.160, data: 0.006) loss: 0.183 
(epoch: 147, iters: 8208, time: 0.162, data: 0.000) loss: 0.137 
(epoch: 147, iters: 8288, time: 0.162, data: 0.000) loss: 0.636 
(epoch: 147, iters: 8368, time: 0.161, data: 0.017) loss: 0.210 
(epoch: 147, iters: 8448, time: 0.163, data: 0.000) loss: 0.223 
(epoch: 147, iters: 8528, time: 0.165, data: 0.000) loss: 0.398 
(epoch: 147, iters: 8608, time: 0.162, data: 0.000) loss: 0.397 
(epoch: 147, iters: 8688, time: 0.162, data: 0.000) loss: 0.405 
(epoch: 147, iters: 8768, time: 0.162, data: 0.021) loss: 0.389 
(epoch: 147, iters: 8848, time: 0.165, data: 0.000) loss: 0.076 
(epoch: 147, iters: 8928, time: 0.162, data: 0.005) loss: 0.102 
(epoch: 147, iters: 9008, time: 0.164, data: 0.006) loss: 0.803 
(epoch: 147, iters: 9088, time: 0.163, data: 0.000) loss: 0.098 
(epoch: 147, iters: 9168, time: 0.162, data: 0.000) loss: 0.296 
(epoch: 147, iters: 9248, time: 0.162, data: 0.027) loss: 0.474 
(epoch: 147, iters: 9328, time: 0.163, data: 0.000) loss: 0.073 
(epoch: 147, iters: 9408, time: 0.163, data: 0.000) loss: 0.289 
(epoch: 147, iters: 9488, time: 0.161, data: 0.006) loss: 0.323 
(epoch: 147, iters: 9568, time: 0.164, data: 0.033) loss: 0.298 
(epoch: 147, iters: 9648, time: 0.162, data: 0.000) loss: 0.436 
(epoch: 147, iters: 9728, time: 0.163, data: 0.032) loss: 1.378 
(epoch: 147, iters: 9808, time: 0.162, data: 0.000) loss: 0.454 
(epoch: 147, iters: 9888, time: 0.162, data: 0.013) loss: 0.147 
(epoch: 147, iters: 9968, time: 0.165, data: 0.000) loss: 0.384 
(epoch: 147, iters: 10048, time: 0.162, data: 0.013) loss: 0.208 
(epoch: 147, iters: 10128, time: 0.162, data: 0.000) loss: 0.118 
saving the model at the end of epoch 147, iters 1498224
End of epoch 147 / 200 	 Time Taken: 1647 sec
learning rate = 0.0001030
(epoch: 148, iters: 16, time: 0.178, data: 0.000) loss: 0.312 
saving the latest model (epoch 148, total_steps 1498240)
(epoch: 148, iters: 96, time: 0.163, data: 0.016) loss: 0.316 
(epoch: 148, iters: 176, time: 0.164, data: 0.011) loss: 0.626 
(epoch: 148, iters: 256, time: 0.163, data: 0.000) loss: 0.190 
(epoch: 148, iters: 336, time: 0.163, data: 0.005) loss: 0.233 
(epoch: 148, iters: 416, time: 0.162, data: 0.000) loss: 0.441 
(epoch: 148, iters: 496, time: 0.162, data: 0.000) loss: 0.597 
(epoch: 148, iters: 576, time: 0.164, data: 0.000) loss: 0.287 
(epoch: 148, iters: 656, time: 0.162, data: 0.005) loss: 0.337 
(epoch: 148, iters: 736, time: 0.163, data: 0.006) loss: 0.693 
(epoch: 148, iters: 816, time: 0.163, data: 0.000) loss: 0.162 
(epoch: 148, iters: 896, time: 0.162, data: 0.000) loss: 0.215 
(epoch: 148, iters: 976, time: 0.162, data: 0.000) loss: 0.757 
(epoch: 148, iters: 1056, time: 0.162, data: 0.014) loss: 0.619 
(epoch: 148, iters: 1136, time: 0.163, data: 0.000) loss: 0.210 
(epoch: 148, iters: 1216, time: 0.163, data: 0.025) loss: 0.259 
(epoch: 148, iters: 1296, time: 0.165, data: 0.000) loss: 0.274 
(epoch: 148, iters: 1376, time: 0.163, data: 0.000) loss: 0.445 
(epoch: 148, iters: 1456, time: 0.161, data: 0.000) loss: 0.071 
(epoch: 148, iters: 1536, time: 0.163, data: 0.005) loss: 0.314 
(epoch: 148, iters: 1616, time: 0.162, data: 0.023) loss: 0.369 
(epoch: 148, iters: 1696, time: 0.162, data: 0.000) loss: 0.303 
(epoch: 148, iters: 1776, time: 0.162, data: 0.000) loss: 0.204 
(epoch: 148, iters: 1856, time: 0.163, data: 0.027) loss: 0.459 
(epoch: 148, iters: 1936, time: 0.165, data: 0.000) loss: 0.226 
(epoch: 148, iters: 2016, time: 0.162, data: 0.000) loss: 0.423 
(epoch: 148, iters: 2096, time: 0.163, data: 0.009) loss: 0.258 
(epoch: 148, iters: 2176, time: 0.164, data: 0.000) loss: 0.221 
(epoch: 148, iters: 2256, time: 0.162, data: 0.000) loss: 0.124 
(epoch: 148, iters: 2336, time: 0.163, data: 0.014) loss: 0.535 
(epoch: 148, iters: 2416, time: 0.162, data: 0.017) loss: 0.064 
(epoch: 148, iters: 2496, time: 0.164, data: 0.000) loss: 0.233 
(epoch: 148, iters: 2576, time: 0.162, data: 0.000) loss: 0.165 
(epoch: 148, iters: 2656, time: 0.162, data: 0.000) loss: 0.115 
(epoch: 148, iters: 2736, time: 0.165, data: 0.005) loss: 0.206 
(epoch: 148, iters: 2816, time: 0.162, data: 0.032) loss: 0.154 
(epoch: 148, iters: 2896, time: 0.162, data: 0.000) loss: 0.318 
(epoch: 148, iters: 2976, time: 0.162, data: 0.000) loss: 0.348 
(epoch: 148, iters: 3056, time: 0.165, data: 0.000) loss: 0.554 
(epoch: 148, iters: 3136, time: 0.165, data: 0.014) loss: 0.289 
(epoch: 148, iters: 3216, time: 0.163, data: 0.000) loss: 0.267 
(epoch: 148, iters: 3296, time: 0.163, data: 0.015) loss: 0.209 
(epoch: 148, iters: 3376, time: 0.162, data: 0.023) loss: 0.327 
(epoch: 148, iters: 3456, time: 0.162, data: 0.000) loss: 0.297 
(epoch: 148, iters: 3536, time: 0.163, data: 0.014) loss: 0.145 
(epoch: 148, iters: 3616, time: 0.163, data: 0.000) loss: 0.544 
(epoch: 148, iters: 3696, time: 0.162, data: 0.018) loss: 0.293 
(epoch: 148, iters: 3776, time: 0.163, data: 0.000) loss: 0.379 
(epoch: 148, iters: 3856, time: 0.164, data: 0.000) loss: 0.152 
(epoch: 148, iters: 3936, time: 0.162, data: 0.000) loss: 0.604 
(epoch: 148, iters: 4016, time: 0.162, data: 0.000) loss: 0.701 
saving the latest model (epoch 148, total_steps 1502240)
(epoch: 148, iters: 4096, time: 0.162, data: 0.029) loss: 1.083 
(epoch: 148, iters: 4176, time: 0.165, data: 0.000) loss: 0.179 
(epoch: 148, iters: 4256, time: 0.163, data: 0.024) loss: 0.225 
(epoch: 148, iters: 4336, time: 0.164, data: 0.000) loss: 0.351 
(epoch: 148, iters: 4416, time: 0.163, data: 0.025) loss: 0.169 
(epoch: 148, iters: 4496, time: 0.162, data: 0.000) loss: 0.865 
(epoch: 148, iters: 4576, time: 0.163, data: 0.000) loss: 0.165 
(epoch: 148, iters: 4656, time: 0.162, data: 0.005) loss: 0.687 
(epoch: 148, iters: 4736, time: 0.162, data: 0.000) loss: 0.091 
(epoch: 148, iters: 4816, time: 0.163, data: 0.009) loss: 0.025 
(epoch: 148, iters: 4896, time: 0.161, data: 0.024) loss: 0.193 
(epoch: 148, iters: 4976, time: 0.164, data: 0.000) loss: 0.064 
(epoch: 148, iters: 5056, time: 0.165, data: 0.000) loss: 0.204 
(epoch: 148, iters: 5136, time: 0.162, data: 0.005) loss: 0.089 
(epoch: 148, iters: 5216, time: 0.162, data: 0.025) loss: 0.142 
(epoch: 148, iters: 5296, time: 0.164, data: 0.015) loss: 0.050 
(epoch: 148, iters: 5376, time: 0.163, data: 0.005) loss: 0.157 
(epoch: 148, iters: 5456, time: 0.163, data: 0.000) loss: 0.728 
(epoch: 148, iters: 5536, time: 0.163, data: 0.033) loss: 0.157 
(epoch: 148, iters: 5616, time: 0.163, data: 0.000) loss: 0.066 
(epoch: 148, iters: 5696, time: 0.163, data: 0.000) loss: 1.034 
(epoch: 148, iters: 5776, time: 0.162, data: 0.000) loss: 0.309 
(epoch: 148, iters: 5856, time: 0.164, data: 0.000) loss: 0.478 
(epoch: 148, iters: 5936, time: 0.162, data: 0.009) loss: 0.058 
(epoch: 148, iters: 6016, time: 0.162, data: 0.006) loss: 0.389 
(epoch: 148, iters: 6096, time: 0.163, data: 0.000) loss: 0.354 
(epoch: 148, iters: 6176, time: 0.160, data: 0.013) loss: 0.352 
(epoch: 148, iters: 6256, time: 0.163, data: 0.000) loss: 0.261 
(epoch: 148, iters: 6336, time: 0.167, data: 0.000) loss: 0.241 
(epoch: 148, iters: 6416, time: 0.163, data: 0.011) loss: 0.510 
(epoch: 148, iters: 6496, time: 0.162, data: 0.015) loss: 0.078 
(epoch: 148, iters: 6576, time: 0.163, data: 0.032) loss: 0.191 
(epoch: 148, iters: 6656, time: 0.162, data: 0.000) loss: 0.781 
(epoch: 148, iters: 6736, time: 0.164, data: 0.000) loss: 1.218 
(epoch: 148, iters: 6816, time: 0.162, data: 0.000) loss: 0.416 
(epoch: 148, iters: 6896, time: 0.163, data: 0.009) loss: 0.154 
(epoch: 148, iters: 6976, time: 0.161, data: 0.000) loss: 0.097 
(epoch: 148, iters: 7056, time: 0.162, data: 0.000) loss: 0.226 
(epoch: 148, iters: 7136, time: 0.163, data: 0.019) loss: 0.307 
(epoch: 148, iters: 7216, time: 0.164, data: 0.000) loss: 0.350 
(epoch: 148, iters: 7296, time: 0.163, data: 0.000) loss: 0.199 
(epoch: 148, iters: 7376, time: 0.163, data: 0.000) loss: 0.251 
(epoch: 148, iters: 7456, time: 0.163, data: 0.029) loss: 0.181 
(epoch: 148, iters: 7536, time: 0.162, data: 0.000) loss: 0.383 
(epoch: 148, iters: 7616, time: 0.162, data: 0.022) loss: 0.544 
(epoch: 148, iters: 7696, time: 0.162, data: 0.000) loss: 0.283 
(epoch: 148, iters: 7776, time: 0.165, data: 0.000) loss: 0.437 
(epoch: 148, iters: 7856, time: 0.164, data: 0.000) loss: 0.596 
(epoch: 148, iters: 7936, time: 0.163, data: 0.000) loss: 0.229 
(epoch: 148, iters: 8016, time: 0.163, data: 0.000) loss: 0.118 
saving the latest model (epoch 148, total_steps 1506240)
(epoch: 148, iters: 8096, time: 0.163, data: 0.000) loss: 0.212 
(epoch: 148, iters: 8176, time: 0.163, data: 0.000) loss: 0.225 
(epoch: 148, iters: 8256, time: 0.163, data: 0.000) loss: 0.099 
(epoch: 148, iters: 8336, time: 0.162, data: 0.025) loss: 0.359 
(epoch: 148, iters: 8416, time: 0.165, data: 0.000) loss: 0.269 
(epoch: 148, iters: 8496, time: 0.164, data: 0.000) loss: 0.292 
(epoch: 148, iters: 8576, time: 0.165, data: 0.005) loss: 0.755 
(epoch: 148, iters: 8656, time: 0.163, data: 0.005) loss: 0.122 
(epoch: 148, iters: 8736, time: 0.163, data: 0.000) loss: 0.327 
(epoch: 148, iters: 8816, time: 0.163, data: 0.000) loss: 0.260 
(epoch: 148, iters: 8896, time: 0.162, data: 0.000) loss: 0.551 
(epoch: 148, iters: 8976, time: 0.163, data: 0.031) loss: 0.175 
(epoch: 148, iters: 9056, time: 0.162, data: 0.000) loss: 0.598 
(epoch: 148, iters: 9136, time: 0.162, data: 0.013) loss: 0.722 
(epoch: 148, iters: 9216, time: 0.164, data: 0.000) loss: 0.357 
(epoch: 148, iters: 9296, time: 0.162, data: 0.011) loss: 0.278 
(epoch: 148, iters: 9376, time: 0.163, data: 0.000) loss: 0.526 
(epoch: 148, iters: 9456, time: 0.164, data: 0.000) loss: 0.462 
(epoch: 148, iters: 9536, time: 0.163, data: 0.024) loss: 0.514 
(epoch: 148, iters: 9616, time: 0.163, data: 0.000) loss: 0.350 
(epoch: 148, iters: 9696, time: 0.164, data: 0.000) loss: 0.398 
(epoch: 148, iters: 9776, time: 0.163, data: 0.000) loss: 0.240 
(epoch: 148, iters: 9856, time: 0.163, data: 0.000) loss: 0.205 
(epoch: 148, iters: 9936, time: 0.164, data: 0.006) loss: 0.183 
(epoch: 148, iters: 10016, time: 0.164, data: 0.000) loss: 0.298 
(epoch: 148, iters: 10096, time: 0.163, data: 0.016) loss: 0.172 
(epoch: 148, iters: 10176, time: 0.162, data: 0.000) loss: 0.145 
saving the model at the end of epoch 148, iters 1508416
End of epoch 148 / 200 	 Time Taken: 1663 sec
learning rate = 0.0001010
saving the latest model (epoch 149, total_steps 1508432)
(epoch: 149, iters: 64, time: 0.166, data: 0.003) loss: 0.331 
(epoch: 149, iters: 144, time: 0.166, data: 0.038) loss: 0.097 
(epoch: 149, iters: 224, time: 0.167, data: 0.000) loss: 0.344 
(epoch: 149, iters: 304, time: 0.167, data: 0.013) loss: 0.176 
(epoch: 149, iters: 384, time: 0.168, data: 0.000) loss: 0.155 
(epoch: 149, iters: 464, time: 0.166, data: 0.024) loss: 0.585 
(epoch: 149, iters: 544, time: 0.168, data: 0.000) loss: 0.120 
(epoch: 149, iters: 624, time: 0.166, data: 0.000) loss: 0.557 
(epoch: 149, iters: 704, time: 0.166, data: 0.019) loss: 0.278 
(epoch: 149, iters: 784, time: 0.167, data: 0.000) loss: 0.202 
(epoch: 149, iters: 864, time: 0.166, data: 0.005) loss: 0.456 
(epoch: 149, iters: 944, time: 0.168, data: 0.000) loss: 0.166 
(epoch: 149, iters: 1024, time: 0.167, data: 0.000) loss: 0.315 
(epoch: 149, iters: 1104, time: 0.163, data: 0.008) loss: 0.452 
(epoch: 149, iters: 1184, time: 0.164, data: 0.000) loss: 0.576 
(epoch: 149, iters: 1264, time: 0.166, data: 0.010) loss: 0.322 
(epoch: 149, iters: 1344, time: 0.166, data: 0.000) loss: 0.342 
(epoch: 149, iters: 1424, time: 0.167, data: 0.011) loss: 0.354 
(epoch: 149, iters: 1504, time: 0.166, data: 0.000) loss: 0.199 
(epoch: 149, iters: 1584, time: 0.168, data: 0.000) loss: 0.397 
(epoch: 149, iters: 1664, time: 0.166, data: 0.033) loss: 0.287 
(epoch: 149, iters: 1744, time: 0.166, data: 0.000) loss: 0.521 
(epoch: 149, iters: 1824, time: 0.166, data: 0.000) loss: 0.200 
(epoch: 149, iters: 1904, time: 0.167, data: 0.000) loss: 0.554 
(epoch: 149, iters: 1984, time: 0.165, data: 0.025) loss: 0.273 
(epoch: 149, iters: 2064, time: 0.166, data: 0.000) loss: 0.191 
(epoch: 149, iters: 2144, time: 0.164, data: 0.000) loss: 0.146 
(epoch: 149, iters: 2224, time: 0.167, data: 0.015) loss: 0.491 
(epoch: 149, iters: 2304, time: 0.166, data: 0.000) loss: 0.157 
(epoch: 149, iters: 2384, time: 0.168, data: 0.005) loss: 0.366 
(epoch: 149, iters: 2464, time: 0.166, data: 0.000) loss: 0.688 
(epoch: 149, iters: 2544, time: 0.165, data: 0.013) loss: 0.102 
(epoch: 149, iters: 2624, time: 0.165, data: 0.000) loss: 0.191 
(epoch: 149, iters: 2704, time: 0.166, data: 0.030) loss: 0.507 
(epoch: 149, iters: 2784, time: 0.168, data: 0.000) loss: 0.296 
(epoch: 149, iters: 2864, time: 0.165, data: 0.000) loss: 0.165 
(epoch: 149, iters: 2944, time: 0.167, data: 0.005) loss: 0.347 
(epoch: 149, iters: 3024, time: 0.166, data: 0.000) loss: 0.145 
(epoch: 149, iters: 3104, time: 0.166, data: 0.000) loss: 0.538 
(epoch: 149, iters: 3184, time: 0.166, data: 0.022) loss: 0.070 
(epoch: 149, iters: 3264, time: 0.171, data: 0.000) loss: 0.253 
(epoch: 149, iters: 3344, time: 0.165, data: 0.015) loss: 0.061 
(epoch: 149, iters: 3424, time: 0.165, data: 0.013) loss: 0.176 
(epoch: 149, iters: 3504, time: 0.166, data: 0.000) loss: 0.229 
(epoch: 149, iters: 3584, time: 0.164, data: 0.000) loss: 0.563 
(epoch: 149, iters: 3664, time: 0.164, data: 0.006) loss: 0.216 
(epoch: 149, iters: 3744, time: 0.166, data: 0.000) loss: 0.211 
(epoch: 149, iters: 3824, time: 0.167, data: 0.008) loss: 0.248 
(epoch: 149, iters: 3904, time: 0.164, data: 0.000) loss: 0.349 
(epoch: 149, iters: 3984, time: 0.167, data: 0.006) loss: 0.467 
saving the latest model (epoch 149, total_steps 1512432)
(epoch: 149, iters: 4064, time: 0.166, data: 0.000) loss: 0.909 
(epoch: 149, iters: 4144, time: 0.166, data: 0.008) loss: 0.240 
(epoch: 149, iters: 4224, time: 0.168, data: 0.005) loss: 0.432 
(epoch: 149, iters: 4304, time: 0.164, data: 0.005) loss: 0.161 
(epoch: 149, iters: 4384, time: 0.167, data: 0.011) loss: 0.155 
(epoch: 149, iters: 4464, time: 0.166, data: 0.005) loss: 0.217 
(epoch: 149, iters: 4544, time: 0.170, data: 0.000) loss: 0.764 
(epoch: 149, iters: 4624, time: 0.164, data: 0.000) loss: 0.912 
(epoch: 149, iters: 4704, time: 0.166, data: 0.006) loss: 0.196 
(epoch: 149, iters: 4784, time: 0.167, data: 0.005) loss: 0.281 
(epoch: 149, iters: 4864, time: 0.167, data: 0.008) loss: 0.406 
(epoch: 149, iters: 4944, time: 0.165, data: 0.000) loss: 0.595 
(epoch: 149, iters: 5024, time: 0.165, data: 0.006) loss: 0.340 
(epoch: 149, iters: 5104, time: 0.166, data: 0.023) loss: 0.181 
(epoch: 149, iters: 5184, time: 0.166, data: 0.000) loss: 1.000 
(epoch: 149, iters: 5264, time: 0.166, data: 0.000) loss: 0.874 
(epoch: 149, iters: 5344, time: 0.166, data: 0.005) loss: 0.318 
(epoch: 149, iters: 5424, time: 0.165, data: 0.000) loss: 0.193 
(epoch: 149, iters: 5504, time: 0.166, data: 0.005) loss: 0.250 
(epoch: 149, iters: 5584, time: 0.166, data: 0.010) loss: 0.449 
(epoch: 149, iters: 5664, time: 0.167, data: 0.000) loss: 0.288 
(epoch: 149, iters: 5744, time: 0.165, data: 0.016) loss: 0.209 
(epoch: 149, iters: 5824, time: 0.165, data: 0.038) loss: 0.138 
(epoch: 149, iters: 5904, time: 0.169, data: 0.000) loss: 0.509 
(epoch: 149, iters: 5984, time: 0.167, data: 0.005) loss: 0.334 
(epoch: 149, iters: 6064, time: 0.166, data: 0.000) loss: 0.569 
(epoch: 149, iters: 6144, time: 0.166, data: 0.000) loss: 0.208 
(epoch: 149, iters: 6224, time: 0.166, data: 0.000) loss: 0.436 
(epoch: 149, iters: 6304, time: 0.166, data: 0.000) loss: 0.115 
(epoch: 149, iters: 6384, time: 0.165, data: 0.000) loss: 0.206 
(epoch: 149, iters: 6464, time: 0.166, data: 0.000) loss: 0.465 
(epoch: 149, iters: 6544, time: 0.164, data: 0.000) loss: 0.048 
(epoch: 149, iters: 6624, time: 0.168, data: 0.008) loss: 0.790 
(epoch: 149, iters: 6704, time: 0.166, data: 0.008) loss: 0.254 
(epoch: 149, iters: 6784, time: 0.167, data: 0.000) loss: 0.260 
(epoch: 149, iters: 6864, time: 0.168, data: 0.000) loss: 0.221 
(epoch: 149, iters: 6944, time: 0.166, data: 0.000) loss: 0.254 
(epoch: 149, iters: 7024, time: 0.167, data: 0.020) loss: 0.484 
(epoch: 149, iters: 7104, time: 0.166, data: 0.011) loss: 0.422 
(epoch: 149, iters: 7184, time: 0.168, data: 0.000) loss: 0.581 
(epoch: 149, iters: 7264, time: 0.165, data: 0.000) loss: 0.078 
(epoch: 149, iters: 7344, time: 0.167, data: 0.009) loss: 0.314 
(epoch: 149, iters: 7424, time: 0.166, data: 0.000) loss: 0.072 
(epoch: 149, iters: 7504, time: 0.165, data: 0.000) loss: 0.558 
(epoch: 149, iters: 7584, time: 0.166, data: 0.005) loss: 0.535 
(epoch: 149, iters: 7664, time: 0.166, data: 0.030) loss: 0.293 
(epoch: 149, iters: 7744, time: 0.166, data: 0.000) loss: 0.450 
(epoch: 149, iters: 7824, time: 0.166, data: 0.014) loss: 0.190 
(epoch: 149, iters: 7904, time: 0.168, data: 0.008) loss: 0.546 
(epoch: 149, iters: 7984, time: 0.168, data: 0.000) loss: 0.326 
saving the latest model (epoch 149, total_steps 1516432)
(epoch: 149, iters: 8064, time: 0.167, data: 0.005) loss: 0.277 
(epoch: 149, iters: 8144, time: 0.167, data: 0.022) loss: 0.267 
(epoch: 149, iters: 8224, time: 0.168, data: 0.000) loss: 0.839 
(epoch: 149, iters: 8304, time: 0.167, data: 0.006) loss: 0.271 
(epoch: 149, iters: 8384, time: 0.166, data: 0.000) loss: 0.171 
(epoch: 149, iters: 8464, time: 0.164, data: 0.000) loss: 0.173 
(epoch: 149, iters: 8544, time: 0.165, data: 0.000) loss: 0.237 
(epoch: 149, iters: 8624, time: 0.164, data: 0.016) loss: 0.491 
(epoch: 149, iters: 8704, time: 0.165, data: 0.011) loss: 0.228 
(epoch: 149, iters: 8784, time: 0.167, data: 0.000) loss: 0.646 
(epoch: 149, iters: 8864, time: 0.166, data: 0.011) loss: 0.350 
(epoch: 149, iters: 8944, time: 0.165, data: 0.000) loss: 0.268 
(epoch: 149, iters: 9024, time: 0.163, data: 0.000) loss: 0.067 
(epoch: 149, iters: 9104, time: 0.164, data: 0.000) loss: 0.395 
(epoch: 149, iters: 9184, time: 0.166, data: 0.000) loss: 0.172 
(epoch: 149, iters: 9264, time: 0.164, data: 0.000) loss: 0.415 
(epoch: 149, iters: 9344, time: 0.164, data: 0.000) loss: 0.313 
(epoch: 149, iters: 9424, time: 0.164, data: 0.015) loss: 0.235 
(epoch: 149, iters: 9504, time: 0.167, data: 0.000) loss: 0.216 
(epoch: 149, iters: 9584, time: 0.165, data: 0.022) loss: 0.305 
(epoch: 149, iters: 9664, time: 0.165, data: 0.000) loss: 0.493 
(epoch: 149, iters: 9744, time: 0.167, data: 0.013) loss: 0.228 
(epoch: 149, iters: 9824, time: 0.164, data: 0.000) loss: 0.447 
(epoch: 149, iters: 9904, time: 0.168, data: 0.000) loss: 0.423 
(epoch: 149, iters: 9984, time: 0.168, data: 0.000) loss: 0.311 
(epoch: 149, iters: 10064, time: 0.165, data: 0.000) loss: 0.601 
(epoch: 149, iters: 10144, time: 0.166, data: 0.005) loss: 0.172 
saving the model at the end of epoch 149, iters 1518608
End of epoch 149 / 200 	 Time Taken: 1696 sec
learning rate = 0.0000990
saving the latest model (epoch 150, total_steps 1518624)
(epoch: 150, iters: 32, time: 0.165, data: 0.005) loss: 0.122 
(epoch: 150, iters: 112, time: 0.164, data: 0.000) loss: 0.615 
(epoch: 150, iters: 192, time: 0.163, data: 0.012) loss: 0.398 
(epoch: 150, iters: 272, time: 0.163, data: 0.000) loss: 0.174 
(epoch: 150, iters: 352, time: 0.163, data: 0.000) loss: 0.328 
(epoch: 150, iters: 432, time: 0.164, data: 0.020) loss: 0.493 
(epoch: 150, iters: 512, time: 0.163, data: 0.006) loss: 0.137 
(epoch: 150, iters: 592, time: 0.164, data: 0.006) loss: 0.287 
(epoch: 150, iters: 672, time: 0.165, data: 0.000) loss: 0.455 
(epoch: 150, iters: 752, time: 0.166, data: 0.000) loss: 0.210 
(epoch: 150, iters: 832, time: 0.163, data: 0.000) loss: 0.086 
(epoch: 150, iters: 912, time: 0.162, data: 0.008) loss: 0.350 
(epoch: 150, iters: 992, time: 0.163, data: 0.011) loss: 0.212 
(epoch: 150, iters: 1072, time: 0.162, data: 0.000) loss: 0.581 
(epoch: 150, iters: 1152, time: 0.161, data: 0.005) loss: 0.540 
(epoch: 150, iters: 1232, time: 0.161, data: 0.000) loss: 0.203 
(epoch: 150, iters: 1312, time: 0.162, data: 0.019) loss: 0.375 
(epoch: 150, iters: 1392, time: 0.163, data: 0.000) loss: 0.242 
(epoch: 150, iters: 1472, time: 0.161, data: 0.000) loss: 0.224 
(epoch: 150, iters: 1552, time: 0.163, data: 0.000) loss: 0.300 
(epoch: 150, iters: 1632, time: 0.162, data: 0.000) loss: 0.300 
(epoch: 150, iters: 1712, time: 0.161, data: 0.032) loss: 0.129 
(epoch: 150, iters: 1792, time: 0.162, data: 0.000) loss: 0.138 
(epoch: 150, iters: 1872, time: 0.164, data: 0.030) loss: 0.320 
(epoch: 150, iters: 1952, time: 0.163, data: 0.000) loss: 0.330 
(epoch: 150, iters: 2032, time: 0.162, data: 0.000) loss: 0.130 
(epoch: 150, iters: 2112, time: 0.161, data: 0.000) loss: 0.617 
(epoch: 150, iters: 2192, time: 0.164, data: 0.031) loss: 0.635 
(epoch: 150, iters: 2272, time: 0.164, data: 0.000) loss: 0.459 
(epoch: 150, iters: 2352, time: 0.162, data: 0.005) loss: 0.388 
(epoch: 150, iters: 2432, time: 0.164, data: 0.013) loss: 0.092 
(epoch: 150, iters: 2512, time: 0.164, data: 0.027) loss: 0.248 
(epoch: 150, iters: 2592, time: 0.163, data: 0.000) loss: 0.361 
(epoch: 150, iters: 2672, time: 0.163, data: 0.031) loss: 0.214 
(epoch: 150, iters: 2752, time: 0.162, data: 0.000) loss: 0.245 
(epoch: 150, iters: 2832, time: 0.162, data: 0.006) loss: 0.210 
(epoch: 150, iters: 2912, time: 0.162, data: 0.000) loss: 0.451 
(epoch: 150, iters: 2992, time: 0.163, data: 0.016) loss: 0.470 
(epoch: 150, iters: 3072, time: 0.162, data: 0.008) loss: 0.362 
(epoch: 150, iters: 3152, time: 0.162, data: 0.000) loss: 0.541 
(epoch: 150, iters: 3232, time: 0.162, data: 0.015) loss: 0.304 
(epoch: 150, iters: 3312, time: 0.164, data: 0.033) loss: 0.362 
(epoch: 150, iters: 3392, time: 0.166, data: 0.000) loss: 0.364 
(epoch: 150, iters: 3472, time: 0.161, data: 0.000) loss: 0.468 
(epoch: 150, iters: 3552, time: 0.161, data: 0.005) loss: 0.104 
(epoch: 150, iters: 3632, time: 0.161, data: 0.011) loss: 0.115 
(epoch: 150, iters: 3712, time: 0.162, data: 0.000) loss: 0.145 
(epoch: 150, iters: 3792, time: 0.164, data: 0.005) loss: 0.306 
(epoch: 150, iters: 3872, time: 0.163, data: 0.005) loss: 0.209 
(epoch: 150, iters: 3952, time: 0.164, data: 0.000) loss: 0.252 
saving the latest model (epoch 150, total_steps 1522624)
(epoch: 150, iters: 4032, time: 0.163, data: 0.000) loss: 0.088 
(epoch: 150, iters: 4112, time: 0.163, data: 0.017) loss: 0.433 
(epoch: 150, iters: 4192, time: 0.163, data: 0.000) loss: 0.468 
(epoch: 150, iters: 4272, time: 0.161, data: 0.000) loss: 0.069 
(epoch: 150, iters: 4352, time: 0.161, data: 0.000) loss: 0.127 
(epoch: 150, iters: 4432, time: 0.163, data: 0.007) loss: 0.440 
(epoch: 150, iters: 4512, time: 0.163, data: 0.000) loss: 0.191 
(epoch: 150, iters: 4592, time: 0.161, data: 0.005) loss: 0.242 
(epoch: 150, iters: 4672, time: 0.162, data: 0.018) loss: 0.113 
(epoch: 150, iters: 4752, time: 0.159, data: 0.000) loss: 0.444 
(epoch: 150, iters: 4832, time: 0.161, data: 0.000) loss: 0.190 
(epoch: 150, iters: 4912, time: 0.163, data: 0.005) loss: 0.512 
(epoch: 150, iters: 4992, time: 0.161, data: 0.000) loss: 0.491 
(epoch: 150, iters: 5072, time: 0.160, data: 0.010) loss: 0.611 
(epoch: 150, iters: 5152, time: 0.161, data: 0.000) loss: 0.255 
(epoch: 150, iters: 5232, time: 0.162, data: 0.020) loss: 0.537 
(epoch: 150, iters: 5312, time: 0.161, data: 0.005) loss: 0.204 
(epoch: 150, iters: 5392, time: 0.162, data: 0.000) loss: 0.237 
(epoch: 150, iters: 5472, time: 0.162, data: 0.013) loss: 0.259 
(epoch: 150, iters: 5552, time: 0.161, data: 0.008) loss: 0.132 
(epoch: 150, iters: 5632, time: 0.162, data: 0.000) loss: 0.294 
(epoch: 150, iters: 5712, time: 0.162, data: 0.027) loss: 0.169 
(epoch: 150, iters: 5792, time: 0.163, data: 0.000) loss: 0.065 
(epoch: 150, iters: 5872, time: 0.162, data: 0.008) loss: 0.266 
(epoch: 150, iters: 5952, time: 0.163, data: 0.008) loss: 0.872 
(epoch: 150, iters: 6032, time: 0.161, data: 0.000) loss: 0.330 
(epoch: 150, iters: 6112, time: 0.162, data: 0.026) loss: 0.305 
(epoch: 150, iters: 6192, time: 0.161, data: 0.000) loss: 0.304 
(epoch: 150, iters: 6272, time: 0.163, data: 0.017) loss: 0.446 
(epoch: 150, iters: 6352, time: 0.163, data: 0.024) loss: 0.714 
(epoch: 150, iters: 6432, time: 0.166, data: 0.000) loss: 0.324 
(epoch: 150, iters: 6512, time: 0.163, data: 0.000) loss: 0.324 
(epoch: 150, iters: 6592, time: 0.164, data: 0.010) loss: 0.950 
(epoch: 150, iters: 6672, time: 0.166, data: 0.000) loss: 0.238 
(epoch: 150, iters: 6752, time: 0.163, data: 0.020) loss: 0.342 
(epoch: 150, iters: 6832, time: 0.177, data: 0.000) loss: 0.637 
(epoch: 150, iters: 6912, time: 0.185, data: 0.000) loss: 0.203 
(epoch: 150, iters: 6992, time: 0.168, data: 0.000) loss: 0.405 
(epoch: 150, iters: 7072, time: 0.184, data: 0.005) loss: 0.373 
(epoch: 150, iters: 7152, time: 0.176, data: 0.000) loss: 0.105 
(epoch: 150, iters: 7232, time: 0.166, data: 0.000) loss: 0.256 
(epoch: 150, iters: 7312, time: 0.165, data: 0.000) loss: 0.140 
(epoch: 150, iters: 7392, time: 0.157, data: 0.008) loss: 0.148 
(epoch: 150, iters: 7472, time: 0.162, data: 0.021) loss: 0.271 
(epoch: 150, iters: 7552, time: 0.163, data: 0.025) loss: 0.090 
(epoch: 150, iters: 7632, time: 0.162, data: 0.031) loss: 0.348 
(epoch: 150, iters: 7712, time: 0.162, data: 0.000) loss: 0.375 
(epoch: 150, iters: 7792, time: 0.161, data: 0.008) loss: 0.681 
(epoch: 150, iters: 7872, time: 0.161, data: 0.000) loss: 0.150 
(epoch: 150, iters: 7952, time: 0.159, data: 0.015) loss: 0.210 
saving the latest model (epoch 150, total_steps 1526624)
(epoch: 150, iters: 8032, time: 0.161, data: 0.000) loss: 0.550 
(epoch: 150, iters: 8112, time: 0.161, data: 0.037) loss: 0.516 
(epoch: 150, iters: 8192, time: 0.161, data: 0.000) loss: 0.264 
(epoch: 150, iters: 8272, time: 0.162, data: 0.000) loss: 0.135 
(epoch: 150, iters: 8352, time: 0.161, data: 0.005) loss: 0.833 
(epoch: 150, iters: 8432, time: 0.161, data: 0.010) loss: 0.223 
(epoch: 150, iters: 8512, time: 0.161, data: 0.000) loss: 0.635 
(epoch: 150, iters: 8592, time: 0.163, data: 0.005) loss: 0.300 
(epoch: 150, iters: 8672, time: 0.165, data: 0.000) loss: 0.427 
(epoch: 150, iters: 8752, time: 0.161, data: 0.000) loss: 0.974 
(epoch: 150, iters: 8832, time: 0.161, data: 0.000) loss: 0.362 
(epoch: 150, iters: 8912, time: 0.161, data: 0.000) loss: 0.318 
(epoch: 150, iters: 8992, time: 0.164, data: 0.000) loss: 0.421 
(epoch: 150, iters: 9072, time: 0.160, data: 0.019) loss: 0.103 
(epoch: 150, iters: 9152, time: 0.159, data: 0.008) loss: 0.331 
(epoch: 150, iters: 9232, time: 0.161, data: 0.000) loss: 0.206 
(epoch: 150, iters: 9312, time: 0.160, data: 0.016) loss: 0.338 
(epoch: 150, iters: 9392, time: 0.162, data: 0.000) loss: 0.322 
(epoch: 150, iters: 9472, time: 0.161, data: 0.000) loss: 0.207 
(epoch: 150, iters: 9552, time: 0.161, data: 0.000) loss: 0.342 
(epoch: 150, iters: 9632, time: 0.161, data: 0.009) loss: 0.184 
(epoch: 150, iters: 9712, time: 0.160, data: 0.000) loss: 1.128 
(epoch: 150, iters: 9792, time: 0.160, data: 0.021) loss: 0.284 
(epoch: 150, iters: 9872, time: 0.159, data: 0.000) loss: 0.336 
(epoch: 150, iters: 9952, time: 0.160, data: 0.011) loss: 0.192 
(epoch: 150, iters: 10032, time: 0.161, data: 0.033) loss: 0.349 
(epoch: 150, iters: 10112, time: 0.160, data: 0.000) loss: 0.186 
(epoch: 150, iters: 10192, time: 0.098, data: 0.029) loss: 0.047 
saving the model at the end of epoch 150, iters 1528800
End of epoch 150 / 200 	 Time Taken: 1664 sec
learning rate = 0.0000970
saving the latest model (epoch 151, total_steps 1528816)
(epoch: 151, iters: 80, time: 0.165, data: 0.168) loss: 0.141 
(epoch: 151, iters: 160, time: 0.163, data: 0.000) loss: 0.359 
(epoch: 151, iters: 240, time: 0.163, data: 0.015) loss: 0.329 
(epoch: 151, iters: 320, time: 0.163, data: 0.000) loss: 0.109 
(epoch: 151, iters: 400, time: 0.161, data: 0.000) loss: 0.185 
(epoch: 151, iters: 480, time: 0.163, data: 0.008) loss: 0.585 
(epoch: 151, iters: 560, time: 0.163, data: 0.010) loss: 0.348 
(epoch: 151, iters: 640, time: 0.163, data: 0.014) loss: 0.483 
(epoch: 151, iters: 720, time: 0.162, data: 0.009) loss: 0.144 
(epoch: 151, iters: 800, time: 0.163, data: 0.000) loss: 0.095 
(epoch: 151, iters: 880, time: 0.161, data: 0.000) loss: 0.642 
(epoch: 151, iters: 960, time: 0.164, data: 0.000) loss: 0.158 
(epoch: 151, iters: 1040, time: 0.163, data: 0.027) loss: 0.126 
(epoch: 151, iters: 1120, time: 0.164, data: 0.000) loss: 0.154 
(epoch: 151, iters: 1200, time: 0.162, data: 0.016) loss: 0.132 
(epoch: 151, iters: 1280, time: 0.162, data: 0.000) loss: 0.082 
(epoch: 151, iters: 1360, time: 0.160, data: 0.000) loss: 0.185 
(epoch: 151, iters: 1440, time: 0.164, data: 0.032) loss: 0.540 
(epoch: 151, iters: 1520, time: 0.163, data: 0.000) loss: 0.394 
(epoch: 151, iters: 1600, time: 0.161, data: 0.000) loss: 0.529 
(epoch: 151, iters: 1680, time: 0.161, data: 0.000) loss: 0.386 
(epoch: 151, iters: 1760, time: 0.161, data: 0.000) loss: 0.237 
(epoch: 151, iters: 1840, time: 0.162, data: 0.000) loss: 0.439 
(epoch: 151, iters: 1920, time: 0.163, data: 0.005) loss: 0.580 
(epoch: 151, iters: 2000, time: 0.162, data: 0.009) loss: 0.644 
(epoch: 151, iters: 2080, time: 0.162, data: 0.000) loss: 0.186 
(epoch: 151, iters: 2160, time: 0.162, data: 0.005) loss: 0.196 
(epoch: 151, iters: 2240, time: 0.163, data: 0.000) loss: 0.653 
(epoch: 151, iters: 2320, time: 0.164, data: 0.024) loss: 0.472 
(epoch: 151, iters: 2400, time: 0.161, data: 0.007) loss: 0.332 
(epoch: 151, iters: 2480, time: 0.163, data: 0.000) loss: 0.382 
(epoch: 151, iters: 2560, time: 0.163, data: 0.000) loss: 0.325 
(epoch: 151, iters: 2640, time: 0.163, data: 0.010) loss: 0.328 
(epoch: 151, iters: 2720, time: 0.163, data: 0.000) loss: 0.076 
(epoch: 151, iters: 2800, time: 0.162, data: 0.000) loss: 0.383 
(epoch: 151, iters: 2880, time: 0.163, data: 0.014) loss: 0.372 
(epoch: 151, iters: 2960, time: 0.162, data: 0.008) loss: 0.326 
(epoch: 151, iters: 3040, time: 0.165, data: 0.000) loss: 0.363 
(epoch: 151, iters: 3120, time: 0.161, data: 0.015) loss: 0.889 
(epoch: 151, iters: 3200, time: 0.161, data: 0.005) loss: 0.132 
(epoch: 151, iters: 3280, time: 0.162, data: 0.011) loss: 0.112 
(epoch: 151, iters: 3360, time: 0.163, data: 0.000) loss: 0.420 
(epoch: 151, iters: 3440, time: 0.162, data: 0.000) loss: 0.222 
(epoch: 151, iters: 3520, time: 0.161, data: 0.000) loss: 0.371 
(epoch: 151, iters: 3600, time: 0.162, data: 0.000) loss: 0.305 
(epoch: 151, iters: 3680, time: 0.161, data: 0.025) loss: 0.396 
(epoch: 151, iters: 3760, time: 0.162, data: 0.000) loss: 0.217 
(epoch: 151, iters: 3840, time: 0.162, data: 0.000) loss: 0.311 
(epoch: 151, iters: 3920, time: 0.161, data: 0.008) loss: 0.248 
(epoch: 151, iters: 4000, time: 0.162, data: 0.006) loss: 0.165 
saving the latest model (epoch 151, total_steps 1532816)
(epoch: 151, iters: 4080, time: 0.162, data: 0.000) loss: 0.679 
(epoch: 151, iters: 4160, time: 0.161, data: 0.015) loss: 0.286 
(epoch: 151, iters: 4240, time: 0.164, data: 0.000) loss: 0.068 
(epoch: 151, iters: 4320, time: 0.162, data: 0.023) loss: 0.177 
(epoch: 151, iters: 4400, time: 0.165, data: 0.005) loss: 0.185 
(epoch: 151, iters: 4480, time: 0.163, data: 0.005) loss: 0.511 
(epoch: 151, iters: 4560, time: 0.164, data: 0.005) loss: 0.409 
(epoch: 151, iters: 4640, time: 0.161, data: 0.000) loss: 0.232 
(epoch: 151, iters: 4720, time: 0.163, data: 0.006) loss: 0.135 
(epoch: 151, iters: 4800, time: 0.162, data: 0.000) loss: 0.093 
(epoch: 151, iters: 4880, time: 0.162, data: 0.008) loss: 0.787 
(epoch: 151, iters: 4960, time: 0.162, data: 0.000) loss: 0.334 
(epoch: 151, iters: 5040, time: 0.161, data: 0.000) loss: 0.134 
(epoch: 151, iters: 5120, time: 0.163, data: 0.000) loss: 0.290 
(epoch: 151, iters: 5200, time: 0.162, data: 0.000) loss: 0.397 
(epoch: 151, iters: 5280, time: 0.162, data: 0.008) loss: 0.199 
(epoch: 151, iters: 5360, time: 0.163, data: 0.005) loss: 0.266 
(epoch: 151, iters: 5440, time: 0.164, data: 0.005) loss: 0.129 
(epoch: 151, iters: 5520, time: 0.161, data: 0.000) loss: 0.653 
(epoch: 151, iters: 5600, time: 0.163, data: 0.008) loss: 0.125 
(epoch: 151, iters: 5680, time: 0.163, data: 0.000) loss: 0.466 
(epoch: 151, iters: 5760, time: 0.162, data: 0.005) loss: 0.087 
(epoch: 151, iters: 5840, time: 0.165, data: 0.000) loss: 0.224 
(epoch: 151, iters: 5920, time: 0.161, data: 0.000) loss: 0.457 
(epoch: 151, iters: 6000, time: 0.162, data: 0.000) loss: 0.532 
(epoch: 151, iters: 6080, time: 0.163, data: 0.005) loss: 0.501 
(epoch: 151, iters: 6160, time: 0.164, data: 0.011) loss: 0.746 
(epoch: 151, iters: 6240, time: 0.163, data: 0.000) loss: 0.255 
(epoch: 151, iters: 6320, time: 0.164, data: 0.000) loss: 0.275 
(epoch: 151, iters: 6400, time: 0.162, data: 0.000) loss: 0.473 
(epoch: 151, iters: 6480, time: 0.163, data: 0.010) loss: 0.388 
(epoch: 151, iters: 6560, time: 0.164, data: 0.000) loss: 0.264 
(epoch: 151, iters: 6640, time: 0.161, data: 0.005) loss: 0.139 
(epoch: 151, iters: 6720, time: 0.163, data: 0.011) loss: 0.378 
(epoch: 151, iters: 6800, time: 0.163, data: 0.027) loss: 0.425 
(epoch: 151, iters: 6880, time: 0.163, data: 0.000) loss: 0.145 
(epoch: 151, iters: 6960, time: 0.164, data: 0.029) loss: 0.102 
(epoch: 151, iters: 7040, time: 0.164, data: 0.000) loss: 0.166 
(epoch: 151, iters: 7120, time: 0.162, data: 0.032) loss: 0.053 
(epoch: 151, iters: 7200, time: 0.161, data: 0.000) loss: 0.326 
(epoch: 151, iters: 7280, time: 0.166, data: 0.000) loss: 0.200 
(epoch: 151, iters: 7360, time: 0.162, data: 0.000) loss: 0.191 
(epoch: 151, iters: 7440, time: 0.162, data: 0.015) loss: 0.456 
(epoch: 151, iters: 7520, time: 0.160, data: 0.017) loss: 0.380 
(epoch: 151, iters: 7600, time: 0.160, data: 0.000) loss: 0.848 
(epoch: 151, iters: 7680, time: 0.164, data: 0.009) loss: 0.077 
(epoch: 151, iters: 7760, time: 0.163, data: 0.005) loss: 0.131 
(epoch: 151, iters: 7840, time: 0.162, data: 0.000) loss: 0.237 
(epoch: 151, iters: 7920, time: 0.162, data: 0.000) loss: 0.539 
(epoch: 151, iters: 8000, time: 0.162, data: 0.005) loss: 0.280 
saving the latest model (epoch 151, total_steps 1536816)
(epoch: 151, iters: 8080, time: 0.162, data: 0.000) loss: 0.311 
(epoch: 151, iters: 8160, time: 0.161, data: 0.005) loss: 0.405 
(epoch: 151, iters: 8240, time: 0.160, data: 0.014) loss: 0.215 
(epoch: 151, iters: 8320, time: 0.162, data: 0.014) loss: 0.323 
(epoch: 151, iters: 8400, time: 0.164, data: 0.000) loss: 0.482 
(epoch: 151, iters: 8480, time: 0.165, data: 0.008) loss: 0.209 
(epoch: 151, iters: 8560, time: 0.163, data: 0.005) loss: 0.732 
(epoch: 151, iters: 8640, time: 0.163, data: 0.000) loss: 0.260 
(epoch: 151, iters: 8720, time: 0.161, data: 0.000) loss: 0.080 
(epoch: 151, iters: 8800, time: 0.162, data: 0.012) loss: 0.570 
(epoch: 151, iters: 8880, time: 0.162, data: 0.000) loss: 0.248 
(epoch: 151, iters: 8960, time: 0.160, data: 0.005) loss: 0.371 
(epoch: 151, iters: 9040, time: 0.162, data: 0.011) loss: 0.202 
(epoch: 151, iters: 9120, time: 0.162, data: 0.000) loss: 0.373 
(epoch: 151, iters: 9200, time: 0.164, data: 0.000) loss: 0.279 
(epoch: 151, iters: 9280, time: 0.162, data: 0.018) loss: 0.051 
(epoch: 151, iters: 9360, time: 0.162, data: 0.006) loss: 0.590 
(epoch: 151, iters: 9440, time: 0.162, data: 0.000) loss: 0.433 
(epoch: 151, iters: 9520, time: 0.163, data: 0.000) loss: 0.717 
(epoch: 151, iters: 9600, time: 0.163, data: 0.005) loss: 0.350 
(epoch: 151, iters: 9680, time: 0.162, data: 0.000) loss: 0.533 
(epoch: 151, iters: 9760, time: 0.162, data: 0.000) loss: 0.183 
(epoch: 151, iters: 9840, time: 0.161, data: 0.000) loss: 0.573 
(epoch: 151, iters: 9920, time: 0.163, data: 0.016) loss: 0.176 
(epoch: 151, iters: 10000, time: 0.164, data: 0.000) loss: 0.416 
(epoch: 151, iters: 10080, time: 0.162, data: 0.000) loss: 0.231 
(epoch: 151, iters: 10160, time: 0.161, data: 0.000) loss: 0.117 
saving the model at the end of epoch 151, iters 1538992
End of epoch 151 / 200 	 Time Taken: 1658 sec
learning rate = 0.0000950
saving the latest model (epoch 152, total_steps 1539008)
(epoch: 152, iters: 48, time: 0.165, data: 0.000) loss: 0.314 
(epoch: 152, iters: 128, time: 0.165, data: 0.022) loss: 0.171 
(epoch: 152, iters: 208, time: 0.163, data: 0.000) loss: 0.539 
(epoch: 152, iters: 288, time: 0.163, data: 0.000) loss: 0.271 
(epoch: 152, iters: 368, time: 0.163, data: 0.030) loss: 0.241 
(epoch: 152, iters: 448, time: 0.163, data: 0.000) loss: 0.077 
(epoch: 152, iters: 528, time: 0.163, data: 0.000) loss: 0.261 
(epoch: 152, iters: 608, time: 0.164, data: 0.000) loss: 0.111 
(epoch: 152, iters: 688, time: 0.163, data: 0.000) loss: 0.205 
(epoch: 152, iters: 768, time: 0.163, data: 0.031) loss: 0.128 
(epoch: 152, iters: 848, time: 0.164, data: 0.000) loss: 0.564 
(epoch: 152, iters: 928, time: 0.163, data: 0.000) loss: 0.413 
(epoch: 152, iters: 1008, time: 0.163, data: 0.024) loss: 0.421 
(epoch: 152, iters: 1088, time: 0.161, data: 0.000) loss: 0.413 
(epoch: 152, iters: 1168, time: 0.162, data: 0.000) loss: 0.511 
(epoch: 152, iters: 1248, time: 0.162, data: 0.024) loss: 0.197 
(epoch: 152, iters: 1328, time: 0.163, data: 0.000) loss: 0.244 
(epoch: 152, iters: 1408, time: 0.162, data: 0.010) loss: 0.146 
(epoch: 152, iters: 1488, time: 0.160, data: 0.000) loss: 0.223 
(epoch: 152, iters: 1568, time: 0.162, data: 0.017) loss: 0.366 
(epoch: 152, iters: 1648, time: 0.162, data: 0.000) loss: 0.476 
(epoch: 152, iters: 1728, time: 0.163, data: 0.005) loss: 0.347 
(epoch: 152, iters: 1808, time: 0.162, data: 0.000) loss: 0.332 
(epoch: 152, iters: 1888, time: 0.164, data: 0.000) loss: 0.185 
(epoch: 152, iters: 1968, time: 0.163, data: 0.000) loss: 0.201 
(epoch: 152, iters: 2048, time: 0.163, data: 0.017) loss: 0.286 
(epoch: 152, iters: 2128, time: 0.162, data: 0.000) loss: 0.099 
(epoch: 152, iters: 2208, time: 0.164, data: 0.005) loss: 0.576 
(epoch: 152, iters: 2288, time: 0.162, data: 0.000) loss: 0.245 
(epoch: 152, iters: 2368, time: 0.162, data: 0.000) loss: 0.313 
(epoch: 152, iters: 2448, time: 0.162, data: 0.006) loss: 0.089 
(epoch: 152, iters: 2528, time: 0.162, data: 0.013) loss: 0.588 
(epoch: 152, iters: 2608, time: 0.166, data: 0.005) loss: 0.373 
(epoch: 152, iters: 2688, time: 0.164, data: 0.000) loss: 0.494 
(epoch: 152, iters: 2768, time: 0.163, data: 0.000) loss: 0.390 
(epoch: 152, iters: 2848, time: 0.164, data: 0.000) loss: 0.052 
(epoch: 152, iters: 2928, time: 0.163, data: 0.000) loss: 0.811 
(epoch: 152, iters: 3008, time: 0.163, data: 0.018) loss: 0.049 
(epoch: 152, iters: 3088, time: 0.163, data: 0.000) loss: 0.539 
(epoch: 152, iters: 3168, time: 0.162, data: 0.005) loss: 0.263 
(epoch: 152, iters: 3248, time: 0.163, data: 0.000) loss: 0.109 
(epoch: 152, iters: 3328, time: 0.163, data: 0.005) loss: 0.129 
(epoch: 152, iters: 3408, time: 0.164, data: 0.000) loss: 0.302 
(epoch: 152, iters: 3488, time: 0.163, data: 0.000) loss: 0.217 
(epoch: 152, iters: 3568, time: 0.164, data: 0.007) loss: 0.532 
(epoch: 152, iters: 3648, time: 0.163, data: 0.000) loss: 0.478 
(epoch: 152, iters: 3728, time: 0.164, data: 0.000) loss: 0.357 
(epoch: 152, iters: 3808, time: 0.162, data: 0.005) loss: 0.431 
(epoch: 152, iters: 3888, time: 0.163, data: 0.025) loss: 0.157 
(epoch: 152, iters: 3968, time: 0.163, data: 0.000) loss: 0.155 
saving the latest model (epoch 152, total_steps 1543008)
(epoch: 152, iters: 4048, time: 0.163, data: 0.005) loss: 0.173 
(epoch: 152, iters: 4128, time: 0.165, data: 0.000) loss: 0.389 
(epoch: 152, iters: 4208, time: 0.164, data: 0.000) loss: 0.608 
(epoch: 152, iters: 4288, time: 0.163, data: 0.007) loss: 0.330 
(epoch: 152, iters: 4368, time: 0.165, data: 0.000) loss: 0.268 
(epoch: 152, iters: 4448, time: 0.164, data: 0.011) loss: 0.267 
(epoch: 152, iters: 4528, time: 0.162, data: 0.000) loss: 0.281 
(epoch: 152, iters: 4608, time: 0.162, data: 0.008) loss: 0.109 
(epoch: 152, iters: 4688, time: 0.162, data: 0.000) loss: 0.281 
(epoch: 152, iters: 4768, time: 0.164, data: 0.018) loss: 0.327 
(epoch: 152, iters: 4848, time: 0.165, data: 0.028) loss: 0.355 
(epoch: 152, iters: 4928, time: 0.162, data: 0.000) loss: 0.205 
(epoch: 152, iters: 5008, time: 0.163, data: 0.000) loss: 0.580 
(epoch: 152, iters: 5088, time: 0.161, data: 0.023) loss: 0.184 
(epoch: 152, iters: 5168, time: 0.161, data: 0.000) loss: 0.358 
(epoch: 152, iters: 5248, time: 0.162, data: 0.000) loss: 0.217 
(epoch: 152, iters: 5328, time: 0.161, data: 0.000) loss: 0.679 
(epoch: 152, iters: 5408, time: 0.162, data: 0.005) loss: 0.332 
(epoch: 152, iters: 5488, time: 0.163, data: 0.000) loss: 0.775 
(epoch: 152, iters: 5568, time: 0.164, data: 0.009) loss: 0.168 
(epoch: 152, iters: 5648, time: 0.161, data: 0.000) loss: 0.177 
(epoch: 152, iters: 5728, time: 0.163, data: 0.000) loss: 0.484 
(epoch: 152, iters: 5808, time: 0.165, data: 0.025) loss: 0.187 
(epoch: 152, iters: 5888, time: 0.162, data: 0.000) loss: 0.530 
(epoch: 152, iters: 5968, time: 0.161, data: 0.000) loss: 0.362 
(epoch: 152, iters: 6048, time: 0.162, data: 0.006) loss: 0.394 
(epoch: 152, iters: 6128, time: 0.163, data: 0.022) loss: 0.178 
(epoch: 152, iters: 6208, time: 0.161, data: 0.000) loss: 0.636 
(epoch: 152, iters: 6288, time: 0.164, data: 0.021) loss: 0.374 
(epoch: 152, iters: 6368, time: 0.165, data: 0.005) loss: 0.343 
(epoch: 152, iters: 6448, time: 0.162, data: 0.000) loss: 0.062 
(epoch: 152, iters: 6528, time: 0.165, data: 0.000) loss: 0.641 
(epoch: 152, iters: 6608, time: 0.163, data: 0.000) loss: 0.404 
(epoch: 152, iters: 6688, time: 0.163, data: 0.016) loss: 0.483 
(epoch: 152, iters: 6768, time: 0.162, data: 0.005) loss: 0.264 
(epoch: 152, iters: 6848, time: 0.166, data: 0.000) loss: 0.335 
(epoch: 152, iters: 6928, time: 0.162, data: 0.005) loss: 0.185 
(epoch: 152, iters: 7008, time: 0.165, data: 0.000) loss: 0.141 
(epoch: 152, iters: 7088, time: 0.161, data: 0.013) loss: 0.136 
(epoch: 152, iters: 7168, time: 0.163, data: 0.000) loss: 0.162 
(epoch: 152, iters: 7248, time: 0.163, data: 0.000) loss: 0.665 
(epoch: 152, iters: 7328, time: 0.164, data: 0.005) loss: 0.832 
(epoch: 152, iters: 7408, time: 0.164, data: 0.005) loss: 0.548 
(epoch: 152, iters: 7488, time: 0.163, data: 0.024) loss: 0.518 
(epoch: 152, iters: 7568, time: 0.163, data: 0.005) loss: 0.319 
(epoch: 152, iters: 7648, time: 0.163, data: 0.009) loss: 0.130 
(epoch: 152, iters: 7728, time: 0.161, data: 0.008) loss: 0.209 
(epoch: 152, iters: 7808, time: 0.162, data: 0.011) loss: 0.247 
(epoch: 152, iters: 7888, time: 0.164, data: 0.000) loss: 0.528 
(epoch: 152, iters: 7968, time: 0.163, data: 0.000) loss: 0.076 
saving the latest model (epoch 152, total_steps 1547008)
(epoch: 152, iters: 8048, time: 0.163, data: 0.027) loss: 0.193 
(epoch: 152, iters: 8128, time: 0.163, data: 0.006) loss: 0.371 
(epoch: 152, iters: 8208, time: 0.163, data: 0.005) loss: 0.216 
(epoch: 152, iters: 8288, time: 0.166, data: 0.000) loss: 0.415 
(epoch: 152, iters: 8368, time: 0.163, data: 0.019) loss: 0.313 
(epoch: 152, iters: 8448, time: 0.165, data: 0.000) loss: 0.630 
(epoch: 152, iters: 8528, time: 0.165, data: 0.008) loss: 0.319 
(epoch: 152, iters: 8608, time: 0.164, data: 0.022) loss: 0.174 
(epoch: 152, iters: 8688, time: 0.162, data: 0.000) loss: 0.349 
(epoch: 152, iters: 8768, time: 0.166, data: 0.000) loss: 0.366 
(epoch: 152, iters: 8848, time: 0.163, data: 0.005) loss: 0.177 
(epoch: 152, iters: 8928, time: 0.160, data: 0.032) loss: 0.342 
(epoch: 152, iters: 9008, time: 0.163, data: 0.000) loss: 0.523 
(epoch: 152, iters: 9088, time: 0.163, data: 0.000) loss: 0.326 
(epoch: 152, iters: 9168, time: 0.162, data: 0.008) loss: 0.321 
(epoch: 152, iters: 9248, time: 0.163, data: 0.018) loss: 0.827 
(epoch: 152, iters: 9328, time: 0.162, data: 0.000) loss: 0.458 
(epoch: 152, iters: 9408, time: 0.161, data: 0.000) loss: 0.443 
(epoch: 152, iters: 9488, time: 0.163, data: 0.005) loss: 0.370 
(epoch: 152, iters: 9568, time: 0.163, data: 0.000) loss: 0.479 
(epoch: 152, iters: 9648, time: 0.163, data: 0.019) loss: 0.258 
(epoch: 152, iters: 9728, time: 0.162, data: 0.013) loss: 0.377 
(epoch: 152, iters: 9808, time: 0.161, data: 0.000) loss: 0.306 
(epoch: 152, iters: 9888, time: 0.163, data: 0.000) loss: 0.496 
(epoch: 152, iters: 9968, time: 0.163, data: 0.000) loss: 0.825 
(epoch: 152, iters: 10048, time: 0.163, data: 0.015) loss: 0.244 
(epoch: 152, iters: 10128, time: 0.163, data: 0.000) loss: 0.413 
saving the model at the end of epoch 152, iters 1549184
End of epoch 152 / 200 	 Time Taken: 1664 sec
learning rate = 0.0000931
(epoch: 153, iters: 16, time: 0.178, data: 0.021) loss: 0.402 
saving the latest model (epoch 153, total_steps 1549200)
(epoch: 153, iters: 96, time: 0.164, data: 0.000) loss: 0.385 
(epoch: 153, iters: 176, time: 0.163, data: 0.016) loss: 0.049 
(epoch: 153, iters: 256, time: 0.166, data: 0.000) loss: 0.261 
(epoch: 153, iters: 336, time: 0.163, data: 0.000) loss: 0.447 
(epoch: 153, iters: 416, time: 0.165, data: 0.007) loss: 0.540 
(epoch: 153, iters: 496, time: 0.165, data: 0.000) loss: 0.174 
(epoch: 153, iters: 576, time: 0.163, data: 0.000) loss: 0.105 
(epoch: 153, iters: 656, time: 0.164, data: 0.000) loss: 0.286 
(epoch: 153, iters: 736, time: 0.164, data: 0.005) loss: 0.139 
(epoch: 153, iters: 816, time: 0.166, data: 0.000) loss: 0.268 
(epoch: 153, iters: 896, time: 0.163, data: 0.020) loss: 0.174 
(epoch: 153, iters: 976, time: 0.163, data: 0.031) loss: 0.307 
(epoch: 153, iters: 1056, time: 0.165, data: 0.000) loss: 0.053 
(epoch: 153, iters: 1136, time: 0.162, data: 0.005) loss: 0.183 
(epoch: 153, iters: 1216, time: 0.161, data: 0.000) loss: 0.295 
(epoch: 153, iters: 1296, time: 0.161, data: 0.000) loss: 0.292 
(epoch: 153, iters: 1376, time: 0.163, data: 0.000) loss: 0.079 
(epoch: 153, iters: 1456, time: 0.163, data: 0.010) loss: 0.133 
(epoch: 153, iters: 1536, time: 0.163, data: 0.000) loss: 0.317 
(epoch: 153, iters: 1616, time: 0.164, data: 0.000) loss: 0.257 
(epoch: 153, iters: 1696, time: 0.163, data: 0.032) loss: 0.435 
(epoch: 153, iters: 1776, time: 0.164, data: 0.000) loss: 0.562 
(epoch: 153, iters: 1856, time: 0.162, data: 0.005) loss: 0.328 
(epoch: 153, iters: 1936, time: 0.165, data: 0.000) loss: 0.551 
(epoch: 153, iters: 2016, time: 0.165, data: 0.010) loss: 0.082 
(epoch: 153, iters: 2096, time: 0.164, data: 0.000) loss: 0.463 
(epoch: 153, iters: 2176, time: 0.164, data: 0.000) loss: 0.026 
(epoch: 153, iters: 2256, time: 0.163, data: 0.000) loss: 0.311 
(epoch: 153, iters: 2336, time: 0.164, data: 0.000) loss: 0.388 
(epoch: 153, iters: 2416, time: 0.172, data: 0.000) loss: 0.441 
(epoch: 153, iters: 2496, time: 0.163, data: 0.000) loss: 0.300 
(epoch: 153, iters: 2576, time: 0.166, data: 0.008) loss: 0.257 
(epoch: 153, iters: 2656, time: 0.164, data: 0.008) loss: 0.322 
(epoch: 153, iters: 2736, time: 0.166, data: 0.000) loss: 0.333 
(epoch: 153, iters: 2816, time: 0.162, data: 0.000) loss: 0.676 
(epoch: 153, iters: 2896, time: 0.165, data: 0.000) loss: 0.427 
(epoch: 153, iters: 2976, time: 0.164, data: 0.021) loss: 0.605 
(epoch: 153, iters: 3056, time: 0.164, data: 0.005) loss: 0.547 
(epoch: 153, iters: 3136, time: 0.163, data: 0.005) loss: 0.081 
(epoch: 153, iters: 3216, time: 0.165, data: 0.000) loss: 0.219 
(epoch: 153, iters: 3296, time: 0.164, data: 0.014) loss: 0.110 
(epoch: 153, iters: 3376, time: 0.162, data: 0.006) loss: 0.316 
(epoch: 153, iters: 3456, time: 0.162, data: 0.010) loss: 0.136 
(epoch: 153, iters: 3536, time: 0.165, data: 0.000) loss: 0.415 
(epoch: 153, iters: 3616, time: 0.162, data: 0.023) loss: 0.238 
(epoch: 153, iters: 3696, time: 0.163, data: 0.000) loss: 0.231 
(epoch: 153, iters: 3776, time: 0.162, data: 0.000) loss: 0.119 
(epoch: 153, iters: 3856, time: 0.164, data: 0.005) loss: 0.339 
(epoch: 153, iters: 3936, time: 0.164, data: 0.000) loss: 0.272 
(epoch: 153, iters: 4016, time: 0.164, data: 0.009) loss: 0.075 
saving the latest model (epoch 153, total_steps 1553200)
(epoch: 153, iters: 4096, time: 0.163, data: 0.000) loss: 0.697 
(epoch: 153, iters: 4176, time: 0.165, data: 0.000) loss: 0.271 
(epoch: 153, iters: 4256, time: 0.164, data: 0.000) loss: 0.543 
(epoch: 153, iters: 4336, time: 0.165, data: 0.009) loss: 0.055 
(epoch: 153, iters: 4416, time: 0.165, data: 0.017) loss: 0.327 
(epoch: 153, iters: 4496, time: 0.163, data: 0.014) loss: 0.404 
(epoch: 153, iters: 4576, time: 0.166, data: 0.031) loss: 0.244 
(epoch: 153, iters: 4656, time: 0.164, data: 0.000) loss: 0.278 
(epoch: 153, iters: 4736, time: 0.164, data: 0.000) loss: 0.233 
(epoch: 153, iters: 4816, time: 0.163, data: 0.000) loss: 0.253 
(epoch: 153, iters: 4896, time: 0.164, data: 0.000) loss: 0.298 
(epoch: 153, iters: 4976, time: 0.163, data: 0.000) loss: 0.534 
(epoch: 153, iters: 5056, time: 0.162, data: 0.015) loss: 0.303 
(epoch: 153, iters: 5136, time: 0.162, data: 0.000) loss: 0.338 
(epoch: 153, iters: 5216, time: 0.162, data: 0.020) loss: 0.116 
(epoch: 153, iters: 5296, time: 0.165, data: 0.024) loss: 0.294 
(epoch: 153, iters: 5376, time: 0.163, data: 0.000) loss: 0.278 
(epoch: 153, iters: 5456, time: 0.164, data: 0.010) loss: 0.154 
(epoch: 153, iters: 5536, time: 0.166, data: 0.000) loss: 0.650 
(epoch: 153, iters: 5616, time: 0.162, data: 0.025) loss: 0.196 
(epoch: 153, iters: 5696, time: 0.162, data: 0.000) loss: 0.557 
(epoch: 153, iters: 5776, time: 0.163, data: 0.021) loss: 0.129 
(epoch: 153, iters: 5856, time: 0.162, data: 0.000) loss: 0.845 
(epoch: 153, iters: 5936, time: 0.163, data: 0.000) loss: 0.362 
(epoch: 153, iters: 6016, time: 0.165, data: 0.000) loss: 0.424 
(epoch: 153, iters: 6096, time: 0.163, data: 0.023) loss: 0.169 
(epoch: 153, iters: 6176, time: 0.164, data: 0.000) loss: 0.186 
(epoch: 153, iters: 6256, time: 0.164, data: 0.000) loss: 0.062 
(epoch: 153, iters: 6336, time: 0.164, data: 0.000) loss: 0.328 
(epoch: 153, iters: 6416, time: 0.163, data: 0.028) loss: 0.103 
(epoch: 153, iters: 6496, time: 0.164, data: 0.005) loss: 0.148 
(epoch: 153, iters: 6576, time: 0.166, data: 0.013) loss: 0.115 
(epoch: 153, iters: 6656, time: 0.168, data: 0.000) loss: 0.317 
(epoch: 153, iters: 6736, time: 0.164, data: 0.006) loss: 0.557 
(epoch: 153, iters: 6816, time: 0.163, data: 0.000) loss: 0.360 
(epoch: 153, iters: 6896, time: 0.164, data: 0.000) loss: 0.488 
(epoch: 153, iters: 6976, time: 0.161, data: 0.011) loss: 0.210 
(epoch: 153, iters: 7056, time: 0.163, data: 0.000) loss: 0.337 
(epoch: 153, iters: 7136, time: 0.165, data: 0.000) loss: 0.136 
(epoch: 153, iters: 7216, time: 0.164, data: 0.000) loss: 0.251 
(epoch: 153, iters: 7296, time: 0.163, data: 0.000) loss: 0.473 
(epoch: 153, iters: 7376, time: 0.164, data: 0.020) loss: 0.193 
(epoch: 153, iters: 7456, time: 0.163, data: 0.015) loss: 0.311 
(epoch: 153, iters: 7536, time: 0.164, data: 0.000) loss: 0.386 
(epoch: 153, iters: 7616, time: 0.164, data: 0.000) loss: 0.634 
(epoch: 153, iters: 7696, time: 0.164, data: 0.005) loss: 0.192 
(epoch: 153, iters: 7776, time: 0.164, data: 0.000) loss: 0.118 
(epoch: 153, iters: 7856, time: 0.163, data: 0.024) loss: 0.306 
(epoch: 153, iters: 7936, time: 0.165, data: 0.000) loss: 0.280 
(epoch: 153, iters: 8016, time: 0.163, data: 0.023) loss: 0.088 
saving the latest model (epoch 153, total_steps 1557200)
(epoch: 153, iters: 8096, time: 0.164, data: 0.000) loss: 0.361 
(epoch: 153, iters: 8176, time: 0.162, data: 0.000) loss: 0.796 
(epoch: 153, iters: 8256, time: 0.167, data: 0.000) loss: 0.117 
(epoch: 153, iters: 8336, time: 0.165, data: 0.006) loss: 0.424 
(epoch: 153, iters: 8416, time: 0.166, data: 0.011) loss: 0.264 
(epoch: 153, iters: 8496, time: 0.165, data: 0.000) loss: 0.356 
(epoch: 153, iters: 8576, time: 0.163, data: 0.015) loss: 0.443 
(epoch: 153, iters: 8656, time: 0.164, data: 0.010) loss: 0.056 
(epoch: 153, iters: 8736, time: 0.164, data: 0.000) loss: 0.471 
(epoch: 153, iters: 8816, time: 0.164, data: 0.000) loss: 0.352 
(epoch: 153, iters: 8896, time: 0.164, data: 0.024) loss: 0.491 
(epoch: 153, iters: 8976, time: 0.168, data: 0.014) loss: 0.106 
(epoch: 153, iters: 9056, time: 0.162, data: 0.021) loss: 0.178 
(epoch: 153, iters: 9136, time: 0.162, data: 0.000) loss: 0.398 
(epoch: 153, iters: 9216, time: 0.164, data: 0.005) loss: 0.487 
(epoch: 153, iters: 9296, time: 0.164, data: 0.000) loss: 0.472 
(epoch: 153, iters: 9376, time: 0.162, data: 0.015) loss: 0.568 
(epoch: 153, iters: 9456, time: 0.164, data: 0.020) loss: 0.099 
(epoch: 153, iters: 9536, time: 0.163, data: 0.000) loss: 0.262 
(epoch: 153, iters: 9616, time: 0.163, data: 0.005) loss: 0.055 
(epoch: 153, iters: 9696, time: 0.165, data: 0.000) loss: 0.330 
(epoch: 153, iters: 9776, time: 0.161, data: 0.005) loss: 0.259 
(epoch: 153, iters: 9856, time: 0.165, data: 0.000) loss: 0.577 
(epoch: 153, iters: 9936, time: 0.166, data: 0.008) loss: 0.356 
(epoch: 153, iters: 10016, time: 0.165, data: 0.000) loss: 0.268 
(epoch: 153, iters: 10096, time: 0.164, data: 0.000) loss: 0.294 
(epoch: 153, iters: 10176, time: 0.162, data: 0.032) loss: 0.094 
saving the model at the end of epoch 153, iters 1559376
End of epoch 153 / 200 	 Time Taken: 1670 sec
learning rate = 0.0000911
saving the latest model (epoch 154, total_steps 1559392)
(epoch: 154, iters: 64, time: 0.163, data: 0.000) loss: 0.191 
(epoch: 154, iters: 144, time: 0.163, data: 0.000) loss: 0.164 
(epoch: 154, iters: 224, time: 0.163, data: 0.000) loss: 0.550 
(epoch: 154, iters: 304, time: 0.164, data: 0.005) loss: 0.351 
(epoch: 154, iters: 384, time: 0.163, data: 0.000) loss: 0.301 
(epoch: 154, iters: 464, time: 0.164, data: 0.023) loss: 0.269 
(epoch: 154, iters: 544, time: 0.163, data: 0.000) loss: 0.156 
(epoch: 154, iters: 624, time: 0.165, data: 0.000) loss: 0.512 
(epoch: 154, iters: 704, time: 0.164, data: 0.007) loss: 0.379 
(epoch: 154, iters: 784, time: 0.165, data: 0.000) loss: 0.192 
(epoch: 154, iters: 864, time: 0.164, data: 0.005) loss: 0.285 
(epoch: 154, iters: 944, time: 0.163, data: 0.000) loss: 0.152 
(epoch: 154, iters: 1024, time: 0.167, data: 0.000) loss: 0.333 
(epoch: 154, iters: 1104, time: 0.165, data: 0.000) loss: 0.301 
(epoch: 154, iters: 1184, time: 0.165, data: 0.006) loss: 0.076 
(epoch: 154, iters: 1264, time: 0.164, data: 0.000) loss: 0.233 
(epoch: 154, iters: 1344, time: 0.165, data: 0.005) loss: 0.489 
(epoch: 154, iters: 1424, time: 0.163, data: 0.012) loss: 0.529 
(epoch: 154, iters: 1504, time: 0.164, data: 0.005) loss: 0.382 
(epoch: 154, iters: 1584, time: 0.163, data: 0.009) loss: 0.322 
(epoch: 154, iters: 1664, time: 0.162, data: 0.000) loss: 0.314 
(epoch: 154, iters: 1744, time: 0.163, data: 0.023) loss: 0.235 
(epoch: 154, iters: 1824, time: 0.164, data: 0.000) loss: 0.311 
(epoch: 154, iters: 1904, time: 0.163, data: 0.010) loss: 0.379 
(epoch: 154, iters: 1984, time: 0.163, data: 0.000) loss: 0.811 
(epoch: 154, iters: 2064, time: 0.164, data: 0.000) loss: 0.118 
(epoch: 154, iters: 2144, time: 0.162, data: 0.005) loss: 0.273 
(epoch: 154, iters: 2224, time: 0.162, data: 0.000) loss: 0.221 
(epoch: 154, iters: 2304, time: 0.161, data: 0.005) loss: 0.192 
(epoch: 154, iters: 2384, time: 0.161, data: 0.000) loss: 0.122 
(epoch: 154, iters: 2464, time: 0.163, data: 0.000) loss: 0.249 
(epoch: 154, iters: 2544, time: 0.164, data: 0.016) loss: 0.194 
(epoch: 154, iters: 2624, time: 0.164, data: 0.000) loss: 0.282 
(epoch: 154, iters: 2704, time: 0.163, data: 0.000) loss: 0.249 
(epoch: 154, iters: 2784, time: 0.164, data: 0.000) loss: 0.395 
(epoch: 154, iters: 2864, time: 0.164, data: 0.015) loss: 0.830 
(epoch: 154, iters: 2944, time: 0.163, data: 0.000) loss: 0.231 
(epoch: 154, iters: 3024, time: 0.164, data: 0.015) loss: 0.319 
(epoch: 154, iters: 3104, time: 0.163, data: 0.005) loss: 0.445 
(epoch: 154, iters: 3184, time: 0.165, data: 0.000) loss: 0.342 
(epoch: 154, iters: 3264, time: 0.163, data: 0.000) loss: 0.037 
(epoch: 154, iters: 3344, time: 0.164, data: 0.005) loss: 0.250 
(epoch: 154, iters: 3424, time: 0.163, data: 0.000) loss: 0.570 
(epoch: 154, iters: 3504, time: 0.163, data: 0.010) loss: 0.337 
(epoch: 154, iters: 3584, time: 0.167, data: 0.005) loss: 0.840 
(epoch: 154, iters: 3664, time: 0.163, data: 0.005) loss: 0.247 
(epoch: 154, iters: 3744, time: 0.163, data: 0.008) loss: 0.194 
(epoch: 154, iters: 3824, time: 0.163, data: 0.000) loss: 0.234 
(epoch: 154, iters: 3904, time: 0.164, data: 0.000) loss: 0.407 
(epoch: 154, iters: 3984, time: 0.165, data: 0.009) loss: 0.317 
saving the latest model (epoch 154, total_steps 1563392)
(epoch: 154, iters: 4064, time: 0.164, data: 0.000) loss: 0.278 
(epoch: 154, iters: 4144, time: 0.162, data: 0.017) loss: 0.607 
(epoch: 154, iters: 4224, time: 0.162, data: 0.000) loss: 0.148 
(epoch: 154, iters: 4304, time: 0.164, data: 0.005) loss: 0.157 
(epoch: 154, iters: 4384, time: 0.164, data: 0.016) loss: 0.290 
(epoch: 154, iters: 4464, time: 0.163, data: 0.000) loss: 0.155 
(epoch: 154, iters: 4544, time: 0.163, data: 0.017) loss: 0.081 
(epoch: 154, iters: 4624, time: 0.162, data: 0.000) loss: 0.467 
(epoch: 154, iters: 4704, time: 0.163, data: 0.000) loss: 0.410 
(epoch: 154, iters: 4784, time: 0.163, data: 0.000) loss: 0.225 
(epoch: 154, iters: 4864, time: 0.162, data: 0.029) loss: 0.212 
(epoch: 154, iters: 4944, time: 0.162, data: 0.000) loss: 0.144 
(epoch: 154, iters: 5024, time: 0.162, data: 0.005) loss: 0.210 
(epoch: 154, iters: 5104, time: 0.162, data: 0.000) loss: 0.071 
(epoch: 154, iters: 5184, time: 0.164, data: 0.005) loss: 0.429 
(epoch: 154, iters: 5264, time: 0.164, data: 0.000) loss: 0.150 
(epoch: 154, iters: 5344, time: 0.163, data: 0.010) loss: 0.241 
(epoch: 154, iters: 5424, time: 0.164, data: 0.000) loss: 0.546 
(epoch: 154, iters: 5504, time: 0.165, data: 0.000) loss: 0.153 
(epoch: 154, iters: 5584, time: 0.163, data: 0.005) loss: 0.612 
(epoch: 154, iters: 5664, time: 0.164, data: 0.006) loss: 0.350 
(epoch: 154, iters: 5744, time: 0.164, data: 0.011) loss: 0.222 
(epoch: 154, iters: 5824, time: 0.164, data: 0.000) loss: 0.256 
(epoch: 154, iters: 5904, time: 0.163, data: 0.000) loss: 0.290 
(epoch: 154, iters: 5984, time: 0.164, data: 0.009) loss: 0.150 
(epoch: 154, iters: 6064, time: 0.163, data: 0.000) loss: 0.192 
(epoch: 154, iters: 6144, time: 0.162, data: 0.000) loss: 0.366 
(epoch: 154, iters: 6224, time: 0.164, data: 0.005) loss: 0.120 
(epoch: 154, iters: 6304, time: 0.163, data: 0.008) loss: 0.153 
(epoch: 154, iters: 6384, time: 0.164, data: 0.008) loss: 0.520 
(epoch: 154, iters: 6464, time: 0.161, data: 0.014) loss: 0.156 
(epoch: 154, iters: 6544, time: 0.162, data: 0.000) loss: 0.712 
(epoch: 154, iters: 6624, time: 0.162, data: 0.000) loss: 0.140 
(epoch: 154, iters: 6704, time: 0.161, data: 0.031) loss: 0.372 
(epoch: 154, iters: 6784, time: 0.162, data: 0.000) loss: 0.113 
(epoch: 154, iters: 6864, time: 0.163, data: 0.031) loss: 0.165 
(epoch: 154, iters: 6944, time: 0.164, data: 0.000) loss: 0.104 
(epoch: 154, iters: 7024, time: 0.164, data: 0.009) loss: 0.157 
(epoch: 154, iters: 7104, time: 0.164, data: 0.000) loss: 0.129 
(epoch: 154, iters: 7184, time: 0.164, data: 0.018) loss: 0.110 
(epoch: 154, iters: 7264, time: 0.166, data: 0.000) loss: 0.187 
(epoch: 154, iters: 7344, time: 0.162, data: 0.000) loss: 0.271 
(epoch: 154, iters: 7424, time: 0.162, data: 0.005) loss: 0.484 
(epoch: 154, iters: 7504, time: 0.164, data: 0.000) loss: 0.271 
(epoch: 154, iters: 7584, time: 0.164, data: 0.014) loss: 0.435 
(epoch: 154, iters: 7664, time: 0.163, data: 0.000) loss: 0.184 
(epoch: 154, iters: 7744, time: 0.164, data: 0.005) loss: 0.311 
(epoch: 154, iters: 7824, time: 0.163, data: 0.025) loss: 0.253 
(epoch: 154, iters: 7904, time: 0.163, data: 0.000) loss: 0.149 
(epoch: 154, iters: 7984, time: 0.165, data: 0.000) loss: 0.310 
saving the latest model (epoch 154, total_steps 1567392)
(epoch: 154, iters: 8064, time: 0.163, data: 0.000) loss: 0.456 
(epoch: 154, iters: 8144, time: 0.162, data: 0.005) loss: 0.054 
(epoch: 154, iters: 8224, time: 0.164, data: 0.000) loss: 0.531 
(epoch: 154, iters: 8304, time: 0.163, data: 0.000) loss: 0.250 
(epoch: 154, iters: 8384, time: 0.164, data: 0.006) loss: 0.054 
(epoch: 154, iters: 8464, time: 0.162, data: 0.000) loss: 0.554 
(epoch: 154, iters: 8544, time: 0.163, data: 0.005) loss: 0.157 
(epoch: 154, iters: 8624, time: 0.165, data: 0.000) loss: 0.129 
(epoch: 154, iters: 8704, time: 0.164, data: 0.028) loss: 0.413 
(epoch: 154, iters: 8784, time: 0.162, data: 0.005) loss: 0.469 
(epoch: 154, iters: 8864, time: 0.165, data: 0.008) loss: 0.304 
(epoch: 154, iters: 8944, time: 0.162, data: 0.000) loss: 0.127 
(epoch: 154, iters: 9024, time: 0.163, data: 0.000) loss: 0.251 
(epoch: 154, iters: 9104, time: 0.168, data: 0.000) loss: 0.159 
(epoch: 154, iters: 9184, time: 0.163, data: 0.000) loss: 0.529 
(epoch: 154, iters: 9264, time: 0.162, data: 0.000) loss: 0.138 
(epoch: 154, iters: 9344, time: 0.163, data: 0.015) loss: 0.195 
(epoch: 154, iters: 9424, time: 0.164, data: 0.000) loss: 0.149 
(epoch: 154, iters: 9504, time: 0.163, data: 0.006) loss: 0.393 
(epoch: 154, iters: 9584, time: 0.163, data: 0.019) loss: 0.286 
(epoch: 154, iters: 9664, time: 0.163, data: 0.000) loss: 0.362 
(epoch: 154, iters: 9744, time: 0.165, data: 0.020) loss: 0.171 
(epoch: 154, iters: 9824, time: 0.166, data: 0.008) loss: 0.136 
(epoch: 154, iters: 9904, time: 0.163, data: 0.000) loss: 0.196 
(epoch: 154, iters: 9984, time: 0.163, data: 0.027) loss: 0.143 
(epoch: 154, iters: 10064, time: 0.163, data: 0.000) loss: 0.229 
(epoch: 154, iters: 10144, time: 0.164, data: 0.013) loss: 0.306 
saving the model at the end of epoch 154, iters 1569568
End of epoch 154 / 200 	 Time Taken: 1668 sec
learning rate = 0.0000891
saving the latest model (epoch 155, total_steps 1569584)
(epoch: 155, iters: 32, time: 0.164, data: 0.011) loss: 0.565 
(epoch: 155, iters: 112, time: 0.163, data: 0.000) loss: 0.534 
(epoch: 155, iters: 192, time: 0.163, data: 0.000) loss: 0.402 
(epoch: 155, iters: 272, time: 0.162, data: 0.000) loss: 0.887 
(epoch: 155, iters: 352, time: 0.163, data: 0.007) loss: 0.249 
(epoch: 155, iters: 432, time: 0.163, data: 0.000) loss: 0.557 
(epoch: 155, iters: 512, time: 0.163, data: 0.000) loss: 0.817 
(epoch: 155, iters: 592, time: 0.162, data: 0.014) loss: 0.321 
(epoch: 155, iters: 672, time: 0.163, data: 0.000) loss: 0.107 
(epoch: 155, iters: 752, time: 0.162, data: 0.006) loss: 0.131 
(epoch: 155, iters: 832, time: 0.163, data: 0.006) loss: 0.068 
(epoch: 155, iters: 912, time: 0.162, data: 0.000) loss: 0.310 
(epoch: 155, iters: 992, time: 0.164, data: 0.000) loss: 0.133 
(epoch: 155, iters: 1072, time: 0.165, data: 0.000) loss: 0.143 
(epoch: 155, iters: 1152, time: 0.164, data: 0.009) loss: 0.454 
(epoch: 155, iters: 1232, time: 0.162, data: 0.008) loss: 0.077 
(epoch: 155, iters: 1312, time: 0.163, data: 0.000) loss: 0.295 
(epoch: 155, iters: 1392, time: 0.162, data: 0.000) loss: 0.182 
(epoch: 155, iters: 1472, time: 0.163, data: 0.000) loss: 0.619 
(epoch: 155, iters: 1552, time: 0.163, data: 0.000) loss: 0.156 
(epoch: 155, iters: 1632, time: 0.162, data: 0.022) loss: 0.684 
(epoch: 155, iters: 1712, time: 0.161, data: 0.000) loss: 0.096 
(epoch: 155, iters: 1792, time: 0.162, data: 0.011) loss: 0.257 
(epoch: 155, iters: 1872, time: 0.162, data: 0.000) loss: 0.067 
(epoch: 155, iters: 1952, time: 0.162, data: 0.000) loss: 0.294 
(epoch: 155, iters: 2032, time: 0.163, data: 0.005) loss: 0.374 
(epoch: 155, iters: 2112, time: 0.163, data: 0.005) loss: 0.239 
(epoch: 155, iters: 2192, time: 0.162, data: 0.008) loss: 0.179 
(epoch: 155, iters: 2272, time: 0.163, data: 0.006) loss: 0.158 
(epoch: 155, iters: 2352, time: 0.165, data: 0.000) loss: 0.607 
(epoch: 155, iters: 2432, time: 0.163, data: 0.009) loss: 0.278 
(epoch: 155, iters: 2512, time: 0.163, data: 0.000) loss: 0.216 
(epoch: 155, iters: 2592, time: 0.164, data: 0.006) loss: 0.182 
(epoch: 155, iters: 2672, time: 0.163, data: 0.000) loss: 0.431 
(epoch: 155, iters: 2752, time: 0.163, data: 0.000) loss: 0.094 
(epoch: 155, iters: 2832, time: 0.164, data: 0.013) loss: 0.236 
(epoch: 155, iters: 2912, time: 0.164, data: 0.012) loss: 0.182 
(epoch: 155, iters: 2992, time: 0.163, data: 0.000) loss: 0.698 
(epoch: 155, iters: 3072, time: 0.164, data: 0.011) loss: 0.280 
(epoch: 155, iters: 3152, time: 0.162, data: 0.000) loss: 0.076 
(epoch: 155, iters: 3232, time: 0.163, data: 0.032) loss: 0.211 
(epoch: 155, iters: 3312, time: 0.163, data: 0.000) loss: 0.273 
(epoch: 155, iters: 3392, time: 0.162, data: 0.000) loss: 0.528 
(epoch: 155, iters: 3472, time: 0.162, data: 0.000) loss: 0.266 
(epoch: 155, iters: 3552, time: 0.161, data: 0.006) loss: 0.202 
(epoch: 155, iters: 3632, time: 0.163, data: 0.006) loss: 0.427 
(epoch: 155, iters: 3712, time: 0.162, data: 0.000) loss: 0.282 
(epoch: 155, iters: 3792, time: 0.162, data: 0.008) loss: 0.608 
(epoch: 155, iters: 3872, time: 0.162, data: 0.000) loss: 0.461 
(epoch: 155, iters: 3952, time: 0.163, data: 0.021) loss: 0.405 
saving the latest model (epoch 155, total_steps 1573584)
(epoch: 155, iters: 4032, time: 0.162, data: 0.013) loss: 0.237 
(epoch: 155, iters: 4112, time: 0.161, data: 0.000) loss: 0.441 
(epoch: 155, iters: 4192, time: 0.162, data: 0.000) loss: 0.298 
(epoch: 155, iters: 4272, time: 0.164, data: 0.014) loss: 0.525 
(epoch: 155, iters: 4352, time: 0.162, data: 0.000) loss: 0.137 
(epoch: 155, iters: 4432, time: 0.162, data: 0.005) loss: 0.455 
(epoch: 155, iters: 4512, time: 0.163, data: 0.005) loss: 0.237 
(epoch: 155, iters: 4592, time: 0.163, data: 0.005) loss: 0.155 
(epoch: 155, iters: 4672, time: 0.163, data: 0.005) loss: 0.205 
(epoch: 155, iters: 4752, time: 0.164, data: 0.016) loss: 0.378 
(epoch: 155, iters: 4832, time: 0.163, data: 0.000) loss: 0.451 
(epoch: 155, iters: 4912, time: 0.165, data: 0.008) loss: 0.215 
(epoch: 155, iters: 4992, time: 0.163, data: 0.013) loss: 0.269 
(epoch: 155, iters: 5072, time: 0.162, data: 0.000) loss: 0.144 
(epoch: 155, iters: 5152, time: 0.163, data: 0.000) loss: 0.684 
(epoch: 155, iters: 5232, time: 0.161, data: 0.005) loss: 0.100 
(epoch: 155, iters: 5312, time: 0.160, data: 0.000) loss: 0.478 
(epoch: 155, iters: 5392, time: 0.164, data: 0.008) loss: 0.187 
(epoch: 155, iters: 5472, time: 0.164, data: 0.000) loss: 0.156 
(epoch: 155, iters: 5552, time: 0.163, data: 0.013) loss: 0.355 
(epoch: 155, iters: 5632, time: 0.162, data: 0.023) loss: 0.297 
(epoch: 155, iters: 5712, time: 0.167, data: 0.000) loss: 0.519 
(epoch: 155, iters: 5792, time: 0.163, data: 0.000) loss: 0.137 
(epoch: 155, iters: 5872, time: 0.167, data: 0.008) loss: 0.215 
(epoch: 155, iters: 5952, time: 0.162, data: 0.000) loss: 0.337 
(epoch: 155, iters: 6032, time: 0.165, data: 0.015) loss: 0.221 
(epoch: 155, iters: 6112, time: 0.164, data: 0.014) loss: 0.354 
(epoch: 155, iters: 6192, time: 0.165, data: 0.000) loss: 0.624 
(epoch: 155, iters: 6272, time: 0.163, data: 0.035) loss: 0.335 
(epoch: 155, iters: 6352, time: 0.161, data: 0.000) loss: 0.170 
(epoch: 155, iters: 6432, time: 0.163, data: 0.018) loss: 0.148 
(epoch: 155, iters: 6512, time: 0.163, data: 0.016) loss: 0.141 
(epoch: 155, iters: 6592, time: 0.165, data: 0.039) loss: 0.180 
(epoch: 155, iters: 6672, time: 0.162, data: 0.000) loss: 0.353 
(epoch: 155, iters: 6752, time: 0.164, data: 0.032) loss: 0.127 
(epoch: 155, iters: 6832, time: 0.162, data: 0.000) loss: 0.258 
(epoch: 155, iters: 6912, time: 0.162, data: 0.005) loss: 0.302 
(epoch: 155, iters: 6992, time: 0.163, data: 0.000) loss: 0.128 
(epoch: 155, iters: 7072, time: 0.163, data: 0.000) loss: 0.195 
(epoch: 155, iters: 7152, time: 0.163, data: 0.005) loss: 0.397 
(epoch: 155, iters: 7232, time: 0.163, data: 0.000) loss: 0.345 
(epoch: 155, iters: 7312, time: 0.164, data: 0.014) loss: 0.169 
(epoch: 155, iters: 7392, time: 0.162, data: 0.005) loss: 0.115 
(epoch: 155, iters: 7472, time: 0.162, data: 0.000) loss: 0.676 
(epoch: 155, iters: 7552, time: 0.162, data: 0.027) loss: 0.109 
(epoch: 155, iters: 7632, time: 0.162, data: 0.000) loss: 0.865 
(epoch: 155, iters: 7712, time: 0.163, data: 0.000) loss: 0.394 
(epoch: 155, iters: 7792, time: 0.163, data: 0.008) loss: 0.207 
(epoch: 155, iters: 7872, time: 0.162, data: 0.009) loss: 0.221 
(epoch: 155, iters: 7952, time: 0.163, data: 0.000) loss: 0.142 
saving the latest model (epoch 155, total_steps 1577584)
(epoch: 155, iters: 8032, time: 0.161, data: 0.000) loss: 0.172 
(epoch: 155, iters: 8112, time: 0.161, data: 0.020) loss: 0.305 
(epoch: 155, iters: 8192, time: 0.162, data: 0.022) loss: 0.524 
(epoch: 155, iters: 8272, time: 0.162, data: 0.000) loss: 0.221 
(epoch: 155, iters: 8352, time: 0.164, data: 0.006) loss: 0.081 
(epoch: 155, iters: 8432, time: 0.165, data: 0.000) loss: 0.146 
(epoch: 155, iters: 8512, time: 0.162, data: 0.011) loss: 0.259 
(epoch: 155, iters: 8592, time: 0.162, data: 0.000) loss: 0.197 
(epoch: 155, iters: 8672, time: 0.164, data: 0.000) loss: 0.207 
(epoch: 155, iters: 8752, time: 0.164, data: 0.000) loss: 0.217 
(epoch: 155, iters: 8832, time: 0.164, data: 0.000) loss: 0.325 
(epoch: 155, iters: 8912, time: 0.161, data: 0.000) loss: 0.315 
(epoch: 155, iters: 8992, time: 0.165, data: 0.000) loss: 0.433 
(epoch: 155, iters: 9072, time: 0.164, data: 0.011) loss: 0.320 
(epoch: 155, iters: 9152, time: 0.163, data: 0.000) loss: 0.152 
(epoch: 155, iters: 9232, time: 0.163, data: 0.005) loss: 0.566 
(epoch: 155, iters: 9312, time: 0.162, data: 0.008) loss: 0.140 
(epoch: 155, iters: 9392, time: 0.163, data: 0.000) loss: 0.085 
(epoch: 155, iters: 9472, time: 0.162, data: 0.000) loss: 0.333 
(epoch: 155, iters: 9552, time: 0.162, data: 0.005) loss: 0.844 
(epoch: 155, iters: 9632, time: 0.163, data: 0.012) loss: 0.336 
(epoch: 155, iters: 9712, time: 0.163, data: 0.023) loss: 0.301 
(epoch: 155, iters: 9792, time: 0.162, data: 0.000) loss: 0.207 
(epoch: 155, iters: 9872, time: 0.162, data: 0.000) loss: 0.190 
(epoch: 155, iters: 9952, time: 0.164, data: 0.012) loss: 0.520 
(epoch: 155, iters: 10032, time: 0.162, data: 0.000) loss: 0.277 
(epoch: 155, iters: 10112, time: 0.161, data: 0.000) loss: 0.043 
(epoch: 155, iters: 10192, time: 0.100, data: 0.005) loss: 0.675 
saving the model at the end of epoch 155, iters 1579760
End of epoch 155 / 200 	 Time Taken: 1663 sec
learning rate = 0.0000871
saving the latest model (epoch 156, total_steps 1579776)
(epoch: 156, iters: 80, time: 0.164, data: 0.182) loss: 0.275 
(epoch: 156, iters: 160, time: 0.162, data: 0.025) loss: 0.647 
(epoch: 156, iters: 240, time: 0.162, data: 0.000) loss: 0.148 
(epoch: 156, iters: 320, time: 0.164, data: 0.010) loss: 0.291 
(epoch: 156, iters: 400, time: 0.162, data: 0.000) loss: 0.282 
(epoch: 156, iters: 480, time: 0.163, data: 0.005) loss: 0.367 
(epoch: 156, iters: 560, time: 0.162, data: 0.000) loss: 0.729 
(epoch: 156, iters: 640, time: 0.163, data: 0.030) loss: 0.199 
(epoch: 156, iters: 720, time: 0.162, data: 0.006) loss: 0.153 
(epoch: 156, iters: 800, time: 0.164, data: 0.000) loss: 0.075 
(epoch: 156, iters: 880, time: 0.163, data: 0.010) loss: 0.210 
(epoch: 156, iters: 960, time: 0.163, data: 0.017) loss: 0.199 
(epoch: 156, iters: 1040, time: 0.163, data: 0.000) loss: 0.097 
(epoch: 156, iters: 1120, time: 0.162, data: 0.000) loss: 0.161 
(epoch: 156, iters: 1200, time: 0.166, data: 0.015) loss: 0.296 
(epoch: 156, iters: 1280, time: 0.161, data: 0.008) loss: 0.416 
(epoch: 156, iters: 1360, time: 0.162, data: 0.005) loss: 0.084 
(epoch: 156, iters: 1440, time: 0.163, data: 0.000) loss: 0.469 
(epoch: 156, iters: 1520, time: 0.162, data: 0.006) loss: 0.560 
(epoch: 156, iters: 1600, time: 0.163, data: 0.000) loss: 0.224 
(epoch: 156, iters: 1680, time: 0.161, data: 0.000) loss: 0.446 
(epoch: 156, iters: 1760, time: 0.162, data: 0.000) loss: 0.242 
(epoch: 156, iters: 1840, time: 0.164, data: 0.000) loss: 0.163 
(epoch: 156, iters: 1920, time: 0.162, data: 0.022) loss: 0.317 
(epoch: 156, iters: 2000, time: 0.163, data: 0.000) loss: 0.316 
(epoch: 156, iters: 2080, time: 0.162, data: 0.030) loss: 0.441 
(epoch: 156, iters: 2160, time: 0.161, data: 0.000) loss: 0.386 
(epoch: 156, iters: 2240, time: 0.164, data: 0.013) loss: 0.802 
(epoch: 156, iters: 2320, time: 0.162, data: 0.005) loss: 0.121 
(epoch: 156, iters: 2400, time: 0.162, data: 0.000) loss: 0.712 
(epoch: 156, iters: 2480, time: 0.162, data: 0.006) loss: 0.469 
(epoch: 156, iters: 2560, time: 0.162, data: 0.008) loss: 0.170 
(epoch: 156, iters: 2640, time: 0.162, data: 0.020) loss: 0.261 
(epoch: 156, iters: 2720, time: 0.162, data: 0.000) loss: 0.064 
(epoch: 156, iters: 2800, time: 0.163, data: 0.000) loss: 0.515 
(epoch: 156, iters: 2880, time: 0.164, data: 0.022) loss: 0.372 
(epoch: 156, iters: 2960, time: 0.162, data: 0.000) loss: 0.057 
(epoch: 156, iters: 3040, time: 0.163, data: 0.000) loss: 0.163 
(epoch: 156, iters: 3120, time: 0.160, data: 0.008) loss: 0.513 
(epoch: 156, iters: 3200, time: 0.163, data: 0.000) loss: 0.231 
(epoch: 156, iters: 3280, time: 0.162, data: 0.013) loss: 0.253 
(epoch: 156, iters: 3360, time: 0.162, data: 0.000) loss: 0.283 
(epoch: 156, iters: 3440, time: 0.162, data: 0.016) loss: 0.455 
(epoch: 156, iters: 3520, time: 0.164, data: 0.005) loss: 0.103 
(epoch: 156, iters: 3600, time: 0.163, data: 0.013) loss: 0.425 
(epoch: 156, iters: 3680, time: 0.163, data: 0.005) loss: 0.048 
(epoch: 156, iters: 3760, time: 0.163, data: 0.005) loss: 0.136 
(epoch: 156, iters: 3840, time: 0.162, data: 0.000) loss: 0.538 
(epoch: 156, iters: 3920, time: 0.163, data: 0.000) loss: 0.172 
(epoch: 156, iters: 4000, time: 0.160, data: 0.020) loss: 0.275 
saving the latest model (epoch 156, total_steps 1583776)
(epoch: 156, iters: 4080, time: 0.162, data: 0.000) loss: 0.408 
(epoch: 156, iters: 4160, time: 0.166, data: 0.013) loss: 0.181 
(epoch: 156, iters: 4240, time: 0.162, data: 0.000) loss: 0.275 
(epoch: 156, iters: 4320, time: 0.162, data: 0.000) loss: 0.136 
(epoch: 156, iters: 4400, time: 0.161, data: 0.000) loss: 0.160 
(epoch: 156, iters: 4480, time: 0.163, data: 0.000) loss: 0.229 
(epoch: 156, iters: 4560, time: 0.162, data: 0.008) loss: 0.313 
(epoch: 156, iters: 4640, time: 0.164, data: 0.008) loss: 0.377 
(epoch: 156, iters: 4720, time: 0.163, data: 0.000) loss: 0.130 
(epoch: 156, iters: 4800, time: 0.162, data: 0.010) loss: 0.418 
(epoch: 156, iters: 4880, time: 0.163, data: 0.000) loss: 0.119 
(epoch: 156, iters: 4960, time: 0.164, data: 0.008) loss: 0.116 
(epoch: 156, iters: 5040, time: 0.163, data: 0.014) loss: 0.273 
(epoch: 156, iters: 5120, time: 0.164, data: 0.000) loss: 0.332 
(epoch: 156, iters: 5200, time: 0.163, data: 0.006) loss: 0.263 
(epoch: 156, iters: 5280, time: 0.162, data: 0.000) loss: 0.340 
(epoch: 156, iters: 5360, time: 0.165, data: 0.005) loss: 0.547 
(epoch: 156, iters: 5440, time: 0.163, data: 0.005) loss: 0.275 
(epoch: 156, iters: 5520, time: 0.163, data: 0.000) loss: 0.336 
(epoch: 156, iters: 5600, time: 0.162, data: 0.000) loss: 0.346 
(epoch: 156, iters: 5680, time: 0.163, data: 0.005) loss: 0.605 
(epoch: 156, iters: 5760, time: 0.163, data: 0.000) loss: 0.159 
(epoch: 156, iters: 5840, time: 0.163, data: 0.010) loss: 0.300 
(epoch: 156, iters: 5920, time: 0.163, data: 0.008) loss: 0.183 
(epoch: 156, iters: 6000, time: 0.163, data: 0.000) loss: 0.701 
(epoch: 156, iters: 6080, time: 0.163, data: 0.005) loss: 0.738 
(epoch: 156, iters: 6160, time: 0.161, data: 0.018) loss: 0.080 
(epoch: 156, iters: 6240, time: 0.162, data: 0.000) loss: 0.247 
(epoch: 156, iters: 6320, time: 0.164, data: 0.000) loss: 0.320 
(epoch: 156, iters: 6400, time: 0.162, data: 0.005) loss: 0.132 
(epoch: 156, iters: 6480, time: 0.167, data: 0.005) loss: 0.181 
(epoch: 156, iters: 6560, time: 0.165, data: 0.016) loss: 0.169 
(epoch: 156, iters: 6640, time: 0.163, data: 0.006) loss: 0.543 
(epoch: 156, iters: 6720, time: 0.163, data: 0.008) loss: 0.177 
(epoch: 156, iters: 6800, time: 0.165, data: 0.000) loss: 0.340 
(epoch: 156, iters: 6880, time: 0.165, data: 0.006) loss: 0.158 
(epoch: 156, iters: 6960, time: 0.162, data: 0.000) loss: 0.199 
(epoch: 156, iters: 7040, time: 0.165, data: 0.005) loss: 0.049 
(epoch: 156, iters: 7120, time: 0.163, data: 0.000) loss: 0.346 
(epoch: 156, iters: 7200, time: 0.162, data: 0.008) loss: 0.649 
(epoch: 156, iters: 7280, time: 0.164, data: 0.005) loss: 0.190 
(epoch: 156, iters: 7360, time: 0.162, data: 0.000) loss: 0.775 
(epoch: 156, iters: 7440, time: 0.162, data: 0.000) loss: 0.266 
(epoch: 156, iters: 7520, time: 0.161, data: 0.000) loss: 0.086 
(epoch: 156, iters: 7600, time: 0.163, data: 0.010) loss: 0.259 
(epoch: 156, iters: 7680, time: 0.162, data: 0.000) loss: 0.228 
(epoch: 156, iters: 7760, time: 0.161, data: 0.000) loss: 0.153 
(epoch: 156, iters: 7840, time: 0.163, data: 0.005) loss: 0.801 
(epoch: 156, iters: 7920, time: 0.164, data: 0.000) loss: 0.257 
(epoch: 156, iters: 8000, time: 0.163, data: 0.005) loss: 0.266 
saving the latest model (epoch 156, total_steps 1587776)
(epoch: 156, iters: 8080, time: 0.163, data: 0.000) loss: 0.620 
(epoch: 156, iters: 8160, time: 0.162, data: 0.000) loss: 0.444 
(epoch: 156, iters: 8240, time: 0.163, data: 0.000) loss: 0.079 
(epoch: 156, iters: 8320, time: 0.164, data: 0.000) loss: 0.434 
(epoch: 156, iters: 8400, time: 0.162, data: 0.022) loss: 0.262 
(epoch: 156, iters: 8480, time: 0.163, data: 0.000) loss: 0.104 
(epoch: 156, iters: 8560, time: 0.165, data: 0.000) loss: 0.069 
(epoch: 156, iters: 8640, time: 0.163, data: 0.005) loss: 0.486 
(epoch: 156, iters: 8720, time: 0.162, data: 0.000) loss: 0.774 
(epoch: 156, iters: 8800, time: 0.163, data: 0.000) loss: 0.043 
(epoch: 156, iters: 8880, time: 0.164, data: 0.006) loss: 0.269 
(epoch: 156, iters: 8960, time: 0.162, data: 0.000) loss: 0.259 
(epoch: 156, iters: 9040, time: 0.163, data: 0.025) loss: 0.323 
(epoch: 156, iters: 9120, time: 0.163, data: 0.000) loss: 0.361 
(epoch: 156, iters: 9200, time: 0.162, data: 0.000) loss: 0.446 
(epoch: 156, iters: 9280, time: 0.162, data: 0.008) loss: 0.365 
(epoch: 156, iters: 9360, time: 0.163, data: 0.000) loss: 0.164 
(epoch: 156, iters: 9440, time: 0.162, data: 0.000) loss: 0.725 
(epoch: 156, iters: 9520, time: 0.163, data: 0.005) loss: 0.269 
(epoch: 156, iters: 9600, time: 0.164, data: 0.020) loss: 0.471 
(epoch: 156, iters: 9680, time: 0.164, data: 0.000) loss: 0.345 
(epoch: 156, iters: 9760, time: 0.164, data: 0.000) loss: 0.230 
(epoch: 156, iters: 9840, time: 0.165, data: 0.009) loss: 0.488 
(epoch: 156, iters: 9920, time: 0.163, data: 0.024) loss: 0.276 
(epoch: 156, iters: 10000, time: 0.164, data: 0.000) loss: 0.510 
(epoch: 156, iters: 10080, time: 0.163, data: 0.000) loss: 0.371 
(epoch: 156, iters: 10160, time: 0.163, data: 0.000) loss: 0.076 
saving the model at the end of epoch 156, iters 1589952
End of epoch 156 / 200 	 Time Taken: 1663 sec
learning rate = 0.0000851
saving the latest model (epoch 157, total_steps 1589968)
(epoch: 157, iters: 48, time: 0.165, data: 0.005) loss: 0.161 
(epoch: 157, iters: 128, time: 0.162, data: 0.015) loss: 0.917 
(epoch: 157, iters: 208, time: 0.163, data: 0.000) loss: 0.252 
(epoch: 157, iters: 288, time: 0.162, data: 0.010) loss: 0.167 
(epoch: 157, iters: 368, time: 0.164, data: 0.026) loss: 0.129 
(epoch: 157, iters: 448, time: 0.163, data: 0.000) loss: 0.218 
(epoch: 157, iters: 528, time: 0.165, data: 0.005) loss: 0.398 
(epoch: 157, iters: 608, time: 0.163, data: 0.023) loss: 0.112 
(epoch: 157, iters: 688, time: 0.162, data: 0.000) loss: 0.131 
(epoch: 157, iters: 768, time: 0.162, data: 0.010) loss: 0.180 
(epoch: 157, iters: 848, time: 0.164, data: 0.008) loss: 0.108 
(epoch: 157, iters: 928, time: 0.164, data: 0.011) loss: 0.164 
(epoch: 157, iters: 1008, time: 0.163, data: 0.009) loss: 0.469 
(epoch: 157, iters: 1088, time: 0.163, data: 0.005) loss: 0.421 
(epoch: 157, iters: 1168, time: 0.166, data: 0.012) loss: 0.423 
(epoch: 157, iters: 1248, time: 0.166, data: 0.000) loss: 0.097 
(epoch: 157, iters: 1328, time: 0.163, data: 0.006) loss: 0.043 
(epoch: 157, iters: 1408, time: 0.163, data: 0.000) loss: 0.120 
(epoch: 157, iters: 1488, time: 0.162, data: 0.000) loss: 0.104 
(epoch: 157, iters: 1568, time: 0.163, data: 0.000) loss: 0.426 
(epoch: 157, iters: 1648, time: 0.162, data: 0.015) loss: 0.302 
(epoch: 157, iters: 1728, time: 0.161, data: 0.000) loss: 0.088 
(epoch: 157, iters: 1808, time: 0.161, data: 0.000) loss: 0.245 
(epoch: 157, iters: 1888, time: 0.163, data: 0.000) loss: 0.415 
(epoch: 157, iters: 1968, time: 0.162, data: 0.000) loss: 0.074 
(epoch: 157, iters: 2048, time: 0.160, data: 0.000) loss: 0.602 
(epoch: 157, iters: 2128, time: 0.160, data: 0.006) loss: 0.488 
(epoch: 157, iters: 2208, time: 0.160, data: 0.000) loss: 0.309 
(epoch: 157, iters: 2288, time: 0.165, data: 0.009) loss: 0.142 
(epoch: 157, iters: 2368, time: 0.164, data: 0.000) loss: 0.133 
(epoch: 157, iters: 2448, time: 0.163, data: 0.000) loss: 0.421 
(epoch: 157, iters: 2528, time: 0.162, data: 0.000) loss: 0.379 
(epoch: 157, iters: 2608, time: 0.161, data: 0.005) loss: 0.464 
(epoch: 157, iters: 2688, time: 0.161, data: 0.011) loss: 0.223 
(epoch: 157, iters: 2768, time: 0.160, data: 0.000) loss: 0.246 
(epoch: 157, iters: 2848, time: 0.160, data: 0.000) loss: 0.283 
(epoch: 157, iters: 2928, time: 0.160, data: 0.000) loss: 0.082 
(epoch: 157, iters: 3008, time: 0.161, data: 0.000) loss: 0.031 
(epoch: 157, iters: 3088, time: 0.162, data: 0.005) loss: 0.101 
(epoch: 157, iters: 3168, time: 0.161, data: 0.000) loss: 0.304 
(epoch: 157, iters: 3248, time: 0.160, data: 0.000) loss: 0.252 
(epoch: 157, iters: 3328, time: 0.160, data: 0.011) loss: 0.218 
(epoch: 157, iters: 3408, time: 0.160, data: 0.000) loss: 0.437 
(epoch: 157, iters: 3488, time: 0.162, data: 0.028) loss: 0.489 
(epoch: 157, iters: 3568, time: 0.161, data: 0.000) loss: 0.086 
(epoch: 157, iters: 3648, time: 0.161, data: 0.008) loss: 0.135 
(epoch: 157, iters: 3728, time: 0.161, data: 0.000) loss: 0.208 
(epoch: 157, iters: 3808, time: 0.162, data: 0.024) loss: 0.239 
(epoch: 157, iters: 3888, time: 0.161, data: 0.000) loss: 0.256 
(epoch: 157, iters: 3968, time: 0.160, data: 0.018) loss: 1.022 
saving the latest model (epoch 157, total_steps 1593968)
(epoch: 157, iters: 4048, time: 0.161, data: 0.037) loss: 0.192 
(epoch: 157, iters: 4128, time: 0.160, data: 0.000) loss: 0.203 
(epoch: 157, iters: 4208, time: 0.162, data: 0.014) loss: 0.296 
(epoch: 157, iters: 4288, time: 0.162, data: 0.000) loss: 0.615 
(epoch: 157, iters: 4368, time: 0.163, data: 0.005) loss: 0.223 
(epoch: 157, iters: 4448, time: 0.163, data: 0.005) loss: 0.524 
(epoch: 157, iters: 4528, time: 0.161, data: 0.000) loss: 0.376 
(epoch: 157, iters: 4608, time: 0.163, data: 0.000) loss: 0.236 
(epoch: 157, iters: 4688, time: 0.161, data: 0.023) loss: 0.348 
(epoch: 157, iters: 4768, time: 0.161, data: 0.000) loss: 0.557 
(epoch: 157, iters: 4848, time: 0.162, data: 0.000) loss: 0.244 
(epoch: 157, iters: 4928, time: 0.162, data: 0.018) loss: 0.260 
(epoch: 157, iters: 5008, time: 0.162, data: 0.000) loss: 0.058 
(epoch: 157, iters: 5088, time: 0.162, data: 0.000) loss: 0.421 
(epoch: 157, iters: 5168, time: 0.162, data: 0.000) loss: 0.290 
(epoch: 157, iters: 5248, time: 0.162, data: 0.015) loss: 0.333 
(epoch: 157, iters: 5328, time: 0.162, data: 0.000) loss: 0.484 
(epoch: 157, iters: 5408, time: 0.161, data: 0.032) loss: 0.194 
(epoch: 157, iters: 5488, time: 0.162, data: 0.000) loss: 0.101 
(epoch: 157, iters: 5568, time: 0.161, data: 0.031) loss: 0.382 
(epoch: 157, iters: 5648, time: 0.160, data: 0.000) loss: 0.820 
(epoch: 157, iters: 5728, time: 0.162, data: 0.011) loss: 0.199 
(epoch: 157, iters: 5808, time: 0.162, data: 0.000) loss: 0.398 
(epoch: 157, iters: 5888, time: 0.164, data: 0.000) loss: 0.314 
(epoch: 157, iters: 5968, time: 0.162, data: 0.000) loss: 0.155 
(epoch: 157, iters: 6048, time: 0.162, data: 0.008) loss: 0.045 
(epoch: 157, iters: 6128, time: 0.162, data: 0.000) loss: 0.183 
(epoch: 157, iters: 6208, time: 0.163, data: 0.031) loss: 0.427 
(epoch: 157, iters: 6288, time: 0.162, data: 0.000) loss: 0.382 
(epoch: 157, iters: 6368, time: 0.161, data: 0.000) loss: 0.308 
(epoch: 157, iters: 6448, time: 0.161, data: 0.000) loss: 0.188 
(epoch: 157, iters: 6528, time: 0.161, data: 0.000) loss: 0.540 
(epoch: 157, iters: 6608, time: 0.162, data: 0.015) loss: 0.246 
(epoch: 157, iters: 6688, time: 0.163, data: 0.024) loss: 0.560 
(epoch: 157, iters: 6768, time: 0.163, data: 0.031) loss: 0.325 
(epoch: 157, iters: 6848, time: 0.164, data: 0.000) loss: 0.374 
(epoch: 157, iters: 6928, time: 0.161, data: 0.000) loss: 0.451 
(epoch: 157, iters: 7008, time: 0.162, data: 0.005) loss: 0.275 
(epoch: 157, iters: 7088, time: 0.162, data: 0.013) loss: 0.180 
(epoch: 157, iters: 7168, time: 0.161, data: 0.000) loss: 0.669 
(epoch: 157, iters: 7248, time: 0.160, data: 0.000) loss: 0.148 
(epoch: 157, iters: 7328, time: 0.163, data: 0.005) loss: 0.600 
(epoch: 157, iters: 7408, time: 0.162, data: 0.000) loss: 0.220 
(epoch: 157, iters: 7488, time: 0.161, data: 0.020) loss: 0.503 
(epoch: 157, iters: 7568, time: 0.162, data: 0.005) loss: 0.174 
(epoch: 157, iters: 7648, time: 0.161, data: 0.018) loss: 0.071 
(epoch: 157, iters: 7728, time: 0.165, data: 0.000) loss: 0.312 
(epoch: 157, iters: 7808, time: 0.164, data: 0.000) loss: 0.319 
(epoch: 157, iters: 7888, time: 0.160, data: 0.000) loss: 0.103 
(epoch: 157, iters: 7968, time: 0.163, data: 0.042) loss: 0.254 
saving the latest model (epoch 157, total_steps 1597968)
(epoch: 157, iters: 8048, time: 0.163, data: 0.000) loss: 0.256 
(epoch: 157, iters: 8128, time: 0.163, data: 0.000) loss: 0.275 
(epoch: 157, iters: 8208, time: 0.161, data: 0.000) loss: 0.057 
(epoch: 157, iters: 8288, time: 0.162, data: 0.028) loss: 0.323 
(epoch: 157, iters: 8368, time: 0.164, data: 0.009) loss: 0.152 
(epoch: 157, iters: 8448, time: 0.163, data: 0.000) loss: 0.359 
(epoch: 157, iters: 8528, time: 0.162, data: 0.000) loss: 0.236 
(epoch: 157, iters: 8608, time: 0.163, data: 0.000) loss: 0.425 
(epoch: 157, iters: 8688, time: 0.160, data: 0.016) loss: 0.750 
(epoch: 157, iters: 8768, time: 0.163, data: 0.000) loss: 0.211 
(epoch: 157, iters: 8848, time: 0.160, data: 0.014) loss: 0.361 
(epoch: 157, iters: 8928, time: 0.161, data: 0.005) loss: 0.721 
(epoch: 157, iters: 9008, time: 0.164, data: 0.011) loss: 0.900 
(epoch: 157, iters: 9088, time: 0.162, data: 0.000) loss: 0.334 
(epoch: 157, iters: 9168, time: 0.162, data: 0.025) loss: 0.439 
(epoch: 157, iters: 9248, time: 0.164, data: 0.000) loss: 0.206 
(epoch: 157, iters: 9328, time: 0.163, data: 0.024) loss: 0.310 
(epoch: 157, iters: 9408, time: 0.161, data: 0.000) loss: 0.509 
(epoch: 157, iters: 9488, time: 0.161, data: 0.000) loss: 0.107 
(epoch: 157, iters: 9568, time: 0.162, data: 0.009) loss: 0.408 
(epoch: 157, iters: 9648, time: 0.160, data: 0.006) loss: 0.751 
(epoch: 157, iters: 9728, time: 0.161, data: 0.000) loss: 0.271 
(epoch: 157, iters: 9808, time: 0.163, data: 0.000) loss: 0.113 
(epoch: 157, iters: 9888, time: 0.163, data: 0.030) loss: 0.435 
(epoch: 157, iters: 9968, time: 0.161, data: 0.000) loss: 0.547 
(epoch: 157, iters: 10048, time: 0.164, data: 0.011) loss: 0.551 
(epoch: 157, iters: 10128, time: 0.162, data: 0.014) loss: 0.222 
saving the model at the end of epoch 157, iters 1600144
End of epoch 157 / 200 	 Time Taken: 1655 sec
learning rate = 0.0000832
(epoch: 158, iters: 16, time: 0.179, data: 0.000) loss: 0.187 
saving the latest model (epoch 158, total_steps 1600160)
(epoch: 158, iters: 96, time: 0.162, data: 0.026) loss: 0.152 
(epoch: 158, iters: 176, time: 0.162, data: 0.046) loss: 0.275 
(epoch: 158, iters: 256, time: 0.162, data: 0.000) loss: 0.213 
(epoch: 158, iters: 336, time: 0.162, data: 0.000) loss: 0.136 
(epoch: 158, iters: 416, time: 0.161, data: 0.017) loss: 0.417 
(epoch: 158, iters: 496, time: 0.161, data: 0.000) loss: 0.468 
(epoch: 158, iters: 576, time: 0.161, data: 0.013) loss: 0.270 
(epoch: 158, iters: 656, time: 0.161, data: 0.000) loss: 0.487 
(epoch: 158, iters: 736, time: 0.161, data: 0.000) loss: 0.139 
(epoch: 158, iters: 816, time: 0.163, data: 0.022) loss: 0.384 
(epoch: 158, iters: 896, time: 0.162, data: 0.000) loss: 0.403 
(epoch: 158, iters: 976, time: 0.164, data: 0.000) loss: 0.134 
(epoch: 158, iters: 1056, time: 0.160, data: 0.000) loss: 0.657 
(epoch: 158, iters: 1136, time: 0.161, data: 0.000) loss: 0.476 
(epoch: 158, iters: 1216, time: 0.162, data: 0.025) loss: 0.242 
(epoch: 158, iters: 1296, time: 0.163, data: 0.000) loss: 0.121 
(epoch: 158, iters: 1376, time: 0.160, data: 0.010) loss: 0.315 
(epoch: 158, iters: 1456, time: 0.163, data: 0.020) loss: 0.088 
(epoch: 158, iters: 1536, time: 0.162, data: 0.005) loss: 0.126 
(epoch: 158, iters: 1616, time: 0.161, data: 0.000) loss: 0.119 
(epoch: 158, iters: 1696, time: 0.161, data: 0.000) loss: 0.233 
(epoch: 158, iters: 1776, time: 0.161, data: 0.008) loss: 0.447 
(epoch: 158, iters: 1856, time: 0.161, data: 0.005) loss: 0.101 
(epoch: 158, iters: 1936, time: 0.163, data: 0.000) loss: 0.190 
(epoch: 158, iters: 2016, time: 0.163, data: 0.000) loss: 0.213 
(epoch: 158, iters: 2096, time: 0.163, data: 0.000) loss: 0.320 
(epoch: 158, iters: 2176, time: 0.162, data: 0.014) loss: 0.183 
(epoch: 158, iters: 2256, time: 0.162, data: 0.000) loss: 0.329 
(epoch: 158, iters: 2336, time: 0.160, data: 0.024) loss: 0.212 
(epoch: 158, iters: 2416, time: 0.162, data: 0.000) loss: 0.198 
(epoch: 158, iters: 2496, time: 0.162, data: 0.000) loss: 0.183 
(epoch: 158, iters: 2576, time: 0.163, data: 0.000) loss: 0.200 
(epoch: 158, iters: 2656, time: 0.160, data: 0.011) loss: 0.078 
(epoch: 158, iters: 2736, time: 0.162, data: 0.000) loss: 0.577 
(epoch: 158, iters: 2816, time: 0.162, data: 0.000) loss: 0.270 
(epoch: 158, iters: 2896, time: 0.167, data: 0.005) loss: 0.278 
(epoch: 158, iters: 2976, time: 0.162, data: 0.000) loss: 0.247 
(epoch: 158, iters: 3056, time: 0.160, data: 0.000) loss: 0.108 
(epoch: 158, iters: 3136, time: 0.160, data: 0.000) loss: 0.270 
(epoch: 158, iters: 3216, time: 0.160, data: 0.009) loss: 0.175 
(epoch: 158, iters: 3296, time: 0.164, data: 0.008) loss: 0.252 
(epoch: 158, iters: 3376, time: 0.161, data: 0.006) loss: 0.171 
(epoch: 158, iters: 3456, time: 0.160, data: 0.015) loss: 0.256 
(epoch: 158, iters: 3536, time: 0.161, data: 0.000) loss: 0.216 
(epoch: 158, iters: 3616, time: 0.161, data: 0.018) loss: 0.281 
(epoch: 158, iters: 3696, time: 0.161, data: 0.029) loss: 0.322 
(epoch: 158, iters: 3776, time: 0.161, data: 0.000) loss: 0.116 
(epoch: 158, iters: 3856, time: 0.161, data: 0.000) loss: 0.290 
(epoch: 158, iters: 3936, time: 0.162, data: 0.016) loss: 0.166 
(epoch: 158, iters: 4016, time: 0.160, data: 0.000) loss: 0.319 
saving the latest model (epoch 158, total_steps 1604160)
(epoch: 158, iters: 4096, time: 0.160, data: 0.024) loss: 0.118 
(epoch: 158, iters: 4176, time: 0.160, data: 0.000) loss: 0.152 
(epoch: 158, iters: 4256, time: 0.161, data: 0.000) loss: 0.288 
(epoch: 158, iters: 4336, time: 0.162, data: 0.005) loss: 0.067 
(epoch: 158, iters: 4416, time: 0.161, data: 0.017) loss: 0.581 
(epoch: 158, iters: 4496, time: 0.163, data: 0.000) loss: 0.341 
(epoch: 158, iters: 4576, time: 0.162, data: 0.008) loss: 0.336 
(epoch: 158, iters: 4656, time: 0.163, data: 0.006) loss: 0.212 
(epoch: 158, iters: 4736, time: 0.161, data: 0.015) loss: 0.283 
(epoch: 158, iters: 4816, time: 0.161, data: 0.000) loss: 0.134 
(epoch: 158, iters: 4896, time: 0.160, data: 0.000) loss: 0.203 
(epoch: 158, iters: 4976, time: 0.161, data: 0.000) loss: 0.423 
(epoch: 158, iters: 5056, time: 0.160, data: 0.000) loss: 0.451 
(epoch: 158, iters: 5136, time: 0.159, data: 0.000) loss: 0.080 
(epoch: 158, iters: 5216, time: 0.161, data: 0.000) loss: 0.176 
(epoch: 158, iters: 5296, time: 0.160, data: 0.020) loss: 0.264 
(epoch: 158, iters: 5376, time: 0.160, data: 0.006) loss: 0.350 
(epoch: 158, iters: 5456, time: 0.161, data: 0.006) loss: 0.309 
(epoch: 158, iters: 5536, time: 0.161, data: 0.022) loss: 0.273 
(epoch: 158, iters: 5616, time: 0.165, data: 0.000) loss: 0.272 
(epoch: 158, iters: 5696, time: 0.162, data: 0.000) loss: 0.495 
(epoch: 158, iters: 5776, time: 0.161, data: 0.013) loss: 0.190 
(epoch: 158, iters: 5856, time: 0.160, data: 0.000) loss: 0.701 
(epoch: 158, iters: 5936, time: 0.161, data: 0.021) loss: 0.588 
(epoch: 158, iters: 6016, time: 0.161, data: 0.006) loss: 0.363 
(epoch: 158, iters: 6096, time: 0.161, data: 0.000) loss: 0.200 
(epoch: 158, iters: 6176, time: 0.163, data: 0.000) loss: 0.116 
(epoch: 158, iters: 6256, time: 0.162, data: 0.005) loss: 0.531 
(epoch: 158, iters: 6336, time: 0.162, data: 0.000) loss: 0.299 
(epoch: 158, iters: 6416, time: 0.163, data: 0.000) loss: 0.427 
(epoch: 158, iters: 6496, time: 0.162, data: 0.000) loss: 0.219 
(epoch: 158, iters: 6576, time: 0.163, data: 0.027) loss: 0.184 
(epoch: 158, iters: 6656, time: 0.163, data: 0.000) loss: 0.349 
(epoch: 158, iters: 6736, time: 0.162, data: 0.005) loss: 0.197 
(epoch: 158, iters: 6816, time: 0.160, data: 0.008) loss: 0.265 
(epoch: 158, iters: 6896, time: 0.161, data: 0.000) loss: 0.221 
(epoch: 158, iters: 6976, time: 0.160, data: 0.000) loss: 0.278 
(epoch: 158, iters: 7056, time: 0.162, data: 0.015) loss: 0.387 
(epoch: 158, iters: 7136, time: 0.161, data: 0.009) loss: 0.459 
(epoch: 158, iters: 7216, time: 0.161, data: 0.005) loss: 0.490 
(epoch: 158, iters: 7296, time: 0.161, data: 0.000) loss: 1.135 
(epoch: 158, iters: 7376, time: 0.162, data: 0.000) loss: 0.393 
(epoch: 158, iters: 7456, time: 0.159, data: 0.015) loss: 0.106 
(epoch: 158, iters: 7536, time: 0.160, data: 0.000) loss: 0.076 
(epoch: 158, iters: 7616, time: 0.160, data: 0.005) loss: 0.288 
(epoch: 158, iters: 7696, time: 0.162, data: 0.029) loss: 0.592 
(epoch: 158, iters: 7776, time: 0.163, data: 0.000) loss: 0.243 
(epoch: 158, iters: 7856, time: 0.161, data: 0.000) loss: 0.343 
(epoch: 158, iters: 7936, time: 0.162, data: 0.018) loss: 0.630 
(epoch: 158, iters: 8016, time: 0.162, data: 0.026) loss: 0.103 
saving the latest model (epoch 158, total_steps 1608160)
(epoch: 158, iters: 8096, time: 0.161, data: 0.000) loss: 0.174 
(epoch: 158, iters: 8176, time: 0.161, data: 0.000) loss: 0.140 
(epoch: 158, iters: 8256, time: 0.161, data: 0.000) loss: 0.396 
(epoch: 158, iters: 8336, time: 0.162, data: 0.028) loss: 0.391 
(epoch: 158, iters: 8416, time: 0.162, data: 0.000) loss: 0.187 
(epoch: 158, iters: 8496, time: 0.161, data: 0.006) loss: 0.364 
(epoch: 158, iters: 8576, time: 0.159, data: 0.013) loss: 0.307 
(epoch: 158, iters: 8656, time: 0.160, data: 0.000) loss: 0.297 
(epoch: 158, iters: 8736, time: 0.160, data: 0.014) loss: 0.223 
(epoch: 158, iters: 8816, time: 0.160, data: 0.000) loss: 0.388 
(epoch: 158, iters: 8896, time: 0.161, data: 0.000) loss: 0.172 
(epoch: 158, iters: 8976, time: 0.160, data: 0.000) loss: 0.166 
(epoch: 158, iters: 9056, time: 0.159, data: 0.000) loss: 0.198 
(epoch: 158, iters: 9136, time: 0.161, data: 0.000) loss: 0.368 
(epoch: 158, iters: 9216, time: 0.161, data: 0.009) loss: 0.162 
(epoch: 158, iters: 9296, time: 0.160, data: 0.009) loss: 0.236 
(epoch: 158, iters: 9376, time: 0.161, data: 0.006) loss: 0.423 
(epoch: 158, iters: 9456, time: 0.160, data: 0.000) loss: 0.128 
(epoch: 158, iters: 9536, time: 0.161, data: 0.013) loss: 0.498 
(epoch: 158, iters: 9616, time: 0.161, data: 0.000) loss: 0.118 
(epoch: 158, iters: 9696, time: 0.161, data: 0.017) loss: 0.166 
(epoch: 158, iters: 9776, time: 0.160, data: 0.000) loss: 0.227 
(epoch: 158, iters: 9856, time: 0.161, data: 0.000) loss: 0.086 
(epoch: 158, iters: 9936, time: 0.160, data: 0.000) loss: 0.118 
(epoch: 158, iters: 10016, time: 0.160, data: 0.005) loss: 0.212 
(epoch: 158, iters: 10096, time: 0.163, data: 0.006) loss: 0.256 
(epoch: 158, iters: 10176, time: 0.163, data: 0.008) loss: 0.304 
saving the model at the end of epoch 158, iters 1610336
End of epoch 158 / 200 	 Time Taken: 1647 sec
learning rate = 0.0000812
saving the latest model (epoch 159, total_steps 1610352)
(epoch: 159, iters: 64, time: 0.164, data: 0.003) loss: 0.525 
(epoch: 159, iters: 144, time: 0.164, data: 0.024) loss: 0.327 
(epoch: 159, iters: 224, time: 0.163, data: 0.042) loss: 0.381 
(epoch: 159, iters: 304, time: 0.163, data: 0.000) loss: 0.119 
(epoch: 159, iters: 384, time: 0.163, data: 0.000) loss: 0.098 
(epoch: 159, iters: 464, time: 0.162, data: 0.019) loss: 0.397 
(epoch: 159, iters: 544, time: 0.165, data: 0.000) loss: 0.056 
(epoch: 159, iters: 624, time: 0.163, data: 0.000) loss: 0.177 
(epoch: 159, iters: 704, time: 0.162, data: 0.000) loss: 0.098 
(epoch: 159, iters: 784, time: 0.167, data: 0.000) loss: 0.515 
(epoch: 159, iters: 864, time: 0.162, data: 0.000) loss: 0.348 
(epoch: 159, iters: 944, time: 0.163, data: 0.000) loss: 0.437 
(epoch: 159, iters: 1024, time: 0.163, data: 0.005) loss: 0.555 
(epoch: 159, iters: 1104, time: 0.163, data: 0.000) loss: 0.547 
(epoch: 159, iters: 1184, time: 0.163, data: 0.009) loss: 0.540 
(epoch: 159, iters: 1264, time: 0.162, data: 0.010) loss: 0.244 
(epoch: 159, iters: 1344, time: 0.162, data: 0.000) loss: 0.115 
(epoch: 159, iters: 1424, time: 0.161, data: 0.005) loss: 0.371 
(epoch: 159, iters: 1504, time: 0.161, data: 0.000) loss: 0.191 
(epoch: 159, iters: 1584, time: 0.161, data: 0.000) loss: 0.108 
(epoch: 159, iters: 1664, time: 0.161, data: 0.000) loss: 0.382 
(epoch: 159, iters: 1744, time: 0.160, data: 0.000) loss: 0.132 
(epoch: 159, iters: 1824, time: 0.162, data: 0.000) loss: 0.317 
(epoch: 159, iters: 1904, time: 0.159, data: 0.005) loss: 0.147 
(epoch: 159, iters: 1984, time: 0.161, data: 0.000) loss: 0.283 
(epoch: 159, iters: 2064, time: 0.160, data: 0.020) loss: 0.601 
(epoch: 159, iters: 2144, time: 0.161, data: 0.000) loss: 0.304 
(epoch: 159, iters: 2224, time: 0.162, data: 0.000) loss: 0.139 
(epoch: 159, iters: 2304, time: 0.162, data: 0.005) loss: 0.329 
(epoch: 159, iters: 2384, time: 0.162, data: 0.017) loss: 0.617 
(epoch: 159, iters: 2464, time: 0.161, data: 0.000) loss: 0.414 
(epoch: 159, iters: 2544, time: 0.162, data: 0.041) loss: 0.197 
(epoch: 159, iters: 2624, time: 0.162, data: 0.000) loss: 0.161 
(epoch: 159, iters: 2704, time: 0.162, data: 0.000) loss: 0.261 
(epoch: 159, iters: 2784, time: 0.162, data: 0.021) loss: 0.066 
(epoch: 159, iters: 2864, time: 0.162, data: 0.000) loss: 0.508 
(epoch: 159, iters: 2944, time: 0.162, data: 0.005) loss: 0.339 
(epoch: 159, iters: 3024, time: 0.163, data: 0.000) loss: 0.564 
(epoch: 159, iters: 3104, time: 0.162, data: 0.011) loss: 0.727 
(epoch: 159, iters: 3184, time: 0.162, data: 0.005) loss: 0.332 
(epoch: 159, iters: 3264, time: 0.163, data: 0.000) loss: 0.312 
(epoch: 159, iters: 3344, time: 0.164, data: 0.013) loss: 0.413 
(epoch: 159, iters: 3424, time: 0.161, data: 0.000) loss: 0.499 
(epoch: 159, iters: 3504, time: 0.161, data: 0.005) loss: 0.526 
(epoch: 159, iters: 3584, time: 0.161, data: 0.010) loss: 0.179 
(epoch: 159, iters: 3664, time: 0.161, data: 0.000) loss: 0.246 
(epoch: 159, iters: 3744, time: 0.163, data: 0.008) loss: 0.473 
(epoch: 159, iters: 3824, time: 0.162, data: 0.000) loss: 0.436 
(epoch: 159, iters: 3904, time: 0.160, data: 0.000) loss: 0.166 
(epoch: 159, iters: 3984, time: 0.161, data: 0.016) loss: 0.539 
saving the latest model (epoch 159, total_steps 1614352)
(epoch: 159, iters: 4064, time: 0.162, data: 0.005) loss: 0.091 
(epoch: 159, iters: 4144, time: 0.163, data: 0.005) loss: 0.127 
(epoch: 159, iters: 4224, time: 0.161, data: 0.000) loss: 0.475 
(epoch: 159, iters: 4304, time: 0.163, data: 0.000) loss: 0.518 
(epoch: 159, iters: 4384, time: 0.161, data: 0.000) loss: 0.258 
(epoch: 159, iters: 4464, time: 0.163, data: 0.000) loss: 0.295 
(epoch: 159, iters: 4544, time: 0.162, data: 0.000) loss: 0.078 
(epoch: 159, iters: 4624, time: 0.160, data: 0.000) loss: 0.122 
(epoch: 159, iters: 4704, time: 0.160, data: 0.000) loss: 0.619 
(epoch: 159, iters: 4784, time: 0.161, data: 0.008) loss: 0.251 
(epoch: 159, iters: 4864, time: 0.163, data: 0.000) loss: 0.752 
(epoch: 159, iters: 4944, time: 0.161, data: 0.015) loss: 0.335 
(epoch: 159, iters: 5024, time: 0.160, data: 0.000) loss: 0.175 
(epoch: 159, iters: 5104, time: 0.162, data: 0.006) loss: 0.327 
(epoch: 159, iters: 5184, time: 0.163, data: 0.005) loss: 0.388 
(epoch: 159, iters: 5264, time: 0.162, data: 0.000) loss: 0.137 
(epoch: 159, iters: 5344, time: 0.160, data: 0.005) loss: 0.175 
(epoch: 159, iters: 5424, time: 0.164, data: 0.000) loss: 0.383 
(epoch: 159, iters: 5504, time: 0.161, data: 0.008) loss: 0.268 
(epoch: 159, iters: 5584, time: 0.163, data: 0.000) loss: 0.487 
(epoch: 159, iters: 5664, time: 0.160, data: 0.023) loss: 0.276 
(epoch: 159, iters: 5744, time: 0.162, data: 0.000) loss: 0.365 
(epoch: 159, iters: 5824, time: 0.163, data: 0.013) loss: 0.219 
(epoch: 159, iters: 5904, time: 0.160, data: 0.000) loss: 0.376 
(epoch: 159, iters: 5984, time: 0.160, data: 0.000) loss: 0.279 
(epoch: 159, iters: 6064, time: 0.160, data: 0.000) loss: 0.560 
(epoch: 159, iters: 6144, time: 0.162, data: 0.000) loss: 0.282 
(epoch: 159, iters: 6224, time: 0.161, data: 0.000) loss: 0.677 
(epoch: 159, iters: 6304, time: 0.163, data: 0.000) loss: 0.472 
(epoch: 159, iters: 6384, time: 0.163, data: 0.000) loss: 0.265 
(epoch: 159, iters: 6464, time: 0.164, data: 0.025) loss: 0.242 
(epoch: 159, iters: 6544, time: 0.162, data: 0.014) loss: 0.307 
(epoch: 159, iters: 6624, time: 0.164, data: 0.000) loss: 0.237 
(epoch: 159, iters: 6704, time: 0.163, data: 0.000) loss: 0.218 
(epoch: 159, iters: 6784, time: 0.165, data: 0.011) loss: 0.311 
(epoch: 159, iters: 6864, time: 0.162, data: 0.009) loss: 0.246 
(epoch: 159, iters: 6944, time: 0.163, data: 0.000) loss: 0.154 
(epoch: 159, iters: 7024, time: 0.160, data: 0.005) loss: 0.257 
(epoch: 159, iters: 7104, time: 0.163, data: 0.016) loss: 0.234 
(epoch: 159, iters: 7184, time: 0.161, data: 0.005) loss: 0.213 
(epoch: 159, iters: 7264, time: 0.166, data: 0.000) loss: 0.194 
(epoch: 159, iters: 7344, time: 0.161, data: 0.024) loss: 0.169 
(epoch: 159, iters: 7424, time: 0.161, data: 0.000) loss: 0.199 
(epoch: 159, iters: 7504, time: 0.161, data: 0.000) loss: 0.399 
(epoch: 159, iters: 7584, time: 0.163, data: 0.005) loss: 0.391 
(epoch: 159, iters: 7664, time: 0.161, data: 0.000) loss: 0.228 
(epoch: 159, iters: 7744, time: 0.162, data: 0.000) loss: 0.405 
(epoch: 159, iters: 7824, time: 0.161, data: 0.009) loss: 0.173 
(epoch: 159, iters: 7904, time: 0.164, data: 0.000) loss: 0.310 
(epoch: 159, iters: 7984, time: 0.162, data: 0.011) loss: 0.052 
saving the latest model (epoch 159, total_steps 1618352)
(epoch: 159, iters: 8064, time: 0.161, data: 0.014) loss: 0.324 
(epoch: 159, iters: 8144, time: 0.163, data: 0.014) loss: 0.132 
(epoch: 159, iters: 8224, time: 0.162, data: 0.009) loss: 0.029 
(epoch: 159, iters: 8304, time: 0.162, data: 0.000) loss: 0.053 
(epoch: 159, iters: 8384, time: 0.162, data: 0.009) loss: 0.195 
(epoch: 159, iters: 8464, time: 0.162, data: 0.005) loss: 0.189 
(epoch: 159, iters: 8544, time: 0.163, data: 0.000) loss: 0.147 
(epoch: 159, iters: 8624, time: 0.164, data: 0.000) loss: 0.923 
(epoch: 159, iters: 8704, time: 0.163, data: 0.000) loss: 0.177 
(epoch: 159, iters: 8784, time: 0.163, data: 0.022) loss: 0.329 
(epoch: 159, iters: 8864, time: 0.164, data: 0.000) loss: 0.164 
(epoch: 159, iters: 8944, time: 0.162, data: 0.000) loss: 0.748 
(epoch: 159, iters: 9024, time: 0.162, data: 0.000) loss: 0.088 
(epoch: 159, iters: 9104, time: 0.164, data: 0.025) loss: 0.103 
(epoch: 159, iters: 9184, time: 0.163, data: 0.000) loss: 0.163 
(epoch: 159, iters: 9264, time: 0.161, data: 0.000) loss: 0.215 
(epoch: 159, iters: 9344, time: 0.166, data: 0.005) loss: 0.222 
(epoch: 159, iters: 9424, time: 0.165, data: 0.024) loss: 0.225 
(epoch: 159, iters: 9504, time: 0.164, data: 0.000) loss: 0.052 
(epoch: 159, iters: 9584, time: 0.162, data: 0.013) loss: 0.100 
(epoch: 159, iters: 9664, time: 0.163, data: 0.015) loss: 0.387 
(epoch: 159, iters: 9744, time: 0.163, data: 0.000) loss: 0.141 
(epoch: 159, iters: 9824, time: 0.161, data: 0.006) loss: 0.251 
(epoch: 159, iters: 9904, time: 0.164, data: 0.000) loss: 0.353 
(epoch: 159, iters: 9984, time: 0.160, data: 0.019) loss: 0.355 
(epoch: 159, iters: 10064, time: 0.161, data: 0.000) loss: 0.631 
(epoch: 159, iters: 10144, time: 0.166, data: 0.008) loss: 0.330 
saving the model at the end of epoch 159, iters 1620528
End of epoch 159 / 200 	 Time Taken: 1656 sec
learning rate = 0.0000792
saving the latest model (epoch 160, total_steps 1620544)
(epoch: 160, iters: 32, time: 0.164, data: 0.007) loss: 0.136 
(epoch: 160, iters: 112, time: 0.160, data: 0.000) loss: 0.263 
(epoch: 160, iters: 192, time: 0.157, data: 0.000) loss: 0.261 
(epoch: 160, iters: 272, time: 0.160, data: 0.006) loss: 0.245 
(epoch: 160, iters: 352, time: 0.159, data: 0.005) loss: 0.174 
(epoch: 160, iters: 432, time: 0.160, data: 0.005) loss: 0.499 
(epoch: 160, iters: 512, time: 0.160, data: 0.005) loss: 0.218 
(epoch: 160, iters: 592, time: 0.161, data: 0.000) loss: 0.291 
(epoch: 160, iters: 672, time: 0.159, data: 0.006) loss: 0.176 
(epoch: 160, iters: 752, time: 0.161, data: 0.008) loss: 0.158 
(epoch: 160, iters: 832, time: 0.163, data: 0.000) loss: 0.343 
(epoch: 160, iters: 912, time: 0.161, data: 0.005) loss: 0.239 
(epoch: 160, iters: 992, time: 0.159, data: 0.000) loss: 0.628 
(epoch: 160, iters: 1072, time: 0.160, data: 0.013) loss: 0.136 
(epoch: 160, iters: 1152, time: 0.160, data: 0.008) loss: 0.171 
(epoch: 160, iters: 1232, time: 0.160, data: 0.000) loss: 0.171 
(epoch: 160, iters: 1312, time: 0.158, data: 0.005) loss: 0.133 
(epoch: 160, iters: 1392, time: 0.159, data: 0.011) loss: 0.578 
(epoch: 160, iters: 1472, time: 0.160, data: 0.000) loss: 0.325 
(epoch: 160, iters: 1552, time: 0.160, data: 0.005) loss: 0.554 
(epoch: 160, iters: 1632, time: 0.160, data: 0.000) loss: 0.030 
(epoch: 160, iters: 1712, time: 0.159, data: 0.023) loss: 0.423 
(epoch: 160, iters: 1792, time: 0.161, data: 0.000) loss: 0.374 
(epoch: 160, iters: 1872, time: 0.160, data: 0.000) loss: 0.528 
(epoch: 160, iters: 1952, time: 0.161, data: 0.000) loss: 0.071 
(epoch: 160, iters: 2032, time: 0.160, data: 0.024) loss: 0.640 
(epoch: 160, iters: 2112, time: 0.160, data: 0.000) loss: 0.262 
(epoch: 160, iters: 2192, time: 0.160, data: 0.000) loss: 0.373 
(epoch: 160, iters: 2272, time: 0.161, data: 0.000) loss: 0.404 
(epoch: 160, iters: 2352, time: 0.160, data: 0.000) loss: 0.182 
(epoch: 160, iters: 2432, time: 0.162, data: 0.019) loss: 0.475 
(epoch: 160, iters: 2512, time: 0.160, data: 0.000) loss: 0.495 
(epoch: 160, iters: 2592, time: 0.161, data: 0.000) loss: 0.250 
(epoch: 160, iters: 2672, time: 0.158, data: 0.008) loss: 0.052 
(epoch: 160, iters: 2752, time: 0.159, data: 0.000) loss: 0.372 
(epoch: 160, iters: 2832, time: 0.161, data: 0.005) loss: 0.284 
(epoch: 160, iters: 2912, time: 0.162, data: 0.000) loss: 0.278 
(epoch: 160, iters: 2992, time: 0.159, data: 0.006) loss: 0.058 
(epoch: 160, iters: 3072, time: 0.161, data: 0.005) loss: 0.239 
(epoch: 160, iters: 3152, time: 0.159, data: 0.000) loss: 0.470 
(epoch: 160, iters: 3232, time: 0.159, data: 0.029) loss: 0.140 
(epoch: 160, iters: 3312, time: 0.162, data: 0.000) loss: 0.548 
(epoch: 160, iters: 3392, time: 0.159, data: 0.000) loss: 0.226 
(epoch: 160, iters: 3472, time: 0.160, data: 0.000) loss: 0.310 
(epoch: 160, iters: 3552, time: 0.159, data: 0.000) loss: 0.164 
(epoch: 160, iters: 3632, time: 0.158, data: 0.000) loss: 0.123 
(epoch: 160, iters: 3712, time: 0.160, data: 0.005) loss: 0.626 
(epoch: 160, iters: 3792, time: 0.161, data: 0.000) loss: 0.382 
(epoch: 160, iters: 3872, time: 0.159, data: 0.005) loss: 0.363 
(epoch: 160, iters: 3952, time: 0.159, data: 0.000) loss: 0.455 
saving the latest model (epoch 160, total_steps 1624544)
(epoch: 160, iters: 4032, time: 0.159, data: 0.005) loss: 0.373 
(epoch: 160, iters: 4112, time: 0.159, data: 0.006) loss: 0.167 
(epoch: 160, iters: 4192, time: 0.160, data: 0.005) loss: 0.417 
(epoch: 160, iters: 4272, time: 0.158, data: 0.008) loss: 0.236 
(epoch: 160, iters: 4352, time: 0.159, data: 0.014) loss: 0.186 
(epoch: 160, iters: 4432, time: 0.162, data: 0.006) loss: 0.107 
(epoch: 160, iters: 4512, time: 0.164, data: 0.000) loss: 0.126 
(epoch: 160, iters: 4592, time: 0.160, data: 0.000) loss: 0.180 
(epoch: 160, iters: 4672, time: 0.160, data: 0.000) loss: 0.144 
(epoch: 160, iters: 4752, time: 0.159, data: 0.006) loss: 0.311 
(epoch: 160, iters: 4832, time: 0.160, data: 0.000) loss: 0.290 
(epoch: 160, iters: 4912, time: 0.161, data: 0.000) loss: 0.244 
(epoch: 160, iters: 4992, time: 0.159, data: 0.005) loss: 0.070 
(epoch: 160, iters: 5072, time: 0.162, data: 0.000) loss: 0.138 
(epoch: 160, iters: 5152, time: 0.160, data: 0.006) loss: 0.507 
(epoch: 160, iters: 5232, time: 0.161, data: 0.000) loss: 0.186 
(epoch: 160, iters: 5312, time: 0.159, data: 0.000) loss: 0.740 
(epoch: 160, iters: 5392, time: 0.159, data: 0.000) loss: 0.068 
(epoch: 160, iters: 5472, time: 0.158, data: 0.020) loss: 0.264 
(epoch: 160, iters: 5552, time: 0.158, data: 0.005) loss: 0.196 
(epoch: 160, iters: 5632, time: 0.160, data: 0.000) loss: 0.255 
(epoch: 160, iters: 5712, time: 0.160, data: 0.000) loss: 0.272 
(epoch: 160, iters: 5792, time: 0.160, data: 0.018) loss: 0.312 
(epoch: 160, iters: 5872, time: 0.159, data: 0.016) loss: 0.136 
(epoch: 160, iters: 5952, time: 0.161, data: 0.005) loss: 0.328 
(epoch: 160, iters: 6032, time: 0.162, data: 0.005) loss: 0.320 
(epoch: 160, iters: 6112, time: 0.160, data: 0.000) loss: 0.414 
(epoch: 160, iters: 6192, time: 0.159, data: 0.014) loss: 0.195 
(epoch: 160, iters: 6272, time: 0.159, data: 0.005) loss: 0.464 
(epoch: 160, iters: 6352, time: 0.159, data: 0.005) loss: 0.233 
(epoch: 160, iters: 6432, time: 0.159, data: 0.000) loss: 0.176 
(epoch: 160, iters: 6512, time: 0.160, data: 0.000) loss: 0.712 
(epoch: 160, iters: 6592, time: 0.161, data: 0.000) loss: 0.324 
(epoch: 160, iters: 6672, time: 0.163, data: 0.005) loss: 0.101 
(epoch: 160, iters: 6752, time: 0.160, data: 0.000) loss: 0.480 
(epoch: 160, iters: 6832, time: 0.160, data: 0.000) loss: 0.360 
(epoch: 160, iters: 6912, time: 0.158, data: 0.000) loss: 0.104 
(epoch: 160, iters: 6992, time: 0.161, data: 0.000) loss: 0.117 
(epoch: 160, iters: 7072, time: 0.161, data: 0.018) loss: 0.369 
(epoch: 160, iters: 7152, time: 0.160, data: 0.010) loss: 0.288 
(epoch: 160, iters: 7232, time: 0.159, data: 0.000) loss: 0.336 
(epoch: 160, iters: 7312, time: 0.161, data: 0.000) loss: 0.278 
(epoch: 160, iters: 7392, time: 0.159, data: 0.020) loss: 0.237 
(epoch: 160, iters: 7472, time: 0.160, data: 0.006) loss: 0.325 
(epoch: 160, iters: 7552, time: 0.160, data: 0.018) loss: 0.190 
(epoch: 160, iters: 7632, time: 0.158, data: 0.000) loss: 0.119 
(epoch: 160, iters: 7712, time: 0.158, data: 0.000) loss: 0.104 
(epoch: 160, iters: 7792, time: 0.160, data: 0.006) loss: 0.079 
(epoch: 160, iters: 7872, time: 0.159, data: 0.000) loss: 0.204 
(epoch: 160, iters: 7952, time: 0.159, data: 0.032) loss: 0.166 
saving the latest model (epoch 160, total_steps 1628544)
(epoch: 160, iters: 8032, time: 0.158, data: 0.000) loss: 0.126 
(epoch: 160, iters: 8112, time: 0.159, data: 0.012) loss: 1.103 
(epoch: 160, iters: 8192, time: 0.160, data: 0.000) loss: 0.219 
(epoch: 160, iters: 8272, time: 0.160, data: 0.000) loss: 0.097 
(epoch: 160, iters: 8352, time: 0.161, data: 0.000) loss: 0.304 
(epoch: 160, iters: 8432, time: 0.158, data: 0.023) loss: 0.161 
(epoch: 160, iters: 8512, time: 0.157, data: 0.000) loss: 0.193 
(epoch: 160, iters: 8592, time: 0.160, data: 0.012) loss: 0.100 
(epoch: 160, iters: 8672, time: 0.160, data: 0.009) loss: 0.114 
(epoch: 160, iters: 8752, time: 0.161, data: 0.000) loss: 0.089 
(epoch: 160, iters: 8832, time: 0.159, data: 0.009) loss: 0.408 
(epoch: 160, iters: 8912, time: 0.160, data: 0.000) loss: 0.411 
(epoch: 160, iters: 8992, time: 0.158, data: 0.000) loss: 0.384 
(epoch: 160, iters: 9072, time: 0.158, data: 0.000) loss: 0.091 
(epoch: 160, iters: 9152, time: 0.157, data: 0.030) loss: 0.082 
(epoch: 160, iters: 9232, time: 0.160, data: 0.000) loss: 0.296 
(epoch: 160, iters: 9312, time: 0.160, data: 0.000) loss: 0.361 
(epoch: 160, iters: 9392, time: 0.160, data: 0.000) loss: 0.298 
(epoch: 160, iters: 9472, time: 0.158, data: 0.005) loss: 0.127 
(epoch: 160, iters: 9552, time: 0.161, data: 0.006) loss: 0.525 
(epoch: 160, iters: 9632, time: 0.159, data: 0.000) loss: 0.293 
(epoch: 160, iters: 9712, time: 0.161, data: 0.000) loss: 0.867 
(epoch: 160, iters: 9792, time: 0.161, data: 0.024) loss: 0.343 
(epoch: 160, iters: 9872, time: 0.160, data: 0.000) loss: 0.196 
(epoch: 160, iters: 9952, time: 0.160, data: 0.005) loss: 0.288 
(epoch: 160, iters: 10032, time: 0.159, data: 0.008) loss: 0.489 
(epoch: 160, iters: 10112, time: 0.158, data: 0.000) loss: 0.435 
(epoch: 160, iters: 10192, time: 0.096, data: 0.016) loss: 0.450 
saving the model at the end of epoch 160, iters 1630720
End of epoch 160 / 200 	 Time Taken: 1631 sec
learning rate = 0.0000772
saving the latest model (epoch 161, total_steps 1630736)
(epoch: 161, iters: 80, time: 0.162, data: 0.165) loss: 0.456 
(epoch: 161, iters: 160, time: 0.164, data: 0.000) loss: 0.277 
(epoch: 161, iters: 240, time: 0.167, data: 0.006) loss: 0.113 
(epoch: 161, iters: 320, time: 0.163, data: 0.000) loss: 0.090 
(epoch: 161, iters: 400, time: 0.165, data: 0.029) loss: 0.221 
(epoch: 161, iters: 480, time: 0.164, data: 0.018) loss: 0.188 
(epoch: 161, iters: 560, time: 0.165, data: 0.000) loss: 0.671 
(epoch: 161, iters: 640, time: 0.162, data: 0.008) loss: 0.058 
(epoch: 161, iters: 720, time: 0.164, data: 0.000) loss: 0.197 
(epoch: 161, iters: 800, time: 0.165, data: 0.000) loss: 0.114 
(epoch: 161, iters: 880, time: 0.163, data: 0.000) loss: 0.158 
(epoch: 161, iters: 960, time: 0.164, data: 0.000) loss: 0.157 
(epoch: 161, iters: 1040, time: 0.162, data: 0.017) loss: 0.441 
(epoch: 161, iters: 1120, time: 0.162, data: 0.000) loss: 0.121 
(epoch: 161, iters: 1200, time: 0.164, data: 0.010) loss: 0.328 
(epoch: 161, iters: 1280, time: 0.164, data: 0.000) loss: 0.298 
(epoch: 161, iters: 1360, time: 0.167, data: 0.006) loss: 0.126 
(epoch: 161, iters: 1440, time: 0.163, data: 0.000) loss: 0.715 
(epoch: 161, iters: 1520, time: 0.164, data: 0.006) loss: 0.250 
(epoch: 161, iters: 1600, time: 0.162, data: 0.000) loss: 0.247 
(epoch: 161, iters: 1680, time: 0.164, data: 0.014) loss: 0.241 
(epoch: 161, iters: 1760, time: 0.161, data: 0.032) loss: 0.285 
(epoch: 161, iters: 1840, time: 0.164, data: 0.000) loss: 0.181 
(epoch: 161, iters: 1920, time: 0.163, data: 0.000) loss: 0.362 
(epoch: 161, iters: 2000, time: 0.163, data: 0.012) loss: 0.105 
(epoch: 161, iters: 2080, time: 0.166, data: 0.000) loss: 0.188 
(epoch: 161, iters: 2160, time: 0.160, data: 0.000) loss: 0.286 
(epoch: 161, iters: 2240, time: 0.164, data: 0.018) loss: 0.533 
(epoch: 161, iters: 2320, time: 0.162, data: 0.000) loss: 0.133 
(epoch: 161, iters: 2400, time: 0.163, data: 0.016) loss: 0.230 
(epoch: 161, iters: 2480, time: 0.161, data: 0.000) loss: 0.509 
(epoch: 161, iters: 2560, time: 0.165, data: 0.013) loss: 0.099 
(epoch: 161, iters: 2640, time: 0.162, data: 0.005) loss: 0.134 
(epoch: 161, iters: 2720, time: 0.164, data: 0.000) loss: 0.423 
(epoch: 161, iters: 2800, time: 0.161, data: 0.000) loss: 0.110 
(epoch: 161, iters: 2880, time: 0.162, data: 0.005) loss: 0.376 
(epoch: 161, iters: 2960, time: 0.163, data: 0.000) loss: 0.176 
(epoch: 161, iters: 3040, time: 0.164, data: 0.011) loss: 0.246 
(epoch: 161, iters: 3120, time: 0.164, data: 0.000) loss: 0.387 
(epoch: 161, iters: 3200, time: 0.164, data: 0.000) loss: 0.382 
(epoch: 161, iters: 3280, time: 0.164, data: 0.009) loss: 0.412 
(epoch: 161, iters: 3360, time: 0.163, data: 0.009) loss: 0.163 
(epoch: 161, iters: 3440, time: 0.164, data: 0.000) loss: 0.030 
(epoch: 161, iters: 3520, time: 0.162, data: 0.000) loss: 0.150 
(epoch: 161, iters: 3600, time: 0.161, data: 0.000) loss: 0.113 
(epoch: 161, iters: 3680, time: 0.162, data: 0.005) loss: 0.301 
(epoch: 161, iters: 3760, time: 0.164, data: 0.005) loss: 0.089 
(epoch: 161, iters: 3840, time: 0.162, data: 0.000) loss: 0.083 
(epoch: 161, iters: 3920, time: 0.161, data: 0.000) loss: 0.240 
(epoch: 161, iters: 4000, time: 0.161, data: 0.005) loss: 0.137 
saving the latest model (epoch 161, total_steps 1634736)
(epoch: 161, iters: 4080, time: 0.161, data: 0.006) loss: 0.324 
(epoch: 161, iters: 4160, time: 0.162, data: 0.000) loss: 0.477 
(epoch: 161, iters: 4240, time: 0.163, data: 0.000) loss: 0.286 
(epoch: 161, iters: 4320, time: 0.162, data: 0.008) loss: 0.520 
(epoch: 161, iters: 4400, time: 0.164, data: 0.009) loss: 0.325 
(epoch: 161, iters: 4480, time: 0.162, data: 0.000) loss: 0.315 
(epoch: 161, iters: 4560, time: 0.163, data: 0.006) loss: 0.115 
(epoch: 161, iters: 4640, time: 0.163, data: 0.033) loss: 0.261 
(epoch: 161, iters: 4720, time: 0.162, data: 0.000) loss: 0.156 
(epoch: 161, iters: 4800, time: 0.164, data: 0.030) loss: 0.180 
(epoch: 161, iters: 4880, time: 0.164, data: 0.000) loss: 0.435 
(epoch: 161, iters: 4960, time: 0.163, data: 0.000) loss: 0.288 
(epoch: 161, iters: 5040, time: 0.164, data: 0.022) loss: 0.311 
(epoch: 161, iters: 5120, time: 0.165, data: 0.000) loss: 0.219 
(epoch: 161, iters: 5200, time: 0.163, data: 0.013) loss: 0.127 
(epoch: 161, iters: 5280, time: 0.162, data: 0.005) loss: 0.300 
(epoch: 161, iters: 5360, time: 0.163, data: 0.000) loss: 0.073 
(epoch: 161, iters: 5440, time: 0.162, data: 0.011) loss: 0.138 
(epoch: 161, iters: 5520, time: 0.161, data: 0.000) loss: 0.337 
(epoch: 161, iters: 5600, time: 0.164, data: 0.000) loss: 0.580 
(epoch: 161, iters: 5680, time: 0.163, data: 0.000) loss: 0.340 
(epoch: 161, iters: 5760, time: 0.163, data: 0.005) loss: 0.120 
(epoch: 161, iters: 5840, time: 0.162, data: 0.000) loss: 0.703 
(epoch: 161, iters: 5920, time: 0.163, data: 0.014) loss: 0.306 
(epoch: 161, iters: 6000, time: 0.165, data: 0.000) loss: 0.412 
(epoch: 161, iters: 6080, time: 0.166, data: 0.008) loss: 0.228 
(epoch: 161, iters: 6160, time: 0.162, data: 0.005) loss: 0.255 
(epoch: 161, iters: 6240, time: 0.163, data: 0.019) loss: 0.292 
(epoch: 161, iters: 6320, time: 0.163, data: 0.022) loss: 0.044 
(epoch: 161, iters: 6400, time: 0.163, data: 0.000) loss: 0.235 
(epoch: 161, iters: 6480, time: 0.165, data: 0.000) loss: 0.443 
(epoch: 161, iters: 6560, time: 0.163, data: 0.013) loss: 0.384 
(epoch: 161, iters: 6640, time: 0.164, data: 0.000) loss: 0.303 
(epoch: 161, iters: 6720, time: 0.162, data: 0.000) loss: 0.294 
(epoch: 161, iters: 6800, time: 0.162, data: 0.015) loss: 0.280 
(epoch: 161, iters: 6880, time: 0.161, data: 0.005) loss: 0.329 
(epoch: 161, iters: 6960, time: 0.163, data: 0.005) loss: 0.200 
(epoch: 161, iters: 7040, time: 0.163, data: 0.000) loss: 0.248 
(epoch: 161, iters: 7120, time: 0.164, data: 0.000) loss: 0.321 
(epoch: 161, iters: 7200, time: 0.165, data: 0.009) loss: 0.246 
(epoch: 161, iters: 7280, time: 0.162, data: 0.000) loss: 0.398 
(epoch: 161, iters: 7360, time: 0.164, data: 0.028) loss: 0.249 
(epoch: 161, iters: 7440, time: 0.161, data: 0.000) loss: 0.181 
(epoch: 161, iters: 7520, time: 0.164, data: 0.000) loss: 0.228 
(epoch: 161, iters: 7600, time: 0.162, data: 0.000) loss: 0.287 
(epoch: 161, iters: 7680, time: 0.161, data: 0.015) loss: 0.152 
(epoch: 161, iters: 7760, time: 0.163, data: 0.000) loss: 0.186 
(epoch: 161, iters: 7840, time: 0.163, data: 0.025) loss: 0.307 
(epoch: 161, iters: 7920, time: 0.164, data: 0.000) loss: 0.168 
(epoch: 161, iters: 8000, time: 0.163, data: 0.000) loss: 0.190 
saving the latest model (epoch 161, total_steps 1638736)
(epoch: 161, iters: 8080, time: 0.164, data: 0.000) loss: 0.174 
(epoch: 161, iters: 8160, time: 0.162, data: 0.005) loss: 0.382 
(epoch: 161, iters: 8240, time: 0.163, data: 0.032) loss: 0.215 
(epoch: 161, iters: 8320, time: 0.163, data: 0.000) loss: 0.185 
(epoch: 161, iters: 8400, time: 0.162, data: 0.000) loss: 0.542 
(epoch: 161, iters: 8480, time: 0.164, data: 0.008) loss: 0.301 
(epoch: 161, iters: 8560, time: 0.164, data: 0.000) loss: 0.071 
(epoch: 161, iters: 8640, time: 0.164, data: 0.000) loss: 0.537 
(epoch: 161, iters: 8720, time: 0.163, data: 0.000) loss: 0.371 
(epoch: 161, iters: 8800, time: 0.169, data: 0.016) loss: 0.350 
(epoch: 161, iters: 8880, time: 0.162, data: 0.008) loss: 0.217 
(epoch: 161, iters: 8960, time: 0.163, data: 0.000) loss: 0.299 
(epoch: 161, iters: 9040, time: 0.159, data: 0.000) loss: 0.393 
(epoch: 161, iters: 9120, time: 0.162, data: 0.005) loss: 0.374 
(epoch: 161, iters: 9200, time: 0.161, data: 0.000) loss: 0.162 
(epoch: 161, iters: 9280, time: 0.163, data: 0.010) loss: 0.181 
(epoch: 161, iters: 9360, time: 0.160, data: 0.018) loss: 0.248 
(epoch: 161, iters: 9440, time: 0.162, data: 0.009) loss: 0.650 
(epoch: 161, iters: 9520, time: 0.159, data: 0.033) loss: 0.378 
(epoch: 161, iters: 9600, time: 0.162, data: 0.000) loss: 0.530 
(epoch: 161, iters: 9680, time: 0.161, data: 0.005) loss: 0.131 
(epoch: 161, iters: 9760, time: 0.161, data: 0.008) loss: 0.398 
(epoch: 161, iters: 9840, time: 0.162, data: 0.000) loss: 0.194 
(epoch: 161, iters: 9920, time: 0.162, data: 0.000) loss: 0.165 
(epoch: 161, iters: 10000, time: 0.160, data: 0.000) loss: 0.064 
(epoch: 161, iters: 10080, time: 0.162, data: 0.000) loss: 0.325 
(epoch: 161, iters: 10160, time: 0.162, data: 0.009) loss: 0.225 
saving the model at the end of epoch 161, iters 1640912
End of epoch 161 / 200 	 Time Taken: 1662 sec
learning rate = 0.0000752
saving the latest model (epoch 162, total_steps 1640928)
(epoch: 162, iters: 48, time: 0.163, data: 0.000) loss: 0.146 
(epoch: 162, iters: 128, time: 0.159, data: 0.011) loss: 0.648 
(epoch: 162, iters: 208, time: 0.158, data: 0.000) loss: 0.242 
(epoch: 162, iters: 288, time: 0.161, data: 0.006) loss: 0.425 
(epoch: 162, iters: 368, time: 0.161, data: 0.000) loss: 0.365 
(epoch: 162, iters: 448, time: 0.158, data: 0.000) loss: 0.172 
(epoch: 162, iters: 528, time: 0.158, data: 0.009) loss: 0.442 
(epoch: 162, iters: 608, time: 0.159, data: 0.000) loss: 0.124 
(epoch: 162, iters: 688, time: 0.159, data: 0.016) loss: 0.409 
(epoch: 162, iters: 768, time: 0.157, data: 0.000) loss: 0.265 
(epoch: 162, iters: 848, time: 0.158, data: 0.024) loss: 0.155 
(epoch: 162, iters: 928, time: 0.160, data: 0.000) loss: 0.336 
(epoch: 162, iters: 1008, time: 0.159, data: 0.000) loss: 0.099 
(epoch: 162, iters: 1088, time: 0.160, data: 0.005) loss: 0.074 
(epoch: 162, iters: 1168, time: 0.162, data: 0.000) loss: 0.195 
(epoch: 162, iters: 1248, time: 0.158, data: 0.005) loss: 0.073 
(epoch: 162, iters: 1328, time: 0.159, data: 0.006) loss: 0.107 
(epoch: 162, iters: 1408, time: 0.160, data: 0.000) loss: 0.094 
(epoch: 162, iters: 1488, time: 0.159, data: 0.012) loss: 0.243 
(epoch: 162, iters: 1568, time: 0.159, data: 0.000) loss: 0.300 
(epoch: 162, iters: 1648, time: 0.160, data: 0.011) loss: 0.297 
(epoch: 162, iters: 1728, time: 0.160, data: 0.005) loss: 0.113 
(epoch: 162, iters: 1808, time: 0.160, data: 0.000) loss: 0.379 
(epoch: 162, iters: 1888, time: 0.160, data: 0.015) loss: 0.732 
(epoch: 162, iters: 1968, time: 0.159, data: 0.000) loss: 0.381 
(epoch: 162, iters: 2048, time: 0.160, data: 0.000) loss: 0.131 
(epoch: 162, iters: 2128, time: 0.159, data: 0.020) loss: 0.439 
(epoch: 162, iters: 2208, time: 0.160, data: 0.021) loss: 0.351 
(epoch: 162, iters: 2288, time: 0.158, data: 0.000) loss: 0.238 
(epoch: 162, iters: 2368, time: 0.160, data: 0.013) loss: 0.182 
(epoch: 162, iters: 2448, time: 0.159, data: 0.014) loss: 0.452 
(epoch: 162, iters: 2528, time: 0.160, data: 0.000) loss: 0.129 
(epoch: 162, iters: 2608, time: 0.160, data: 0.000) loss: 0.736 
(epoch: 162, iters: 2688, time: 0.160, data: 0.018) loss: 0.141 
(epoch: 162, iters: 2768, time: 0.160, data: 0.000) loss: 0.252 
(epoch: 162, iters: 2848, time: 0.160, data: 0.031) loss: 0.232 
(epoch: 162, iters: 2928, time: 0.160, data: 0.000) loss: 0.364 
(epoch: 162, iters: 3008, time: 0.159, data: 0.000) loss: 0.651 
(epoch: 162, iters: 3088, time: 0.163, data: 0.006) loss: 0.058 
(epoch: 162, iters: 3168, time: 0.160, data: 0.000) loss: 0.082 
(epoch: 162, iters: 3248, time: 0.160, data: 0.005) loss: 0.205 
(epoch: 162, iters: 3328, time: 0.163, data: 0.000) loss: 0.122 
(epoch: 162, iters: 3408, time: 0.161, data: 0.023) loss: 0.332 
(epoch: 162, iters: 3488, time: 0.158, data: 0.000) loss: 0.206 
(epoch: 162, iters: 3568, time: 0.160, data: 0.005) loss: 0.055 
(epoch: 162, iters: 3648, time: 0.160, data: 0.000) loss: 0.384 
(epoch: 162, iters: 3728, time: 0.159, data: 0.025) loss: 0.283 
(epoch: 162, iters: 3808, time: 0.159, data: 0.000) loss: 0.122 
(epoch: 162, iters: 3888, time: 0.159, data: 0.000) loss: 0.297 
(epoch: 162, iters: 3968, time: 0.159, data: 0.000) loss: 0.446 
saving the latest model (epoch 162, total_steps 1644928)
(epoch: 162, iters: 4048, time: 0.159, data: 0.000) loss: 0.419 
(epoch: 162, iters: 4128, time: 0.162, data: 0.000) loss: 0.404 
(epoch: 162, iters: 4208, time: 0.162, data: 0.000) loss: 0.358 
(epoch: 162, iters: 4288, time: 0.161, data: 0.000) loss: 0.430 
(epoch: 162, iters: 4368, time: 0.159, data: 0.000) loss: 0.057 
(epoch: 162, iters: 4448, time: 0.160, data: 0.006) loss: 0.124 
(epoch: 162, iters: 4528, time: 0.161, data: 0.033) loss: 0.499 
(epoch: 162, iters: 4608, time: 0.162, data: 0.000) loss: 0.514 
(epoch: 162, iters: 4688, time: 0.159, data: 0.020) loss: 0.254 
(epoch: 162, iters: 4768, time: 0.158, data: 0.000) loss: 0.402 
(epoch: 162, iters: 4848, time: 0.163, data: 0.014) loss: 0.665 
(epoch: 162, iters: 4928, time: 0.160, data: 0.008) loss: 0.331 
(epoch: 162, iters: 5008, time: 0.160, data: 0.018) loss: 0.221 
(epoch: 162, iters: 5088, time: 0.160, data: 0.000) loss: 0.714 
(epoch: 162, iters: 5168, time: 0.160, data: 0.024) loss: 0.196 
(epoch: 162, iters: 5248, time: 0.159, data: 0.000) loss: 0.240 
(epoch: 162, iters: 5328, time: 0.160, data: 0.000) loss: 0.614 
(epoch: 162, iters: 5408, time: 0.158, data: 0.009) loss: 0.274 
(epoch: 162, iters: 5488, time: 0.160, data: 0.000) loss: 0.576 
(epoch: 162, iters: 5568, time: 0.160, data: 0.008) loss: 0.378 
(epoch: 162, iters: 5648, time: 0.162, data: 0.000) loss: 0.531 
(epoch: 162, iters: 5728, time: 0.162, data: 0.008) loss: 0.464 
(epoch: 162, iters: 5808, time: 0.159, data: 0.000) loss: 0.677 
(epoch: 162, iters: 5888, time: 0.162, data: 0.000) loss: 0.233 
(epoch: 162, iters: 5968, time: 0.161, data: 0.000) loss: 0.073 
(epoch: 162, iters: 6048, time: 0.162, data: 0.000) loss: 0.361 
(epoch: 162, iters: 6128, time: 0.160, data: 0.000) loss: 0.412 
(epoch: 162, iters: 6208, time: 0.160, data: 0.000) loss: 0.339 
(epoch: 162, iters: 6288, time: 0.159, data: 0.014) loss: 0.230 
(epoch: 162, iters: 6368, time: 0.161, data: 0.020) loss: 0.125 
(epoch: 162, iters: 6448, time: 0.160, data: 0.000) loss: 0.352 
(epoch: 162, iters: 6528, time: 0.158, data: 0.037) loss: 0.555 
(epoch: 162, iters: 6608, time: 0.161, data: 0.000) loss: 0.202 
(epoch: 162, iters: 6688, time: 0.160, data: 0.000) loss: 0.187 
(epoch: 162, iters: 6768, time: 0.159, data: 0.005) loss: 0.265 
(epoch: 162, iters: 6848, time: 0.160, data: 0.000) loss: 0.744 
(epoch: 162, iters: 6928, time: 0.161, data: 0.016) loss: 0.266 
(epoch: 162, iters: 7008, time: 0.161, data: 0.008) loss: 0.622 
(epoch: 162, iters: 7088, time: 0.160, data: 0.000) loss: 0.289 
(epoch: 162, iters: 7168, time: 0.161, data: 0.036) loss: 0.249 
(epoch: 162, iters: 7248, time: 0.161, data: 0.000) loss: 0.308 
(epoch: 162, iters: 7328, time: 0.160, data: 0.000) loss: 0.397 
(epoch: 162, iters: 7408, time: 0.162, data: 0.006) loss: 0.205 
(epoch: 162, iters: 7488, time: 0.159, data: 0.000) loss: 0.206 
(epoch: 162, iters: 7568, time: 0.160, data: 0.000) loss: 0.136 
(epoch: 162, iters: 7648, time: 0.159, data: 0.000) loss: 0.534 
(epoch: 162, iters: 7728, time: 0.157, data: 0.016) loss: 0.176 
(epoch: 162, iters: 7808, time: 0.160, data: 0.009) loss: 0.070 
(epoch: 162, iters: 7888, time: 0.160, data: 0.008) loss: 0.261 
(epoch: 162, iters: 7968, time: 0.156, data: 0.000) loss: 0.241 
saving the latest model (epoch 162, total_steps 1648928)
(epoch: 162, iters: 8048, time: 0.158, data: 0.005) loss: 0.126 
(epoch: 162, iters: 8128, time: 0.160, data: 0.000) loss: 0.190 
(epoch: 162, iters: 8208, time: 0.160, data: 0.018) loss: 0.086 
(epoch: 162, iters: 8288, time: 0.157, data: 0.010) loss: 0.244 
(epoch: 162, iters: 8368, time: 0.160, data: 0.006) loss: 0.264 
(epoch: 162, iters: 8448, time: 0.161, data: 0.000) loss: 0.354 
(epoch: 162, iters: 8528, time: 0.160, data: 0.024) loss: 0.424 
(epoch: 162, iters: 8608, time: 0.161, data: 0.007) loss: 0.540 
(epoch: 162, iters: 8688, time: 0.159, data: 0.000) loss: 0.270 
(epoch: 162, iters: 8768, time: 0.161, data: 0.005) loss: 0.451 
(epoch: 162, iters: 8848, time: 0.159, data: 0.008) loss: 0.225 
(epoch: 162, iters: 8928, time: 0.160, data: 0.000) loss: 0.367 
(epoch: 162, iters: 9008, time: 0.159, data: 0.005) loss: 0.421 
(epoch: 162, iters: 9088, time: 0.160, data: 0.000) loss: 0.159 
(epoch: 162, iters: 9168, time: 0.160, data: 0.014) loss: 0.127 
(epoch: 162, iters: 9248, time: 0.161, data: 0.034) loss: 0.261 
(epoch: 162, iters: 9328, time: 0.161, data: 0.000) loss: 0.256 
(epoch: 162, iters: 9408, time: 0.159, data: 0.000) loss: 0.677 
(epoch: 162, iters: 9488, time: 0.160, data: 0.000) loss: 0.734 
(epoch: 162, iters: 9568, time: 0.159, data: 0.008) loss: 0.495 
(epoch: 162, iters: 9648, time: 0.160, data: 0.000) loss: 0.277 
(epoch: 162, iters: 9728, time: 0.160, data: 0.000) loss: 0.175 
(epoch: 162, iters: 9808, time: 0.160, data: 0.022) loss: 0.560 
(epoch: 162, iters: 9888, time: 0.158, data: 0.000) loss: 0.133 
(epoch: 162, iters: 9968, time: 0.159, data: 0.016) loss: 0.642 
(epoch: 162, iters: 10048, time: 0.160, data: 0.000) loss: 0.100 
(epoch: 162, iters: 10128, time: 0.160, data: 0.033) loss: 0.657 
saving the model at the end of epoch 162, iters 1651104
End of epoch 162 / 200 	 Time Taken: 1632 sec
learning rate = 0.0000733
(epoch: 163, iters: 16, time: 0.179, data: 0.000) loss: 0.175 
saving the latest model (epoch 163, total_steps 1651120)
(epoch: 163, iters: 96, time: 0.164, data: 0.000) loss: 0.043 
(epoch: 163, iters: 176, time: 0.163, data: 0.000) loss: 0.291 
(epoch: 163, iters: 256, time: 0.162, data: 0.028) loss: 0.387 
(epoch: 163, iters: 336, time: 0.163, data: 0.000) loss: 0.154 
(epoch: 163, iters: 416, time: 0.166, data: 0.008) loss: 0.213 
(epoch: 163, iters: 496, time: 0.163, data: 0.005) loss: 0.267 
(epoch: 163, iters: 576, time: 0.164, data: 0.008) loss: 0.151 
(epoch: 163, iters: 656, time: 0.163, data: 0.032) loss: 0.146 
(epoch: 163, iters: 736, time: 0.161, data: 0.000) loss: 0.194 
(epoch: 163, iters: 816, time: 0.161, data: 0.020) loss: 0.044 
(epoch: 163, iters: 896, time: 0.162, data: 0.000) loss: 0.204 
(epoch: 163, iters: 976, time: 0.163, data: 0.000) loss: 0.122 
(epoch: 163, iters: 1056, time: 0.163, data: 0.000) loss: 0.158 
(epoch: 163, iters: 1136, time: 0.163, data: 0.015) loss: 0.199 
(epoch: 163, iters: 1216, time: 0.163, data: 0.005) loss: 0.118 
(epoch: 163, iters: 1296, time: 0.163, data: 0.000) loss: 0.132 
(epoch: 163, iters: 1376, time: 0.162, data: 0.000) loss: 0.311 
(epoch: 163, iters: 1456, time: 0.164, data: 0.019) loss: 0.490 
(epoch: 163, iters: 1536, time: 0.165, data: 0.030) loss: 0.075 
(epoch: 163, iters: 1616, time: 0.164, data: 0.000) loss: 0.242 
(epoch: 163, iters: 1696, time: 0.165, data: 0.000) loss: 0.613 
(epoch: 163, iters: 1776, time: 0.161, data: 0.000) loss: 0.113 
(epoch: 163, iters: 1856, time: 0.160, data: 0.000) loss: 0.096 
(epoch: 163, iters: 1936, time: 0.159, data: 0.008) loss: 0.304 
(epoch: 163, iters: 2016, time: 0.159, data: 0.005) loss: 0.532 
(epoch: 163, iters: 2096, time: 0.160, data: 0.000) loss: 0.255 
(epoch: 163, iters: 2176, time: 0.163, data: 0.010) loss: 0.222 
(epoch: 163, iters: 2256, time: 0.162, data: 0.000) loss: 0.697 
(epoch: 163, iters: 2336, time: 0.163, data: 0.000) loss: 0.355 
(epoch: 163, iters: 2416, time: 0.163, data: 0.008) loss: 0.294 
(epoch: 163, iters: 2496, time: 0.163, data: 0.000) loss: 0.126 
(epoch: 163, iters: 2576, time: 0.161, data: 0.008) loss: 0.355 
(epoch: 163, iters: 2656, time: 0.160, data: 0.000) loss: 0.919 
(epoch: 163, iters: 2736, time: 0.161, data: 0.000) loss: 0.463 
(epoch: 163, iters: 2816, time: 0.162, data: 0.017) loss: 0.147 
(epoch: 163, iters: 2896, time: 0.161, data: 0.005) loss: 0.074 
(epoch: 163, iters: 2976, time: 0.162, data: 0.000) loss: 0.075 
(epoch: 163, iters: 3056, time: 0.162, data: 0.000) loss: 0.118 
(epoch: 163, iters: 3136, time: 0.161, data: 0.013) loss: 0.206 
(epoch: 163, iters: 3216, time: 0.162, data: 0.000) loss: 0.097 
(epoch: 163, iters: 3296, time: 0.161, data: 0.024) loss: 0.353 
(epoch: 163, iters: 3376, time: 0.161, data: 0.000) loss: 0.232 
(epoch: 163, iters: 3456, time: 0.160, data: 0.013) loss: 0.188 
(epoch: 163, iters: 3536, time: 0.160, data: 0.008) loss: 0.111 
(epoch: 163, iters: 3616, time: 0.164, data: 0.000) loss: 0.356 
(epoch: 163, iters: 3696, time: 0.164, data: 0.008) loss: 0.168 
(epoch: 163, iters: 3776, time: 0.164, data: 0.010) loss: 0.285 
(epoch: 163, iters: 3856, time: 0.164, data: 0.000) loss: 0.241 
(epoch: 163, iters: 3936, time: 0.162, data: 0.000) loss: 0.447 
(epoch: 163, iters: 4016, time: 0.163, data: 0.000) loss: 0.174 
saving the latest model (epoch 163, total_steps 1655120)
(epoch: 163, iters: 4096, time: 0.162, data: 0.000) loss: 0.241 
(epoch: 163, iters: 4176, time: 0.161, data: 0.005) loss: 0.361 
(epoch: 163, iters: 4256, time: 0.164, data: 0.000) loss: 0.803 
(epoch: 163, iters: 4336, time: 0.166, data: 0.005) loss: 0.142 
(epoch: 163, iters: 4416, time: 0.164, data: 0.000) loss: 0.025 
(epoch: 163, iters: 4496, time: 0.163, data: 0.008) loss: 0.269 
(epoch: 163, iters: 4576, time: 0.162, data: 0.000) loss: 0.584 
(epoch: 163, iters: 4656, time: 0.164, data: 0.000) loss: 0.461 
(epoch: 163, iters: 4736, time: 0.165, data: 0.000) loss: 0.289 
(epoch: 163, iters: 4816, time: 0.163, data: 0.036) loss: 0.467 
(epoch: 163, iters: 4896, time: 0.164, data: 0.005) loss: 0.314 
(epoch: 163, iters: 4976, time: 0.164, data: 0.000) loss: 0.280 
(epoch: 163, iters: 5056, time: 0.163, data: 0.010) loss: 0.149 
(epoch: 163, iters: 5136, time: 0.162, data: 0.000) loss: 0.137 
(epoch: 163, iters: 5216, time: 0.163, data: 0.000) loss: 0.185 
(epoch: 163, iters: 5296, time: 0.163, data: 0.008) loss: 0.529 
(epoch: 163, iters: 5376, time: 0.161, data: 0.011) loss: 0.426 
(epoch: 163, iters: 5456, time: 0.164, data: 0.000) loss: 0.193 
(epoch: 163, iters: 5536, time: 0.162, data: 0.005) loss: 0.220 
(epoch: 163, iters: 5616, time: 0.160, data: 0.000) loss: 0.377 
(epoch: 163, iters: 5696, time: 0.161, data: 0.016) loss: 0.139 
(epoch: 163, iters: 5776, time: 0.163, data: 0.005) loss: 0.187 
(epoch: 163, iters: 5856, time: 0.163, data: 0.005) loss: 0.146 
(epoch: 163, iters: 5936, time: 0.162, data: 0.000) loss: 0.033 
(epoch: 163, iters: 6016, time: 0.164, data: 0.016) loss: 0.486 
(epoch: 163, iters: 6096, time: 0.160, data: 0.000) loss: 0.146 
(epoch: 163, iters: 6176, time: 0.158, data: 0.000) loss: 0.200 
(epoch: 163, iters: 6256, time: 0.163, data: 0.000) loss: 0.725 
(epoch: 163, iters: 6336, time: 0.161, data: 0.020) loss: 0.444 
(epoch: 163, iters: 6416, time: 0.163, data: 0.000) loss: 0.118 
(epoch: 163, iters: 6496, time: 0.161, data: 0.000) loss: 0.098 
(epoch: 163, iters: 6576, time: 0.163, data: 0.000) loss: 0.139 
(epoch: 163, iters: 6656, time: 0.161, data: 0.005) loss: 0.046 
(epoch: 163, iters: 6736, time: 0.164, data: 0.014) loss: 0.348 
(epoch: 163, iters: 6816, time: 0.161, data: 0.000) loss: 0.075 
(epoch: 163, iters: 6896, time: 0.161, data: 0.000) loss: 0.565 
(epoch: 163, iters: 6976, time: 0.161, data: 0.005) loss: 0.266 
(epoch: 163, iters: 7056, time: 0.161, data: 0.000) loss: 0.300 
(epoch: 163, iters: 7136, time: 0.160, data: 0.005) loss: 0.313 
(epoch: 163, iters: 7216, time: 0.160, data: 0.000) loss: 0.467 
(epoch: 163, iters: 7296, time: 0.161, data: 0.008) loss: 0.037 
(epoch: 163, iters: 7376, time: 0.163, data: 0.000) loss: 0.183 
(epoch: 163, iters: 7456, time: 0.164, data: 0.010) loss: 0.207 
(epoch: 163, iters: 7536, time: 0.160, data: 0.008) loss: 0.635 
(epoch: 163, iters: 7616, time: 0.160, data: 0.000) loss: 0.267 
(epoch: 163, iters: 7696, time: 0.162, data: 0.015) loss: 0.329 
(epoch: 163, iters: 7776, time: 0.159, data: 0.005) loss: 0.313 
(epoch: 163, iters: 7856, time: 0.160, data: 0.011) loss: 0.561 
(epoch: 163, iters: 7936, time: 0.162, data: 0.000) loss: 0.412 
(epoch: 163, iters: 8016, time: 0.164, data: 0.005) loss: 0.214 
saving the latest model (epoch 163, total_steps 1659120)
(epoch: 163, iters: 8096, time: 0.162, data: 0.000) loss: 0.100 
(epoch: 163, iters: 8176, time: 0.166, data: 0.000) loss: 0.332 
(epoch: 163, iters: 8256, time: 0.161, data: 0.000) loss: 0.105 
(epoch: 163, iters: 8336, time: 0.163, data: 0.005) loss: 0.238 
(epoch: 163, iters: 8416, time: 0.162, data: 0.005) loss: 0.625 
(epoch: 163, iters: 8496, time: 0.161, data: 0.033) loss: 0.351 
(epoch: 163, iters: 8576, time: 0.162, data: 0.000) loss: 0.358 
(epoch: 163, iters: 8656, time: 0.160, data: 0.000) loss: 0.169 
(epoch: 163, iters: 8736, time: 0.163, data: 0.005) loss: 0.120 
(epoch: 163, iters: 8816, time: 0.164, data: 0.013) loss: 0.585 
(epoch: 163, iters: 8896, time: 0.163, data: 0.005) loss: 0.525 
(epoch: 163, iters: 8976, time: 0.162, data: 0.005) loss: 0.080 
(epoch: 163, iters: 9056, time: 0.162, data: 0.000) loss: 0.434 
(epoch: 163, iters: 9136, time: 0.161, data: 0.015) loss: 0.336 
(epoch: 163, iters: 9216, time: 0.162, data: 0.000) loss: 0.259 
(epoch: 163, iters: 9296, time: 0.164, data: 0.009) loss: 0.432 
(epoch: 163, iters: 9376, time: 0.163, data: 0.000) loss: 0.513 
(epoch: 163, iters: 9456, time: 0.161, data: 0.000) loss: 0.179 
(epoch: 163, iters: 9536, time: 0.163, data: 0.000) loss: 0.450 
(epoch: 163, iters: 9616, time: 0.164, data: 0.000) loss: 0.306 
(epoch: 163, iters: 9696, time: 0.163, data: 0.000) loss: 0.556 
(epoch: 163, iters: 9776, time: 0.163, data: 0.008) loss: 0.424 
(epoch: 163, iters: 9856, time: 0.162, data: 0.000) loss: 0.754 
(epoch: 163, iters: 9936, time: 0.162, data: 0.005) loss: 0.139 
(epoch: 163, iters: 10016, time: 0.161, data: 0.013) loss: 0.260 
(epoch: 163, iters: 10096, time: 0.161, data: 0.000) loss: 0.055 
(epoch: 163, iters: 10176, time: 0.162, data: 0.000) loss: 0.423 
saving the model at the end of epoch 163, iters 1661296
End of epoch 163 / 200 	 Time Taken: 1655 sec
learning rate = 0.0000713
saving the latest model (epoch 164, total_steps 1661312)
(epoch: 164, iters: 64, time: 0.161, data: 0.000) loss: 0.624 
(epoch: 164, iters: 144, time: 0.159, data: 0.024) loss: 0.375 
(epoch: 164, iters: 224, time: 0.161, data: 0.000) loss: 0.050 
(epoch: 164, iters: 304, time: 0.160, data: 0.000) loss: 0.301 
(epoch: 164, iters: 384, time: 0.161, data: 0.000) loss: 0.188 
(epoch: 164, iters: 464, time: 0.160, data: 0.000) loss: 0.281 
(epoch: 164, iters: 544, time: 0.160, data: 0.000) loss: 0.340 
(epoch: 164, iters: 624, time: 0.160, data: 0.000) loss: 0.092 
(epoch: 164, iters: 704, time: 0.160, data: 0.015) loss: 0.123 
(epoch: 164, iters: 784, time: 0.161, data: 0.008) loss: 0.566 
(epoch: 164, iters: 864, time: 0.159, data: 0.000) loss: 0.333 
(epoch: 164, iters: 944, time: 0.159, data: 0.008) loss: 0.317 
(epoch: 164, iters: 1024, time: 0.159, data: 0.010) loss: 0.378 
(epoch: 164, iters: 1104, time: 0.160, data: 0.000) loss: 0.139 
(epoch: 164, iters: 1184, time: 0.161, data: 0.000) loss: 0.707 
(epoch: 164, iters: 1264, time: 0.159, data: 0.020) loss: 0.770 
(epoch: 164, iters: 1344, time: 0.160, data: 0.000) loss: 0.133 
(epoch: 164, iters: 1424, time: 0.160, data: 0.024) loss: 0.506 
(epoch: 164, iters: 1504, time: 0.158, data: 0.000) loss: 0.346 
(epoch: 164, iters: 1584, time: 0.160, data: 0.020) loss: 0.355 
(epoch: 164, iters: 1664, time: 0.159, data: 0.000) loss: 0.133 
(epoch: 164, iters: 1744, time: 0.161, data: 0.000) loss: 0.195 
(epoch: 164, iters: 1824, time: 0.159, data: 0.005) loss: 0.252 
(epoch: 164, iters: 1904, time: 0.160, data: 0.000) loss: 0.550 
(epoch: 164, iters: 1984, time: 0.160, data: 0.006) loss: 0.119 
(epoch: 164, iters: 2064, time: 0.159, data: 0.000) loss: 0.071 
(epoch: 164, iters: 2144, time: 0.160, data: 0.000) loss: 0.253 
(epoch: 164, iters: 2224, time: 0.160, data: 0.009) loss: 0.109 
(epoch: 164, iters: 2304, time: 0.159, data: 0.000) loss: 0.256 
(epoch: 164, iters: 2384, time: 0.159, data: 0.009) loss: 0.369 
(epoch: 164, iters: 2464, time: 0.162, data: 0.034) loss: 0.088 
(epoch: 164, iters: 2544, time: 0.160, data: 0.000) loss: 1.299 
(epoch: 164, iters: 2624, time: 0.160, data: 0.011) loss: 0.376 
(epoch: 164, iters: 2704, time: 0.160, data: 0.000) loss: 0.714 
(epoch: 164, iters: 2784, time: 0.160, data: 0.021) loss: 0.275 
(epoch: 164, iters: 2864, time: 0.158, data: 0.000) loss: 0.113 
(epoch: 164, iters: 2944, time: 0.161, data: 0.000) loss: 0.326 
(epoch: 164, iters: 3024, time: 0.160, data: 0.000) loss: 0.099 
(epoch: 164, iters: 3104, time: 0.159, data: 0.018) loss: 0.074 
(epoch: 164, iters: 3184, time: 0.159, data: 0.000) loss: 0.345 
(epoch: 164, iters: 3264, time: 0.159, data: 0.010) loss: 0.137 
(epoch: 164, iters: 3344, time: 0.159, data: 0.000) loss: 0.190 
(epoch: 164, iters: 3424, time: 0.163, data: 0.008) loss: 0.310 
(epoch: 164, iters: 3504, time: 0.158, data: 0.014) loss: 0.881 
(epoch: 164, iters: 3584, time: 0.158, data: 0.008) loss: 0.438 
(epoch: 164, iters: 3664, time: 0.159, data: 0.006) loss: 0.047 
(epoch: 164, iters: 3744, time: 0.160, data: 0.000) loss: 0.183 
(epoch: 164, iters: 3824, time: 0.161, data: 0.000) loss: 0.416 
(epoch: 164, iters: 3904, time: 0.159, data: 0.009) loss: 0.078 
(epoch: 164, iters: 3984, time: 0.157, data: 0.000) loss: 0.538 
saving the latest model (epoch 164, total_steps 1665312)
(epoch: 164, iters: 4064, time: 0.160, data: 0.042) loss: 0.366 
(epoch: 164, iters: 4144, time: 0.158, data: 0.000) loss: 0.302 
(epoch: 164, iters: 4224, time: 0.159, data: 0.000) loss: 0.204 
(epoch: 164, iters: 4304, time: 0.159, data: 0.000) loss: 0.238 
(epoch: 164, iters: 4384, time: 0.162, data: 0.000) loss: 0.131 
(epoch: 164, iters: 4464, time: 0.161, data: 0.005) loss: 0.269 
(epoch: 164, iters: 4544, time: 0.160, data: 0.010) loss: 0.168 
(epoch: 164, iters: 4624, time: 0.161, data: 0.000) loss: 0.129 
(epoch: 164, iters: 4704, time: 0.159, data: 0.000) loss: 0.409 
(epoch: 164, iters: 4784, time: 0.159, data: 0.000) loss: 0.356 
(epoch: 164, iters: 4864, time: 0.160, data: 0.014) loss: 0.453 
(epoch: 164, iters: 4944, time: 0.163, data: 0.016) loss: 0.433 
(epoch: 164, iters: 5024, time: 0.158, data: 0.010) loss: 0.177 
(epoch: 164, iters: 5104, time: 0.158, data: 0.000) loss: 0.130 
(epoch: 164, iters: 5184, time: 0.158, data: 0.000) loss: 0.252 
(epoch: 164, iters: 5264, time: 0.157, data: 0.016) loss: 0.045 
(epoch: 164, iters: 5344, time: 0.161, data: 0.016) loss: 0.134 
(epoch: 164, iters: 5424, time: 0.160, data: 0.000) loss: 0.291 
(epoch: 164, iters: 5504, time: 0.160, data: 0.008) loss: 0.130 
(epoch: 164, iters: 5584, time: 0.159, data: 0.005) loss: 0.213 
(epoch: 164, iters: 5664, time: 0.160, data: 0.005) loss: 0.316 
(epoch: 164, iters: 5744, time: 0.159, data: 0.011) loss: 0.120 
(epoch: 164, iters: 5824, time: 0.160, data: 0.000) loss: 0.375 
(epoch: 164, iters: 5904, time: 0.160, data: 0.021) loss: 0.405 
(epoch: 164, iters: 5984, time: 0.157, data: 0.005) loss: 0.535 
(epoch: 164, iters: 6064, time: 0.156, data: 0.005) loss: 0.086 
(epoch: 164, iters: 6144, time: 0.158, data: 0.000) loss: 0.184 
(epoch: 164, iters: 6224, time: 0.159, data: 0.021) loss: 0.067 
(epoch: 164, iters: 6304, time: 0.157, data: 0.025) loss: 0.278 
(epoch: 164, iters: 6384, time: 0.159, data: 0.000) loss: 0.420 
(epoch: 164, iters: 6464, time: 0.156, data: 0.010) loss: 0.116 
(epoch: 164, iters: 6544, time: 0.156, data: 0.000) loss: 0.231 
(epoch: 164, iters: 6624, time: 0.156, data: 0.005) loss: 0.126 
(epoch: 164, iters: 6704, time: 0.156, data: 0.000) loss: 0.353 
(epoch: 164, iters: 6784, time: 0.158, data: 0.000) loss: 0.359 
(epoch: 164, iters: 6864, time: 0.158, data: 0.000) loss: 0.220 
(epoch: 164, iters: 6944, time: 0.159, data: 0.000) loss: 0.235 
(epoch: 164, iters: 7024, time: 0.159, data: 0.022) loss: 0.292 
(epoch: 164, iters: 7104, time: 0.157, data: 0.000) loss: 0.138 
(epoch: 164, iters: 7184, time: 0.161, data: 0.000) loss: 0.153 
(epoch: 164, iters: 7264, time: 0.160, data: 0.000) loss: 0.278 
(epoch: 164, iters: 7344, time: 0.157, data: 0.000) loss: 0.295 
(epoch: 164, iters: 7424, time: 0.158, data: 0.015) loss: 0.839 
(epoch: 164, iters: 7504, time: 0.158, data: 0.000) loss: 0.441 
(epoch: 164, iters: 7584, time: 0.158, data: 0.005) loss: 0.800 
(epoch: 164, iters: 7664, time: 0.158, data: 0.013) loss: 0.227 
(epoch: 164, iters: 7744, time: 0.158, data: 0.000) loss: 0.132 
(epoch: 164, iters: 7824, time: 0.158, data: 0.000) loss: 0.277 
(epoch: 164, iters: 7904, time: 0.159, data: 0.000) loss: 0.150 
(epoch: 164, iters: 7984, time: 0.158, data: 0.000) loss: 0.502 
saving the latest model (epoch 164, total_steps 1669312)
(epoch: 164, iters: 8064, time: 0.159, data: 0.005) loss: 0.514 
(epoch: 164, iters: 8144, time: 0.158, data: 0.005) loss: 0.266 
(epoch: 164, iters: 8224, time: 0.157, data: 0.000) loss: 0.360 
(epoch: 164, iters: 8304, time: 0.160, data: 0.000) loss: 0.169 
(epoch: 164, iters: 8384, time: 0.159, data: 0.020) loss: 0.468 
(epoch: 164, iters: 8464, time: 0.158, data: 0.000) loss: 0.113 
(epoch: 164, iters: 8544, time: 0.159, data: 0.000) loss: 0.383 
(epoch: 164, iters: 8624, time: 0.160, data: 0.005) loss: 0.098 
(epoch: 164, iters: 8704, time: 0.159, data: 0.000) loss: 0.159 
(epoch: 164, iters: 8784, time: 0.160, data: 0.000) loss: 0.161 
(epoch: 164, iters: 8864, time: 0.160, data: 0.000) loss: 0.388 
(epoch: 164, iters: 8944, time: 0.160, data: 0.005) loss: 0.152 
(epoch: 164, iters: 9024, time: 0.161, data: 0.000) loss: 0.969 
(epoch: 164, iters: 9104, time: 0.160, data: 0.031) loss: 0.353 
(epoch: 164, iters: 9184, time: 0.159, data: 0.000) loss: 0.184 
(epoch: 164, iters: 9264, time: 0.159, data: 0.000) loss: 0.054 
(epoch: 164, iters: 9344, time: 0.158, data: 0.006) loss: 0.502 
(epoch: 164, iters: 9424, time: 0.160, data: 0.000) loss: 0.109 
(epoch: 164, iters: 9504, time: 0.160, data: 0.000) loss: 0.224 
(epoch: 164, iters: 9584, time: 0.160, data: 0.018) loss: 0.250 
(epoch: 164, iters: 9664, time: 0.160, data: 0.000) loss: 0.207 
(epoch: 164, iters: 9744, time: 0.160, data: 0.008) loss: 0.371 
(epoch: 164, iters: 9824, time: 0.159, data: 0.000) loss: 0.369 
(epoch: 164, iters: 9904, time: 0.161, data: 0.009) loss: 0.182 
(epoch: 164, iters: 9984, time: 0.159, data: 0.000) loss: 0.181 
(epoch: 164, iters: 10064, time: 0.161, data: 0.008) loss: 0.253 
(epoch: 164, iters: 10144, time: 0.158, data: 0.011) loss: 0.088 
saving the model at the end of epoch 164, iters 1671488
End of epoch 164 / 200 	 Time Taken: 1627 sec
learning rate = 0.0000693
saving the latest model (epoch 165, total_steps 1671504)
(epoch: 165, iters: 32, time: 0.166, data: 0.000) loss: 0.488 
(epoch: 165, iters: 112, time: 0.160, data: 0.000) loss: 0.132 
(epoch: 165, iters: 192, time: 0.160, data: 0.008) loss: 0.531 
(epoch: 165, iters: 272, time: 0.161, data: 0.000) loss: 0.232 
(epoch: 165, iters: 352, time: 0.163, data: 0.000) loss: 0.330 
(epoch: 165, iters: 432, time: 0.159, data: 0.006) loss: 0.055 
(epoch: 165, iters: 512, time: 0.160, data: 0.000) loss: 0.107 
(epoch: 165, iters: 592, time: 0.161, data: 0.014) loss: 0.231 
(epoch: 165, iters: 672, time: 0.161, data: 0.022) loss: 0.501 
(epoch: 165, iters: 752, time: 0.159, data: 0.032) loss: 0.292 
(epoch: 165, iters: 832, time: 0.165, data: 0.000) loss: 0.553 
(epoch: 165, iters: 912, time: 0.162, data: 0.028) loss: 0.280 
(epoch: 165, iters: 992, time: 0.161, data: 0.000) loss: 0.125 
(epoch: 165, iters: 1072, time: 0.161, data: 0.000) loss: 0.346 
(epoch: 165, iters: 1152, time: 0.160, data: 0.008) loss: 0.209 
(epoch: 165, iters: 1232, time: 0.161, data: 0.000) loss: 0.436 
(epoch: 165, iters: 1312, time: 0.161, data: 0.000) loss: 0.083 
(epoch: 165, iters: 1392, time: 0.162, data: 0.015) loss: 0.217 
(epoch: 165, iters: 1472, time: 0.162, data: 0.021) loss: 0.065 
(epoch: 165, iters: 1552, time: 0.161, data: 0.005) loss: 0.583 
(epoch: 165, iters: 1632, time: 0.159, data: 0.023) loss: 0.483 
(epoch: 165, iters: 1712, time: 0.161, data: 0.000) loss: 0.674 
(epoch: 165, iters: 1792, time: 0.160, data: 0.000) loss: 0.504 
(epoch: 165, iters: 1872, time: 0.161, data: 0.005) loss: 0.348 
(epoch: 165, iters: 1952, time: 0.160, data: 0.000) loss: 0.235 
(epoch: 165, iters: 2032, time: 0.160, data: 0.000) loss: 0.201 
(epoch: 165, iters: 2112, time: 0.161, data: 0.017) loss: 0.204 
(epoch: 165, iters: 2192, time: 0.161, data: 0.018) loss: 0.168 
(epoch: 165, iters: 2272, time: 0.158, data: 0.000) loss: 0.369 
(epoch: 165, iters: 2352, time: 0.160, data: 0.013) loss: 0.238 
(epoch: 165, iters: 2432, time: 0.161, data: 0.000) loss: 0.046 
(epoch: 165, iters: 2512, time: 0.161, data: 0.000) loss: 0.467 
(epoch: 165, iters: 2592, time: 0.161, data: 0.005) loss: 0.164 
(epoch: 165, iters: 2672, time: 0.162, data: 0.000) loss: 0.448 
(epoch: 165, iters: 2752, time: 0.161, data: 0.000) loss: 1.066 
(epoch: 165, iters: 2832, time: 0.160, data: 0.000) loss: 0.192 
(epoch: 165, iters: 2912, time: 0.160, data: 0.005) loss: 0.233 
(epoch: 165, iters: 2992, time: 0.161, data: 0.000) loss: 0.440 
(epoch: 165, iters: 3072, time: 0.161, data: 0.018) loss: 0.130 
(epoch: 165, iters: 3152, time: 0.162, data: 0.021) loss: 0.121 
(epoch: 165, iters: 3232, time: 0.160, data: 0.000) loss: 0.257 
(epoch: 165, iters: 3312, time: 0.161, data: 0.000) loss: 0.289 
(epoch: 165, iters: 3392, time: 0.159, data: 0.009) loss: 0.423 
(epoch: 165, iters: 3472, time: 0.159, data: 0.024) loss: 0.193 
(epoch: 165, iters: 3552, time: 0.160, data: 0.000) loss: 0.337 
(epoch: 165, iters: 3632, time: 0.158, data: 0.000) loss: 0.115 
(epoch: 165, iters: 3712, time: 0.159, data: 0.000) loss: 0.263 
(epoch: 165, iters: 3792, time: 0.161, data: 0.000) loss: 0.419 
(epoch: 165, iters: 3872, time: 0.159, data: 0.013) loss: 0.124 
(epoch: 165, iters: 3952, time: 0.160, data: 0.008) loss: 0.301 
saving the latest model (epoch 165, total_steps 1675504)
(epoch: 165, iters: 4032, time: 0.160, data: 0.000) loss: 0.156 
(epoch: 165, iters: 4112, time: 0.160, data: 0.006) loss: 0.272 
(epoch: 165, iters: 4192, time: 0.160, data: 0.005) loss: 0.357 
(epoch: 165, iters: 4272, time: 0.160, data: 0.000) loss: 0.294 
(epoch: 165, iters: 4352, time: 0.159, data: 0.014) loss: 0.671 
(epoch: 165, iters: 4432, time: 0.160, data: 0.000) loss: 0.132 
(epoch: 165, iters: 4512, time: 0.160, data: 0.005) loss: 0.093 
(epoch: 165, iters: 4592, time: 0.161, data: 0.000) loss: 0.260 
(epoch: 165, iters: 4672, time: 0.161, data: 0.008) loss: 0.352 
(epoch: 165, iters: 4752, time: 0.159, data: 0.000) loss: 0.160 
(epoch: 165, iters: 4832, time: 0.160, data: 0.040) loss: 0.225 
(epoch: 165, iters: 4912, time: 0.160, data: 0.000) loss: 0.317 
(epoch: 165, iters: 4992, time: 0.159, data: 0.000) loss: 0.236 
(epoch: 165, iters: 5072, time: 0.163, data: 0.000) loss: 0.114 
(epoch: 165, iters: 5152, time: 0.162, data: 0.012) loss: 0.329 
(epoch: 165, iters: 5232, time: 0.161, data: 0.005) loss: 0.169 
(epoch: 165, iters: 5312, time: 0.160, data: 0.000) loss: 0.637 
(epoch: 165, iters: 5392, time: 0.159, data: 0.005) loss: 0.249 
(epoch: 165, iters: 5472, time: 0.160, data: 0.000) loss: 0.395 
(epoch: 165, iters: 5552, time: 0.159, data: 0.009) loss: 0.632 
(epoch: 165, iters: 5632, time: 0.162, data: 0.000) loss: 0.503 
(epoch: 165, iters: 5712, time: 0.162, data: 0.000) loss: 0.567 
(epoch: 165, iters: 5792, time: 0.161, data: 0.000) loss: 0.456 
(epoch: 165, iters: 5872, time: 0.161, data: 0.023) loss: 0.391 
(epoch: 165, iters: 5952, time: 0.161, data: 0.000) loss: 0.160 
(epoch: 165, iters: 6032, time: 0.162, data: 0.000) loss: 0.295 
(epoch: 165, iters: 6112, time: 0.162, data: 0.005) loss: 0.303 
(epoch: 165, iters: 6192, time: 0.159, data: 0.000) loss: 0.674 
(epoch: 165, iters: 6272, time: 0.159, data: 0.022) loss: 0.062 
(epoch: 165, iters: 6352, time: 0.160, data: 0.000) loss: 0.329 
(epoch: 165, iters: 6432, time: 0.159, data: 0.000) loss: 0.055 
(epoch: 165, iters: 6512, time: 0.160, data: 0.024) loss: 0.488 
(epoch: 165, iters: 6592, time: 0.159, data: 0.000) loss: 0.453 
(epoch: 165, iters: 6672, time: 0.162, data: 0.000) loss: 0.491 
(epoch: 165, iters: 6752, time: 0.162, data: 0.014) loss: 0.303 
(epoch: 165, iters: 6832, time: 0.160, data: 0.000) loss: 0.021 
(epoch: 165, iters: 6912, time: 0.161, data: 0.033) loss: 0.397 
(epoch: 165, iters: 6992, time: 0.162, data: 0.000) loss: 0.138 
(epoch: 165, iters: 7072, time: 0.163, data: 0.000) loss: 0.226 
(epoch: 165, iters: 7152, time: 0.163, data: 0.000) loss: 0.258 
(epoch: 165, iters: 7232, time: 0.162, data: 0.000) loss: 0.218 
(epoch: 165, iters: 7312, time: 0.160, data: 0.010) loss: 0.229 
(epoch: 165, iters: 7392, time: 0.162, data: 0.008) loss: 0.232 
(epoch: 165, iters: 7472, time: 0.162, data: 0.000) loss: 0.242 
(epoch: 165, iters: 7552, time: 0.160, data: 0.000) loss: 0.446 
(epoch: 165, iters: 7632, time: 0.161, data: 0.000) loss: 0.069 
(epoch: 165, iters: 7712, time: 0.162, data: 0.000) loss: 0.316 
(epoch: 165, iters: 7792, time: 0.159, data: 0.005) loss: 0.180 
(epoch: 165, iters: 7872, time: 0.162, data: 0.010) loss: 0.408 
(epoch: 165, iters: 7952, time: 0.161, data: 0.000) loss: 0.432 
saving the latest model (epoch 165, total_steps 1679504)
(epoch: 165, iters: 8032, time: 0.161, data: 0.000) loss: 0.361 
(epoch: 165, iters: 8112, time: 0.160, data: 0.020) loss: 0.232 
(epoch: 165, iters: 8192, time: 0.160, data: 0.000) loss: 0.277 
(epoch: 165, iters: 8272, time: 0.160, data: 0.000) loss: 0.090 
(epoch: 165, iters: 8352, time: 0.162, data: 0.005) loss: 0.552 
(epoch: 165, iters: 8432, time: 0.161, data: 0.000) loss: 0.213 
(epoch: 165, iters: 8512, time: 0.160, data: 0.005) loss: 0.230 
(epoch: 165, iters: 8592, time: 0.162, data: 0.000) loss: 0.200 
(epoch: 165, iters: 8672, time: 0.161, data: 0.006) loss: 0.176 
(epoch: 165, iters: 8752, time: 0.163, data: 0.000) loss: 0.244 
(epoch: 165, iters: 8832, time: 0.161, data: 0.000) loss: 0.060 
(epoch: 165, iters: 8912, time: 0.160, data: 0.015) loss: 0.475 
(epoch: 165, iters: 8992, time: 0.159, data: 0.005) loss: 0.458 
(epoch: 165, iters: 9072, time: 0.159, data: 0.011) loss: 0.209 
(epoch: 165, iters: 9152, time: 0.160, data: 0.000) loss: 0.157 
(epoch: 165, iters: 9232, time: 0.161, data: 0.009) loss: 0.206 
(epoch: 165, iters: 9312, time: 0.161, data: 0.032) loss: 1.128 
(epoch: 165, iters: 9392, time: 0.159, data: 0.000) loss: 0.296 
(epoch: 165, iters: 9472, time: 0.160, data: 0.008) loss: 0.151 
(epoch: 165, iters: 9552, time: 0.157, data: 0.000) loss: 0.287 
(epoch: 165, iters: 9632, time: 0.158, data: 0.010) loss: 0.362 
(epoch: 165, iters: 9712, time: 0.159, data: 0.000) loss: 0.480 
(epoch: 165, iters: 9792, time: 0.159, data: 0.023) loss: 0.182 
(epoch: 165, iters: 9872, time: 0.160, data: 0.000) loss: 0.145 
(epoch: 165, iters: 9952, time: 0.162, data: 0.008) loss: 0.266 
(epoch: 165, iters: 10032, time: 0.160, data: 0.005) loss: 0.119 
(epoch: 165, iters: 10112, time: 0.162, data: 0.000) loss: 0.498 
(epoch: 165, iters: 10192, time: 0.096, data: 0.000) loss: 0.134 
saving the model at the end of epoch 165, iters 1681680
End of epoch 165 / 200 	 Time Taken: 1638 sec
learning rate = 0.0000673
saving the latest model (epoch 166, total_steps 1681696)
(epoch: 166, iters: 80, time: 0.162, data: 0.187) loss: 0.103 
(epoch: 166, iters: 160, time: 0.161, data: 0.016) loss: 0.331 
(epoch: 166, iters: 240, time: 0.160, data: 0.009) loss: 0.411 
(epoch: 166, iters: 320, time: 0.161, data: 0.000) loss: 0.202 
(epoch: 166, iters: 400, time: 0.162, data: 0.024) loss: 0.359 
(epoch: 166, iters: 480, time: 0.162, data: 0.000) loss: 0.138 
(epoch: 166, iters: 560, time: 0.161, data: 0.000) loss: 0.820 
(epoch: 166, iters: 640, time: 0.159, data: 0.000) loss: 0.149 
(epoch: 166, iters: 720, time: 0.159, data: 0.029) loss: 0.347 
(epoch: 166, iters: 800, time: 0.160, data: 0.000) loss: 0.354 
(epoch: 166, iters: 880, time: 0.162, data: 0.000) loss: 0.098 
(epoch: 166, iters: 960, time: 0.161, data: 0.000) loss: 0.415 
(epoch: 166, iters: 1040, time: 0.161, data: 0.019) loss: 0.199 
(epoch: 166, iters: 1120, time: 0.160, data: 0.000) loss: 0.190 
(epoch: 166, iters: 1200, time: 0.159, data: 0.000) loss: 0.129 
(epoch: 166, iters: 1280, time: 0.159, data: 0.000) loss: 0.132 
(epoch: 166, iters: 1360, time: 0.159, data: 0.015) loss: 0.159 
(epoch: 166, iters: 1440, time: 0.159, data: 0.024) loss: 0.379 
(epoch: 166, iters: 1520, time: 0.161, data: 0.000) loss: 0.252 
(epoch: 166, iters: 1600, time: 0.160, data: 0.000) loss: 0.438 
(epoch: 166, iters: 1680, time: 0.159, data: 0.023) loss: 0.135 
(epoch: 166, iters: 1760, time: 0.159, data: 0.000) loss: 0.247 
(epoch: 166, iters: 1840, time: 0.156, data: 0.023) loss: 0.266 
(epoch: 166, iters: 1920, time: 0.159, data: 0.000) loss: 0.208 
(epoch: 166, iters: 2000, time: 0.161, data: 0.010) loss: 0.207 
(epoch: 166, iters: 2080, time: 0.161, data: 0.000) loss: 0.364 
(epoch: 166, iters: 2160, time: 0.159, data: 0.011) loss: 0.165 
(epoch: 166, iters: 2240, time: 0.159, data: 0.016) loss: 0.349 
(epoch: 166, iters: 2320, time: 0.159, data: 0.000) loss: 0.478 
(epoch: 166, iters: 2400, time: 0.161, data: 0.006) loss: 0.468 
(epoch: 166, iters: 2480, time: 0.159, data: 0.000) loss: 0.407 
(epoch: 166, iters: 2560, time: 0.158, data: 0.008) loss: 0.490 
(epoch: 166, iters: 2640, time: 0.161, data: 0.000) loss: 0.525 
(epoch: 166, iters: 2720, time: 0.159, data: 0.013) loss: 0.140 
(epoch: 166, iters: 2800, time: 0.159, data: 0.005) loss: 0.515 
(epoch: 166, iters: 2880, time: 0.160, data: 0.000) loss: 0.200 
(epoch: 166, iters: 2960, time: 0.162, data: 0.021) loss: 0.295 
(epoch: 166, iters: 3040, time: 0.159, data: 0.010) loss: 0.216 
(epoch: 166, iters: 3120, time: 0.160, data: 0.000) loss: 0.140 
(epoch: 166, iters: 3200, time: 0.159, data: 0.000) loss: 0.249 
(epoch: 166, iters: 3280, time: 0.160, data: 0.020) loss: 0.200 
(epoch: 166, iters: 3360, time: 0.159, data: 0.020) loss: 0.349 
(epoch: 166, iters: 3440, time: 0.159, data: 0.000) loss: 0.140 
(epoch: 166, iters: 3520, time: 0.158, data: 0.032) loss: 0.296 
(epoch: 166, iters: 3600, time: 0.160, data: 0.000) loss: 0.291 
(epoch: 166, iters: 3680, time: 0.163, data: 0.008) loss: 0.120 
(epoch: 166, iters: 3760, time: 0.159, data: 0.000) loss: 0.412 
(epoch: 166, iters: 3840, time: 0.161, data: 0.018) loss: 0.556 
(epoch: 166, iters: 3920, time: 0.161, data: 0.000) loss: 0.446 
(epoch: 166, iters: 4000, time: 0.160, data: 0.025) loss: 0.467 
saving the latest model (epoch 166, total_steps 1685696)
(epoch: 166, iters: 4080, time: 0.160, data: 0.000) loss: 0.639 
(epoch: 166, iters: 4160, time: 0.161, data: 0.010) loss: 0.245 
(epoch: 166, iters: 4240, time: 0.159, data: 0.005) loss: 0.113 
(epoch: 166, iters: 4320, time: 0.159, data: 0.000) loss: 0.218 
(epoch: 166, iters: 4400, time: 0.160, data: 0.000) loss: 0.194 
(epoch: 166, iters: 4480, time: 0.160, data: 0.000) loss: 0.187 
(epoch: 166, iters: 4560, time: 0.161, data: 0.026) loss: 0.261 
(epoch: 166, iters: 4640, time: 0.160, data: 0.000) loss: 0.168 
(epoch: 166, iters: 4720, time: 0.161, data: 0.000) loss: 0.072 
(epoch: 166, iters: 4800, time: 0.159, data: 0.006) loss: 0.275 
(epoch: 166, iters: 4880, time: 0.159, data: 0.018) loss: 0.401 
(epoch: 166, iters: 4960, time: 0.160, data: 0.000) loss: 0.129 
(epoch: 166, iters: 5040, time: 0.161, data: 0.011) loss: 0.235 
(epoch: 166, iters: 5120, time: 0.158, data: 0.005) loss: 0.224 
(epoch: 166, iters: 5200, time: 0.160, data: 0.010) loss: 0.349 
(epoch: 166, iters: 5280, time: 0.160, data: 0.000) loss: 0.170 
(epoch: 166, iters: 5360, time: 0.160, data: 0.000) loss: 0.117 
(epoch: 166, iters: 5440, time: 0.160, data: 0.014) loss: 0.106 
(epoch: 166, iters: 5520, time: 0.160, data: 0.000) loss: 0.526 
(epoch: 166, iters: 5600, time: 0.160, data: 0.000) loss: 0.223 
(epoch: 166, iters: 5680, time: 0.160, data: 0.000) loss: 0.256 
(epoch: 166, iters: 5760, time: 0.159, data: 0.000) loss: 0.424 
(epoch: 166, iters: 5840, time: 0.159, data: 0.000) loss: 0.641 
(epoch: 166, iters: 5920, time: 0.159, data: 0.000) loss: 0.178 
(epoch: 166, iters: 6000, time: 0.160, data: 0.008) loss: 0.365 
(epoch: 166, iters: 6080, time: 0.160, data: 0.008) loss: 0.386 
(epoch: 166, iters: 6160, time: 0.161, data: 0.000) loss: 0.164 
(epoch: 166, iters: 6240, time: 0.159, data: 0.014) loss: 0.166 
(epoch: 166, iters: 6320, time: 0.158, data: 0.008) loss: 0.046 
(epoch: 166, iters: 6400, time: 0.159, data: 0.000) loss: 0.149 
(epoch: 166, iters: 6480, time: 0.160, data: 0.015) loss: 0.652 
(epoch: 166, iters: 6560, time: 0.159, data: 0.000) loss: 0.114 
(epoch: 166, iters: 6640, time: 0.161, data: 0.000) loss: 0.459 
(epoch: 166, iters: 6720, time: 0.161, data: 0.000) loss: 0.237 
(epoch: 166, iters: 6800, time: 0.157, data: 0.000) loss: 0.558 
(epoch: 166, iters: 6880, time: 0.159, data: 0.000) loss: 0.162 
(epoch: 166, iters: 6960, time: 0.161, data: 0.000) loss: 0.340 
(epoch: 166, iters: 7040, time: 0.163, data: 0.000) loss: 0.056 
(epoch: 166, iters: 7120, time: 0.161, data: 0.000) loss: 0.380 
(epoch: 166, iters: 7200, time: 0.161, data: 0.006) loss: 0.321 
(epoch: 166, iters: 7280, time: 0.159, data: 0.000) loss: 0.424 
(epoch: 166, iters: 7360, time: 0.161, data: 0.020) loss: 0.341 
(epoch: 166, iters: 7440, time: 0.163, data: 0.005) loss: 0.161 
(epoch: 166, iters: 7520, time: 0.159, data: 0.000) loss: 0.160 
(epoch: 166, iters: 7600, time: 0.163, data: 0.006) loss: 0.578 
(epoch: 166, iters: 7680, time: 0.168, data: 0.011) loss: 0.138 
(epoch: 166, iters: 7760, time: 0.156, data: 0.000) loss: 0.383 
(epoch: 166, iters: 7840, time: 0.157, data: 0.000) loss: 0.685 
(epoch: 166, iters: 7920, time: 0.158, data: 0.021) loss: 0.236 
(epoch: 166, iters: 8000, time: 0.161, data: 0.000) loss: 0.229 
saving the latest model (epoch 166, total_steps 1689696)
(epoch: 166, iters: 8080, time: 0.159, data: 0.000) loss: 0.515 
(epoch: 166, iters: 8160, time: 0.158, data: 0.005) loss: 0.657 
(epoch: 166, iters: 8240, time: 0.157, data: 0.017) loss: 0.595 
(epoch: 166, iters: 8320, time: 0.173, data: 0.000) loss: 0.332 
(epoch: 166, iters: 8400, time: 0.167, data: 0.020) loss: 0.278 
(epoch: 166, iters: 8480, time: 0.159, data: 0.000) loss: 0.222 
(epoch: 166, iters: 8560, time: 0.161, data: 0.000) loss: 0.486 
(epoch: 166, iters: 8640, time: 0.159, data: 0.011) loss: 0.325 
(epoch: 166, iters: 8720, time: 0.160, data: 0.000) loss: 0.238 
(epoch: 166, iters: 8800, time: 0.160, data: 0.000) loss: 0.545 
(epoch: 166, iters: 8880, time: 0.160, data: 0.024) loss: 0.285 
(epoch: 166, iters: 8960, time: 0.163, data: 0.000) loss: 0.134 
(epoch: 166, iters: 9040, time: 0.163, data: 0.005) loss: 0.163 
(epoch: 166, iters: 9120, time: 0.158, data: 0.000) loss: 0.139 
(epoch: 166, iters: 9200, time: 0.159, data: 0.000) loss: 0.318 
(epoch: 166, iters: 9280, time: 0.160, data: 0.018) loss: 0.157 
(epoch: 166, iters: 9360, time: 0.157, data: 0.024) loss: 0.384 
(epoch: 166, iters: 9440, time: 0.158, data: 0.000) loss: 0.086 
(epoch: 166, iters: 9520, time: 0.158, data: 0.000) loss: 0.447 
(epoch: 166, iters: 9600, time: 0.158, data: 0.006) loss: 0.220 
(epoch: 166, iters: 9680, time: 0.158, data: 0.000) loss: 0.386 
(epoch: 166, iters: 9760, time: 0.160, data: 0.000) loss: 0.209 
(epoch: 166, iters: 9840, time: 0.158, data: 0.032) loss: 0.278 
(epoch: 166, iters: 9920, time: 0.158, data: 0.000) loss: 0.036 
(epoch: 166, iters: 10000, time: 0.158, data: 0.000) loss: 0.505 
(epoch: 166, iters: 10080, time: 0.159, data: 0.018) loss: 0.075 
(epoch: 166, iters: 10160, time: 0.157, data: 0.017) loss: 0.367 
saving the model at the end of epoch 166, iters 1691872
End of epoch 166 / 200 	 Time Taken: 1634 sec
learning rate = 0.0000653
saving the latest model (epoch 167, total_steps 1691888)
(epoch: 167, iters: 48, time: 0.161, data: 0.000) loss: 0.211 
(epoch: 167, iters: 128, time: 0.161, data: 0.022) loss: 0.186 
(epoch: 167, iters: 208, time: 0.158, data: 0.000) loss: 0.278 
(epoch: 167, iters: 288, time: 0.157, data: 0.024) loss: 0.498 
(epoch: 167, iters: 368, time: 0.157, data: 0.000) loss: 0.197 
(epoch: 167, iters: 448, time: 0.156, data: 0.006) loss: 0.132 
(epoch: 167, iters: 528, time: 0.158, data: 0.009) loss: 0.106 
(epoch: 167, iters: 608, time: 0.162, data: 0.000) loss: 0.260 
(epoch: 167, iters: 688, time: 0.166, data: 0.033) loss: 0.073 
(epoch: 167, iters: 768, time: 0.161, data: 0.005) loss: 0.386 
(epoch: 167, iters: 848, time: 0.159, data: 0.000) loss: 0.296 
(epoch: 167, iters: 928, time: 0.160, data: 0.024) loss: 0.480 
(epoch: 167, iters: 1008, time: 0.161, data: 0.000) loss: 0.521 
(epoch: 167, iters: 1088, time: 0.161, data: 0.024) loss: 0.394 
(epoch: 167, iters: 1168, time: 0.159, data: 0.000) loss: 0.060 
(epoch: 167, iters: 1248, time: 0.159, data: 0.011) loss: 0.108 
(epoch: 167, iters: 1328, time: 0.160, data: 0.000) loss: 0.326 
(epoch: 167, iters: 1408, time: 0.161, data: 0.024) loss: 0.333 
(epoch: 167, iters: 1488, time: 0.160, data: 0.000) loss: 0.095 
(epoch: 167, iters: 1568, time: 0.159, data: 0.000) loss: 0.309 
(epoch: 167, iters: 1648, time: 0.160, data: 0.015) loss: 0.123 
(epoch: 167, iters: 1728, time: 0.160, data: 0.007) loss: 0.363 
(epoch: 167, iters: 1808, time: 0.160, data: 0.008) loss: 0.330 
(epoch: 167, iters: 1888, time: 0.158, data: 0.011) loss: 0.145 
(epoch: 167, iters: 1968, time: 0.159, data: 0.000) loss: 0.149 
(epoch: 167, iters: 2048, time: 0.157, data: 0.000) loss: 0.268 
(epoch: 167, iters: 2128, time: 0.158, data: 0.017) loss: 0.294 
(epoch: 167, iters: 2208, time: 0.159, data: 0.000) loss: 0.677 
(epoch: 167, iters: 2288, time: 0.160, data: 0.021) loss: 0.251 
(epoch: 167, iters: 2368, time: 0.160, data: 0.006) loss: 0.213 
(epoch: 167, iters: 2448, time: 0.161, data: 0.013) loss: 0.376 
(epoch: 167, iters: 2528, time: 0.158, data: 0.000) loss: 0.151 
(epoch: 167, iters: 2608, time: 0.160, data: 0.020) loss: 0.073 
(epoch: 167, iters: 2688, time: 0.159, data: 0.029) loss: 0.625 
(epoch: 167, iters: 2768, time: 0.160, data: 0.024) loss: 0.079 
(epoch: 167, iters: 2848, time: 0.161, data: 0.018) loss: 0.694 
(epoch: 167, iters: 2928, time: 0.161, data: 0.013) loss: 0.401 
(epoch: 167, iters: 3008, time: 0.162, data: 0.024) loss: 0.299 
(epoch: 167, iters: 3088, time: 0.160, data: 0.000) loss: 0.715 
(epoch: 167, iters: 3168, time: 0.160, data: 0.000) loss: 0.414 
(epoch: 167, iters: 3248, time: 0.160, data: 0.005) loss: 0.398 
(epoch: 167, iters: 3328, time: 0.157, data: 0.009) loss: 0.261 
(epoch: 167, iters: 3408, time: 0.160, data: 0.000) loss: 0.709 
(epoch: 167, iters: 3488, time: 0.163, data: 0.000) loss: 0.207 
(epoch: 167, iters: 3568, time: 0.163, data: 0.005) loss: 0.668 
(epoch: 167, iters: 3648, time: 0.159, data: 0.000) loss: 0.547 
(epoch: 167, iters: 3728, time: 0.158, data: 0.005) loss: 0.533 
(epoch: 167, iters: 3808, time: 0.159, data: 0.005) loss: 0.184 
(epoch: 167, iters: 3888, time: 0.157, data: 0.000) loss: 0.225 
(epoch: 167, iters: 3968, time: 0.157, data: 0.000) loss: 0.194 
saving the latest model (epoch 167, total_steps 1695888)
(epoch: 167, iters: 4048, time: 0.158, data: 0.016) loss: 0.103 
(epoch: 167, iters: 4128, time: 0.158, data: 0.000) loss: 0.331 
(epoch: 167, iters: 4208, time: 0.158, data: 0.008) loss: 0.328 
(epoch: 167, iters: 4288, time: 0.158, data: 0.000) loss: 0.054 
(epoch: 167, iters: 4368, time: 0.159, data: 0.006) loss: 0.465 
(epoch: 167, iters: 4448, time: 0.158, data: 0.000) loss: 0.302 
(epoch: 167, iters: 4528, time: 0.160, data: 0.006) loss: 0.200 
(epoch: 167, iters: 4608, time: 0.158, data: 0.000) loss: 0.192 
(epoch: 167, iters: 4688, time: 0.159, data: 0.000) loss: 0.173 
(epoch: 167, iters: 4768, time: 0.159, data: 0.000) loss: 0.259 
(epoch: 167, iters: 4848, time: 0.158, data: 0.005) loss: 0.462 
(epoch: 167, iters: 4928, time: 0.158, data: 0.000) loss: 0.311 
(epoch: 167, iters: 5008, time: 0.161, data: 0.000) loss: 0.372 
(epoch: 167, iters: 5088, time: 0.159, data: 0.000) loss: 0.055 
(epoch: 167, iters: 5168, time: 0.162, data: 0.008) loss: 0.514 
(epoch: 167, iters: 5248, time: 0.160, data: 0.000) loss: 0.250 
(epoch: 167, iters: 5328, time: 0.159, data: 0.005) loss: 0.389 
(epoch: 167, iters: 5408, time: 0.160, data: 0.000) loss: 0.143 
(epoch: 167, iters: 5488, time: 0.158, data: 0.006) loss: 0.127 
(epoch: 167, iters: 5568, time: 0.157, data: 0.012) loss: 0.219 
(epoch: 167, iters: 5648, time: 0.157, data: 0.000) loss: 0.262 
(epoch: 167, iters: 5728, time: 0.158, data: 0.000) loss: 0.312 
(epoch: 167, iters: 5808, time: 0.157, data: 0.017) loss: 0.137 
(epoch: 167, iters: 5888, time: 0.154, data: 0.006) loss: 0.202 
(epoch: 167, iters: 5968, time: 0.157, data: 0.000) loss: 0.241 
(epoch: 167, iters: 6048, time: 0.159, data: 0.011) loss: 0.815 
(epoch: 167, iters: 6128, time: 0.159, data: 0.000) loss: 0.239 
(epoch: 167, iters: 6208, time: 0.160, data: 0.000) loss: 0.278 
(epoch: 167, iters: 6288, time: 0.159, data: 0.018) loss: 0.176 
(epoch: 167, iters: 6368, time: 0.158, data: 0.009) loss: 0.250 
(epoch: 167, iters: 6448, time: 0.158, data: 0.000) loss: 0.164 
(epoch: 167, iters: 6528, time: 0.159, data: 0.008) loss: 0.184 
(epoch: 167, iters: 6608, time: 0.160, data: 0.008) loss: 0.046 
(epoch: 167, iters: 6688, time: 0.159, data: 0.000) loss: 0.479 
(epoch: 167, iters: 6768, time: 0.159, data: 0.000) loss: 0.191 
(epoch: 167, iters: 6848, time: 0.160, data: 0.008) loss: 0.246 
(epoch: 167, iters: 6928, time: 0.162, data: 0.000) loss: 0.070 
(epoch: 167, iters: 7008, time: 0.158, data: 0.000) loss: 0.483 
(epoch: 167, iters: 7088, time: 0.160, data: 0.005) loss: 0.077 
(epoch: 167, iters: 7168, time: 0.158, data: 0.010) loss: 0.091 
(epoch: 167, iters: 7248, time: 0.162, data: 0.000) loss: 0.181 
(epoch: 167, iters: 7328, time: 0.159, data: 0.000) loss: 0.614 
(epoch: 167, iters: 7408, time: 0.158, data: 0.015) loss: 0.041 
(epoch: 167, iters: 7488, time: 0.159, data: 0.000) loss: 0.396 
(epoch: 167, iters: 7568, time: 0.159, data: 0.008) loss: 0.122 
(epoch: 167, iters: 7648, time: 0.161, data: 0.000) loss: 0.107 
(epoch: 167, iters: 7728, time: 0.159, data: 0.000) loss: 0.305 
(epoch: 167, iters: 7808, time: 0.159, data: 0.011) loss: 0.330 
(epoch: 167, iters: 7888, time: 0.160, data: 0.000) loss: 0.127 
(epoch: 167, iters: 7968, time: 0.160, data: 0.015) loss: 0.315 
saving the latest model (epoch 167, total_steps 1699888)
(epoch: 167, iters: 8048, time: 0.161, data: 0.017) loss: 0.609 
(epoch: 167, iters: 8128, time: 0.158, data: 0.000) loss: 0.080 
(epoch: 167, iters: 8208, time: 0.160, data: 0.000) loss: 0.357 
(epoch: 167, iters: 8288, time: 0.160, data: 0.006) loss: 0.081 
(epoch: 167, iters: 8368, time: 0.160, data: 0.021) loss: 0.387 
(epoch: 167, iters: 8448, time: 0.160, data: 0.000) loss: 0.205 
(epoch: 167, iters: 8528, time: 0.161, data: 0.025) loss: 0.249 
(epoch: 167, iters: 8608, time: 0.159, data: 0.000) loss: 0.090 
(epoch: 167, iters: 8688, time: 0.160, data: 0.000) loss: 0.097 
(epoch: 167, iters: 8768, time: 0.164, data: 0.005) loss: 0.247 
(epoch: 167, iters: 8848, time: 0.161, data: 0.000) loss: 0.092 
(epoch: 167, iters: 8928, time: 0.162, data: 0.021) loss: 0.366 
(epoch: 167, iters: 9008, time: 0.161, data: 0.006) loss: 0.118 
(epoch: 167, iters: 9088, time: 0.162, data: 0.011) loss: 0.229 
(epoch: 167, iters: 9168, time: 0.160, data: 0.000) loss: 0.200 
(epoch: 167, iters: 9248, time: 0.161, data: 0.015) loss: 0.038 
(epoch: 167, iters: 9328, time: 0.159, data: 0.000) loss: 0.531 
(epoch: 167, iters: 9408, time: 0.160, data: 0.000) loss: 0.228 
(epoch: 167, iters: 9488, time: 0.163, data: 0.000) loss: 0.431 
(epoch: 167, iters: 9568, time: 0.160, data: 0.000) loss: 0.284 
(epoch: 167, iters: 9648, time: 0.159, data: 0.006) loss: 0.485 
(epoch: 167, iters: 9728, time: 0.157, data: 0.010) loss: 0.490 
(epoch: 167, iters: 9808, time: 0.159, data: 0.000) loss: 0.519 
(epoch: 167, iters: 9888, time: 0.158, data: 0.005) loss: 0.211 
(epoch: 167, iters: 9968, time: 0.159, data: 0.010) loss: 0.697 
(epoch: 167, iters: 10048, time: 0.158, data: 0.005) loss: 0.160 
(epoch: 167, iters: 10128, time: 0.158, data: 0.005) loss: 0.122 
saving the model at the end of epoch 167, iters 1702064
End of epoch 167 / 200 	 Time Taken: 1627 sec
learning rate = 0.0000634
(epoch: 168, iters: 16, time: 0.178, data: 0.009) loss: 0.150 
saving the latest model (epoch 168, total_steps 1702080)
(epoch: 168, iters: 96, time: 0.161, data: 0.000) loss: 0.197 
(epoch: 168, iters: 176, time: 0.159, data: 0.025) loss: 0.114 
(epoch: 168, iters: 256, time: 0.158, data: 0.005) loss: 0.529 
(epoch: 168, iters: 336, time: 0.161, data: 0.010) loss: 0.187 
(epoch: 168, iters: 416, time: 0.163, data: 0.000) loss: 0.198 
(epoch: 168, iters: 496, time: 0.163, data: 0.009) loss: 0.185 
(epoch: 168, iters: 576, time: 0.160, data: 0.000) loss: 0.586 
(epoch: 168, iters: 656, time: 0.158, data: 0.022) loss: 0.326 
(epoch: 168, iters: 736, time: 0.160, data: 0.000) loss: 0.230 
(epoch: 168, iters: 816, time: 0.160, data: 0.000) loss: 0.428 
(epoch: 168, iters: 896, time: 0.161, data: 0.028) loss: 0.423 
(epoch: 168, iters: 976, time: 0.161, data: 0.005) loss: 0.116 
(epoch: 168, iters: 1056, time: 0.161, data: 0.024) loss: 0.317 
(epoch: 168, iters: 1136, time: 0.162, data: 0.000) loss: 0.279 
(epoch: 168, iters: 1216, time: 0.161, data: 0.009) loss: 0.207 
(epoch: 168, iters: 1296, time: 0.161, data: 0.000) loss: 0.071 
(epoch: 168, iters: 1376, time: 0.160, data: 0.013) loss: 0.447 
(epoch: 168, iters: 1456, time: 0.162, data: 0.000) loss: 0.090 
(epoch: 168, iters: 1536, time: 0.160, data: 0.023) loss: 0.128 
(epoch: 168, iters: 1616, time: 0.161, data: 0.000) loss: 0.227 
(epoch: 168, iters: 1696, time: 0.161, data: 0.005) loss: 0.365 
(epoch: 168, iters: 1776, time: 0.160, data: 0.000) loss: 0.443 
(epoch: 168, iters: 1856, time: 0.160, data: 0.008) loss: 0.470 
(epoch: 168, iters: 1936, time: 0.162, data: 0.000) loss: 0.099 
(epoch: 168, iters: 2016, time: 0.163, data: 0.000) loss: 0.223 
(epoch: 168, iters: 2096, time: 0.161, data: 0.020) loss: 0.291 
(epoch: 168, iters: 2176, time: 0.163, data: 0.008) loss: 0.087 
(epoch: 168, iters: 2256, time: 0.160, data: 0.005) loss: 0.331 
(epoch: 168, iters: 2336, time: 0.158, data: 0.000) loss: 0.447 
(epoch: 168, iters: 2416, time: 0.160, data: 0.008) loss: 0.080 
(epoch: 168, iters: 2496, time: 0.160, data: 0.000) loss: 0.961 
(epoch: 168, iters: 2576, time: 0.161, data: 0.022) loss: 0.363 
(epoch: 168, iters: 2656, time: 0.161, data: 0.000) loss: 0.111 
(epoch: 168, iters: 2736, time: 0.162, data: 0.013) loss: 0.151 
(epoch: 168, iters: 2816, time: 0.159, data: 0.014) loss: 0.267 
(epoch: 168, iters: 2896, time: 0.159, data: 0.021) loss: 0.272 
(epoch: 168, iters: 2976, time: 0.161, data: 0.000) loss: 0.143 
(epoch: 168, iters: 3056, time: 0.161, data: 0.000) loss: 0.223 
(epoch: 168, iters: 3136, time: 0.161, data: 0.000) loss: 0.237 
(epoch: 168, iters: 3216, time: 0.159, data: 0.005) loss: 0.300 
(epoch: 168, iters: 3296, time: 0.160, data: 0.000) loss: 0.202 
(epoch: 168, iters: 3376, time: 0.160, data: 0.016) loss: 0.422 
(epoch: 168, iters: 3456, time: 0.159, data: 0.014) loss: 0.279 
(epoch: 168, iters: 3536, time: 0.162, data: 0.000) loss: 0.304 
(epoch: 168, iters: 3616, time: 0.162, data: 0.009) loss: 0.321 
(epoch: 168, iters: 3696, time: 0.160, data: 0.000) loss: 0.295 
(epoch: 168, iters: 3776, time: 0.159, data: 0.005) loss: 0.687 
(epoch: 168, iters: 3856, time: 0.160, data: 0.000) loss: 0.289 
(epoch: 168, iters: 3936, time: 0.160, data: 0.008) loss: 0.284 
(epoch: 168, iters: 4016, time: 0.159, data: 0.000) loss: 0.284 
saving the latest model (epoch 168, total_steps 1706080)
(epoch: 168, iters: 4096, time: 0.160, data: 0.006) loss: 0.136 
(epoch: 168, iters: 4176, time: 0.161, data: 0.000) loss: 0.401 
(epoch: 168, iters: 4256, time: 0.159, data: 0.005) loss: 0.477 
(epoch: 168, iters: 4336, time: 0.158, data: 0.000) loss: 0.126 
(epoch: 168, iters: 4416, time: 0.157, data: 0.000) loss: 0.519 
(epoch: 168, iters: 4496, time: 0.160, data: 0.034) loss: 0.060 
(epoch: 168, iters: 4576, time: 0.158, data: 0.000) loss: 0.412 
(epoch: 168, iters: 4656, time: 0.158, data: 0.000) loss: 0.292 
(epoch: 168, iters: 4736, time: 0.158, data: 0.020) loss: 0.165 
(epoch: 168, iters: 4816, time: 0.159, data: 0.000) loss: 0.294 
(epoch: 168, iters: 4896, time: 0.159, data: 0.000) loss: 0.313 
(epoch: 168, iters: 4976, time: 0.160, data: 0.005) loss: 0.167 
(epoch: 168, iters: 5056, time: 0.158, data: 0.000) loss: 0.069 
(epoch: 168, iters: 5136, time: 0.159, data: 0.008) loss: 0.171 
(epoch: 168, iters: 5216, time: 0.158, data: 0.000) loss: 0.639 
(epoch: 168, iters: 5296, time: 0.158, data: 0.009) loss: 0.356 
(epoch: 168, iters: 5376, time: 0.160, data: 0.000) loss: 0.414 
(epoch: 168, iters: 5456, time: 0.159, data: 0.000) loss: 0.201 
(epoch: 168, iters: 5536, time: 0.158, data: 0.005) loss: 0.170 
(epoch: 168, iters: 5616, time: 0.160, data: 0.000) loss: 0.139 
(epoch: 168, iters: 5696, time: 0.159, data: 0.005) loss: 0.373 
(epoch: 168, iters: 5776, time: 0.160, data: 0.000) loss: 0.338 
(epoch: 168, iters: 5856, time: 0.161, data: 0.000) loss: 0.358 
(epoch: 168, iters: 5936, time: 0.163, data: 0.010) loss: 0.337 
(epoch: 168, iters: 6016, time: 0.160, data: 0.005) loss: 0.146 
(epoch: 168, iters: 6096, time: 0.160, data: 0.000) loss: 0.346 
(epoch: 168, iters: 6176, time: 0.160, data: 0.005) loss: 0.254 
(epoch: 168, iters: 6256, time: 0.161, data: 0.000) loss: 0.249 
(epoch: 168, iters: 6336, time: 0.160, data: 0.000) loss: 0.144 
(epoch: 168, iters: 6416, time: 0.163, data: 0.000) loss: 0.171 
(epoch: 168, iters: 6496, time: 0.159, data: 0.008) loss: 0.465 
(epoch: 168, iters: 6576, time: 0.160, data: 0.008) loss: 0.280 
(epoch: 168, iters: 6656, time: 0.159, data: 0.000) loss: 0.219 
(epoch: 168, iters: 6736, time: 0.161, data: 0.030) loss: 0.371 
(epoch: 168, iters: 6816, time: 0.160, data: 0.000) loss: 0.188 
(epoch: 168, iters: 6896, time: 0.160, data: 0.019) loss: 0.457 
(epoch: 168, iters: 6976, time: 0.159, data: 0.000) loss: 0.172 
(epoch: 168, iters: 7056, time: 0.160, data: 0.017) loss: 0.197 
(epoch: 168, iters: 7136, time: 0.159, data: 0.000) loss: 0.098 
(epoch: 168, iters: 7216, time: 0.162, data: 0.000) loss: 0.143 
(epoch: 168, iters: 7296, time: 0.162, data: 0.000) loss: 0.056 
(epoch: 168, iters: 7376, time: 0.158, data: 0.008) loss: 0.914 
(epoch: 168, iters: 7456, time: 0.160, data: 0.028) loss: 0.175 
(epoch: 168, iters: 7536, time: 0.160, data: 0.000) loss: 0.146 
(epoch: 168, iters: 7616, time: 0.161, data: 0.000) loss: 0.185 
(epoch: 168, iters: 7696, time: 0.160, data: 0.018) loss: 0.213 
(epoch: 168, iters: 7776, time: 0.160, data: 0.006) loss: 0.413 
(epoch: 168, iters: 7856, time: 0.159, data: 0.005) loss: 0.198 
(epoch: 168, iters: 7936, time: 0.159, data: 0.020) loss: 0.179 
(epoch: 168, iters: 8016, time: 0.161, data: 0.000) loss: 0.351 
saving the latest model (epoch 168, total_steps 1710080)
(epoch: 168, iters: 8096, time: 0.161, data: 0.005) loss: 0.160 
(epoch: 168, iters: 8176, time: 0.159, data: 0.000) loss: 0.147 
(epoch: 168, iters: 8256, time: 0.161, data: 0.030) loss: 0.229 
(epoch: 168, iters: 8336, time: 0.159, data: 0.000) loss: 0.092 
(epoch: 168, iters: 8416, time: 0.160, data: 0.000) loss: 0.548 
(epoch: 168, iters: 8496, time: 0.160, data: 0.006) loss: 0.383 
(epoch: 168, iters: 8576, time: 0.158, data: 0.000) loss: 0.030 
(epoch: 168, iters: 8656, time: 0.160, data: 0.031) loss: 0.187 
(epoch: 168, iters: 8736, time: 0.160, data: 0.000) loss: 0.164 
(epoch: 168, iters: 8816, time: 0.161, data: 0.000) loss: 0.239 
(epoch: 168, iters: 8896, time: 0.160, data: 0.011) loss: 0.155 
(epoch: 168, iters: 8976, time: 0.161, data: 0.009) loss: 0.232 
(epoch: 168, iters: 9056, time: 0.160, data: 0.000) loss: 0.181 
(epoch: 168, iters: 9136, time: 0.161, data: 0.000) loss: 0.340 
(epoch: 168, iters: 9216, time: 0.160, data: 0.000) loss: 0.167 
(epoch: 168, iters: 9296, time: 0.160, data: 0.008) loss: 0.043 
(epoch: 168, iters: 9376, time: 0.159, data: 0.008) loss: 0.375 
(epoch: 168, iters: 9456, time: 0.158, data: 0.000) loss: 0.334 
(epoch: 168, iters: 9536, time: 0.158, data: 0.005) loss: 0.440 
(epoch: 168, iters: 9616, time: 0.161, data: 0.005) loss: 0.611 
(epoch: 168, iters: 9696, time: 0.159, data: 0.000) loss: 0.155 
(epoch: 168, iters: 9776, time: 0.160, data: 0.013) loss: 0.116 
(epoch: 168, iters: 9856, time: 0.160, data: 0.000) loss: 0.142 
(epoch: 168, iters: 9936, time: 0.161, data: 0.022) loss: 0.214 
(epoch: 168, iters: 10016, time: 0.160, data: 0.000) loss: 0.162 
(epoch: 168, iters: 10096, time: 0.163, data: 0.000) loss: 0.230 
(epoch: 168, iters: 10176, time: 0.159, data: 0.000) loss: 0.185 
saving the model at the end of epoch 168, iters 1712256
End of epoch 168 / 200 	 Time Taken: 1632 sec
learning rate = 0.0000614
saving the latest model (epoch 169, total_steps 1712272)
(epoch: 169, iters: 64, time: 0.162, data: 0.003) loss: 0.247 
(epoch: 169, iters: 144, time: 0.158, data: 0.015) loss: 0.198 
(epoch: 169, iters: 224, time: 0.162, data: 0.034) loss: 0.230 
(epoch: 169, iters: 304, time: 0.160, data: 0.000) loss: 0.154 
(epoch: 169, iters: 384, time: 0.157, data: 0.011) loss: 0.676 
(epoch: 169, iters: 464, time: 0.159, data: 0.000) loss: 0.150 
(epoch: 169, iters: 544, time: 0.159, data: 0.000) loss: 0.505 
(epoch: 169, iters: 624, time: 0.158, data: 0.016) loss: 0.277 
(epoch: 169, iters: 704, time: 0.157, data: 0.006) loss: 0.253 
(epoch: 169, iters: 784, time: 0.159, data: 0.005) loss: 0.341 
(epoch: 169, iters: 864, time: 0.159, data: 0.005) loss: 0.375 
(epoch: 169, iters: 944, time: 0.157, data: 0.000) loss: 0.178 
(epoch: 169, iters: 1024, time: 0.159, data: 0.019) loss: 0.061 
(epoch: 169, iters: 1104, time: 0.157, data: 0.000) loss: 0.164 
(epoch: 169, iters: 1184, time: 0.158, data: 0.017) loss: 0.220 
(epoch: 169, iters: 1264, time: 0.157, data: 0.005) loss: 0.100 
(epoch: 169, iters: 1344, time: 0.159, data: 0.024) loss: 0.086 
(epoch: 169, iters: 1424, time: 0.159, data: 0.000) loss: 0.160 
(epoch: 169, iters: 1504, time: 0.159, data: 0.000) loss: 0.320 
(epoch: 169, iters: 1584, time: 0.159, data: 0.006) loss: 0.136 
(epoch: 169, iters: 1664, time: 0.158, data: 0.000) loss: 0.227 
(epoch: 169, iters: 1744, time: 0.160, data: 0.015) loss: 0.139 
(epoch: 169, iters: 1824, time: 0.159, data: 0.025) loss: 0.387 
(epoch: 169, iters: 1904, time: 0.158, data: 0.000) loss: 0.385 
(epoch: 169, iters: 1984, time: 0.158, data: 0.000) loss: 0.194 
(epoch: 169, iters: 2064, time: 0.157, data: 0.015) loss: 0.357 
(epoch: 169, iters: 2144, time: 0.159, data: 0.000) loss: 0.069 
(epoch: 169, iters: 2224, time: 0.159, data: 0.000) loss: 0.253 
(epoch: 169, iters: 2304, time: 0.162, data: 0.027) loss: 0.172 
(epoch: 169, iters: 2384, time: 0.162, data: 0.000) loss: 0.483 
(epoch: 169, iters: 2464, time: 0.159, data: 0.005) loss: 0.284 
(epoch: 169, iters: 2544, time: 0.159, data: 0.000) loss: 0.156 
(epoch: 169, iters: 2624, time: 0.159, data: 0.013) loss: 0.307 
(epoch: 169, iters: 2704, time: 0.160, data: 0.029) loss: 0.611 
(epoch: 169, iters: 2784, time: 0.159, data: 0.000) loss: 0.149 
(epoch: 169, iters: 2864, time: 0.157, data: 0.005) loss: 0.311 
(epoch: 169, iters: 2944, time: 0.157, data: 0.000) loss: 0.156 
(epoch: 169, iters: 3024, time: 0.157, data: 0.000) loss: 0.104 
(epoch: 169, iters: 3104, time: 0.158, data: 0.005) loss: 0.172 
(epoch: 169, iters: 3184, time: 0.158, data: 0.014) loss: 0.390 
(epoch: 169, iters: 3264, time: 0.162, data: 0.000) loss: 0.147 
(epoch: 169, iters: 3344, time: 0.164, data: 0.000) loss: 0.414 
(epoch: 169, iters: 3424, time: 0.160, data: 0.005) loss: 0.396 
(epoch: 169, iters: 3504, time: 0.161, data: 0.000) loss: 0.230 
(epoch: 169, iters: 3584, time: 0.161, data: 0.032) loss: 0.216 
(epoch: 169, iters: 3664, time: 0.160, data: 0.000) loss: 0.396 
(epoch: 169, iters: 3744, time: 0.160, data: 0.010) loss: 0.180 
(epoch: 169, iters: 3824, time: 0.160, data: 0.000) loss: 0.242 
(epoch: 169, iters: 3904, time: 0.161, data: 0.010) loss: 0.057 
(epoch: 169, iters: 3984, time: 0.160, data: 0.000) loss: 0.425 
saving the latest model (epoch 169, total_steps 1716272)
(epoch: 169, iters: 4064, time: 0.160, data: 0.014) loss: 0.287 
(epoch: 169, iters: 4144, time: 0.160, data: 0.000) loss: 0.174 
(epoch: 169, iters: 4224, time: 0.158, data: 0.013) loss: 0.363 
(epoch: 169, iters: 4304, time: 0.160, data: 0.000) loss: 0.031 
(epoch: 169, iters: 4384, time: 0.159, data: 0.000) loss: 0.116 
(epoch: 169, iters: 4464, time: 0.160, data: 0.005) loss: 0.124 
(epoch: 169, iters: 4544, time: 0.160, data: 0.000) loss: 0.057 
(epoch: 169, iters: 4624, time: 0.159, data: 0.000) loss: 0.343 
(epoch: 169, iters: 4704, time: 0.161, data: 0.015) loss: 0.071 
(epoch: 169, iters: 4784, time: 0.159, data: 0.014) loss: 0.197 
(epoch: 169, iters: 4864, time: 0.157, data: 0.009) loss: 0.424 
(epoch: 169, iters: 4944, time: 0.159, data: 0.000) loss: 0.375 
(epoch: 169, iters: 5024, time: 0.160, data: 0.019) loss: 0.185 
(epoch: 169, iters: 5104, time: 0.158, data: 0.000) loss: 0.458 
(epoch: 169, iters: 5184, time: 0.159, data: 0.000) loss: 0.183 
(epoch: 169, iters: 5264, time: 0.158, data: 0.000) loss: 0.294 
(epoch: 169, iters: 5344, time: 0.159, data: 0.005) loss: 0.204 
(epoch: 169, iters: 5424, time: 0.160, data: 0.000) loss: 0.162 
(epoch: 169, iters: 5504, time: 0.156, data: 0.014) loss: 0.231 
(epoch: 169, iters: 5584, time: 0.158, data: 0.015) loss: 0.389 
(epoch: 169, iters: 5664, time: 0.159, data: 0.000) loss: 0.202 
(epoch: 169, iters: 5744, time: 0.157, data: 0.008) loss: 0.263 
(epoch: 169, iters: 5824, time: 0.157, data: 0.000) loss: 0.341 
(epoch: 169, iters: 5904, time: 0.157, data: 0.020) loss: 0.384 
(epoch: 169, iters: 5984, time: 0.159, data: 0.005) loss: 0.227 
(epoch: 169, iters: 6064, time: 0.158, data: 0.000) loss: 0.550 
(epoch: 169, iters: 6144, time: 0.157, data: 0.000) loss: 0.161 
(epoch: 169, iters: 6224, time: 0.158, data: 0.000) loss: 0.316 
(epoch: 169, iters: 6304, time: 0.157, data: 0.000) loss: 0.066 
(epoch: 169, iters: 6384, time: 0.159, data: 0.015) loss: 0.400 
(epoch: 169, iters: 6464, time: 0.157, data: 0.010) loss: 0.440 
(epoch: 169, iters: 6544, time: 0.159, data: 0.000) loss: 0.426 
(epoch: 169, iters: 6624, time: 0.160, data: 0.000) loss: 0.325 
(epoch: 169, iters: 6704, time: 0.159, data: 0.027) loss: 0.178 
(epoch: 169, iters: 6784, time: 0.159, data: 0.000) loss: 0.215 
(epoch: 169, iters: 6864, time: 0.158, data: 0.013) loss: 0.106 
(epoch: 169, iters: 6944, time: 0.158, data: 0.005) loss: 0.379 
(epoch: 169, iters: 7024, time: 0.160, data: 0.000) loss: 0.166 
(epoch: 169, iters: 7104, time: 0.158, data: 0.000) loss: 0.495 
(epoch: 169, iters: 7184, time: 0.158, data: 0.000) loss: 0.097 
(epoch: 169, iters: 7264, time: 0.159, data: 0.000) loss: 0.658 
(epoch: 169, iters: 7344, time: 0.158, data: 0.024) loss: 0.633 
(epoch: 169, iters: 7424, time: 0.157, data: 0.000) loss: 0.227 
(epoch: 169, iters: 7504, time: 0.158, data: 0.000) loss: 0.334 
(epoch: 169, iters: 7584, time: 0.159, data: 0.000) loss: 0.484 
(epoch: 169, iters: 7664, time: 0.158, data: 0.024) loss: 0.042 
(epoch: 169, iters: 7744, time: 0.157, data: 0.000) loss: 0.217 
(epoch: 169, iters: 7824, time: 0.158, data: 0.006) loss: 0.450 
(epoch: 169, iters: 7904, time: 0.159, data: 0.006) loss: 0.495 
(epoch: 169, iters: 7984, time: 0.160, data: 0.000) loss: 0.464 
saving the latest model (epoch 169, total_steps 1720272)
(epoch: 169, iters: 8064, time: 0.159, data: 0.005) loss: 0.235 
(epoch: 169, iters: 8144, time: 0.161, data: 0.000) loss: 0.580 
(epoch: 169, iters: 8224, time: 0.159, data: 0.013) loss: 0.076 
(epoch: 169, iters: 8304, time: 0.160, data: 0.000) loss: 0.499 
(epoch: 169, iters: 8384, time: 0.159, data: 0.000) loss: 0.402 
(epoch: 169, iters: 8464, time: 0.159, data: 0.000) loss: 0.115 
(epoch: 169, iters: 8544, time: 0.157, data: 0.000) loss: 0.405 
(epoch: 169, iters: 8624, time: 0.161, data: 0.006) loss: 0.550 
(epoch: 169, iters: 8704, time: 0.158, data: 0.000) loss: 0.136 
(epoch: 169, iters: 8784, time: 0.160, data: 0.000) loss: 0.372 
(epoch: 169, iters: 8864, time: 0.162, data: 0.000) loss: 0.219 
(epoch: 169, iters: 8944, time: 0.159, data: 0.039) loss: 0.244 
(epoch: 169, iters: 9024, time: 0.160, data: 0.000) loss: 0.070 
(epoch: 169, iters: 9104, time: 0.160, data: 0.007) loss: 0.501 
(epoch: 169, iters: 9184, time: 0.160, data: 0.000) loss: 0.164 
(epoch: 169, iters: 9264, time: 0.159, data: 0.006) loss: 0.093 
(epoch: 169, iters: 9344, time: 0.158, data: 0.000) loss: 0.332 
(epoch: 169, iters: 9424, time: 0.162, data: 0.000) loss: 0.209 
(epoch: 169, iters: 9504, time: 0.161, data: 0.023) loss: 0.107 
(epoch: 169, iters: 9584, time: 0.159, data: 0.000) loss: 0.298 
(epoch: 169, iters: 9664, time: 0.159, data: 0.005) loss: 0.197 
(epoch: 169, iters: 9744, time: 0.158, data: 0.000) loss: 0.306 
(epoch: 169, iters: 9824, time: 0.158, data: 0.010) loss: 0.465 
(epoch: 169, iters: 9904, time: 0.158, data: 0.000) loss: 0.131 
(epoch: 169, iters: 9984, time: 0.157, data: 0.000) loss: 0.527 
(epoch: 169, iters: 10064, time: 0.161, data: 0.000) loss: 0.162 
(epoch: 169, iters: 10144, time: 0.159, data: 0.000) loss: 0.411 
saving the model at the end of epoch 169, iters 1722448
End of epoch 169 / 200 	 Time Taken: 1622 sec
learning rate = 0.0000594
saving the latest model (epoch 170, total_steps 1722464)
(epoch: 170, iters: 32, time: 0.166, data: 0.005) loss: 0.240 
(epoch: 170, iters: 112, time: 0.159, data: 0.000) loss: 0.213 
(epoch: 170, iters: 192, time: 0.158, data: 0.023) loss: 0.408 
(epoch: 170, iters: 272, time: 0.159, data: 0.000) loss: 0.352 
(epoch: 170, iters: 352, time: 0.159, data: 0.026) loss: 0.293 
(epoch: 170, iters: 432, time: 0.158, data: 0.000) loss: 0.333 
(epoch: 170, iters: 512, time: 0.159, data: 0.008) loss: 0.074 
(epoch: 170, iters: 592, time: 0.162, data: 0.000) loss: 0.323 
(epoch: 170, iters: 672, time: 0.157, data: 0.024) loss: 0.201 
(epoch: 170, iters: 752, time: 0.158, data: 0.000) loss: 0.456 
(epoch: 170, iters: 832, time: 0.160, data: 0.028) loss: 0.371 
(epoch: 170, iters: 912, time: 0.159, data: 0.000) loss: 0.262 
(epoch: 170, iters: 992, time: 0.160, data: 0.014) loss: 0.060 
(epoch: 170, iters: 1072, time: 0.161, data: 0.000) loss: 0.231 
(epoch: 170, iters: 1152, time: 0.159, data: 0.032) loss: 0.410 
(epoch: 170, iters: 1232, time: 0.159, data: 0.000) loss: 0.283 
(epoch: 170, iters: 1312, time: 0.159, data: 0.000) loss: 0.401 
(epoch: 170, iters: 1392, time: 0.161, data: 0.028) loss: 0.247 
(epoch: 170, iters: 1472, time: 0.160, data: 0.000) loss: 0.404 
(epoch: 170, iters: 1552, time: 0.159, data: 0.000) loss: 0.677 
(epoch: 170, iters: 1632, time: 0.159, data: 0.000) loss: 0.192 
(epoch: 170, iters: 1712, time: 0.159, data: 0.005) loss: 0.072 
(epoch: 170, iters: 1792, time: 0.159, data: 0.005) loss: 0.231 
(epoch: 170, iters: 1872, time: 0.160, data: 0.000) loss: 0.320 
(epoch: 170, iters: 1952, time: 0.158, data: 0.000) loss: 0.534 
(epoch: 170, iters: 2032, time: 0.158, data: 0.000) loss: 0.091 
(epoch: 170, iters: 2112, time: 0.159, data: 0.000) loss: 0.106 
(epoch: 170, iters: 2192, time: 0.159, data: 0.023) loss: 0.264 
(epoch: 170, iters: 2272, time: 0.161, data: 0.000) loss: 0.115 
(epoch: 170, iters: 2352, time: 0.160, data: 0.000) loss: 0.388 
(epoch: 170, iters: 2432, time: 0.160, data: 0.000) loss: 0.321 
(epoch: 170, iters: 2512, time: 0.160, data: 0.000) loss: 0.405 
(epoch: 170, iters: 2592, time: 0.158, data: 0.000) loss: 0.488 
(epoch: 170, iters: 2672, time: 0.160, data: 0.000) loss: 0.042 
(epoch: 170, iters: 2752, time: 0.159, data: 0.013) loss: 0.800 
(epoch: 170, iters: 2832, time: 0.159, data: 0.008) loss: 0.170 
(epoch: 170, iters: 2912, time: 0.160, data: 0.000) loss: 0.215 
(epoch: 170, iters: 2992, time: 0.159, data: 0.008) loss: 0.241 
(epoch: 170, iters: 3072, time: 0.158, data: 0.000) loss: 0.699 
(epoch: 170, iters: 3152, time: 0.161, data: 0.005) loss: 0.177 
(epoch: 170, iters: 3232, time: 0.159, data: 0.017) loss: 0.104 
(epoch: 170, iters: 3312, time: 0.161, data: 0.000) loss: 0.166 
(epoch: 170, iters: 3392, time: 0.159, data: 0.025) loss: 0.102 
(epoch: 170, iters: 3472, time: 0.158, data: 0.000) loss: 0.254 
(epoch: 170, iters: 3552, time: 0.159, data: 0.009) loss: 0.079 
(epoch: 170, iters: 3632, time: 0.159, data: 0.000) loss: 0.150 
(epoch: 170, iters: 3712, time: 0.159, data: 0.008) loss: 0.413 
(epoch: 170, iters: 3792, time: 0.158, data: 0.000) loss: 0.749 
(epoch: 170, iters: 3872, time: 0.158, data: 0.008) loss: 0.170 
(epoch: 170, iters: 3952, time: 0.159, data: 0.024) loss: 0.104 
saving the latest model (epoch 170, total_steps 1726464)
(epoch: 170, iters: 4032, time: 0.158, data: 0.000) loss: 0.177 
(epoch: 170, iters: 4112, time: 0.159, data: 0.000) loss: 0.384 
(epoch: 170, iters: 4192, time: 0.158, data: 0.000) loss: 0.066 
(epoch: 170, iters: 4272, time: 0.158, data: 0.015) loss: 0.226 
(epoch: 170, iters: 4352, time: 0.159, data: 0.000) loss: 0.385 
(epoch: 170, iters: 4432, time: 0.160, data: 0.009) loss: 0.292 
(epoch: 170, iters: 4512, time: 0.159, data: 0.000) loss: 0.643 
(epoch: 170, iters: 4592, time: 0.158, data: 0.013) loss: 0.113 
(epoch: 170, iters: 4672, time: 0.157, data: 0.000) loss: 0.187 
(epoch: 170, iters: 4752, time: 0.160, data: 0.005) loss: 0.187 
(epoch: 170, iters: 4832, time: 0.161, data: 0.005) loss: 0.258 
(epoch: 170, iters: 4912, time: 0.157, data: 0.000) loss: 0.279 
(epoch: 170, iters: 4992, time: 0.159, data: 0.000) loss: 0.219 
(epoch: 170, iters: 5072, time: 0.158, data: 0.020) loss: 0.574 
(epoch: 170, iters: 5152, time: 0.160, data: 0.008) loss: 0.296 
(epoch: 170, iters: 5232, time: 0.159, data: 0.000) loss: 0.043 
(epoch: 170, iters: 5312, time: 0.159, data: 0.000) loss: 0.777 
(epoch: 170, iters: 5392, time: 0.160, data: 0.000) loss: 0.166 
(epoch: 170, iters: 5472, time: 0.157, data: 0.005) loss: 0.266 
(epoch: 170, iters: 5552, time: 0.161, data: 0.000) loss: 0.222 
(epoch: 170, iters: 5632, time: 0.161, data: 0.013) loss: 0.184 
(epoch: 170, iters: 5712, time: 0.161, data: 0.000) loss: 0.361 
(epoch: 170, iters: 5792, time: 0.160, data: 0.008) loss: 0.044 
(epoch: 170, iters: 5872, time: 0.159, data: 0.000) loss: 0.645 
(epoch: 170, iters: 5952, time: 0.160, data: 0.000) loss: 0.046 
(epoch: 170, iters: 6032, time: 0.161, data: 0.031) loss: 0.479 
(epoch: 170, iters: 6112, time: 0.158, data: 0.000) loss: 0.205 
(epoch: 170, iters: 6192, time: 0.158, data: 0.023) loss: 0.107 
(epoch: 170, iters: 6272, time: 0.159, data: 0.000) loss: 0.278 
(epoch: 170, iters: 6352, time: 0.159, data: 0.000) loss: 0.404 
(epoch: 170, iters: 6432, time: 0.159, data: 0.000) loss: 0.458 
(epoch: 170, iters: 6512, time: 0.161, data: 0.000) loss: 0.050 
(epoch: 170, iters: 6592, time: 0.159, data: 0.000) loss: 0.445 
(epoch: 170, iters: 6672, time: 0.159, data: 0.006) loss: 0.403 
(epoch: 170, iters: 6752, time: 0.159, data: 0.000) loss: 0.349 
(epoch: 170, iters: 6832, time: 0.157, data: 0.014) loss: 0.234 
(epoch: 170, iters: 6912, time: 0.158, data: 0.000) loss: 0.239 
(epoch: 170, iters: 6992, time: 0.167, data: 0.013) loss: 0.121 
(epoch: 170, iters: 7072, time: 0.160, data: 0.000) loss: 0.385 
(epoch: 170, iters: 7152, time: 0.162, data: 0.016) loss: 0.507 
(epoch: 170, iters: 7232, time: 0.160, data: 0.000) loss: 0.127 
(epoch: 170, iters: 7312, time: 0.159, data: 0.000) loss: 0.325 
(epoch: 170, iters: 7392, time: 0.160, data: 0.024) loss: 0.476 
(epoch: 170, iters: 7472, time: 0.160, data: 0.000) loss: 0.186 
(epoch: 170, iters: 7552, time: 0.160, data: 0.010) loss: 0.091 
(epoch: 170, iters: 7632, time: 0.159, data: 0.000) loss: 0.360 
(epoch: 170, iters: 7712, time: 0.160, data: 0.000) loss: 0.182 
(epoch: 170, iters: 7792, time: 0.160, data: 0.000) loss: 0.406 
(epoch: 170, iters: 7872, time: 0.160, data: 0.000) loss: 0.393 
(epoch: 170, iters: 7952, time: 0.159, data: 0.006) loss: 0.092 
saving the latest model (epoch 170, total_steps 1730464)
(epoch: 170, iters: 8032, time: 0.163, data: 0.008) loss: 0.198 
(epoch: 170, iters: 8112, time: 0.157, data: 0.000) loss: 0.268 
(epoch: 170, iters: 8192, time: 0.159, data: 0.011) loss: 0.190 
(epoch: 170, iters: 8272, time: 0.159, data: 0.000) loss: 0.263 
(epoch: 170, iters: 8352, time: 0.159, data: 0.005) loss: 0.143 
(epoch: 170, iters: 8432, time: 0.158, data: 0.000) loss: 0.269 
(epoch: 170, iters: 8512, time: 0.160, data: 0.005) loss: 0.600 
(epoch: 170, iters: 8592, time: 0.159, data: 0.021) loss: 0.197 
(epoch: 170, iters: 8672, time: 0.159, data: 0.000) loss: 0.108 
(epoch: 170, iters: 8752, time: 0.160, data: 0.008) loss: 0.649 
(epoch: 170, iters: 8832, time: 0.158, data: 0.000) loss: 0.465 
(epoch: 170, iters: 8912, time: 0.161, data: 0.000) loss: 0.245 
(epoch: 170, iters: 8992, time: 0.157, data: 0.040) loss: 0.188 
(epoch: 170, iters: 9072, time: 0.160, data: 0.000) loss: 0.530 
(epoch: 170, iters: 9152, time: 0.159, data: 0.000) loss: 0.170 
(epoch: 170, iters: 9232, time: 0.159, data: 0.000) loss: 0.137 
(epoch: 170, iters: 9312, time: 0.159, data: 0.006) loss: 0.093 
(epoch: 170, iters: 9392, time: 0.160, data: 0.000) loss: 0.240 
(epoch: 170, iters: 9472, time: 0.160, data: 0.008) loss: 0.139 
(epoch: 170, iters: 9552, time: 0.160, data: 0.000) loss: 0.391 
(epoch: 170, iters: 9632, time: 0.159, data: 0.009) loss: 0.414 
(epoch: 170, iters: 9712, time: 0.161, data: 0.018) loss: 0.337 
(epoch: 170, iters: 9792, time: 0.158, data: 0.000) loss: 0.337 
(epoch: 170, iters: 9872, time: 0.158, data: 0.000) loss: 0.313 
(epoch: 170, iters: 9952, time: 0.161, data: 0.005) loss: 0.288 
(epoch: 170, iters: 10032, time: 0.159, data: 0.006) loss: 0.202 
(epoch: 170, iters: 10112, time: 0.160, data: 0.000) loss: 0.223 
(epoch: 170, iters: 10192, time: 0.095, data: 0.000) loss: 0.483 
saving the model at the end of epoch 170, iters 1732640
End of epoch 170 / 200 	 Time Taken: 1626 sec
learning rate = 0.0000574
saving the latest model (epoch 171, total_steps 1732656)
(epoch: 171, iters: 80, time: 0.164, data: 0.188) loss: 0.081 
(epoch: 171, iters: 160, time: 0.162, data: 0.000) loss: 0.267 
(epoch: 171, iters: 240, time: 0.162, data: 0.000) loss: 0.196 
(epoch: 171, iters: 320, time: 0.157, data: 0.011) loss: 0.138 
(epoch: 171, iters: 400, time: 0.158, data: 0.000) loss: 0.219 
(epoch: 171, iters: 480, time: 0.160, data: 0.000) loss: 0.408 
(epoch: 171, iters: 560, time: 0.158, data: 0.005) loss: 0.088 
(epoch: 171, iters: 640, time: 0.159, data: 0.000) loss: 0.172 
(epoch: 171, iters: 720, time: 0.156, data: 0.028) loss: 0.361 
(epoch: 171, iters: 800, time: 0.157, data: 0.000) loss: 0.262 
(epoch: 171, iters: 880, time: 0.158, data: 0.000) loss: 0.249 
(epoch: 171, iters: 960, time: 0.158, data: 0.000) loss: 0.259 
(epoch: 171, iters: 1040, time: 0.157, data: 0.027) loss: 0.336 
(epoch: 171, iters: 1120, time: 0.158, data: 0.000) loss: 0.076 
(epoch: 171, iters: 1200, time: 0.157, data: 0.008) loss: 0.467 
(epoch: 171, iters: 1280, time: 0.157, data: 0.000) loss: 0.419 
(epoch: 171, iters: 1360, time: 0.158, data: 0.000) loss: 0.116 
(epoch: 171, iters: 1440, time: 0.157, data: 0.000) loss: 0.289 
(epoch: 171, iters: 1520, time: 0.160, data: 0.000) loss: 0.488 
(epoch: 171, iters: 1600, time: 0.159, data: 0.000) loss: 0.228 
(epoch: 171, iters: 1680, time: 0.162, data: 0.000) loss: 0.087 
(epoch: 171, iters: 1760, time: 0.159, data: 0.000) loss: 0.332 
(epoch: 171, iters: 1840, time: 0.158, data: 0.008) loss: 0.254 
(epoch: 171, iters: 1920, time: 0.158, data: 0.006) loss: 0.161 
(epoch: 171, iters: 2000, time: 0.158, data: 0.000) loss: 0.099 
(epoch: 171, iters: 2080, time: 0.159, data: 0.000) loss: 0.440 
(epoch: 171, iters: 2160, time: 0.159, data: 0.000) loss: 0.664 
(epoch: 171, iters: 2240, time: 0.158, data: 0.013) loss: 0.309 
(epoch: 171, iters: 2320, time: 0.158, data: 0.000) loss: 0.252 
(epoch: 171, iters: 2400, time: 0.160, data: 0.027) loss: 0.114 
(epoch: 171, iters: 2480, time: 0.159, data: 0.005) loss: 0.213 
(epoch: 171, iters: 2560, time: 0.161, data: 0.000) loss: 0.300 
(epoch: 171, iters: 2640, time: 0.159, data: 0.006) loss: 0.321 
(epoch: 171, iters: 2720, time: 0.157, data: 0.000) loss: 0.373 
(epoch: 171, iters: 2800, time: 0.156, data: 0.006) loss: 0.149 
(epoch: 171, iters: 2880, time: 0.156, data: 0.000) loss: 0.472 
(epoch: 171, iters: 2960, time: 0.158, data: 0.005) loss: 0.334 
(epoch: 171, iters: 3040, time: 0.158, data: 0.008) loss: 0.405 
(epoch: 171, iters: 3120, time: 0.157, data: 0.041) loss: 0.176 
(epoch: 171, iters: 3200, time: 0.157, data: 0.000) loss: 0.382 
(epoch: 171, iters: 3280, time: 0.156, data: 0.011) loss: 0.057 
(epoch: 171, iters: 3360, time: 0.157, data: 0.000) loss: 0.301 
(epoch: 171, iters: 3440, time: 0.156, data: 0.005) loss: 0.141 
(epoch: 171, iters: 3520, time: 0.156, data: 0.000) loss: 0.193 
(epoch: 171, iters: 3600, time: 0.157, data: 0.010) loss: 0.074 
(epoch: 171, iters: 3680, time: 0.159, data: 0.000) loss: 0.195 
(epoch: 171, iters: 3760, time: 0.157, data: 0.014) loss: 0.152 
(epoch: 171, iters: 3840, time: 0.161, data: 0.005) loss: 0.189 
(epoch: 171, iters: 3920, time: 0.158, data: 0.009) loss: 0.655 
(epoch: 171, iters: 4000, time: 0.157, data: 0.010) loss: 0.292 
saving the latest model (epoch 171, total_steps 1736656)
(epoch: 171, iters: 4080, time: 0.157, data: 0.016) loss: 0.098 
(epoch: 171, iters: 4160, time: 0.160, data: 0.000) loss: 0.064 
(epoch: 171, iters: 4240, time: 0.158, data: 0.020) loss: 0.299 
(epoch: 171, iters: 4320, time: 0.158, data: 0.026) loss: 0.134 
(epoch: 171, iters: 4400, time: 0.158, data: 0.000) loss: 0.168 
(epoch: 171, iters: 4480, time: 0.157, data: 0.000) loss: 0.227 
(epoch: 171, iters: 4560, time: 0.159, data: 0.005) loss: 0.134 
(epoch: 171, iters: 4640, time: 0.158, data: 0.000) loss: 0.223 
(epoch: 171, iters: 4720, time: 0.159, data: 0.018) loss: 0.139 
(epoch: 171, iters: 4800, time: 0.159, data: 0.005) loss: 0.573 
(epoch: 171, iters: 4880, time: 0.157, data: 0.000) loss: 0.672 
(epoch: 171, iters: 4960, time: 0.158, data: 0.032) loss: 0.346 
(epoch: 171, iters: 5040, time: 0.156, data: 0.000) loss: 0.390 
(epoch: 171, iters: 5120, time: 0.155, data: 0.016) loss: 0.343 
(epoch: 171, iters: 5200, time: 0.159, data: 0.016) loss: 0.405 
(epoch: 171, iters: 5280, time: 0.156, data: 0.000) loss: 0.196 
(epoch: 171, iters: 5360, time: 0.157, data: 0.023) loss: 0.104 
(epoch: 171, iters: 5440, time: 0.156, data: 0.000) loss: 0.085 
(epoch: 171, iters: 5520, time: 0.155, data: 0.034) loss: 0.150 
(epoch: 171, iters: 5600, time: 0.158, data: 0.000) loss: 0.390 
(epoch: 171, iters: 5680, time: 0.157, data: 0.019) loss: 0.057 
(epoch: 171, iters: 5760, time: 0.156, data: 0.014) loss: 0.356 
(epoch: 171, iters: 5840, time: 0.155, data: 0.015) loss: 0.039 
(epoch: 171, iters: 5920, time: 0.158, data: 0.000) loss: 0.242 
(epoch: 171, iters: 6000, time: 0.158, data: 0.000) loss: 0.271 
(epoch: 171, iters: 6080, time: 0.155, data: 0.025) loss: 0.520 
(epoch: 171, iters: 6160, time: 0.156, data: 0.000) loss: 0.176 
(epoch: 171, iters: 6240, time: 0.155, data: 0.000) loss: 0.164 
(epoch: 171, iters: 6320, time: 0.155, data: 0.000) loss: 0.208 
(epoch: 171, iters: 6400, time: 0.157, data: 0.000) loss: 0.310 
(epoch: 171, iters: 6480, time: 0.156, data: 0.009) loss: 0.551 
(epoch: 171, iters: 6560, time: 0.156, data: 0.020) loss: 0.234 
(epoch: 171, iters: 6640, time: 0.156, data: 0.006) loss: 0.531 
(epoch: 171, iters: 6720, time: 0.155, data: 0.000) loss: 0.373 
(epoch: 171, iters: 6800, time: 0.157, data: 0.005) loss: 0.185 
(epoch: 171, iters: 6880, time: 0.155, data: 0.010) loss: 0.313 
(epoch: 171, iters: 6960, time: 0.157, data: 0.000) loss: 0.252 
(epoch: 171, iters: 7040, time: 0.154, data: 0.005) loss: 0.226 
(epoch: 171, iters: 7120, time: 0.156, data: 0.017) loss: 0.486 
(epoch: 171, iters: 7200, time: 0.156, data: 0.000) loss: 0.307 
(epoch: 171, iters: 7280, time: 0.156, data: 0.000) loss: 0.240 
(epoch: 171, iters: 7360, time: 0.156, data: 0.005) loss: 0.275 
(epoch: 171, iters: 7440, time: 0.158, data: 0.020) loss: 0.049 
(epoch: 171, iters: 7520, time: 0.160, data: 0.000) loss: 0.371 
(epoch: 171, iters: 7600, time: 0.170, data: 0.011) loss: 0.097 
(epoch: 171, iters: 7680, time: 0.168, data: 0.000) loss: 0.159 
(epoch: 171, iters: 7760, time: 0.170, data: 0.000) loss: 0.055 
(epoch: 171, iters: 7840, time: 0.171, data: 0.009) loss: 0.195 
(epoch: 171, iters: 7920, time: 0.165, data: 0.000) loss: 0.129 
(epoch: 171, iters: 8000, time: 0.166, data: 0.000) loss: 0.458 
saving the latest model (epoch 171, total_steps 1740656)
(epoch: 171, iters: 8080, time: 0.167, data: 0.051) loss: 0.369 
(epoch: 171, iters: 8160, time: 0.159, data: 0.014) loss: 0.344 
(epoch: 171, iters: 8240, time: 0.161, data: 0.025) loss: 0.041 
(epoch: 171, iters: 8320, time: 0.161, data: 0.000) loss: 0.914 
(epoch: 171, iters: 8400, time: 0.160, data: 0.005) loss: 0.410 
(epoch: 171, iters: 8480, time: 0.160, data: 0.000) loss: 0.313 
(epoch: 171, iters: 8560, time: 0.158, data: 0.005) loss: 0.458 
(epoch: 171, iters: 8640, time: 0.159, data: 0.009) loss: 0.063 
(epoch: 171, iters: 8720, time: 0.157, data: 0.005) loss: 0.314 
(epoch: 171, iters: 8800, time: 0.159, data: 0.006) loss: 0.339 
(epoch: 171, iters: 8880, time: 0.157, data: 0.000) loss: 0.231 
(epoch: 171, iters: 8960, time: 0.155, data: 0.000) loss: 0.265 
(epoch: 171, iters: 9040, time: 0.156, data: 0.009) loss: 0.189 
(epoch: 171, iters: 9120, time: 0.156, data: 0.008) loss: 0.337 
(epoch: 171, iters: 9200, time: 0.156, data: 0.000) loss: 0.531 
(epoch: 171, iters: 9280, time: 0.155, data: 0.042) loss: 0.453 
(epoch: 171, iters: 9360, time: 0.158, data: 0.000) loss: 0.157 
(epoch: 171, iters: 9440, time: 0.158, data: 0.022) loss: 0.104 
(epoch: 171, iters: 9520, time: 0.158, data: 0.000) loss: 0.228 
(epoch: 171, iters: 9600, time: 0.158, data: 0.015) loss: 0.173 
(epoch: 171, iters: 9680, time: 0.157, data: 0.011) loss: 0.330 
(epoch: 171, iters: 9760, time: 0.159, data: 0.008) loss: 0.082 
(epoch: 171, iters: 9840, time: 0.157, data: 0.000) loss: 0.380 
(epoch: 171, iters: 9920, time: 0.158, data: 0.018) loss: 0.299 
(epoch: 171, iters: 10000, time: 0.159, data: 0.005) loss: 0.271 
(epoch: 171, iters: 10080, time: 0.157, data: 0.000) loss: 0.400 
(epoch: 171, iters: 10160, time: 0.158, data: 0.000) loss: 0.301 
saving the model at the end of epoch 171, iters 1742832
End of epoch 171 / 200 	 Time Taken: 1618 sec
learning rate = 0.0000554
saving the latest model (epoch 172, total_steps 1742848)
(epoch: 172, iters: 48, time: 0.162, data: 0.005) loss: 0.167 
(epoch: 172, iters: 128, time: 0.160, data: 0.009) loss: 0.240 
(epoch: 172, iters: 208, time: 0.160, data: 0.000) loss: 0.370 
(epoch: 172, iters: 288, time: 0.163, data: 0.000) loss: 0.153 
(epoch: 172, iters: 368, time: 0.158, data: 0.005) loss: 0.154 
(epoch: 172, iters: 448, time: 0.161, data: 0.000) loss: 0.109 
(epoch: 172, iters: 528, time: 0.159, data: 0.000) loss: 0.473 
(epoch: 172, iters: 608, time: 0.160, data: 0.006) loss: 0.068 
(epoch: 172, iters: 688, time: 0.159, data: 0.000) loss: 0.145 
(epoch: 172, iters: 768, time: 0.160, data: 0.017) loss: 0.603 
(epoch: 172, iters: 848, time: 0.158, data: 0.000) loss: 0.221 
(epoch: 172, iters: 928, time: 0.162, data: 0.021) loss: 0.127 
(epoch: 172, iters: 1008, time: 0.157, data: 0.000) loss: 0.241 
(epoch: 172, iters: 1088, time: 0.155, data: 0.019) loss: 0.411 
(epoch: 172, iters: 1168, time: 0.157, data: 0.006) loss: 0.210 
(epoch: 172, iters: 1248, time: 0.156, data: 0.000) loss: 0.608 
(epoch: 172, iters: 1328, time: 0.155, data: 0.000) loss: 0.474 
(epoch: 172, iters: 1408, time: 0.158, data: 0.000) loss: 0.083 
(epoch: 172, iters: 1488, time: 0.158, data: 0.008) loss: 0.320 
(epoch: 172, iters: 1568, time: 0.159, data: 0.005) loss: 0.030 
(epoch: 172, iters: 1648, time: 0.158, data: 0.000) loss: 0.220 
(epoch: 172, iters: 1728, time: 0.158, data: 0.000) loss: 0.279 
(epoch: 172, iters: 1808, time: 0.158, data: 0.024) loss: 0.069 
(epoch: 172, iters: 1888, time: 0.156, data: 0.000) loss: 0.475 
(epoch: 172, iters: 1968, time: 0.156, data: 0.000) loss: 0.864 
(epoch: 172, iters: 2048, time: 0.157, data: 0.008) loss: 0.110 
(epoch: 172, iters: 2128, time: 0.158, data: 0.010) loss: 0.099 
(epoch: 172, iters: 2208, time: 0.158, data: 0.000) loss: 0.234 
(epoch: 172, iters: 2288, time: 0.160, data: 0.000) loss: 0.404 
(epoch: 172, iters: 2368, time: 0.156, data: 0.015) loss: 0.119 
(epoch: 172, iters: 2448, time: 0.157, data: 0.000) loss: 0.094 
(epoch: 172, iters: 2528, time: 0.158, data: 0.005) loss: 0.214 
(epoch: 172, iters: 2608, time: 0.158, data: 0.008) loss: 0.288 
(epoch: 172, iters: 2688, time: 0.160, data: 0.008) loss: 0.197 
(epoch: 172, iters: 2768, time: 0.161, data: 0.000) loss: 0.388 
(epoch: 172, iters: 2848, time: 0.157, data: 0.000) loss: 0.457 
(epoch: 172, iters: 2928, time: 0.158, data: 0.000) loss: 0.293 
(epoch: 172, iters: 3008, time: 0.156, data: 0.016) loss: 0.174 
(epoch: 172, iters: 3088, time: 0.158, data: 0.000) loss: 0.116 
(epoch: 172, iters: 3168, time: 0.159, data: 0.006) loss: 0.391 
(epoch: 172, iters: 3248, time: 0.159, data: 0.000) loss: 0.167 
(epoch: 172, iters: 3328, time: 0.158, data: 0.000) loss: 0.158 
(epoch: 172, iters: 3408, time: 0.161, data: 0.000) loss: 0.355 
(epoch: 172, iters: 3488, time: 0.159, data: 0.008) loss: 0.189 
(epoch: 172, iters: 3568, time: 0.160, data: 0.000) loss: 0.077 
(epoch: 172, iters: 3648, time: 0.159, data: 0.008) loss: 0.345 
(epoch: 172, iters: 3728, time: 0.159, data: 0.000) loss: 0.313 
(epoch: 172, iters: 3808, time: 0.159, data: 0.005) loss: 0.289 
(epoch: 172, iters: 3888, time: 0.157, data: 0.008) loss: 0.279 
(epoch: 172, iters: 3968, time: 0.160, data: 0.000) loss: 0.174 
saving the latest model (epoch 172, total_steps 1746848)
(epoch: 172, iters: 4048, time: 0.159, data: 0.013) loss: 0.275 
(epoch: 172, iters: 4128, time: 0.159, data: 0.015) loss: 0.227 
(epoch: 172, iters: 4208, time: 0.159, data: 0.000) loss: 0.170 
(epoch: 172, iters: 4288, time: 0.159, data: 0.014) loss: 0.335 
(epoch: 172, iters: 4368, time: 0.159, data: 0.005) loss: 0.085 
(epoch: 172, iters: 4448, time: 0.159, data: 0.000) loss: 0.087 
(epoch: 172, iters: 4528, time: 0.161, data: 0.000) loss: 0.054 
(epoch: 172, iters: 4608, time: 0.160, data: 0.019) loss: 0.293 
(epoch: 172, iters: 4688, time: 0.158, data: 0.000) loss: 0.059 
(epoch: 172, iters: 4768, time: 0.160, data: 0.019) loss: 0.347 
(epoch: 172, iters: 4848, time: 0.159, data: 0.000) loss: 0.311 
(epoch: 172, iters: 4928, time: 0.157, data: 0.005) loss: 0.308 
(epoch: 172, iters: 5008, time: 0.160, data: 0.005) loss: 0.960 
(epoch: 172, iters: 5088, time: 0.158, data: 0.000) loss: 0.130 
(epoch: 172, iters: 5168, time: 0.157, data: 0.000) loss: 0.387 
(epoch: 172, iters: 5248, time: 0.158, data: 0.000) loss: 0.146 
(epoch: 172, iters: 5328, time: 0.159, data: 0.005) loss: 0.247 
(epoch: 172, iters: 5408, time: 0.158, data: 0.009) loss: 0.221 
(epoch: 172, iters: 5488, time: 0.160, data: 0.026) loss: 0.045 
(epoch: 172, iters: 5568, time: 0.158, data: 0.000) loss: 0.303 
(epoch: 172, iters: 5648, time: 0.158, data: 0.014) loss: 0.339 
(epoch: 172, iters: 5728, time: 0.158, data: 0.005) loss: 0.158 
(epoch: 172, iters: 5808, time: 0.159, data: 0.000) loss: 0.157 
(epoch: 172, iters: 5888, time: 0.158, data: 0.000) loss: 0.114 
(epoch: 172, iters: 5968, time: 0.160, data: 0.000) loss: 0.165 
(epoch: 172, iters: 6048, time: 0.159, data: 0.032) loss: 0.398 
(epoch: 172, iters: 6128, time: 0.161, data: 0.000) loss: 0.553 
(epoch: 172, iters: 6208, time: 0.159, data: 0.000) loss: 0.674 
(epoch: 172, iters: 6288, time: 0.159, data: 0.005) loss: 0.387 
(epoch: 172, iters: 6368, time: 0.159, data: 0.006) loss: 0.233 
(epoch: 172, iters: 6448, time: 0.158, data: 0.005) loss: 0.288 
(epoch: 172, iters: 6528, time: 0.159, data: 0.000) loss: 0.261 
(epoch: 172, iters: 6608, time: 0.159, data: 0.000) loss: 0.272 
(epoch: 172, iters: 6688, time: 0.158, data: 0.006) loss: 0.090 
(epoch: 172, iters: 6768, time: 0.159, data: 0.000) loss: 0.131 
(epoch: 172, iters: 6848, time: 0.157, data: 0.000) loss: 0.233 
(epoch: 172, iters: 6928, time: 0.157, data: 0.014) loss: 0.167 
(epoch: 172, iters: 7008, time: 0.158, data: 0.008) loss: 0.314 
(epoch: 172, iters: 7088, time: 0.160, data: 0.007) loss: 0.069 
(epoch: 172, iters: 7168, time: 0.160, data: 0.000) loss: 0.322 
(epoch: 172, iters: 7248, time: 0.159, data: 0.032) loss: 0.354 
(epoch: 172, iters: 7328, time: 0.158, data: 0.000) loss: 0.450 
(epoch: 172, iters: 7408, time: 0.160, data: 0.000) loss: 0.401 
(epoch: 172, iters: 7488, time: 0.160, data: 0.024) loss: 0.099 
(epoch: 172, iters: 7568, time: 0.159, data: 0.000) loss: 0.044 
(epoch: 172, iters: 7648, time: 0.161, data: 0.000) loss: 0.529 
(epoch: 172, iters: 7728, time: 0.157, data: 0.014) loss: 0.148 
(epoch: 172, iters: 7808, time: 0.157, data: 0.000) loss: 0.151 
(epoch: 172, iters: 7888, time: 0.160, data: 0.013) loss: 0.735 
(epoch: 172, iters: 7968, time: 0.159, data: 0.008) loss: 0.096 
saving the latest model (epoch 172, total_steps 1750848)
(epoch: 172, iters: 8048, time: 0.158, data: 0.000) loss: 0.121 
(epoch: 172, iters: 8128, time: 0.158, data: 0.000) loss: 0.333 
(epoch: 172, iters: 8208, time: 0.158, data: 0.005) loss: 0.435 
(epoch: 172, iters: 8288, time: 0.158, data: 0.000) loss: 0.268 
(epoch: 172, iters: 8368, time: 0.158, data: 0.006) loss: 0.162 
(epoch: 172, iters: 8448, time: 0.158, data: 0.021) loss: 0.325 
(epoch: 172, iters: 8528, time: 0.158, data: 0.000) loss: 0.335 
(epoch: 172, iters: 8608, time: 0.158, data: 0.006) loss: 0.148 
(epoch: 172, iters: 8688, time: 0.159, data: 0.005) loss: 0.558 
(epoch: 172, iters: 8768, time: 0.159, data: 0.000) loss: 0.259 
(epoch: 172, iters: 8848, time: 0.159, data: 0.009) loss: 0.190 
(epoch: 172, iters: 8928, time: 0.158, data: 0.014) loss: 0.448 
(epoch: 172, iters: 9008, time: 0.158, data: 0.006) loss: 0.141 
(epoch: 172, iters: 9088, time: 0.159, data: 0.000) loss: 0.101 
(epoch: 172, iters: 9168, time: 0.161, data: 0.023) loss: 0.281 
(epoch: 172, iters: 9248, time: 0.159, data: 0.013) loss: 0.186 
(epoch: 172, iters: 9328, time: 0.159, data: 0.005) loss: 0.143 
(epoch: 172, iters: 9408, time: 0.160, data: 0.005) loss: 0.254 
(epoch: 172, iters: 9488, time: 0.160, data: 0.005) loss: 0.379 
(epoch: 172, iters: 9568, time: 0.159, data: 0.000) loss: 0.237 
(epoch: 172, iters: 9648, time: 0.158, data: 0.000) loss: 0.254 
(epoch: 172, iters: 9728, time: 0.160, data: 0.000) loss: 0.156 
(epoch: 172, iters: 9808, time: 0.159, data: 0.005) loss: 0.260 
(epoch: 172, iters: 9888, time: 0.159, data: 0.000) loss: 0.448 
(epoch: 172, iters: 9968, time: 0.159, data: 0.034) loss: 0.053 
(epoch: 172, iters: 10048, time: 0.160, data: 0.000) loss: 0.125 
(epoch: 172, iters: 10128, time: 0.158, data: 0.010) loss: 0.567 
saving the model at the end of epoch 172, iters 1753024
End of epoch 172 / 200 	 Time Taken: 1619 sec
learning rate = 0.0000535
(epoch: 173, iters: 16, time: 0.179, data: 0.000) loss: 0.226 
saving the latest model (epoch 173, total_steps 1753040)
(epoch: 173, iters: 96, time: 0.155, data: 0.012) loss: 0.944 
(epoch: 173, iters: 176, time: 0.159, data: 0.009) loss: 0.301 
(epoch: 173, iters: 256, time: 0.156, data: 0.000) loss: 0.382 
(epoch: 173, iters: 336, time: 0.156, data: 0.015) loss: 0.199 
(epoch: 173, iters: 416, time: 0.155, data: 0.000) loss: 0.371 
(epoch: 173, iters: 496, time: 0.158, data: 0.015) loss: 0.110 
(epoch: 173, iters: 576, time: 0.154, data: 0.025) loss: 0.336 
(epoch: 173, iters: 656, time: 0.158, data: 0.000) loss: 0.499 
(epoch: 173, iters: 736, time: 0.157, data: 0.028) loss: 0.258 
(epoch: 173, iters: 816, time: 0.160, data: 0.009) loss: 0.181 
(epoch: 173, iters: 896, time: 0.160, data: 0.000) loss: 0.019 
(epoch: 173, iters: 976, time: 0.158, data: 0.005) loss: 0.141 
(epoch: 173, iters: 1056, time: 0.160, data: 0.000) loss: 0.132 
(epoch: 173, iters: 1136, time: 0.159, data: 0.000) loss: 0.354 
(epoch: 173, iters: 1216, time: 0.158, data: 0.000) loss: 0.489 
(epoch: 173, iters: 1296, time: 0.158, data: 0.000) loss: 0.154 
(epoch: 173, iters: 1376, time: 0.160, data: 0.026) loss: 0.103 
(epoch: 173, iters: 1456, time: 0.160, data: 0.006) loss: 0.281 
(epoch: 173, iters: 1536, time: 0.161, data: 0.000) loss: 0.190 
(epoch: 173, iters: 1616, time: 0.160, data: 0.020) loss: 0.291 
(epoch: 173, iters: 1696, time: 0.160, data: 0.009) loss: 0.436 
(epoch: 173, iters: 1776, time: 0.158, data: 0.024) loss: 0.246 
(epoch: 173, iters: 1856, time: 0.158, data: 0.000) loss: 0.211 
(epoch: 173, iters: 1936, time: 0.160, data: 0.011) loss: 0.264 
(epoch: 173, iters: 2016, time: 0.159, data: 0.000) loss: 0.146 
(epoch: 173, iters: 2096, time: 0.161, data: 0.000) loss: 0.169 
(epoch: 173, iters: 2176, time: 0.158, data: 0.000) loss: 0.210 
(epoch: 173, iters: 2256, time: 0.159, data: 0.021) loss: 0.160 
(epoch: 173, iters: 2336, time: 0.158, data: 0.008) loss: 0.208 
(epoch: 173, iters: 2416, time: 0.157, data: 0.000) loss: 0.168 
(epoch: 173, iters: 2496, time: 0.159, data: 0.025) loss: 0.138 
(epoch: 173, iters: 2576, time: 0.158, data: 0.000) loss: 0.150 
(epoch: 173, iters: 2656, time: 0.158, data: 0.025) loss: 0.148 
(epoch: 173, iters: 2736, time: 0.161, data: 0.000) loss: 0.448 
(epoch: 173, iters: 2816, time: 0.158, data: 0.000) loss: 0.373 
(epoch: 173, iters: 2896, time: 0.159, data: 0.000) loss: 0.174 
(epoch: 173, iters: 2976, time: 0.160, data: 0.000) loss: 0.231 
(epoch: 173, iters: 3056, time: 0.157, data: 0.013) loss: 0.219 
(epoch: 173, iters: 3136, time: 0.157, data: 0.000) loss: 0.096 
(epoch: 173, iters: 3216, time: 0.160, data: 0.034) loss: 0.221 
(epoch: 173, iters: 3296, time: 0.158, data: 0.000) loss: 0.062 
(epoch: 173, iters: 3376, time: 0.159, data: 0.014) loss: 0.388 
(epoch: 173, iters: 3456, time: 0.158, data: 0.000) loss: 0.575 
(epoch: 173, iters: 3536, time: 0.158, data: 0.000) loss: 0.171 
(epoch: 173, iters: 3616, time: 0.159, data: 0.000) loss: 0.272 
(epoch: 173, iters: 3696, time: 0.159, data: 0.016) loss: 0.151 
(epoch: 173, iters: 3776, time: 0.158, data: 0.000) loss: 0.082 
(epoch: 173, iters: 3856, time: 0.158, data: 0.000) loss: 0.307 
(epoch: 173, iters: 3936, time: 0.160, data: 0.000) loss: 0.118 
(epoch: 173, iters: 4016, time: 0.160, data: 0.020) loss: 0.287 
saving the latest model (epoch 173, total_steps 1757040)
(epoch: 173, iters: 4096, time: 0.159, data: 0.000) loss: 0.229 
(epoch: 173, iters: 4176, time: 0.157, data: 0.000) loss: 0.119 
(epoch: 173, iters: 4256, time: 0.158, data: 0.018) loss: 0.073 
(epoch: 173, iters: 4336, time: 0.160, data: 0.016) loss: 0.470 
(epoch: 173, iters: 4416, time: 0.157, data: 0.000) loss: 0.082 
(epoch: 173, iters: 4496, time: 0.157, data: 0.000) loss: 0.107 
(epoch: 173, iters: 4576, time: 0.160, data: 0.000) loss: 0.372 
(epoch: 173, iters: 4656, time: 0.159, data: 0.005) loss: 0.316 
(epoch: 173, iters: 4736, time: 0.157, data: 0.006) loss: 0.186 
(epoch: 173, iters: 4816, time: 0.158, data: 0.000) loss: 0.141 
(epoch: 173, iters: 4896, time: 0.158, data: 0.011) loss: 0.229 
(epoch: 173, iters: 4976, time: 0.159, data: 0.005) loss: 0.247 
(epoch: 173, iters: 5056, time: 0.160, data: 0.000) loss: 0.243 
(epoch: 173, iters: 5136, time: 0.161, data: 0.015) loss: 0.272 
(epoch: 173, iters: 5216, time: 0.159, data: 0.024) loss: 0.298 
(epoch: 173, iters: 5296, time: 0.161, data: 0.005) loss: 0.233 
(epoch: 173, iters: 5376, time: 0.164, data: 0.014) loss: 0.095 
(epoch: 173, iters: 5456, time: 0.159, data: 0.008) loss: 0.272 
(epoch: 173, iters: 5536, time: 0.161, data: 0.009) loss: 0.117 
(epoch: 173, iters: 5616, time: 0.160, data: 0.000) loss: 0.545 
(epoch: 173, iters: 5696, time: 0.161, data: 0.000) loss: 0.270 
(epoch: 173, iters: 5776, time: 0.162, data: 0.000) loss: 0.192 
(epoch: 173, iters: 5856, time: 0.158, data: 0.000) loss: 0.121 
(epoch: 173, iters: 5936, time: 0.159, data: 0.000) loss: 0.072 
(epoch: 173, iters: 6016, time: 0.160, data: 0.015) loss: 0.297 
(epoch: 173, iters: 6096, time: 0.159, data: 0.032) loss: 0.045 
(epoch: 173, iters: 6176, time: 0.157, data: 0.000) loss: 0.428 
(epoch: 173, iters: 6256, time: 0.158, data: 0.000) loss: 0.129 
(epoch: 173, iters: 6336, time: 0.158, data: 0.005) loss: 0.082 
(epoch: 173, iters: 6416, time: 0.158, data: 0.005) loss: 0.564 
(epoch: 173, iters: 6496, time: 0.160, data: 0.000) loss: 0.423 
(epoch: 173, iters: 6576, time: 0.156, data: 0.000) loss: 0.153 
(epoch: 173, iters: 6656, time: 0.157, data: 0.005) loss: 0.110 
(epoch: 173, iters: 6736, time: 0.160, data: 0.000) loss: 0.128 
(epoch: 173, iters: 6816, time: 0.158, data: 0.020) loss: 0.128 
(epoch: 173, iters: 6896, time: 0.158, data: 0.000) loss: 0.244 
(epoch: 173, iters: 6976, time: 0.159, data: 0.000) loss: 0.177 
(epoch: 173, iters: 7056, time: 0.159, data: 0.000) loss: 0.160 
(epoch: 173, iters: 7136, time: 0.157, data: 0.005) loss: 0.199 
(epoch: 173, iters: 7216, time: 0.159, data: 0.000) loss: 0.336 
(epoch: 173, iters: 7296, time: 0.158, data: 0.000) loss: 0.285 
(epoch: 173, iters: 7376, time: 0.158, data: 0.008) loss: 0.072 
(epoch: 173, iters: 7456, time: 0.161, data: 0.005) loss: 0.113 
(epoch: 173, iters: 7536, time: 0.159, data: 0.000) loss: 0.102 
(epoch: 173, iters: 7616, time: 0.158, data: 0.000) loss: 0.252 
(epoch: 173, iters: 7696, time: 0.160, data: 0.000) loss: 0.089 
(epoch: 173, iters: 7776, time: 0.159, data: 0.033) loss: 0.408 
(epoch: 173, iters: 7856, time: 0.159, data: 0.000) loss: 0.151 
(epoch: 173, iters: 7936, time: 0.158, data: 0.000) loss: 0.212 
(epoch: 173, iters: 8016, time: 0.158, data: 0.000) loss: 0.081 
saving the latest model (epoch 173, total_steps 1761040)
(epoch: 173, iters: 8096, time: 0.159, data: 0.000) loss: 0.114 
(epoch: 173, iters: 8176, time: 0.159, data: 0.000) loss: 0.160 
(epoch: 173, iters: 8256, time: 0.158, data: 0.000) loss: 0.590 
(epoch: 173, iters: 8336, time: 0.159, data: 0.000) loss: 0.382 
(epoch: 173, iters: 8416, time: 0.159, data: 0.006) loss: 0.286 
(epoch: 173, iters: 8496, time: 0.159, data: 0.008) loss: 0.447 
(epoch: 173, iters: 8576, time: 0.159, data: 0.000) loss: 0.065 
(epoch: 173, iters: 8656, time: 0.159, data: 0.000) loss: 0.282 
(epoch: 173, iters: 8736, time: 0.158, data: 0.005) loss: 0.266 
(epoch: 173, iters: 8816, time: 0.159, data: 0.009) loss: 0.138 
(epoch: 173, iters: 8896, time: 0.159, data: 0.000) loss: 0.421 
(epoch: 173, iters: 8976, time: 0.158, data: 0.021) loss: 0.225 
(epoch: 173, iters: 9056, time: 0.160, data: 0.017) loss: 0.483 
(epoch: 173, iters: 9136, time: 0.159, data: 0.000) loss: 0.447 
(epoch: 173, iters: 9216, time: 0.158, data: 0.015) loss: 0.145 
(epoch: 173, iters: 9296, time: 0.158, data: 0.000) loss: 0.478 
(epoch: 173, iters: 9376, time: 0.157, data: 0.005) loss: 0.090 
(epoch: 173, iters: 9456, time: 0.159, data: 0.012) loss: 0.351 
(epoch: 173, iters: 9536, time: 0.159, data: 0.000) loss: 0.387 
(epoch: 173, iters: 9616, time: 0.157, data: 0.000) loss: 0.151 
(epoch: 173, iters: 9696, time: 0.158, data: 0.000) loss: 0.156 
(epoch: 173, iters: 9776, time: 0.157, data: 0.005) loss: 0.451 
(epoch: 173, iters: 9856, time: 0.158, data: 0.000) loss: 0.279 
(epoch: 173, iters: 9936, time: 0.160, data: 0.000) loss: 0.173 
(epoch: 173, iters: 10016, time: 0.158, data: 0.008) loss: 0.094 
(epoch: 173, iters: 10096, time: 0.159, data: 0.000) loss: 0.089 
(epoch: 173, iters: 10176, time: 0.159, data: 0.000) loss: 0.069 
saving the model at the end of epoch 173, iters 1763216
End of epoch 173 / 200 	 Time Taken: 1619 sec
learning rate = 0.0000515
saving the latest model (epoch 174, total_steps 1763232)
(epoch: 174, iters: 64, time: 0.160, data: 0.000) loss: 0.308 
(epoch: 174, iters: 144, time: 0.160, data: 0.012) loss: 0.284 
(epoch: 174, iters: 224, time: 0.154, data: 0.005) loss: 0.178 
(epoch: 174, iters: 304, time: 0.156, data: 0.000) loss: 0.260 
(epoch: 174, iters: 384, time: 0.158, data: 0.010) loss: 0.146 
(epoch: 174, iters: 464, time: 0.156, data: 0.005) loss: 0.067 
(epoch: 174, iters: 544, time: 0.157, data: 0.008) loss: 0.118 
(epoch: 174, iters: 624, time: 0.155, data: 0.000) loss: 0.318 
(epoch: 174, iters: 704, time: 0.154, data: 0.000) loss: 0.281 
(epoch: 174, iters: 784, time: 0.157, data: 0.018) loss: 0.238 
(epoch: 174, iters: 864, time: 0.158, data: 0.000) loss: 0.104 
(epoch: 174, iters: 944, time: 0.156, data: 0.000) loss: 0.072 
(epoch: 174, iters: 1024, time: 0.157, data: 0.008) loss: 0.504 
(epoch: 174, iters: 1104, time: 0.159, data: 0.007) loss: 0.145 
(epoch: 174, iters: 1184, time: 0.156, data: 0.008) loss: 0.350 
(epoch: 174, iters: 1264, time: 0.158, data: 0.000) loss: 0.211 
(epoch: 174, iters: 1344, time: 0.157, data: 0.000) loss: 0.315 
(epoch: 174, iters: 1424, time: 0.160, data: 0.005) loss: 0.055 
(epoch: 174, iters: 1504, time: 0.158, data: 0.000) loss: 0.230 
(epoch: 174, iters: 1584, time: 0.158, data: 0.008) loss: 0.252 
(epoch: 174, iters: 1664, time: 0.158, data: 0.005) loss: 0.230 
(epoch: 174, iters: 1744, time: 0.158, data: 0.000) loss: 0.270 
(epoch: 174, iters: 1824, time: 0.158, data: 0.006) loss: 0.283 
(epoch: 174, iters: 1904, time: 0.158, data: 0.000) loss: 0.185 
(epoch: 174, iters: 1984, time: 0.158, data: 0.008) loss: 0.163 
(epoch: 174, iters: 2064, time: 0.159, data: 0.000) loss: 0.153 
(epoch: 174, iters: 2144, time: 0.157, data: 0.022) loss: 0.280 
(epoch: 174, iters: 2224, time: 0.158, data: 0.000) loss: 0.384 
(epoch: 174, iters: 2304, time: 0.160, data: 0.000) loss: 0.584 
(epoch: 174, iters: 2384, time: 0.158, data: 0.000) loss: 0.302 
(epoch: 174, iters: 2464, time: 0.159, data: 0.006) loss: 0.267 
(epoch: 174, iters: 2544, time: 0.159, data: 0.000) loss: 0.123 
(epoch: 174, iters: 2624, time: 0.159, data: 0.005) loss: 0.405 
(epoch: 174, iters: 2704, time: 0.158, data: 0.000) loss: 0.237 
(epoch: 174, iters: 2784, time: 0.159, data: 0.032) loss: 0.279 
(epoch: 174, iters: 2864, time: 0.158, data: 0.000) loss: 0.217 
(epoch: 174, iters: 2944, time: 0.159, data: 0.000) loss: 0.354 
(epoch: 174, iters: 3024, time: 0.158, data: 0.000) loss: 0.179 
(epoch: 174, iters: 3104, time: 0.157, data: 0.005) loss: 0.257 
(epoch: 174, iters: 3184, time: 0.158, data: 0.000) loss: 0.030 
(epoch: 174, iters: 3264, time: 0.159, data: 0.000) loss: 0.108 
(epoch: 174, iters: 3344, time: 0.158, data: 0.000) loss: 0.663 
(epoch: 174, iters: 3424, time: 0.158, data: 0.017) loss: 0.070 
(epoch: 174, iters: 3504, time: 0.161, data: 0.000) loss: 0.557 
(epoch: 174, iters: 3584, time: 0.160, data: 0.011) loss: 0.186 
(epoch: 174, iters: 3664, time: 0.158, data: 0.000) loss: 0.098 
(epoch: 174, iters: 3744, time: 0.158, data: 0.000) loss: 0.177 
(epoch: 174, iters: 3824, time: 0.158, data: 0.005) loss: 0.245 
(epoch: 174, iters: 3904, time: 0.159, data: 0.017) loss: 0.117 
(epoch: 174, iters: 3984, time: 0.158, data: 0.000) loss: 0.411 
saving the latest model (epoch 174, total_steps 1767232)
(epoch: 174, iters: 4064, time: 0.159, data: 0.000) loss: 0.402 
(epoch: 174, iters: 4144, time: 0.161, data: 0.011) loss: 0.053 
(epoch: 174, iters: 4224, time: 0.157, data: 0.015) loss: 0.103 
(epoch: 174, iters: 4304, time: 0.160, data: 0.000) loss: 0.607 
(epoch: 174, iters: 4384, time: 0.160, data: 0.000) loss: 0.442 
(epoch: 174, iters: 4464, time: 0.159, data: 0.005) loss: 0.222 
(epoch: 174, iters: 4544, time: 0.158, data: 0.008) loss: 0.081 
(epoch: 174, iters: 4624, time: 0.160, data: 0.011) loss: 0.226 
(epoch: 174, iters: 4704, time: 0.159, data: 0.005) loss: 0.196 
(epoch: 174, iters: 4784, time: 0.159, data: 0.009) loss: 0.207 
(epoch: 174, iters: 4864, time: 0.159, data: 0.000) loss: 0.108 
(epoch: 174, iters: 4944, time: 0.158, data: 0.015) loss: 0.062 
(epoch: 174, iters: 5024, time: 0.157, data: 0.034) loss: 0.542 
(epoch: 174, iters: 5104, time: 0.159, data: 0.000) loss: 0.399 
(epoch: 174, iters: 5184, time: 0.158, data: 0.018) loss: 0.091 
(epoch: 174, iters: 5264, time: 0.160, data: 0.000) loss: 0.076 
(epoch: 174, iters: 5344, time: 0.160, data: 0.000) loss: 0.286 
(epoch: 174, iters: 5424, time: 0.161, data: 0.000) loss: 0.050 
(epoch: 174, iters: 5504, time: 0.161, data: 0.006) loss: 0.123 
(epoch: 174, iters: 5584, time: 0.159, data: 0.000) loss: 0.143 
(epoch: 174, iters: 5664, time: 0.160, data: 0.000) loss: 0.227 
(epoch: 174, iters: 5744, time: 0.159, data: 0.000) loss: 0.405 
(epoch: 174, iters: 5824, time: 0.164, data: 0.008) loss: 0.509 
(epoch: 174, iters: 5904, time: 0.157, data: 0.008) loss: 0.280 
(epoch: 174, iters: 5984, time: 0.158, data: 0.005) loss: 0.023 
(epoch: 174, iters: 6064, time: 0.158, data: 0.000) loss: 0.126 
(epoch: 174, iters: 6144, time: 0.159, data: 0.009) loss: 0.292 
(epoch: 174, iters: 6224, time: 0.160, data: 0.000) loss: 0.196 
(epoch: 174, iters: 6304, time: 0.160, data: 0.005) loss: 0.265 
(epoch: 174, iters: 6384, time: 0.158, data: 0.009) loss: 0.115 
(epoch: 174, iters: 6464, time: 0.160, data: 0.009) loss: 0.222 
(epoch: 174, iters: 6544, time: 0.160, data: 0.000) loss: 0.525 
(epoch: 174, iters: 6624, time: 0.159, data: 0.020) loss: 0.373 
(epoch: 174, iters: 6704, time: 0.158, data: 0.012) loss: 0.360 
(epoch: 174, iters: 6784, time: 0.159, data: 0.000) loss: 0.290 
(epoch: 174, iters: 6864, time: 0.165, data: 0.000) loss: 0.413 
(epoch: 174, iters: 6944, time: 0.160, data: 0.000) loss: 0.068 
(epoch: 174, iters: 7024, time: 0.161, data: 0.022) loss: 0.297 
(epoch: 174, iters: 7104, time: 0.161, data: 0.000) loss: 0.222 
(epoch: 174, iters: 7184, time: 0.160, data: 0.000) loss: 0.113 
(epoch: 174, iters: 7264, time: 0.161, data: 0.014) loss: 0.282 
(epoch: 174, iters: 7344, time: 0.160, data: 0.000) loss: 0.344 
(epoch: 174, iters: 7424, time: 0.160, data: 0.009) loss: 0.240 
(epoch: 174, iters: 7504, time: 0.160, data: 0.000) loss: 0.207 
(epoch: 174, iters: 7584, time: 0.160, data: 0.008) loss: 0.375 
(epoch: 174, iters: 7664, time: 0.159, data: 0.000) loss: 0.272 
(epoch: 174, iters: 7744, time: 0.158, data: 0.017) loss: 0.151 
(epoch: 174, iters: 7824, time: 0.160, data: 0.000) loss: 0.027 
(epoch: 174, iters: 7904, time: 0.159, data: 0.018) loss: 0.415 
(epoch: 174, iters: 7984, time: 0.160, data: 0.005) loss: 0.067 
saving the latest model (epoch 174, total_steps 1771232)
(epoch: 174, iters: 8064, time: 0.157, data: 0.000) loss: 0.018 
(epoch: 174, iters: 8144, time: 0.158, data: 0.016) loss: 0.146 
(epoch: 174, iters: 8224, time: 0.160, data: 0.000) loss: 0.072 
(epoch: 174, iters: 8304, time: 0.159, data: 0.000) loss: 0.081 
(epoch: 174, iters: 8384, time: 0.159, data: 0.005) loss: 0.208 
(epoch: 174, iters: 8464, time: 0.158, data: 0.008) loss: 0.076 
(epoch: 174, iters: 8544, time: 0.157, data: 0.000) loss: 0.176 
(epoch: 174, iters: 8624, time: 0.158, data: 0.005) loss: 0.327 
(epoch: 174, iters: 8704, time: 0.159, data: 0.005) loss: 0.299 
(epoch: 174, iters: 8784, time: 0.158, data: 0.019) loss: 0.020 
(epoch: 174, iters: 8864, time: 0.160, data: 0.000) loss: 0.481 
(epoch: 174, iters: 8944, time: 0.159, data: 0.011) loss: 0.099 
(epoch: 174, iters: 9024, time: 0.160, data: 0.000) loss: 0.102 
(epoch: 174, iters: 9104, time: 0.158, data: 0.000) loss: 0.169 
(epoch: 174, iters: 9184, time: 0.158, data: 0.021) loss: 0.151 
(epoch: 174, iters: 9264, time: 0.159, data: 0.023) loss: 0.544 
(epoch: 174, iters: 9344, time: 0.158, data: 0.000) loss: 0.096 
(epoch: 174, iters: 9424, time: 0.162, data: 0.010) loss: 0.213 
(epoch: 174, iters: 9504, time: 0.159, data: 0.014) loss: 0.243 
(epoch: 174, iters: 9584, time: 0.159, data: 0.007) loss: 0.324 
(epoch: 174, iters: 9664, time: 0.159, data: 0.000) loss: 0.085 
(epoch: 174, iters: 9744, time: 0.159, data: 0.000) loss: 0.287 
(epoch: 174, iters: 9824, time: 0.160, data: 0.005) loss: 0.147 
(epoch: 174, iters: 9904, time: 0.159, data: 0.000) loss: 0.358 
(epoch: 174, iters: 9984, time: 0.160, data: 0.005) loss: 0.264 
(epoch: 174, iters: 10064, time: 0.158, data: 0.000) loss: 0.245 
(epoch: 174, iters: 10144, time: 0.158, data: 0.008) loss: 0.969 
saving the model at the end of epoch 174, iters 1773408
End of epoch 174 / 200 	 Time Taken: 1622 sec
learning rate = 0.0000495
saving the latest model (epoch 175, total_steps 1773424)
(epoch: 175, iters: 32, time: 0.166, data: 0.000) loss: 0.206 
(epoch: 175, iters: 112, time: 0.158, data: 0.000) loss: 0.419 
(epoch: 175, iters: 192, time: 0.161, data: 0.011) loss: 0.106 
(epoch: 175, iters: 272, time: 0.158, data: 0.000) loss: 0.237 
(epoch: 175, iters: 352, time: 0.159, data: 0.024) loss: 0.288 
(epoch: 175, iters: 432, time: 0.160, data: 0.000) loss: 0.189 
(epoch: 175, iters: 512, time: 0.159, data: 0.009) loss: 0.058 
(epoch: 175, iters: 592, time: 0.160, data: 0.000) loss: 0.250 
(epoch: 175, iters: 672, time: 0.161, data: 0.010) loss: 0.167 
(epoch: 175, iters: 752, time: 0.157, data: 0.000) loss: 0.295 
(epoch: 175, iters: 832, time: 0.160, data: 0.000) loss: 0.263 
(epoch: 175, iters: 912, time: 0.159, data: 0.005) loss: 0.077 
(epoch: 175, iters: 992, time: 0.159, data: 0.006) loss: 0.213 
(epoch: 175, iters: 1072, time: 0.159, data: 0.000) loss: 0.298 
(epoch: 175, iters: 1152, time: 0.158, data: 0.000) loss: 0.131 
(epoch: 175, iters: 1232, time: 0.159, data: 0.008) loss: 0.405 
(epoch: 175, iters: 1312, time: 0.159, data: 0.014) loss: 0.098 
(epoch: 175, iters: 1392, time: 0.158, data: 0.000) loss: 0.185 
(epoch: 175, iters: 1472, time: 0.160, data: 0.000) loss: 0.103 
(epoch: 175, iters: 1552, time: 0.161, data: 0.006) loss: 0.442 
(epoch: 175, iters: 1632, time: 0.160, data: 0.006) loss: 0.126 
(epoch: 175, iters: 1712, time: 0.158, data: 0.000) loss: 0.323 
(epoch: 175, iters: 1792, time: 0.159, data: 0.005) loss: 0.426 
(epoch: 175, iters: 1872, time: 0.159, data: 0.008) loss: 0.195 
(epoch: 175, iters: 1952, time: 0.159, data: 0.006) loss: 0.174 
(epoch: 175, iters: 2032, time: 0.159, data: 0.000) loss: 0.052 
(epoch: 175, iters: 2112, time: 0.159, data: 0.006) loss: 0.273 
(epoch: 175, iters: 2192, time: 0.159, data: 0.008) loss: 0.267 
(epoch: 175, iters: 2272, time: 0.159, data: 0.005) loss: 0.564 
(epoch: 175, iters: 2352, time: 0.159, data: 0.023) loss: 0.326 
(epoch: 175, iters: 2432, time: 0.160, data: 0.000) loss: 0.317 
(epoch: 175, iters: 2512, time: 0.160, data: 0.000) loss: 0.211 
(epoch: 175, iters: 2592, time: 0.160, data: 0.000) loss: 0.525 
(epoch: 175, iters: 2672, time: 0.160, data: 0.000) loss: 0.175 
(epoch: 175, iters: 2752, time: 0.159, data: 0.008) loss: 0.276 
(epoch: 175, iters: 2832, time: 0.158, data: 0.000) loss: 0.229 
(epoch: 175, iters: 2912, time: 0.159, data: 0.021) loss: 0.416 
(epoch: 175, iters: 2992, time: 0.159, data: 0.006) loss: 0.093 
(epoch: 175, iters: 3072, time: 0.158, data: 0.000) loss: 0.088 
(epoch: 175, iters: 3152, time: 0.158, data: 0.005) loss: 0.299 
(epoch: 175, iters: 3232, time: 0.159, data: 0.005) loss: 0.143 
(epoch: 175, iters: 3312, time: 0.160, data: 0.000) loss: 0.055 
(epoch: 175, iters: 3392, time: 0.158, data: 0.000) loss: 0.075 
(epoch: 175, iters: 3472, time: 0.158, data: 0.039) loss: 0.469 
(epoch: 175, iters: 3552, time: 0.159, data: 0.000) loss: 0.199 
(epoch: 175, iters: 3632, time: 0.160, data: 0.019) loss: 0.507 
(epoch: 175, iters: 3712, time: 0.159, data: 0.000) loss: 0.364 
(epoch: 175, iters: 3792, time: 0.159, data: 0.005) loss: 0.195 
(epoch: 175, iters: 3872, time: 0.159, data: 0.000) loss: 0.225 
(epoch: 175, iters: 3952, time: 0.160, data: 0.024) loss: 0.600 
saving the latest model (epoch 175, total_steps 1777424)
(epoch: 175, iters: 4032, time: 0.160, data: 0.000) loss: 0.227 
(epoch: 175, iters: 4112, time: 0.157, data: 0.000) loss: 0.062 
(epoch: 175, iters: 4192, time: 0.160, data: 0.000) loss: 0.091 
(epoch: 175, iters: 4272, time: 0.160, data: 0.000) loss: 0.332 
(epoch: 175, iters: 4352, time: 0.164, data: 0.005) loss: 0.069 
(epoch: 175, iters: 4432, time: 0.160, data: 0.000) loss: 0.395 
(epoch: 175, iters: 4512, time: 0.158, data: 0.000) loss: 0.504 
(epoch: 175, iters: 4592, time: 0.160, data: 0.000) loss: 0.120 
(epoch: 175, iters: 4672, time: 0.157, data: 0.025) loss: 0.536 
(epoch: 175, iters: 4752, time: 0.159, data: 0.000) loss: 0.468 
(epoch: 175, iters: 4832, time: 0.159, data: 0.000) loss: 0.547 
(epoch: 175, iters: 4912, time: 0.157, data: 0.024) loss: 0.951 
(epoch: 175, iters: 4992, time: 0.159, data: 0.000) loss: 0.159 
(epoch: 175, iters: 5072, time: 0.158, data: 0.032) loss: 0.242 
(epoch: 175, iters: 5152, time: 0.158, data: 0.000) loss: 0.126 
(epoch: 175, iters: 5232, time: 0.160, data: 0.000) loss: 0.045 
(epoch: 175, iters: 5312, time: 0.158, data: 0.000) loss: 0.112 
(epoch: 175, iters: 5392, time: 0.161, data: 0.005) loss: 0.113 
(epoch: 175, iters: 5472, time: 0.160, data: 0.017) loss: 0.372 
(epoch: 175, iters: 5552, time: 0.157, data: 0.000) loss: 0.135 
(epoch: 175, iters: 5632, time: 0.160, data: 0.030) loss: 0.199 
(epoch: 175, iters: 5712, time: 0.159, data: 0.000) loss: 0.177 
(epoch: 175, iters: 5792, time: 0.160, data: 0.000) loss: 0.170 
(epoch: 175, iters: 5872, time: 0.160, data: 0.000) loss: 0.051 
(epoch: 175, iters: 5952, time: 0.160, data: 0.022) loss: 0.114 
(epoch: 175, iters: 6032, time: 0.161, data: 0.000) loss: 0.388 
(epoch: 175, iters: 6112, time: 0.159, data: 0.000) loss: 0.415 
(epoch: 175, iters: 6192, time: 0.158, data: 0.000) loss: 0.449 
(epoch: 175, iters: 6272, time: 0.160, data: 0.000) loss: 0.268 
(epoch: 175, iters: 6352, time: 0.160, data: 0.000) loss: 0.297 
(epoch: 175, iters: 6432, time: 0.158, data: 0.000) loss: 0.128 
(epoch: 175, iters: 6512, time: 0.158, data: 0.000) loss: 0.213 
(epoch: 175, iters: 6592, time: 0.159, data: 0.000) loss: 0.351 
(epoch: 175, iters: 6672, time: 0.159, data: 0.000) loss: 0.098 
(epoch: 175, iters: 6752, time: 0.161, data: 0.005) loss: 0.070 
(epoch: 175, iters: 6832, time: 0.158, data: 0.006) loss: 0.146 
(epoch: 175, iters: 6912, time: 0.158, data: 0.000) loss: 0.331 
(epoch: 175, iters: 6992, time: 0.160, data: 0.005) loss: 0.192 
(epoch: 175, iters: 7072, time: 0.159, data: 0.000) loss: 0.202 
(epoch: 175, iters: 7152, time: 0.161, data: 0.000) loss: 0.236 
(epoch: 175, iters: 7232, time: 0.160, data: 0.000) loss: 0.123 
(epoch: 175, iters: 7312, time: 0.159, data: 0.000) loss: 0.255 
(epoch: 175, iters: 7392, time: 0.159, data: 0.000) loss: 0.443 
(epoch: 175, iters: 7472, time: 0.161, data: 0.013) loss: 0.154 
(epoch: 175, iters: 7552, time: 0.160, data: 0.000) loss: 0.353 
(epoch: 175, iters: 7632, time: 0.160, data: 0.013) loss: 0.164 
(epoch: 175, iters: 7712, time: 0.161, data: 0.009) loss: 0.385 
(epoch: 175, iters: 7792, time: 0.159, data: 0.009) loss: 0.134 
(epoch: 175, iters: 7872, time: 0.159, data: 0.000) loss: 0.320 
(epoch: 175, iters: 7952, time: 0.159, data: 0.008) loss: 0.162 
saving the latest model (epoch 175, total_steps 1781424)
(epoch: 175, iters: 8032, time: 0.160, data: 0.000) loss: 0.274 
(epoch: 175, iters: 8112, time: 0.158, data: 0.024) loss: 0.162 
(epoch: 175, iters: 8192, time: 0.158, data: 0.000) loss: 0.050 
(epoch: 175, iters: 8272, time: 0.160, data: 0.000) loss: 0.269 
(epoch: 175, iters: 8352, time: 0.159, data: 0.006) loss: 0.092 
(epoch: 175, iters: 8432, time: 0.159, data: 0.010) loss: 0.341 
(epoch: 175, iters: 8512, time: 0.160, data: 0.000) loss: 0.273 
(epoch: 175, iters: 8592, time: 0.159, data: 0.000) loss: 0.234 
(epoch: 175, iters: 8672, time: 0.159, data: 0.000) loss: 0.244 
(epoch: 175, iters: 8752, time: 0.159, data: 0.008) loss: 0.402 
(epoch: 175, iters: 8832, time: 0.158, data: 0.010) loss: 0.172 
(epoch: 175, iters: 8912, time: 0.160, data: 0.000) loss: 0.193 
(epoch: 175, iters: 8992, time: 0.158, data: 0.011) loss: 0.558 
(epoch: 175, iters: 9072, time: 0.158, data: 0.000) loss: 0.298 
(epoch: 175, iters: 9152, time: 0.161, data: 0.010) loss: 0.157 
(epoch: 175, iters: 9232, time: 0.158, data: 0.000) loss: 0.481 
(epoch: 175, iters: 9312, time: 0.159, data: 0.040) loss: 0.198 
(epoch: 175, iters: 9392, time: 0.158, data: 0.000) loss: 0.126 
(epoch: 175, iters: 9472, time: 0.159, data: 0.008) loss: 0.273 
(epoch: 175, iters: 9552, time: 0.160, data: 0.011) loss: 0.289 
(epoch: 175, iters: 9632, time: 0.159, data: 0.033) loss: 0.410 
(epoch: 175, iters: 9712, time: 0.159, data: 0.000) loss: 0.439 
(epoch: 175, iters: 9792, time: 0.160, data: 0.010) loss: 0.509 
(epoch: 175, iters: 9872, time: 0.156, data: 0.006) loss: 0.358 
(epoch: 175, iters: 9952, time: 0.159, data: 0.000) loss: 0.139 
(epoch: 175, iters: 10032, time: 0.160, data: 0.000) loss: 0.364 
(epoch: 175, iters: 10112, time: 0.160, data: 0.031) loss: 0.214 
(epoch: 175, iters: 10192, time: 0.096, data: 0.000) loss: 0.267 
saving the model at the end of epoch 175, iters 1783600
End of epoch 175 / 200 	 Time Taken: 1626 sec
learning rate = 0.0000475
saving the latest model (epoch 176, total_steps 1783616)
(epoch: 176, iters: 80, time: 0.164, data: 0.181) loss: 0.466 
(epoch: 176, iters: 160, time: 0.158, data: 0.000) loss: 0.229 
(epoch: 176, iters: 240, time: 0.158, data: 0.000) loss: 0.053 
(epoch: 176, iters: 320, time: 0.157, data: 0.009) loss: 0.456 
(epoch: 176, iters: 400, time: 0.158, data: 0.011) loss: 0.653 
(epoch: 176, iters: 480, time: 0.157, data: 0.000) loss: 0.179 
(epoch: 176, iters: 560, time: 0.157, data: 0.000) loss: 0.077 
(epoch: 176, iters: 640, time: 0.158, data: 0.006) loss: 0.176 
(epoch: 176, iters: 720, time: 0.159, data: 0.000) loss: 0.394 
(epoch: 176, iters: 800, time: 0.158, data: 0.005) loss: 0.054 
(epoch: 176, iters: 880, time: 0.159, data: 0.011) loss: 0.126 
(epoch: 176, iters: 960, time: 0.159, data: 0.000) loss: 0.085 
(epoch: 176, iters: 1040, time: 0.159, data: 0.005) loss: 0.177 
(epoch: 176, iters: 1120, time: 0.159, data: 0.000) loss: 0.250 
(epoch: 176, iters: 1200, time: 0.160, data: 0.000) loss: 0.163 
(epoch: 176, iters: 1280, time: 0.159, data: 0.005) loss: 0.136 
(epoch: 176, iters: 1360, time: 0.159, data: 0.000) loss: 0.172 
(epoch: 176, iters: 1440, time: 0.158, data: 0.013) loss: 0.193 
(epoch: 176, iters: 1520, time: 0.161, data: 0.000) loss: 0.179 
(epoch: 176, iters: 1600, time: 0.161, data: 0.000) loss: 0.091 
(epoch: 176, iters: 1680, time: 0.158, data: 0.000) loss: 0.573 
(epoch: 176, iters: 1760, time: 0.160, data: 0.024) loss: 0.218 
(epoch: 176, iters: 1840, time: 0.160, data: 0.000) loss: 0.098 
(epoch: 176, iters: 1920, time: 0.159, data: 0.000) loss: 0.389 
(epoch: 176, iters: 2000, time: 0.160, data: 0.009) loss: 0.119 
(epoch: 176, iters: 2080, time: 0.160, data: 0.000) loss: 0.337 
(epoch: 176, iters: 2160, time: 0.160, data: 0.013) loss: 0.240 
(epoch: 176, iters: 2240, time: 0.159, data: 0.006) loss: 0.136 
(epoch: 176, iters: 2320, time: 0.160, data: 0.028) loss: 0.182 
(epoch: 176, iters: 2400, time: 0.159, data: 0.000) loss: 0.081 
(epoch: 176, iters: 2480, time: 0.160, data: 0.000) loss: 0.228 
(epoch: 176, iters: 2560, time: 0.159, data: 0.014) loss: 0.455 
(epoch: 176, iters: 2640, time: 0.161, data: 0.000) loss: 0.098 
(epoch: 176, iters: 2720, time: 0.158, data: 0.008) loss: 0.199 
(epoch: 176, iters: 2800, time: 0.158, data: 0.000) loss: 0.161 
(epoch: 176, iters: 2880, time: 0.159, data: 0.011) loss: 0.079 
(epoch: 176, iters: 2960, time: 0.159, data: 0.005) loss: 0.200 
(epoch: 176, iters: 3040, time: 0.159, data: 0.000) loss: 0.281 
(epoch: 176, iters: 3120, time: 0.159, data: 0.026) loss: 0.302 
(epoch: 176, iters: 3200, time: 0.158, data: 0.008) loss: 0.475 
(epoch: 176, iters: 3280, time: 0.157, data: 0.000) loss: 0.108 
(epoch: 176, iters: 3360, time: 0.157, data: 0.009) loss: 0.487 
(epoch: 176, iters: 3440, time: 0.157, data: 0.000) loss: 0.173 
(epoch: 176, iters: 3520, time: 0.157, data: 0.015) loss: 0.342 
(epoch: 176, iters: 3600, time: 0.158, data: 0.025) loss: 0.143 
(epoch: 176, iters: 3680, time: 0.159, data: 0.000) loss: 0.686 
(epoch: 176, iters: 3760, time: 0.157, data: 0.009) loss: 0.278 
(epoch: 176, iters: 3840, time: 0.156, data: 0.005) loss: 0.228 
(epoch: 176, iters: 3920, time: 0.157, data: 0.000) loss: 0.375 
(epoch: 176, iters: 4000, time: 0.158, data: 0.025) loss: 0.253 
saving the latest model (epoch 176, total_steps 1787616)
(epoch: 176, iters: 4080, time: 0.157, data: 0.000) loss: 0.063 
(epoch: 176, iters: 4160, time: 0.156, data: 0.000) loss: 0.333 
(epoch: 176, iters: 4240, time: 0.156, data: 0.020) loss: 0.256 
(epoch: 176, iters: 4320, time: 0.156, data: 0.032) loss: 0.335 
(epoch: 176, iters: 4400, time: 0.157, data: 0.000) loss: 0.106 
(epoch: 176, iters: 4480, time: 0.159, data: 0.031) loss: 0.165 
(epoch: 176, iters: 4560, time: 0.162, data: 0.000) loss: 0.148 
(epoch: 176, iters: 4640, time: 0.157, data: 0.000) loss: 0.153 
(epoch: 176, iters: 4720, time: 0.158, data: 0.000) loss: 0.492 
(epoch: 176, iters: 4800, time: 0.158, data: 0.009) loss: 0.133 
(epoch: 176, iters: 4880, time: 0.161, data: 0.000) loss: 0.231 
(epoch: 176, iters: 4960, time: 0.162, data: 0.015) loss: 0.356 
(epoch: 176, iters: 5040, time: 0.159, data: 0.000) loss: 0.104 
(epoch: 176, iters: 5120, time: 0.158, data: 0.011) loss: 0.174 
(epoch: 176, iters: 5200, time: 0.158, data: 0.000) loss: 0.284 
(epoch: 176, iters: 5280, time: 0.160, data: 0.000) loss: 0.285 
(epoch: 176, iters: 5360, time: 0.160, data: 0.008) loss: 0.412 
(epoch: 176, iters: 5440, time: 0.158, data: 0.025) loss: 0.186 
(epoch: 176, iters: 5520, time: 0.159, data: 0.014) loss: 0.033 
(epoch: 176, iters: 5600, time: 0.162, data: 0.024) loss: 0.568 
(epoch: 176, iters: 5680, time: 0.159, data: 0.000) loss: 0.154 
(epoch: 176, iters: 5760, time: 0.159, data: 0.017) loss: 0.244 
(epoch: 176, iters: 5840, time: 0.159, data: 0.005) loss: 0.142 
(epoch: 176, iters: 5920, time: 0.160, data: 0.000) loss: 0.274 
(epoch: 176, iters: 6000, time: 0.161, data: 0.005) loss: 0.133 
(epoch: 176, iters: 6080, time: 0.161, data: 0.000) loss: 0.225 
(epoch: 176, iters: 6160, time: 0.158, data: 0.000) loss: 0.126 
(epoch: 176, iters: 6240, time: 0.159, data: 0.000) loss: 0.364 
(epoch: 176, iters: 6320, time: 0.160, data: 0.000) loss: 0.495 
(epoch: 176, iters: 6400, time: 0.159, data: 0.000) loss: 0.932 
(epoch: 176, iters: 6480, time: 0.160, data: 0.000) loss: 0.309 
(epoch: 176, iters: 6560, time: 0.160, data: 0.000) loss: 0.050 
(epoch: 176, iters: 6640, time: 0.158, data: 0.000) loss: 0.269 
(epoch: 176, iters: 6720, time: 0.158, data: 0.008) loss: 0.750 
(epoch: 176, iters: 6800, time: 0.158, data: 0.000) loss: 0.302 
(epoch: 176, iters: 6880, time: 0.157, data: 0.019) loss: 0.650 
(epoch: 176, iters: 6960, time: 0.157, data: 0.000) loss: 0.464 
(epoch: 176, iters: 7040, time: 0.158, data: 0.012) loss: 0.169 
(epoch: 176, iters: 7120, time: 0.161, data: 0.000) loss: 0.255 
(epoch: 176, iters: 7200, time: 0.157, data: 0.035) loss: 0.537 
(epoch: 176, iters: 7280, time: 0.159, data: 0.000) loss: 0.578 
(epoch: 176, iters: 7360, time: 0.160, data: 0.000) loss: 0.102 
(epoch: 176, iters: 7440, time: 0.159, data: 0.005) loss: 0.247 
(epoch: 176, iters: 7520, time: 0.159, data: 0.008) loss: 0.099 
(epoch: 176, iters: 7600, time: 0.158, data: 0.008) loss: 0.072 
(epoch: 176, iters: 7680, time: 0.160, data: 0.006) loss: 0.083 
(epoch: 176, iters: 7760, time: 0.157, data: 0.000) loss: 0.283 
(epoch: 176, iters: 7840, time: 0.159, data: 0.010) loss: 0.480 
(epoch: 176, iters: 7920, time: 0.159, data: 0.000) loss: 0.157 
(epoch: 176, iters: 8000, time: 0.159, data: 0.025) loss: 0.243 
saving the latest model (epoch 176, total_steps 1791616)
(epoch: 176, iters: 8080, time: 0.158, data: 0.000) loss: 0.470 
(epoch: 176, iters: 8160, time: 0.160, data: 0.000) loss: 0.292 
(epoch: 176, iters: 8240, time: 0.159, data: 0.000) loss: 0.281 
(epoch: 176, iters: 8320, time: 0.159, data: 0.000) loss: 0.451 
(epoch: 176, iters: 8400, time: 0.159, data: 0.000) loss: 0.241 
(epoch: 176, iters: 8480, time: 0.159, data: 0.000) loss: 0.112 
(epoch: 176, iters: 8560, time: 0.159, data: 0.009) loss: 0.343 
(epoch: 176, iters: 8640, time: 0.160, data: 0.000) loss: 0.437 
(epoch: 176, iters: 8720, time: 0.164, data: 0.008) loss: 0.579 
(epoch: 176, iters: 8800, time: 0.159, data: 0.000) loss: 0.168 
(epoch: 176, iters: 8880, time: 0.159, data: 0.020) loss: 0.081 
(epoch: 176, iters: 8960, time: 0.159, data: 0.008) loss: 0.127 
(epoch: 176, iters: 9040, time: 0.158, data: 0.000) loss: 0.203 
(epoch: 176, iters: 9120, time: 0.159, data: 0.005) loss: 0.302 
(epoch: 176, iters: 9200, time: 0.160, data: 0.000) loss: 0.599 
(epoch: 176, iters: 9280, time: 0.159, data: 0.000) loss: 0.432 
(epoch: 176, iters: 9360, time: 0.160, data: 0.005) loss: 0.610 
(epoch: 176, iters: 9440, time: 0.160, data: 0.008) loss: 0.108 
(epoch: 176, iters: 9520, time: 0.159, data: 0.000) loss: 0.097 
(epoch: 176, iters: 9600, time: 0.159, data: 0.016) loss: 0.051 
(epoch: 176, iters: 9680, time: 0.158, data: 0.009) loss: 0.057 
(epoch: 176, iters: 9760, time: 0.158, data: 0.000) loss: 0.266 
(epoch: 176, iters: 9840, time: 0.157, data: 0.008) loss: 0.207 
(epoch: 176, iters: 9920, time: 0.159, data: 0.008) loss: 0.099 
(epoch: 176, iters: 10000, time: 0.159, data: 0.009) loss: 0.224 
(epoch: 176, iters: 10080, time: 0.159, data: 0.014) loss: 0.333 
(epoch: 176, iters: 10160, time: 0.161, data: 0.008) loss: 0.293 
saving the model at the end of epoch 176, iters 1793792
End of epoch 176 / 200 	 Time Taken: 1623 sec
learning rate = 0.0000455
saving the latest model (epoch 177, total_steps 1793808)
(epoch: 177, iters: 48, time: 0.162, data: 0.000) loss: 0.125 
(epoch: 177, iters: 128, time: 0.155, data: 0.024) loss: 0.688 
(epoch: 177, iters: 208, time: 0.156, data: 0.000) loss: 0.217 
(epoch: 177, iters: 288, time: 0.156, data: 0.000) loss: 0.129 
(epoch: 177, iters: 368, time: 0.153, data: 0.016) loss: 0.100 
(epoch: 177, iters: 448, time: 0.154, data: 0.000) loss: 0.173 
(epoch: 177, iters: 528, time: 0.155, data: 0.014) loss: 0.417 
(epoch: 177, iters: 608, time: 0.155, data: 0.000) loss: 0.216 
(epoch: 177, iters: 688, time: 0.154, data: 0.000) loss: 0.596 
(epoch: 177, iters: 768, time: 0.154, data: 0.009) loss: 0.141 
(epoch: 177, iters: 848, time: 0.156, data: 0.006) loss: 0.365 
(epoch: 177, iters: 928, time: 0.155, data: 0.006) loss: 0.215 
(epoch: 177, iters: 1008, time: 0.157, data: 0.000) loss: 0.594 
(epoch: 177, iters: 1088, time: 0.156, data: 0.000) loss: 0.148 
(epoch: 177, iters: 1168, time: 0.156, data: 0.000) loss: 0.468 
(epoch: 177, iters: 1248, time: 0.154, data: 0.000) loss: 0.166 
(epoch: 177, iters: 1328, time: 0.154, data: 0.016) loss: 0.303 
(epoch: 177, iters: 1408, time: 0.155, data: 0.005) loss: 0.262 
(epoch: 177, iters: 1488, time: 0.156, data: 0.000) loss: 0.512 
(epoch: 177, iters: 1568, time: 0.155, data: 0.000) loss: 0.112 
(epoch: 177, iters: 1648, time: 0.155, data: 0.000) loss: 0.292 
(epoch: 177, iters: 1728, time: 0.155, data: 0.000) loss: 0.402 
(epoch: 177, iters: 1808, time: 0.155, data: 0.000) loss: 0.299 
(epoch: 177, iters: 1888, time: 0.157, data: 0.015) loss: 0.949 
(epoch: 177, iters: 1968, time: 0.155, data: 0.005) loss: 0.345 
(epoch: 177, iters: 2048, time: 0.155, data: 0.005) loss: 0.386 
(epoch: 177, iters: 2128, time: 0.155, data: 0.000) loss: 0.144 
(epoch: 177, iters: 2208, time: 0.154, data: 0.000) loss: 0.109 
(epoch: 177, iters: 2288, time: 0.157, data: 0.000) loss: 0.665 
(epoch: 177, iters: 2368, time: 0.157, data: 0.007) loss: 0.222 
(epoch: 177, iters: 2448, time: 0.157, data: 0.000) loss: 0.632 
(epoch: 177, iters: 2528, time: 0.157, data: 0.000) loss: 0.084 
(epoch: 177, iters: 2608, time: 0.156, data: 0.000) loss: 0.393 
(epoch: 177, iters: 2688, time: 0.155, data: 0.018) loss: 0.425 
(epoch: 177, iters: 2768, time: 0.158, data: 0.000) loss: 0.224 
(epoch: 177, iters: 2848, time: 0.156, data: 0.000) loss: 0.169 
(epoch: 177, iters: 2928, time: 0.157, data: 0.014) loss: 0.795 
(epoch: 177, iters: 3008, time: 0.158, data: 0.000) loss: 0.528 
(epoch: 177, iters: 3088, time: 0.157, data: 0.000) loss: 0.403 
(epoch: 177, iters: 3168, time: 0.158, data: 0.009) loss: 0.080 
(epoch: 177, iters: 3248, time: 0.157, data: 0.000) loss: 0.290 
(epoch: 177, iters: 3328, time: 0.157, data: 0.000) loss: 0.413 
(epoch: 177, iters: 3408, time: 0.156, data: 0.000) loss: 0.252 
(epoch: 177, iters: 3488, time: 0.157, data: 0.032) loss: 0.123 
(epoch: 177, iters: 3568, time: 0.158, data: 0.009) loss: 0.175 
(epoch: 177, iters: 3648, time: 0.157, data: 0.000) loss: 0.187 
(epoch: 177, iters: 3728, time: 0.159, data: 0.031) loss: 0.245 
(epoch: 177, iters: 3808, time: 0.157, data: 0.000) loss: 0.103 
(epoch: 177, iters: 3888, time: 0.158, data: 0.031) loss: 0.365 
(epoch: 177, iters: 3968, time: 0.157, data: 0.000) loss: 0.187 
saving the latest model (epoch 177, total_steps 1797808)
(epoch: 177, iters: 4048, time: 0.159, data: 0.000) loss: 0.565 
(epoch: 177, iters: 4128, time: 0.159, data: 0.006) loss: 0.165 
(epoch: 177, iters: 4208, time: 0.161, data: 0.000) loss: 0.134 
(epoch: 177, iters: 4288, time: 0.156, data: 0.005) loss: 0.251 
(epoch: 177, iters: 4368, time: 0.155, data: 0.000) loss: 0.129 
(epoch: 177, iters: 4448, time: 0.157, data: 0.000) loss: 0.302 
(epoch: 177, iters: 4528, time: 0.156, data: 0.000) loss: 0.091 
(epoch: 177, iters: 4608, time: 0.159, data: 0.005) loss: 0.229 
(epoch: 177, iters: 4688, time: 0.158, data: 0.000) loss: 0.177 
(epoch: 177, iters: 4768, time: 0.158, data: 0.000) loss: 0.204 
(epoch: 177, iters: 4848, time: 0.158, data: 0.000) loss: 0.123 
(epoch: 177, iters: 4928, time: 0.162, data: 0.000) loss: 0.105 
(epoch: 177, iters: 5008, time: 0.162, data: 0.008) loss: 0.150 
(epoch: 177, iters: 5088, time: 0.162, data: 0.009) loss: 0.276 
(epoch: 177, iters: 5168, time: 0.163, data: 0.012) loss: 0.564 
(epoch: 177, iters: 5248, time: 0.160, data: 0.000) loss: 0.188 
(epoch: 177, iters: 5328, time: 0.164, data: 0.000) loss: 0.433 
(epoch: 177, iters: 5408, time: 0.161, data: 0.016) loss: 0.031 
(epoch: 177, iters: 5488, time: 0.161, data: 0.000) loss: 0.279 
(epoch: 177, iters: 5568, time: 0.162, data: 0.021) loss: 0.193 
(epoch: 177, iters: 5648, time: 0.162, data: 0.000) loss: 0.292 
(epoch: 177, iters: 5728, time: 0.161, data: 0.000) loss: 0.612 
(epoch: 177, iters: 5808, time: 0.162, data: 0.016) loss: 0.227 
(epoch: 177, iters: 5888, time: 0.162, data: 0.000) loss: 0.177 
(epoch: 177, iters: 5968, time: 0.161, data: 0.009) loss: 0.183 
(epoch: 177, iters: 6048, time: 0.161, data: 0.005) loss: 0.119 
(epoch: 177, iters: 6128, time: 0.165, data: 0.000) loss: 0.128 
(epoch: 177, iters: 6208, time: 0.163, data: 0.005) loss: 0.097 
(epoch: 177, iters: 6288, time: 0.161, data: 0.006) loss: 0.296 
(epoch: 177, iters: 6368, time: 0.162, data: 0.000) loss: 0.262 
(epoch: 177, iters: 6448, time: 0.162, data: 0.000) loss: 0.284 
(epoch: 177, iters: 6528, time: 0.163, data: 0.018) loss: 0.511 
(epoch: 177, iters: 6608, time: 0.161, data: 0.000) loss: 0.230 
(epoch: 177, iters: 6688, time: 0.164, data: 0.005) loss: 0.351 
(epoch: 177, iters: 6768, time: 0.164, data: 0.000) loss: 0.052 
(epoch: 177, iters: 6848, time: 0.161, data: 0.000) loss: 0.194 
(epoch: 177, iters: 6928, time: 0.161, data: 0.000) loss: 0.281 
(epoch: 177, iters: 7008, time: 0.162, data: 0.000) loss: 0.331 
(epoch: 177, iters: 7088, time: 0.160, data: 0.024) loss: 0.420 
(epoch: 177, iters: 7168, time: 0.161, data: 0.000) loss: 0.182 
(epoch: 177, iters: 7248, time: 0.160, data: 0.000) loss: 0.542 
(epoch: 177, iters: 7328, time: 0.162, data: 0.000) loss: 0.326 
(epoch: 177, iters: 7408, time: 0.161, data: 0.000) loss: 0.680 
(epoch: 177, iters: 7488, time: 0.162, data: 0.032) loss: 0.171 
(epoch: 177, iters: 7568, time: 0.161, data: 0.000) loss: 0.477 
(epoch: 177, iters: 7648, time: 0.162, data: 0.000) loss: 0.187 
(epoch: 177, iters: 7728, time: 0.163, data: 0.000) loss: 0.389 
(epoch: 177, iters: 7808, time: 0.162, data: 0.014) loss: 0.534 
(epoch: 177, iters: 7888, time: 0.162, data: 0.031) loss: 0.476 
(epoch: 177, iters: 7968, time: 0.163, data: 0.000) loss: 0.078 
saving the latest model (epoch 177, total_steps 1801808)
(epoch: 177, iters: 8048, time: 0.162, data: 0.000) loss: 0.157 
(epoch: 177, iters: 8128, time: 0.163, data: 0.031) loss: 0.166 
(epoch: 177, iters: 8208, time: 0.163, data: 0.000) loss: 0.080 
(epoch: 177, iters: 8288, time: 0.162, data: 0.000) loss: 0.130 
(epoch: 177, iters: 8368, time: 0.163, data: 0.014) loss: 0.212 
(epoch: 177, iters: 8448, time: 0.163, data: 0.000) loss: 0.481 
(epoch: 177, iters: 8528, time: 0.165, data: 0.000) loss: 0.347 
(epoch: 177, iters: 8608, time: 0.163, data: 0.000) loss: 0.617 
(epoch: 177, iters: 8688, time: 0.163, data: 0.005) loss: 0.170 
(epoch: 177, iters: 8768, time: 0.162, data: 0.000) loss: 0.519 
(epoch: 177, iters: 8848, time: 0.163, data: 0.000) loss: 0.225 
(epoch: 177, iters: 8928, time: 0.162, data: 0.008) loss: 0.178 
(epoch: 177, iters: 9008, time: 0.163, data: 0.033) loss: 0.079 
(epoch: 177, iters: 9088, time: 0.162, data: 0.000) loss: 0.409 
(epoch: 177, iters: 9168, time: 0.161, data: 0.000) loss: 0.097 
(epoch: 177, iters: 9248, time: 0.161, data: 0.006) loss: 0.311 
(epoch: 177, iters: 9328, time: 0.162, data: 0.009) loss: 0.521 
(epoch: 177, iters: 9408, time: 0.162, data: 0.000) loss: 0.273 
(epoch: 177, iters: 9488, time: 0.162, data: 0.000) loss: 0.170 
(epoch: 177, iters: 9568, time: 0.160, data: 0.006) loss: 0.386 
(epoch: 177, iters: 9648, time: 0.162, data: 0.000) loss: 0.412 
(epoch: 177, iters: 9728, time: 0.163, data: 0.016) loss: 0.509 
(epoch: 177, iters: 9808, time: 0.162, data: 0.000) loss: 0.140 
(epoch: 177, iters: 9888, time: 0.161, data: 0.000) loss: 0.244 
(epoch: 177, iters: 9968, time: 0.163, data: 0.016) loss: 0.194 
(epoch: 177, iters: 10048, time: 0.163, data: 0.018) loss: 0.102 
(epoch: 177, iters: 10128, time: 0.161, data: 0.000) loss: 0.196 
saving the model at the end of epoch 177, iters 1803984
End of epoch 177 / 200 	 Time Taken: 1627 sec
learning rate = 0.0000436
(epoch: 178, iters: 16, time: 0.179, data: 0.000) loss: 0.141 
saving the latest model (epoch 178, total_steps 1804000)
(epoch: 178, iters: 96, time: 0.162, data: 0.042) loss: 0.438 
(epoch: 178, iters: 176, time: 0.164, data: 0.000) loss: 0.357 
(epoch: 178, iters: 256, time: 0.161, data: 0.000) loss: 0.305 
(epoch: 178, iters: 336, time: 0.162, data: 0.020) loss: 0.096 
(epoch: 178, iters: 416, time: 0.163, data: 0.015) loss: 0.212 
(epoch: 178, iters: 496, time: 0.162, data: 0.000) loss: 0.197 
(epoch: 178, iters: 576, time: 0.162, data: 0.000) loss: 0.350 
(epoch: 178, iters: 656, time: 0.161, data: 0.006) loss: 0.209 
(epoch: 178, iters: 736, time: 0.164, data: 0.000) loss: 0.302 
(epoch: 178, iters: 816, time: 0.162, data: 0.008) loss: 0.222 
(epoch: 178, iters: 896, time: 0.162, data: 0.000) loss: 0.344 
(epoch: 178, iters: 976, time: 0.163, data: 0.008) loss: 0.196 
(epoch: 178, iters: 1056, time: 0.162, data: 0.006) loss: 0.091 
(epoch: 178, iters: 1136, time: 0.162, data: 0.005) loss: 0.368 
(epoch: 178, iters: 1216, time: 0.161, data: 0.000) loss: 0.393 
(epoch: 178, iters: 1296, time: 0.162, data: 0.000) loss: 0.283 
(epoch: 178, iters: 1376, time: 0.162, data: 0.008) loss: 0.073 
(epoch: 178, iters: 1456, time: 0.164, data: 0.000) loss: 0.309 
(epoch: 178, iters: 1536, time: 0.162, data: 0.006) loss: 0.557 
(epoch: 178, iters: 1616, time: 0.162, data: 0.000) loss: 0.136 
(epoch: 178, iters: 1696, time: 0.162, data: 0.025) loss: 0.475 
(epoch: 178, iters: 1776, time: 0.161, data: 0.035) loss: 0.370 
(epoch: 178, iters: 1856, time: 0.161, data: 0.000) loss: 0.225 
(epoch: 178, iters: 1936, time: 0.160, data: 0.023) loss: 0.097 
(epoch: 178, iters: 2016, time: 0.162, data: 0.000) loss: 0.238 
(epoch: 178, iters: 2096, time: 0.163, data: 0.013) loss: 0.057 
(epoch: 178, iters: 2176, time: 0.162, data: 0.008) loss: 0.240 
(epoch: 178, iters: 2256, time: 0.159, data: 0.021) loss: 0.253 
(epoch: 178, iters: 2336, time: 0.162, data: 0.000) loss: 0.361 
(epoch: 178, iters: 2416, time: 0.160, data: 0.000) loss: 0.131 
(epoch: 178, iters: 2496, time: 0.162, data: 0.000) loss: 0.183 
(epoch: 178, iters: 2576, time: 0.162, data: 0.008) loss: 0.201 
(epoch: 178, iters: 2656, time: 0.162, data: 0.000) loss: 0.123 
(epoch: 178, iters: 2736, time: 0.162, data: 0.000) loss: 0.166 
(epoch: 178, iters: 2816, time: 0.161, data: 0.005) loss: 0.048 
(epoch: 178, iters: 2896, time: 0.162, data: 0.000) loss: 0.115 
(epoch: 178, iters: 2976, time: 0.162, data: 0.024) loss: 0.199 
(epoch: 178, iters: 3056, time: 0.162, data: 0.000) loss: 0.233 
(epoch: 178, iters: 3136, time: 0.165, data: 0.033) loss: 0.617 
(epoch: 178, iters: 3216, time: 0.166, data: 0.000) loss: 0.077 
(epoch: 178, iters: 3296, time: 0.163, data: 0.000) loss: 0.246 
(epoch: 178, iters: 3376, time: 0.166, data: 0.000) loss: 0.192 
(epoch: 178, iters: 3456, time: 0.164, data: 0.009) loss: 0.163 
(epoch: 178, iters: 3536, time: 0.161, data: 0.008) loss: 0.139 
(epoch: 178, iters: 3616, time: 0.162, data: 0.000) loss: 0.159 
(epoch: 178, iters: 3696, time: 0.162, data: 0.041) loss: 0.274 
(epoch: 178, iters: 3776, time: 0.163, data: 0.000) loss: 0.134 
(epoch: 178, iters: 3856, time: 0.164, data: 0.000) loss: 0.104 
(epoch: 178, iters: 3936, time: 0.163, data: 0.006) loss: 0.176 
(epoch: 178, iters: 4016, time: 0.161, data: 0.000) loss: 0.283 
saving the latest model (epoch 178, total_steps 1808000)
(epoch: 178, iters: 4096, time: 0.162, data: 0.000) loss: 0.189 
(epoch: 178, iters: 4176, time: 0.161, data: 0.020) loss: 0.497 
(epoch: 178, iters: 4256, time: 0.162, data: 0.000) loss: 0.378 
(epoch: 178, iters: 4336, time: 0.161, data: 0.009) loss: 0.079 
(epoch: 178, iters: 4416, time: 0.161, data: 0.000) loss: 0.123 
(epoch: 178, iters: 4496, time: 0.160, data: 0.000) loss: 0.344 
(epoch: 178, iters: 4576, time: 0.161, data: 0.000) loss: 0.364 
(epoch: 178, iters: 4656, time: 0.160, data: 0.006) loss: 0.437 
(epoch: 178, iters: 4736, time: 0.161, data: 0.000) loss: 0.215 
(epoch: 178, iters: 4816, time: 0.162, data: 0.018) loss: 0.385 
(epoch: 178, iters: 4896, time: 0.161, data: 0.000) loss: 0.244 
(epoch: 178, iters: 4976, time: 0.162, data: 0.000) loss: 0.097 
(epoch: 178, iters: 5056, time: 0.162, data: 0.005) loss: 0.085 
(epoch: 178, iters: 5136, time: 0.159, data: 0.006) loss: 0.327 
(epoch: 178, iters: 5216, time: 0.161, data: 0.009) loss: 0.492 
(epoch: 178, iters: 5296, time: 0.162, data: 0.000) loss: 0.273 
(epoch: 178, iters: 5376, time: 0.163, data: 0.018) loss: 0.228 
(epoch: 178, iters: 5456, time: 0.160, data: 0.000) loss: 0.204 
(epoch: 178, iters: 5536, time: 0.160, data: 0.000) loss: 0.155 
(epoch: 178, iters: 5616, time: 0.162, data: 0.036) loss: 0.328 
(epoch: 178, iters: 5696, time: 0.161, data: 0.000) loss: 0.241 
(epoch: 178, iters: 5776, time: 0.161, data: 0.000) loss: 0.205 
(epoch: 178, iters: 5856, time: 0.161, data: 0.005) loss: 0.187 
(epoch: 178, iters: 5936, time: 0.161, data: 0.000) loss: 0.193 
(epoch: 178, iters: 6016, time: 0.161, data: 0.000) loss: 0.207 
(epoch: 178, iters: 6096, time: 0.161, data: 0.000) loss: 0.189 
(epoch: 178, iters: 6176, time: 0.162, data: 0.026) loss: 0.129 
(epoch: 178, iters: 6256, time: 0.161, data: 0.000) loss: 0.048 
(epoch: 178, iters: 6336, time: 0.163, data: 0.000) loss: 0.012 
(epoch: 178, iters: 6416, time: 0.163, data: 0.016) loss: 0.288 
(epoch: 178, iters: 6496, time: 0.162, data: 0.005) loss: 0.136 
(epoch: 178, iters: 6576, time: 0.160, data: 0.012) loss: 0.542 
(epoch: 178, iters: 6656, time: 0.161, data: 0.000) loss: 0.126 
(epoch: 178, iters: 6736, time: 0.160, data: 0.000) loss: 0.048 
(epoch: 178, iters: 6816, time: 0.162, data: 0.006) loss: 0.143 
(epoch: 178, iters: 6896, time: 0.163, data: 0.005) loss: 0.444 
(epoch: 178, iters: 6976, time: 0.162, data: 0.000) loss: 0.355 
(epoch: 178, iters: 7056, time: 0.162, data: 0.000) loss: 0.201 
(epoch: 178, iters: 7136, time: 0.162, data: 0.005) loss: 0.080 
(epoch: 178, iters: 7216, time: 0.161, data: 0.016) loss: 0.199 
(epoch: 178, iters: 7296, time: 0.162, data: 0.008) loss: 0.198 
(epoch: 178, iters: 7376, time: 0.161, data: 0.000) loss: 0.289 
(epoch: 178, iters: 7456, time: 0.163, data: 0.021) loss: 0.180 
(epoch: 178, iters: 7536, time: 0.161, data: 0.000) loss: 0.320 
(epoch: 178, iters: 7616, time: 0.162, data: 0.013) loss: 0.046 
(epoch: 178, iters: 7696, time: 0.161, data: 0.000) loss: 0.114 
(epoch: 178, iters: 7776, time: 0.161, data: 0.000) loss: 0.117 
(epoch: 178, iters: 7856, time: 0.161, data: 0.000) loss: 0.228 
(epoch: 178, iters: 7936, time: 0.161, data: 0.030) loss: 0.494 
(epoch: 178, iters: 8016, time: 0.161, data: 0.005) loss: 0.047 
saving the latest model (epoch 178, total_steps 1812000)
(epoch: 178, iters: 8096, time: 0.162, data: 0.029) loss: 0.380 
(epoch: 178, iters: 8176, time: 0.164, data: 0.000) loss: 0.171 
(epoch: 178, iters: 8256, time: 0.162, data: 0.013) loss: 0.083 
(epoch: 178, iters: 8336, time: 0.161, data: 0.009) loss: 0.108 
(epoch: 178, iters: 8416, time: 0.162, data: 0.006) loss: 0.299 
(epoch: 178, iters: 8496, time: 0.162, data: 0.000) loss: 0.294 
(epoch: 178, iters: 8576, time: 0.162, data: 0.000) loss: 0.537 
(epoch: 178, iters: 8656, time: 0.162, data: 0.018) loss: 0.203 
(epoch: 178, iters: 8736, time: 0.161, data: 0.020) loss: 0.281 
(epoch: 178, iters: 8816, time: 0.162, data: 0.000) loss: 0.229 
(epoch: 178, iters: 8896, time: 0.162, data: 0.005) loss: 0.117 
(epoch: 178, iters: 8976, time: 0.161, data: 0.005) loss: 0.225 
(epoch: 178, iters: 9056, time: 0.164, data: 0.000) loss: 0.226 
(epoch: 178, iters: 9136, time: 0.162, data: 0.000) loss: 0.114 
(epoch: 178, iters: 9216, time: 0.162, data: 0.000) loss: 0.266 
(epoch: 178, iters: 9296, time: 0.162, data: 0.019) loss: 0.081 
(epoch: 178, iters: 9376, time: 0.163, data: 0.011) loss: 0.115 
(epoch: 178, iters: 9456, time: 0.160, data: 0.006) loss: 0.090 
(epoch: 178, iters: 9536, time: 0.160, data: 0.006) loss: 0.061 
(epoch: 178, iters: 9616, time: 0.161, data: 0.018) loss: 0.534 
(epoch: 178, iters: 9696, time: 0.161, data: 0.000) loss: 0.164 
(epoch: 178, iters: 9776, time: 0.162, data: 0.000) loss: 0.294 
(epoch: 178, iters: 9856, time: 0.161, data: 0.008) loss: 0.209 
(epoch: 178, iters: 9936, time: 0.162, data: 0.000) loss: 0.302 
(epoch: 178, iters: 10016, time: 0.163, data: 0.000) loss: 0.082 
(epoch: 178, iters: 10096, time: 0.161, data: 0.000) loss: 0.069 
(epoch: 178, iters: 10176, time: 0.162, data: 0.000) loss: 0.354 
saving the model at the end of epoch 178, iters 1814176
End of epoch 178 / 200 	 Time Taken: 1653 sec
learning rate = 0.0000416
saving the latest model (epoch 179, total_steps 1814192)
(epoch: 179, iters: 64, time: 0.164, data: 0.004) loss: 0.054 
(epoch: 179, iters: 144, time: 0.162, data: 0.020) loss: 0.071 
(epoch: 179, iters: 224, time: 0.165, data: 0.000) loss: 0.253 
(epoch: 179, iters: 304, time: 0.162, data: 0.000) loss: 0.332 
(epoch: 179, iters: 384, time: 0.162, data: 0.030) loss: 0.136 
(epoch: 179, iters: 464, time: 0.162, data: 0.000) loss: 0.201 
(epoch: 179, iters: 544, time: 0.162, data: 0.000) loss: 0.221 
(epoch: 179, iters: 624, time: 0.162, data: 0.011) loss: 0.243 
(epoch: 179, iters: 704, time: 0.163, data: 0.006) loss: 0.319 
(epoch: 179, iters: 784, time: 0.161, data: 0.000) loss: 0.149 
(epoch: 179, iters: 864, time: 0.158, data: 0.014) loss: 0.132 
(epoch: 179, iters: 944, time: 0.169, data: 0.000) loss: 0.155 
(epoch: 179, iters: 1024, time: 0.163, data: 0.000) loss: 0.377 
(epoch: 179, iters: 1104, time: 0.160, data: 0.010) loss: 0.138 
(epoch: 179, iters: 1184, time: 0.157, data: 0.000) loss: 0.436 
(epoch: 179, iters: 1264, time: 0.159, data: 0.024) loss: 0.090 
(epoch: 179, iters: 1344, time: 0.160, data: 0.000) loss: 0.176 
(epoch: 179, iters: 1424, time: 0.160, data: 0.000) loss: 0.062 
(epoch: 179, iters: 1504, time: 0.163, data: 0.000) loss: 0.335 
(epoch: 179, iters: 1584, time: 0.160, data: 0.021) loss: 0.190 
(epoch: 179, iters: 1664, time: 0.160, data: 0.008) loss: 0.145 
(epoch: 179, iters: 1744, time: 0.163, data: 0.000) loss: 0.199 
(epoch: 179, iters: 1824, time: 0.167, data: 0.008) loss: 0.351 
(epoch: 179, iters: 1904, time: 0.161, data: 0.008) loss: 0.178 
(epoch: 179, iters: 1984, time: 0.160, data: 0.014) loss: 0.155 
(epoch: 179, iters: 2064, time: 0.162, data: 0.000) loss: 0.446 
(epoch: 179, iters: 2144, time: 0.162, data: 0.020) loss: 0.104 
(epoch: 179, iters: 2224, time: 0.163, data: 0.006) loss: 0.119 
(epoch: 179, iters: 2304, time: 0.162, data: 0.020) loss: 0.144 
(epoch: 179, iters: 2384, time: 0.162, data: 0.000) loss: 0.316 
(epoch: 179, iters: 2464, time: 0.164, data: 0.000) loss: 0.279 
(epoch: 179, iters: 2544, time: 0.161, data: 0.009) loss: 0.071 
(epoch: 179, iters: 2624, time: 0.160, data: 0.000) loss: 0.239 
(epoch: 179, iters: 2704, time: 0.161, data: 0.000) loss: 0.297 
(epoch: 179, iters: 2784, time: 0.161, data: 0.018) loss: 0.068 
(epoch: 179, iters: 2864, time: 0.159, data: 0.000) loss: 0.261 
(epoch: 179, iters: 2944, time: 0.159, data: 0.021) loss: 0.181 
(epoch: 179, iters: 3024, time: 0.160, data: 0.000) loss: 0.108 
(epoch: 179, iters: 3104, time: 0.161, data: 0.005) loss: 0.176 
(epoch: 179, iters: 3184, time: 0.160, data: 0.000) loss: 0.264 
(epoch: 179, iters: 3264, time: 0.161, data: 0.000) loss: 0.254 
(epoch: 179, iters: 3344, time: 0.162, data: 0.000) loss: 0.150 
(epoch: 179, iters: 3424, time: 0.161, data: 0.000) loss: 0.503 
(epoch: 179, iters: 3504, time: 0.168, data: 0.017) loss: 0.404 
(epoch: 179, iters: 3584, time: 0.161, data: 0.024) loss: 0.439 
(epoch: 179, iters: 3664, time: 0.160, data: 0.000) loss: 0.310 
(epoch: 179, iters: 3744, time: 0.161, data: 0.000) loss: 0.243 
(epoch: 179, iters: 3824, time: 0.161, data: 0.000) loss: 0.312 
(epoch: 179, iters: 3904, time: 0.166, data: 0.000) loss: 0.401 
(epoch: 179, iters: 3984, time: 0.160, data: 0.000) loss: 0.230 
saving the latest model (epoch 179, total_steps 1818192)
(epoch: 179, iters: 4064, time: 0.159, data: 0.000) loss: 0.357 
(epoch: 179, iters: 4144, time: 0.161, data: 0.000) loss: 0.156 
(epoch: 179, iters: 4224, time: 0.158, data: 0.000) loss: 0.256 
(epoch: 179, iters: 4304, time: 0.159, data: 0.017) loss: 0.064 
(epoch: 179, iters: 4384, time: 0.161, data: 0.005) loss: 0.151 
(epoch: 179, iters: 4464, time: 0.161, data: 0.009) loss: 0.290 
(epoch: 179, iters: 4544, time: 0.161, data: 0.000) loss: 0.167 
(epoch: 179, iters: 4624, time: 0.161, data: 0.010) loss: 0.345 
(epoch: 179, iters: 4704, time: 0.162, data: 0.021) loss: 0.321 
(epoch: 179, iters: 4784, time: 0.160, data: 0.027) loss: 0.119 
(epoch: 179, iters: 4864, time: 0.160, data: 0.000) loss: 0.214 
(epoch: 179, iters: 4944, time: 0.161, data: 0.000) loss: 0.438 
(epoch: 179, iters: 5024, time: 0.162, data: 0.006) loss: 0.132 
(epoch: 179, iters: 5104, time: 0.160, data: 0.000) loss: 0.744 
(epoch: 179, iters: 5184, time: 0.159, data: 0.006) loss: 0.234 
(epoch: 179, iters: 5264, time: 0.162, data: 0.012) loss: 0.138 
(epoch: 179, iters: 5344, time: 0.165, data: 0.000) loss: 0.208 
(epoch: 179, iters: 5424, time: 0.162, data: 0.000) loss: 0.127 
(epoch: 179, iters: 5504, time: 0.159, data: 0.000) loss: 0.341 
(epoch: 179, iters: 5584, time: 0.161, data: 0.000) loss: 0.148 
(epoch: 179, iters: 5664, time: 0.159, data: 0.005) loss: 0.191 
(epoch: 179, iters: 5744, time: 0.158, data: 0.000) loss: 0.130 
(epoch: 179, iters: 5824, time: 0.159, data: 0.000) loss: 0.343 
(epoch: 179, iters: 5904, time: 0.161, data: 0.000) loss: 0.218 
(epoch: 179, iters: 5984, time: 0.167, data: 0.000) loss: 0.915 
(epoch: 179, iters: 6064, time: 0.162, data: 0.000) loss: 0.178 
(epoch: 179, iters: 6144, time: 0.160, data: 0.000) loss: 0.359 
(epoch: 179, iters: 6224, time: 0.161, data: 0.025) loss: 0.050 
(epoch: 179, iters: 6304, time: 0.162, data: 0.024) loss: 0.103 
(epoch: 179, iters: 6384, time: 0.161, data: 0.000) loss: 0.128 
(epoch: 179, iters: 6464, time: 0.163, data: 0.000) loss: 0.277 
(epoch: 179, iters: 6544, time: 0.160, data: 0.014) loss: 0.675 
(epoch: 179, iters: 6624, time: 0.160, data: 0.030) loss: 0.177 
(epoch: 179, iters: 6704, time: 0.164, data: 0.000) loss: 0.592 
(epoch: 179, iters: 6784, time: 0.160, data: 0.006) loss: 0.521 
(epoch: 179, iters: 6864, time: 0.158, data: 0.000) loss: 0.120 
(epoch: 179, iters: 6944, time: 0.160, data: 0.000) loss: 0.271 
(epoch: 179, iters: 7024, time: 0.160, data: 0.011) loss: 0.391 
(epoch: 179, iters: 7104, time: 0.161, data: 0.000) loss: 0.131 
(epoch: 179, iters: 7184, time: 0.160, data: 0.014) loss: 0.389 
(epoch: 179, iters: 7264, time: 0.163, data: 0.005) loss: 0.266 
(epoch: 179, iters: 7344, time: 0.161, data: 0.020) loss: 0.163 
(epoch: 179, iters: 7424, time: 0.162, data: 0.000) loss: 0.352 
(epoch: 179, iters: 7504, time: 0.160, data: 0.000) loss: 0.253 
(epoch: 179, iters: 7584, time: 0.165, data: 0.000) loss: 0.159 
(epoch: 179, iters: 7664, time: 0.163, data: 0.008) loss: 0.246 
(epoch: 179, iters: 7744, time: 0.161, data: 0.000) loss: 0.271 
(epoch: 179, iters: 7824, time: 0.161, data: 0.021) loss: 0.390 
(epoch: 179, iters: 7904, time: 0.161, data: 0.017) loss: 0.224 
(epoch: 179, iters: 7984, time: 0.166, data: 0.014) loss: 0.171 
saving the latest model (epoch 179, total_steps 1822192)
(epoch: 179, iters: 8064, time: 0.161, data: 0.021) loss: 0.314 
(epoch: 179, iters: 8144, time: 0.163, data: 0.005) loss: 0.128 
(epoch: 179, iters: 8224, time: 0.163, data: 0.017) loss: 0.289 
(epoch: 179, iters: 8304, time: 0.163, data: 0.000) loss: 0.090 
(epoch: 179, iters: 8384, time: 0.167, data: 0.000) loss: 0.065 
(epoch: 179, iters: 8464, time: 0.167, data: 0.034) loss: 0.330 
(epoch: 179, iters: 8544, time: 0.176, data: 0.000) loss: 0.082 
(epoch: 179, iters: 8624, time: 0.326, data: 0.009) loss: 0.162 
(epoch: 179, iters: 8704, time: 0.159, data: 0.025) loss: 0.043 
(epoch: 179, iters: 8784, time: 0.150, data: 0.000) loss: 0.229 
(epoch: 179, iters: 8864, time: 0.151, data: 0.000) loss: 0.407 
(epoch: 179, iters: 8944, time: 0.152, data: 0.015) loss: 0.227 
(epoch: 179, iters: 9024, time: 0.153, data: 0.000) loss: 0.218 
(epoch: 179, iters: 9104, time: 0.158, data: 0.010) loss: 0.132 
(epoch: 179, iters: 9184, time: 0.155, data: 0.014) loss: 0.281 
(epoch: 179, iters: 9264, time: 0.153, data: 0.005) loss: 0.227 
(epoch: 179, iters: 9344, time: 0.155, data: 0.000) loss: 0.240 
(epoch: 179, iters: 9424, time: 0.150, data: 0.000) loss: 0.431 
(epoch: 179, iters: 9504, time: 0.157, data: 0.007) loss: 0.373 
(epoch: 179, iters: 9584, time: 0.153, data: 0.000) loss: 0.220 
(epoch: 179, iters: 9664, time: 0.155, data: 0.008) loss: 0.456 
(epoch: 179, iters: 9744, time: 0.154, data: 0.000) loss: 0.133 
(epoch: 179, iters: 9824, time: 0.155, data: 0.005) loss: 0.409 
(epoch: 179, iters: 9904, time: 0.155, data: 0.005) loss: 0.120 
(epoch: 179, iters: 9984, time: 0.153, data: 0.000) loss: 0.118 
(epoch: 179, iters: 10064, time: 0.153, data: 0.018) loss: 0.693 
(epoch: 179, iters: 10144, time: 0.154, data: 0.016) loss: 0.294 
saving the model at the end of epoch 179, iters 1824368
End of epoch 179 / 200 	 Time Taken: 1651 sec
learning rate = 0.0000396
saving the latest model (epoch 180, total_steps 1824384)
(epoch: 180, iters: 32, time: 0.166, data: 0.000) loss: 0.433 
(epoch: 180, iters: 112, time: 0.161, data: 0.000) loss: 0.138 
(epoch: 180, iters: 192, time: 0.192, data: 0.000) loss: 0.054 
(epoch: 180, iters: 272, time: 0.166, data: 0.023) loss: 0.224 
(epoch: 180, iters: 352, time: 0.180, data: 0.024) loss: 0.295 
(epoch: 180, iters: 432, time: 0.158, data: 0.020) loss: 0.287 
(epoch: 180, iters: 512, time: 0.160, data: 0.000) loss: 0.300 
(epoch: 180, iters: 592, time: 0.161, data: 0.000) loss: 1.142 
(epoch: 180, iters: 672, time: 0.160, data: 0.000) loss: 0.216 
(epoch: 180, iters: 752, time: 0.158, data: 0.006) loss: 0.101 
(epoch: 180, iters: 832, time: 0.160, data: 0.000) loss: 0.275 
(epoch: 180, iters: 912, time: 0.158, data: 0.000) loss: 0.188 
(epoch: 180, iters: 992, time: 0.160, data: 0.000) loss: 0.240 
(epoch: 180, iters: 1072, time: 0.160, data: 0.018) loss: 0.301 
(epoch: 180, iters: 1152, time: 0.159, data: 0.023) loss: 0.110 
(epoch: 180, iters: 1232, time: 0.159, data: 0.000) loss: 0.042 
(epoch: 180, iters: 1312, time: 0.159, data: 0.000) loss: 0.148 
(epoch: 180, iters: 1392, time: 0.158, data: 0.008) loss: 0.406 
(epoch: 180, iters: 1472, time: 0.159, data: 0.005) loss: 0.157 
(epoch: 180, iters: 1552, time: 0.159, data: 0.000) loss: 0.380 
(epoch: 180, iters: 1632, time: 0.159, data: 0.008) loss: 0.575 
(epoch: 180, iters: 1712, time: 0.158, data: 0.000) loss: 0.271 
(epoch: 180, iters: 1792, time: 0.159, data: 0.000) loss: 0.080 
(epoch: 180, iters: 1872, time: 0.158, data: 0.000) loss: 0.534 
(epoch: 180, iters: 1952, time: 0.160, data: 0.042) loss: 0.240 
(epoch: 180, iters: 2032, time: 0.161, data: 0.000) loss: 0.218 
(epoch: 180, iters: 2112, time: 0.161, data: 0.000) loss: 0.108 
(epoch: 180, iters: 2192, time: 0.160, data: 0.000) loss: 0.272 
(epoch: 180, iters: 2272, time: 0.161, data: 0.008) loss: 0.413 
(epoch: 180, iters: 2352, time: 0.155, data: 0.017) loss: 0.239 
(epoch: 180, iters: 2432, time: 0.155, data: 0.000) loss: 0.277 
(epoch: 180, iters: 2512, time: 0.156, data: 0.000) loss: 0.515 
(epoch: 180, iters: 2592, time: 0.158, data: 0.000) loss: 0.700 
(epoch: 180, iters: 2672, time: 0.155, data: 0.005) loss: 0.068 
(epoch: 180, iters: 2752, time: 0.155, data: 0.014) loss: 0.448 
(epoch: 180, iters: 2832, time: 0.157, data: 0.000) loss: 0.025 
(epoch: 180, iters: 2912, time: 0.154, data: 0.008) loss: 0.035 
(epoch: 180, iters: 2992, time: 0.154, data: 0.000) loss: 0.307 
(epoch: 180, iters: 3072, time: 0.156, data: 0.024) loss: 0.137 
(epoch: 180, iters: 3152, time: 0.156, data: 0.000) loss: 0.251 
(epoch: 180, iters: 3232, time: 0.154, data: 0.000) loss: 0.453 
(epoch: 180, iters: 3312, time: 0.154, data: 0.006) loss: 0.121 
(epoch: 180, iters: 3392, time: 0.156, data: 0.006) loss: 0.699 
(epoch: 180, iters: 3472, time: 0.155, data: 0.000) loss: 0.121 
(epoch: 180, iters: 3552, time: 0.156, data: 0.000) loss: 0.108 
(epoch: 180, iters: 3632, time: 0.154, data: 0.014) loss: 0.178 
(epoch: 180, iters: 3712, time: 0.155, data: 0.014) loss: 0.140 
(epoch: 180, iters: 3792, time: 0.155, data: 0.006) loss: 0.667 
(epoch: 180, iters: 3872, time: 0.156, data: 0.000) loss: 0.048 
(epoch: 180, iters: 3952, time: 0.156, data: 0.034) loss: 0.246 
saving the latest model (epoch 180, total_steps 1828384)
(epoch: 180, iters: 4032, time: 0.154, data: 0.000) loss: 0.157 
(epoch: 180, iters: 4112, time: 0.155, data: 0.000) loss: 0.238 
(epoch: 180, iters: 4192, time: 0.154, data: 0.000) loss: 0.150 
(epoch: 180, iters: 4272, time: 0.156, data: 0.000) loss: 0.252 
(epoch: 180, iters: 4352, time: 0.157, data: 0.000) loss: 0.127 
(epoch: 180, iters: 4432, time: 0.171, data: 0.000) loss: 0.181 
(epoch: 180, iters: 4512, time: 0.155, data: 0.000) loss: 0.316 
(epoch: 180, iters: 4592, time: 0.156, data: 0.000) loss: 0.101 
(epoch: 180, iters: 4672, time: 0.155, data: 0.013) loss: 0.269 
(epoch: 180, iters: 4752, time: 0.154, data: 0.005) loss: 0.224 
(epoch: 180, iters: 4832, time: 0.157, data: 0.000) loss: 0.112 
(epoch: 180, iters: 4912, time: 0.154, data: 0.018) loss: 0.382 
(epoch: 180, iters: 4992, time: 0.154, data: 0.013) loss: 0.237 
(epoch: 180, iters: 5072, time: 0.154, data: 0.021) loss: 0.264 
(epoch: 180, iters: 5152, time: 0.155, data: 0.009) loss: 0.075 
(epoch: 180, iters: 5232, time: 0.157, data: 0.014) loss: 0.376 
(epoch: 180, iters: 5312, time: 0.154, data: 0.016) loss: 0.166 
(epoch: 180, iters: 5392, time: 0.154, data: 0.022) loss: 0.082 
(epoch: 180, iters: 5472, time: 0.153, data: 0.008) loss: 0.456 
(epoch: 180, iters: 5552, time: 0.155, data: 0.005) loss: 0.180 
(epoch: 180, iters: 5632, time: 0.153, data: 0.005) loss: 0.142 
(epoch: 180, iters: 5712, time: 0.154, data: 0.000) loss: 0.108 
(epoch: 180, iters: 5792, time: 0.155, data: 0.031) loss: 0.554 
(epoch: 180, iters: 5872, time: 0.159, data: 0.000) loss: 0.216 
(epoch: 180, iters: 5952, time: 0.153, data: 0.009) loss: 0.164 
(epoch: 180, iters: 6032, time: 0.154, data: 0.000) loss: 0.139 
(epoch: 180, iters: 6112, time: 0.154, data: 0.000) loss: 0.553 
(epoch: 180, iters: 6192, time: 0.153, data: 0.020) loss: 0.227 
(epoch: 180, iters: 6272, time: 0.153, data: 0.000) loss: 0.468 
(epoch: 180, iters: 6352, time: 0.156, data: 0.014) loss: 0.253 
(epoch: 180, iters: 6432, time: 0.155, data: 0.000) loss: 0.154 
(epoch: 180, iters: 6512, time: 0.154, data: 0.000) loss: 0.104 
(epoch: 180, iters: 6592, time: 0.154, data: 0.000) loss: 0.169 
(epoch: 180, iters: 6672, time: 0.156, data: 0.000) loss: 0.072 
(epoch: 180, iters: 6752, time: 0.157, data: 0.006) loss: 0.035 
(epoch: 180, iters: 6832, time: 0.158, data: 0.000) loss: 0.511 
(epoch: 180, iters: 6912, time: 0.158, data: 0.009) loss: 0.248 
(epoch: 180, iters: 6992, time: 0.157, data: 0.019) loss: 0.424 
(epoch: 180, iters: 7072, time: 0.154, data: 0.000) loss: 0.185 
(epoch: 180, iters: 7152, time: 0.154, data: 0.000) loss: 0.322 
(epoch: 180, iters: 7232, time: 0.154, data: 0.000) loss: 0.302 
(epoch: 180, iters: 7312, time: 0.154, data: 0.005) loss: 0.090 
(epoch: 180, iters: 7392, time: 0.152, data: 0.000) loss: 0.127 
(epoch: 180, iters: 7472, time: 0.154, data: 0.025) loss: 0.608 
(epoch: 180, iters: 7552, time: 0.156, data: 0.000) loss: 0.238 
(epoch: 180, iters: 7632, time: 0.157, data: 0.029) loss: 0.149 
(epoch: 180, iters: 7712, time: 0.156, data: 0.000) loss: 0.248 
(epoch: 180, iters: 7792, time: 0.156, data: 0.000) loss: 0.373 
(epoch: 180, iters: 7872, time: 0.154, data: 0.005) loss: 0.303 
(epoch: 180, iters: 7952, time: 0.154, data: 0.011) loss: 0.132 
saving the latest model (epoch 180, total_steps 1832384)
(epoch: 180, iters: 8032, time: 0.158, data: 0.000) loss: 0.321 
(epoch: 180, iters: 8112, time: 0.157, data: 0.000) loss: 0.328 
(epoch: 180, iters: 8192, time: 0.156, data: 0.008) loss: 0.287 
(epoch: 180, iters: 8272, time: 0.155, data: 0.000) loss: 0.057 
(epoch: 180, iters: 8352, time: 0.156, data: 0.000) loss: 0.471 
(epoch: 180, iters: 8432, time: 0.154, data: 0.020) loss: 0.064 
(epoch: 180, iters: 8512, time: 0.155, data: 0.005) loss: 0.153 
(epoch: 180, iters: 8592, time: 0.154, data: 0.000) loss: 0.421 
(epoch: 180, iters: 8672, time: 0.153, data: 0.000) loss: 0.167 
(epoch: 180, iters: 8752, time: 0.151, data: 0.000) loss: 0.129 
(epoch: 180, iters: 8832, time: 0.160, data: 0.019) loss: 0.173 
(epoch: 180, iters: 8912, time: 0.155, data: 0.005) loss: 0.309 
(epoch: 180, iters: 8992, time: 0.154, data: 0.000) loss: 0.039 
(epoch: 180, iters: 9072, time: 0.156, data: 0.005) loss: 0.123 
(epoch: 180, iters: 9152, time: 0.154, data: 0.005) loss: 0.316 
(epoch: 180, iters: 9232, time: 0.154, data: 0.000) loss: 0.066 
(epoch: 180, iters: 9312, time: 0.155, data: 0.017) loss: 0.240 
(epoch: 180, iters: 9392, time: 0.153, data: 0.000) loss: 0.481 
(epoch: 180, iters: 9472, time: 0.155, data: 0.000) loss: 0.188 
(epoch: 180, iters: 9552, time: 0.154, data: 0.033) loss: 0.383 
(epoch: 180, iters: 9632, time: 0.154, data: 0.000) loss: 0.117 
(epoch: 180, iters: 9712, time: 0.154, data: 0.000) loss: 0.225 
(epoch: 180, iters: 9792, time: 0.154, data: 0.000) loss: 0.330 
(epoch: 180, iters: 9872, time: 0.156, data: 0.000) loss: 0.077 
(epoch: 180, iters: 9952, time: 0.153, data: 0.005) loss: 0.184 
(epoch: 180, iters: 10032, time: 0.155, data: 0.000) loss: 0.028 
(epoch: 180, iters: 10112, time: 0.155, data: 0.016) loss: 0.235 
(epoch: 180, iters: 10192, time: 0.093, data: 0.000) loss: 0.045 
saving the model at the end of epoch 180, iters 1834560
End of epoch 180 / 200 	 Time Taken: 1604 sec
learning rate = 0.0000376
saving the latest model (epoch 181, total_steps 1834576)
(epoch: 181, iters: 80, time: 0.158, data: 0.185) loss: 0.155 
(epoch: 181, iters: 160, time: 0.155, data: 0.000) loss: 0.218 
(epoch: 181, iters: 240, time: 0.157, data: 0.000) loss: 0.073 
(epoch: 181, iters: 320, time: 0.158, data: 0.005) loss: 0.296 
(epoch: 181, iters: 400, time: 0.156, data: 0.000) loss: 0.125 
(epoch: 181, iters: 480, time: 0.155, data: 0.008) loss: 0.383 
(epoch: 181, iters: 560, time: 0.154, data: 0.021) loss: 0.584 
(epoch: 181, iters: 640, time: 0.156, data: 0.000) loss: 0.632 
(epoch: 181, iters: 720, time: 0.156, data: 0.000) loss: 0.211 
(epoch: 181, iters: 800, time: 0.158, data: 0.021) loss: 0.147 
(epoch: 181, iters: 880, time: 0.157, data: 0.018) loss: 0.227 
(epoch: 181, iters: 960, time: 0.156, data: 0.000) loss: 0.118 
(epoch: 181, iters: 1040, time: 0.156, data: 0.008) loss: 0.313 
(epoch: 181, iters: 1120, time: 0.155, data: 0.025) loss: 0.253 
(epoch: 181, iters: 1200, time: 0.154, data: 0.000) loss: 0.513 
(epoch: 181, iters: 1280, time: 0.153, data: 0.000) loss: 0.287 
(epoch: 181, iters: 1360, time: 0.156, data: 0.006) loss: 0.389 
(epoch: 181, iters: 1440, time: 0.156, data: 0.009) loss: 0.180 
(epoch: 181, iters: 1520, time: 0.163, data: 0.000) loss: 0.310 
(epoch: 181, iters: 1600, time: 0.155, data: 0.019) loss: 0.245 
(epoch: 181, iters: 1680, time: 0.156, data: 0.000) loss: 0.235 
(epoch: 181, iters: 1760, time: 0.156, data: 0.000) loss: 0.157 
(epoch: 181, iters: 1840, time: 0.154, data: 0.000) loss: 0.137 
(epoch: 181, iters: 1920, time: 0.153, data: 0.041) loss: 0.256 
(epoch: 181, iters: 2000, time: 0.155, data: 0.000) loss: 0.121 
(epoch: 181, iters: 2080, time: 0.155, data: 0.014) loss: 0.282 
(epoch: 181, iters: 2160, time: 0.155, data: 0.008) loss: 0.310 
(epoch: 181, iters: 2240, time: 0.156, data: 0.016) loss: 0.166 
(epoch: 181, iters: 2320, time: 0.158, data: 0.000) loss: 0.361 
(epoch: 181, iters: 2400, time: 0.155, data: 0.020) loss: 0.109 
(epoch: 181, iters: 2480, time: 0.153, data: 0.000) loss: 0.117 
(epoch: 181, iters: 2560, time: 0.153, data: 0.000) loss: 0.100 
(epoch: 181, iters: 2640, time: 0.153, data: 0.026) loss: 0.123 
(epoch: 181, iters: 2720, time: 0.154, data: 0.000) loss: 0.273 
(epoch: 181, iters: 2800, time: 0.154, data: 0.000) loss: 0.184 
(epoch: 181, iters: 2880, time: 0.154, data: 0.008) loss: 0.107 
(epoch: 181, iters: 2960, time: 0.155, data: 0.005) loss: 0.371 
(epoch: 181, iters: 3040, time: 0.158, data: 0.010) loss: 0.100 
(epoch: 181, iters: 3120, time: 0.156, data: 0.000) loss: 0.596 
(epoch: 181, iters: 3200, time: 0.156, data: 0.010) loss: 0.166 
(epoch: 181, iters: 3280, time: 0.155, data: 0.005) loss: 0.320 
(epoch: 181, iters: 3360, time: 0.155, data: 0.000) loss: 0.272 
(epoch: 181, iters: 3440, time: 0.155, data: 0.016) loss: 0.122 
(epoch: 181, iters: 3520, time: 0.156, data: 0.000) loss: 0.742 
(epoch: 181, iters: 3600, time: 0.156, data: 0.000) loss: 0.510 
(epoch: 181, iters: 3680, time: 0.155, data: 0.000) loss: 0.680 
(epoch: 181, iters: 3760, time: 0.155, data: 0.014) loss: 0.215 
(epoch: 181, iters: 3840, time: 0.155, data: 0.010) loss: 0.173 
(epoch: 181, iters: 3920, time: 0.156, data: 0.000) loss: 0.433 
(epoch: 181, iters: 4000, time: 0.158, data: 0.000) loss: 0.089 
saving the latest model (epoch 181, total_steps 1838576)
(epoch: 181, iters: 4080, time: 0.158, data: 0.029) loss: 0.320 
(epoch: 181, iters: 4160, time: 0.157, data: 0.000) loss: 0.409 
(epoch: 181, iters: 4240, time: 0.157, data: 0.025) loss: 0.128 
(epoch: 181, iters: 4320, time: 0.156, data: 0.000) loss: 0.304 
(epoch: 181, iters: 4400, time: 0.156, data: 0.008) loss: 0.027 
(epoch: 181, iters: 4480, time: 0.158, data: 0.005) loss: 0.081 
(epoch: 181, iters: 4560, time: 0.159, data: 0.005) loss: 0.292 
(epoch: 181, iters: 4640, time: 0.155, data: 0.000) loss: 0.064 
(epoch: 181, iters: 4720, time: 0.159, data: 0.000) loss: 0.595 
(epoch: 181, iters: 4800, time: 0.164, data: 0.000) loss: 0.213 
(epoch: 181, iters: 4880, time: 0.165, data: 0.028) loss: 0.318 
(epoch: 181, iters: 4960, time: 0.174, data: 0.000) loss: 0.410 
(epoch: 181, iters: 5040, time: 0.152, data: 0.026) loss: 0.255 
(epoch: 181, iters: 5120, time: 0.153, data: 0.000) loss: 0.403 
(epoch: 181, iters: 5200, time: 0.170, data: 0.009) loss: 0.082 
(epoch: 181, iters: 5280, time: 0.162, data: 0.000) loss: 0.210 
(epoch: 181, iters: 5360, time: 0.151, data: 0.020) loss: 0.144 
(epoch: 181, iters: 5440, time: 0.154, data: 0.006) loss: 0.134 
(epoch: 181, iters: 5520, time: 0.152, data: 0.020) loss: 0.132 
(epoch: 181, iters: 5600, time: 0.153, data: 0.000) loss: 0.113 
(epoch: 181, iters: 5680, time: 0.152, data: 0.005) loss: 0.342 
(epoch: 181, iters: 5760, time: 0.155, data: 0.016) loss: 0.231 
(epoch: 181, iters: 5840, time: 0.153, data: 0.000) loss: 0.137 
(epoch: 181, iters: 5920, time: 0.153, data: 0.005) loss: 0.493 
(epoch: 181, iters: 6000, time: 0.150, data: 0.018) loss: 0.181 
(epoch: 181, iters: 6080, time: 0.152, data: 0.000) loss: 0.190 
(epoch: 181, iters: 6160, time: 0.152, data: 0.031) loss: 0.145 
(epoch: 181, iters: 6240, time: 0.156, data: 0.000) loss: 0.335 
(epoch: 181, iters: 6320, time: 0.154, data: 0.010) loss: 0.084 
(epoch: 181, iters: 6400, time: 0.153, data: 0.014) loss: 0.497 
(epoch: 181, iters: 6480, time: 0.156, data: 0.014) loss: 0.433 
(epoch: 181, iters: 6560, time: 0.154, data: 0.000) loss: 0.171 
(epoch: 181, iters: 6640, time: 0.153, data: 0.000) loss: 0.072 
(epoch: 181, iters: 6720, time: 0.153, data: 0.000) loss: 0.026 
(epoch: 181, iters: 6800, time: 0.154, data: 0.000) loss: 0.139 
(epoch: 181, iters: 6880, time: 0.154, data: 0.021) loss: 0.169 
(epoch: 181, iters: 6960, time: 0.153, data: 0.008) loss: 0.580 
(epoch: 181, iters: 7040, time: 0.152, data: 0.000) loss: 0.151 
(epoch: 181, iters: 7120, time: 0.151, data: 0.027) loss: 0.122 
(epoch: 181, iters: 7200, time: 0.152, data: 0.000) loss: 0.069 
(epoch: 181, iters: 7280, time: 0.154, data: 0.017) loss: 0.346 
(epoch: 181, iters: 7360, time: 0.155, data: 0.000) loss: 0.250 
(epoch: 181, iters: 7440, time: 0.157, data: 0.000) loss: 0.107 
(epoch: 181, iters: 7520, time: 0.154, data: 0.008) loss: 0.072 
(epoch: 181, iters: 7600, time: 0.152, data: 0.024) loss: 0.384 
(epoch: 181, iters: 7680, time: 0.153, data: 0.000) loss: 0.197 
(epoch: 181, iters: 7760, time: 0.161, data: 0.044) loss: 0.316 
(epoch: 181, iters: 7840, time: 0.162, data: 0.000) loss: 0.331 
(epoch: 181, iters: 7920, time: 0.164, data: 0.000) loss: 0.147 
(epoch: 181, iters: 8000, time: 0.162, data: 0.005) loss: 0.109 
saving the latest model (epoch 181, total_steps 1842576)
(epoch: 181, iters: 8080, time: 0.162, data: 0.039) loss: 0.472 
(epoch: 181, iters: 8160, time: 0.175, data: 0.000) loss: 0.507 
(epoch: 181, iters: 8240, time: 0.168, data: 0.008) loss: 0.098 
(epoch: 181, iters: 8320, time: 0.162, data: 0.000) loss: 0.137 
(epoch: 181, iters: 8400, time: 0.169, data: 0.006) loss: 0.205 
(epoch: 181, iters: 8480, time: 0.161, data: 0.000) loss: 0.183 
(epoch: 181, iters: 8560, time: 0.162, data: 0.005) loss: 0.310 
(epoch: 181, iters: 8640, time: 0.161, data: 0.000) loss: 0.113 
(epoch: 181, iters: 8720, time: 0.161, data: 0.031) loss: 0.422 
(epoch: 181, iters: 8800, time: 0.162, data: 0.000) loss: 0.142 
(epoch: 181, iters: 8880, time: 0.160, data: 0.011) loss: 0.186 
(epoch: 181, iters: 8960, time: 0.169, data: 0.000) loss: 0.031 
(epoch: 181, iters: 9040, time: 0.161, data: 0.025) loss: 0.291 
(epoch: 181, iters: 9120, time: 0.160, data: 0.008) loss: 0.147 
(epoch: 181, iters: 9200, time: 0.164, data: 0.024) loss: 0.138 
(epoch: 181, iters: 9280, time: 0.161, data: 0.000) loss: 0.355 
(epoch: 181, iters: 9360, time: 0.161, data: 0.014) loss: 0.188 
(epoch: 181, iters: 9440, time: 0.160, data: 0.000) loss: 0.138 
(epoch: 181, iters: 9520, time: 0.160, data: 0.020) loss: 0.285 
(epoch: 181, iters: 9600, time: 0.162, data: 0.000) loss: 0.229 
(epoch: 181, iters: 9680, time: 0.158, data: 0.010) loss: 0.229 
(epoch: 181, iters: 9760, time: 0.166, data: 0.000) loss: 0.422 
(epoch: 181, iters: 9840, time: 0.161, data: 0.000) loss: 0.184 
(epoch: 181, iters: 9920, time: 0.160, data: 0.006) loss: 0.231 
(epoch: 181, iters: 10000, time: 0.162, data: 0.000) loss: 0.030 
(epoch: 181, iters: 10080, time: 0.161, data: 0.006) loss: 0.128 
(epoch: 181, iters: 10160, time: 0.163, data: 0.000) loss: 0.139 
saving the model at the end of epoch 181, iters 1844752
End of epoch 181 / 200 	 Time Taken: 1605 sec
learning rate = 0.0000356
saving the latest model (epoch 182, total_steps 1844768)
(epoch: 182, iters: 48, time: 0.166, data: 0.000) loss: 0.262 
(epoch: 182, iters: 128, time: 0.160, data: 0.013) loss: 0.259 
(epoch: 182, iters: 208, time: 0.161, data: 0.000) loss: 0.228 
(epoch: 182, iters: 288, time: 0.158, data: 0.005) loss: 0.247 
(epoch: 182, iters: 368, time: 0.158, data: 0.000) loss: 0.198 
(epoch: 182, iters: 448, time: 0.157, data: 0.000) loss: 0.157 
(epoch: 182, iters: 528, time: 0.157, data: 0.006) loss: 0.143 
(epoch: 182, iters: 608, time: 0.159, data: 0.000) loss: 0.231 
(epoch: 182, iters: 688, time: 0.158, data: 0.025) loss: 0.169 
(epoch: 182, iters: 768, time: 0.158, data: 0.000) loss: 0.099 
(epoch: 182, iters: 848, time: 0.156, data: 0.006) loss: 0.089 
(epoch: 182, iters: 928, time: 0.163, data: 0.000) loss: 0.168 
(epoch: 182, iters: 1008, time: 0.159, data: 0.017) loss: 0.258 
(epoch: 182, iters: 1088, time: 0.164, data: 0.006) loss: 0.052 
(epoch: 182, iters: 1168, time: 0.157, data: 0.000) loss: 0.256 
(epoch: 182, iters: 1248, time: 0.158, data: 0.005) loss: 0.576 
(epoch: 182, iters: 1328, time: 0.163, data: 0.000) loss: 0.072 
(epoch: 182, iters: 1408, time: 0.159, data: 0.000) loss: 0.108 
(epoch: 182, iters: 1488, time: 0.157, data: 0.005) loss: 0.230 
(epoch: 182, iters: 1568, time: 0.158, data: 0.006) loss: 0.334 
(epoch: 182, iters: 1648, time: 0.158, data: 0.016) loss: 0.316 
(epoch: 182, iters: 1728, time: 0.157, data: 0.005) loss: 0.260 
(epoch: 182, iters: 1808, time: 0.157, data: 0.033) loss: 0.052 
(epoch: 182, iters: 1888, time: 0.158, data: 0.000) loss: 0.049 
(epoch: 182, iters: 1968, time: 0.157, data: 0.000) loss: 0.070 
(epoch: 182, iters: 2048, time: 0.159, data: 0.008) loss: 0.529 
(epoch: 182, iters: 2128, time: 0.158, data: 0.000) loss: 0.313 
(epoch: 182, iters: 2208, time: 0.159, data: 0.013) loss: 0.298 
(epoch: 182, iters: 2288, time: 0.159, data: 0.000) loss: 0.350 
(epoch: 182, iters: 2368, time: 0.158, data: 0.000) loss: 0.205 
(epoch: 182, iters: 2448, time: 0.158, data: 0.000) loss: 0.361 
(epoch: 182, iters: 2528, time: 0.157, data: 0.022) loss: 0.093 
(epoch: 182, iters: 2608, time: 0.160, data: 0.000) loss: 0.071 
(epoch: 182, iters: 2688, time: 0.158, data: 0.005) loss: 0.472 
(epoch: 182, iters: 2768, time: 0.158, data: 0.000) loss: 0.422 
(epoch: 182, iters: 2848, time: 0.156, data: 0.000) loss: 0.539 
(epoch: 182, iters: 2928, time: 0.157, data: 0.000) loss: 0.151 
(epoch: 182, iters: 3008, time: 0.157, data: 0.005) loss: 0.213 
(epoch: 182, iters: 3088, time: 0.159, data: 0.000) loss: 0.031 
(epoch: 182, iters: 3168, time: 0.158, data: 0.021) loss: 0.235 
(epoch: 182, iters: 3248, time: 0.158, data: 0.000) loss: 0.148 
(epoch: 182, iters: 3328, time: 0.158, data: 0.010) loss: 0.424 
(epoch: 182, iters: 3408, time: 0.159, data: 0.000) loss: 0.186 
(epoch: 182, iters: 3488, time: 0.157, data: 0.000) loss: 0.253 
(epoch: 182, iters: 3568, time: 0.157, data: 0.015) loss: 0.185 
(epoch: 182, iters: 3648, time: 0.159, data: 0.000) loss: 0.176 
(epoch: 182, iters: 3728, time: 0.158, data: 0.000) loss: 0.504 
(epoch: 182, iters: 3808, time: 0.157, data: 0.008) loss: 0.254 
(epoch: 182, iters: 3888, time: 0.158, data: 0.006) loss: 0.240 
(epoch: 182, iters: 3968, time: 0.159, data: 0.005) loss: 0.087 
saving the latest model (epoch 182, total_steps 1848768)
(epoch: 182, iters: 4048, time: 0.157, data: 0.000) loss: 0.155 
(epoch: 182, iters: 4128, time: 0.159, data: 0.006) loss: 0.530 
(epoch: 182, iters: 4208, time: 0.160, data: 0.000) loss: 0.259 
(epoch: 182, iters: 4288, time: 0.157, data: 0.031) loss: 0.083 
(epoch: 182, iters: 4368, time: 0.158, data: 0.005) loss: 0.101 
(epoch: 182, iters: 4448, time: 0.161, data: 0.009) loss: 0.170 
(epoch: 182, iters: 4528, time: 0.159, data: 0.008) loss: 0.301 
(epoch: 182, iters: 4608, time: 0.164, data: 0.005) loss: 0.268 
(epoch: 182, iters: 4688, time: 0.158, data: 0.000) loss: 0.194 
(epoch: 182, iters: 4768, time: 0.159, data: 0.010) loss: 0.093 
(epoch: 182, iters: 4848, time: 0.165, data: 0.000) loss: 0.228 
(epoch: 182, iters: 4928, time: 0.159, data: 0.000) loss: 0.073 
(epoch: 182, iters: 5008, time: 0.159, data: 0.000) loss: 0.084 
(epoch: 182, iters: 5088, time: 0.158, data: 0.009) loss: 0.386 
(epoch: 182, iters: 5168, time: 0.159, data: 0.006) loss: 0.172 
(epoch: 182, iters: 5248, time: 0.158, data: 0.024) loss: 0.071 
(epoch: 182, iters: 5328, time: 0.158, data: 0.000) loss: 0.180 
(epoch: 182, iters: 5408, time: 0.156, data: 0.030) loss: 0.166 
(epoch: 182, iters: 5488, time: 0.158, data: 0.000) loss: 0.240 
(epoch: 182, iters: 5568, time: 0.158, data: 0.010) loss: 0.268 
(epoch: 182, iters: 5648, time: 0.155, data: 0.005) loss: 0.222 
(epoch: 182, iters: 5728, time: 0.157, data: 0.000) loss: 0.162 
(epoch: 182, iters: 5808, time: 0.158, data: 0.014) loss: 0.485 
(epoch: 182, iters: 5888, time: 0.164, data: 0.000) loss: 0.155 
(epoch: 182, iters: 5968, time: 0.156, data: 0.024) loss: 0.336 
(epoch: 182, iters: 6048, time: 0.160, data: 0.000) loss: 0.194 
(epoch: 182, iters: 6128, time: 0.158, data: 0.000) loss: 0.567 
(epoch: 182, iters: 6208, time: 0.159, data: 0.000) loss: 0.035 
(epoch: 182, iters: 6288, time: 0.158, data: 0.029) loss: 0.142 
(epoch: 182, iters: 6368, time: 0.159, data: 0.005) loss: 0.151 
(epoch: 182, iters: 6448, time: 0.158, data: 0.000) loss: 0.023 
(epoch: 182, iters: 6528, time: 0.159, data: 0.014) loss: 0.051 
(epoch: 182, iters: 6608, time: 0.159, data: 0.000) loss: 0.148 
(epoch: 182, iters: 6688, time: 0.159, data: 0.000) loss: 0.436 
(epoch: 182, iters: 6768, time: 0.158, data: 0.000) loss: 0.160 
(epoch: 182, iters: 6848, time: 0.158, data: 0.026) loss: 0.515 
(epoch: 182, iters: 6928, time: 0.158, data: 0.000) loss: 0.286 
(epoch: 182, iters: 7008, time: 0.158, data: 0.000) loss: 0.302 
(epoch: 182, iters: 7088, time: 0.159, data: 0.000) loss: 0.077 
(epoch: 182, iters: 7168, time: 0.158, data: 0.010) loss: 0.371 
(epoch: 182, iters: 7248, time: 0.159, data: 0.000) loss: 0.146 
(epoch: 182, iters: 7328, time: 0.157, data: 0.000) loss: 0.139 
(epoch: 182, iters: 7408, time: 0.158, data: 0.000) loss: 0.102 
(epoch: 182, iters: 7488, time: 0.158, data: 0.014) loss: 0.180 
(epoch: 182, iters: 7568, time: 0.159, data: 0.009) loss: 0.036 
(epoch: 182, iters: 7648, time: 0.157, data: 0.008) loss: 0.179 
(epoch: 182, iters: 7728, time: 0.159, data: 0.000) loss: 0.117 
(epoch: 182, iters: 7808, time: 0.158, data: 0.020) loss: 0.069 
(epoch: 182, iters: 7888, time: 0.158, data: 0.000) loss: 0.244 
(epoch: 182, iters: 7968, time: 0.164, data: 0.000) loss: 0.337 
saving the latest model (epoch 182, total_steps 1852768)
(epoch: 182, iters: 8048, time: 0.157, data: 0.005) loss: 0.165 
(epoch: 182, iters: 8128, time: 0.158, data: 0.000) loss: 0.046 
(epoch: 182, iters: 8208, time: 0.158, data: 0.000) loss: 0.196 
(epoch: 182, iters: 8288, time: 0.159, data: 0.000) loss: 0.077 
(epoch: 182, iters: 8368, time: 0.165, data: 0.000) loss: 0.671 
(epoch: 182, iters: 8448, time: 0.159, data: 0.019) loss: 0.592 
(epoch: 182, iters: 8528, time: 0.160, data: 0.000) loss: 0.297 
(epoch: 182, iters: 8608, time: 0.159, data: 0.021) loss: 0.397 
(epoch: 182, iters: 8688, time: 0.161, data: 0.000) loss: 0.281 
(epoch: 182, iters: 8768, time: 0.161, data: 0.000) loss: 0.063 
(epoch: 182, iters: 8848, time: 0.159, data: 0.000) loss: 0.060 
(epoch: 182, iters: 8928, time: 0.159, data: 0.000) loss: 0.074 
(epoch: 182, iters: 9008, time: 0.158, data: 0.033) loss: 0.161 
(epoch: 182, iters: 9088, time: 0.159, data: 0.000) loss: 0.053 
(epoch: 182, iters: 9168, time: 0.157, data: 0.000) loss: 0.079 
(epoch: 182, iters: 9248, time: 0.157, data: 0.008) loss: 0.234 
(epoch: 182, iters: 9328, time: 0.156, data: 0.000) loss: 0.215 
(epoch: 182, iters: 9408, time: 0.159, data: 0.005) loss: 0.178 
(epoch: 182, iters: 9488, time: 0.159, data: 0.005) loss: 0.253 
(epoch: 182, iters: 9568, time: 0.159, data: 0.000) loss: 0.279 
(epoch: 182, iters: 9648, time: 0.159, data: 0.011) loss: 0.842 
(epoch: 182, iters: 9728, time: 0.156, data: 0.008) loss: 0.181 
(epoch: 182, iters: 9808, time: 0.158, data: 0.013) loss: 0.256 
(epoch: 182, iters: 9888, time: 0.159, data: 0.000) loss: 0.144 
(epoch: 182, iters: 9968, time: 0.157, data: 0.010) loss: 0.149 
(epoch: 182, iters: 10048, time: 0.157, data: 0.000) loss: 0.037 
(epoch: 182, iters: 10128, time: 0.159, data: 0.000) loss: 0.083 
saving the model at the end of epoch 182, iters 1854944
End of epoch 182 / 200 	 Time Taken: 1620 sec
learning rate = 0.0000337
(epoch: 183, iters: 16, time: 0.178, data: 0.005) loss: 0.195 
saving the latest model (epoch 183, total_steps 1854960)
(epoch: 183, iters: 96, time: 0.158, data: 0.000) loss: 0.115 
(epoch: 183, iters: 176, time: 0.157, data: 0.019) loss: 0.016 
(epoch: 183, iters: 256, time: 0.158, data: 0.000) loss: 0.512 
(epoch: 183, iters: 336, time: 0.160, data: 0.008) loss: 0.076 
(epoch: 183, iters: 416, time: 0.156, data: 0.009) loss: 0.111 
(epoch: 183, iters: 496, time: 0.157, data: 0.010) loss: 0.280 
(epoch: 183, iters: 576, time: 0.157, data: 0.000) loss: 0.370 
(epoch: 183, iters: 656, time: 0.155, data: 0.000) loss: 0.052 
(epoch: 183, iters: 736, time: 0.155, data: 0.020) loss: 0.056 
(epoch: 183, iters: 816, time: 0.157, data: 0.005) loss: 0.290 
(epoch: 183, iters: 896, time: 0.155, data: 0.010) loss: 0.150 
(epoch: 183, iters: 976, time: 0.155, data: 0.000) loss: 0.218 
(epoch: 183, iters: 1056, time: 0.157, data: 0.020) loss: 0.096 
(epoch: 183, iters: 1136, time: 0.158, data: 0.000) loss: 0.155 
(epoch: 183, iters: 1216, time: 0.156, data: 0.000) loss: 0.456 
(epoch: 183, iters: 1296, time: 0.157, data: 0.015) loss: 0.323 
(epoch: 183, iters: 1376, time: 0.159, data: 0.000) loss: 0.043 
(epoch: 183, iters: 1456, time: 0.159, data: 0.000) loss: 0.094 
(epoch: 183, iters: 1536, time: 0.158, data: 0.000) loss: 0.539 
(epoch: 183, iters: 1616, time: 0.157, data: 0.000) loss: 0.162 
(epoch: 183, iters: 1696, time: 0.167, data: 0.010) loss: 0.207 
(epoch: 183, iters: 1776, time: 0.158, data: 0.005) loss: 0.384 
(epoch: 183, iters: 1856, time: 0.157, data: 0.000) loss: 0.349 
(epoch: 183, iters: 1936, time: 0.159, data: 0.008) loss: 0.562 
(epoch: 183, iters: 2016, time: 0.159, data: 0.000) loss: 0.096 
(epoch: 183, iters: 2096, time: 0.158, data: 0.000) loss: 0.153 
(epoch: 183, iters: 2176, time: 0.156, data: 0.016) loss: 0.137 
(epoch: 183, iters: 2256, time: 0.157, data: 0.000) loss: 0.507 
(epoch: 183, iters: 2336, time: 0.158, data: 0.000) loss: 0.332 
(epoch: 183, iters: 2416, time: 0.160, data: 0.000) loss: 0.307 
(epoch: 183, iters: 2496, time: 0.160, data: 0.000) loss: 0.220 
(epoch: 183, iters: 2576, time: 0.158, data: 0.031) loss: 0.081 
(epoch: 183, iters: 2656, time: 0.161, data: 0.000) loss: 0.218 
(epoch: 183, iters: 2736, time: 0.159, data: 0.010) loss: 0.304 
(epoch: 183, iters: 2816, time: 0.158, data: 0.000) loss: 0.289 
(epoch: 183, iters: 2896, time: 0.159, data: 0.000) loss: 0.169 
(epoch: 183, iters: 2976, time: 0.158, data: 0.009) loss: 0.096 
(epoch: 183, iters: 3056, time: 0.159, data: 0.010) loss: 0.462 
(epoch: 183, iters: 3136, time: 0.160, data: 0.018) loss: 0.111 
(epoch: 183, iters: 3216, time: 0.161, data: 0.000) loss: 0.104 
(epoch: 183, iters: 3296, time: 0.159, data: 0.000) loss: 0.115 
(epoch: 183, iters: 3376, time: 0.158, data: 0.000) loss: 0.289 
(epoch: 183, iters: 3456, time: 0.161, data: 0.000) loss: 0.190 
(epoch: 183, iters: 3536, time: 0.159, data: 0.015) loss: 0.544 
(epoch: 183, iters: 3616, time: 0.159, data: 0.000) loss: 0.434 
(epoch: 183, iters: 3696, time: 0.157, data: 0.020) loss: 0.100 
(epoch: 183, iters: 3776, time: 0.159, data: 0.006) loss: 0.138 
(epoch: 183, iters: 3856, time: 0.160, data: 0.000) loss: 0.300 
(epoch: 183, iters: 3936, time: 0.157, data: 0.013) loss: 0.132 
(epoch: 183, iters: 4016, time: 0.157, data: 0.000) loss: 0.080 
saving the latest model (epoch 183, total_steps 1858960)
(epoch: 183, iters: 4096, time: 0.158, data: 0.025) loss: 0.167 
(epoch: 183, iters: 4176, time: 0.158, data: 0.000) loss: 0.174 
(epoch: 183, iters: 4256, time: 0.157, data: 0.000) loss: 0.441 
(epoch: 183, iters: 4336, time: 0.158, data: 0.008) loss: 0.254 
(epoch: 183, iters: 4416, time: 0.164, data: 0.000) loss: 0.051 
(epoch: 183, iters: 4496, time: 0.159, data: 0.005) loss: 0.232 
(epoch: 183, iters: 4576, time: 0.156, data: 0.000) loss: 0.122 
(epoch: 183, iters: 4656, time: 0.160, data: 0.000) loss: 0.073 
(epoch: 183, iters: 4736, time: 0.160, data: 0.000) loss: 0.429 
(epoch: 183, iters: 4816, time: 0.165, data: 0.000) loss: 0.455 
(epoch: 183, iters: 4896, time: 0.159, data: 0.005) loss: 0.103 
(epoch: 183, iters: 4976, time: 0.157, data: 0.016) loss: 0.098 
(epoch: 183, iters: 5056, time: 0.160, data: 0.011) loss: 0.351 
(epoch: 183, iters: 5136, time: 0.160, data: 0.000) loss: 0.264 
(epoch: 183, iters: 5216, time: 0.161, data: 0.000) loss: 0.199 
(epoch: 183, iters: 5296, time: 0.157, data: 0.005) loss: 0.641 
(epoch: 183, iters: 5376, time: 0.155, data: 0.000) loss: 0.459 
(epoch: 183, iters: 5456, time: 0.157, data: 0.000) loss: 0.400 
(epoch: 183, iters: 5536, time: 0.159, data: 0.010) loss: 0.197 
(epoch: 183, iters: 5616, time: 0.157, data: 0.000) loss: 0.252 
(epoch: 183, iters: 5696, time: 0.158, data: 0.009) loss: 0.456 
(epoch: 183, iters: 5776, time: 0.159, data: 0.010) loss: 0.454 
(epoch: 183, iters: 5856, time: 0.157, data: 0.000) loss: 0.325 
(epoch: 183, iters: 5936, time: 0.158, data: 0.014) loss: 0.400 
(epoch: 183, iters: 6016, time: 0.159, data: 0.000) loss: 0.372 
(epoch: 183, iters: 6096, time: 0.158, data: 0.005) loss: 0.070 
(epoch: 183, iters: 6176, time: 0.157, data: 0.005) loss: 0.093 
(epoch: 183, iters: 6256, time: 0.158, data: 0.008) loss: 0.106 
(epoch: 183, iters: 6336, time: 0.159, data: 0.000) loss: 0.443 
(epoch: 183, iters: 6416, time: 0.158, data: 0.005) loss: 0.034 
(epoch: 183, iters: 6496, time: 0.158, data: 0.000) loss: 0.250 
(epoch: 183, iters: 6576, time: 0.158, data: 0.000) loss: 0.371 
(epoch: 183, iters: 6656, time: 0.159, data: 0.008) loss: 0.304 
(epoch: 183, iters: 6736, time: 0.156, data: 0.000) loss: 0.213 
(epoch: 183, iters: 6816, time: 0.157, data: 0.008) loss: 0.111 
(epoch: 183, iters: 6896, time: 0.159, data: 0.000) loss: 0.521 
(epoch: 183, iters: 6976, time: 0.158, data: 0.005) loss: 0.430 
(epoch: 183, iters: 7056, time: 0.158, data: 0.013) loss: 0.251 
(epoch: 183, iters: 7136, time: 0.157, data: 0.000) loss: 0.597 
(epoch: 183, iters: 7216, time: 0.159, data: 0.000) loss: 0.150 
(epoch: 183, iters: 7296, time: 0.158, data: 0.013) loss: 0.079 
(epoch: 183, iters: 7376, time: 0.158, data: 0.000) loss: 0.303 
(epoch: 183, iters: 7456, time: 0.158, data: 0.000) loss: 0.078 
(epoch: 183, iters: 7536, time: 0.170, data: 0.005) loss: 0.452 
(epoch: 183, iters: 7616, time: 0.165, data: 0.000) loss: 0.382 
(epoch: 183, iters: 7696, time: 0.157, data: 0.000) loss: 0.121 
(epoch: 183, iters: 7776, time: 0.155, data: 0.000) loss: 0.163 
(epoch: 183, iters: 7856, time: 0.159, data: 0.006) loss: 0.710 
(epoch: 183, iters: 7936, time: 0.157, data: 0.000) loss: 0.304 
(epoch: 183, iters: 8016, time: 0.159, data: 0.000) loss: 0.375 
saving the latest model (epoch 183, total_steps 1862960)
(epoch: 183, iters: 8096, time: 0.158, data: 0.005) loss: 0.400 
(epoch: 183, iters: 8176, time: 0.158, data: 0.000) loss: 0.127 
(epoch: 183, iters: 8256, time: 0.160, data: 0.000) loss: 0.398 
(epoch: 183, iters: 8336, time: 0.154, data: 0.000) loss: 0.086 
(epoch: 183, iters: 8416, time: 0.157, data: 0.000) loss: 0.208 
(epoch: 183, iters: 8496, time: 0.157, data: 0.000) loss: 0.238 
(epoch: 183, iters: 8576, time: 0.158, data: 0.011) loss: 0.218 
(epoch: 183, iters: 8656, time: 0.157, data: 0.009) loss: 0.228 
(epoch: 183, iters: 8736, time: 0.158, data: 0.000) loss: 0.248 
(epoch: 183, iters: 8816, time: 0.157, data: 0.000) loss: 0.098 
(epoch: 183, iters: 8896, time: 0.158, data: 0.005) loss: 0.129 
(epoch: 183, iters: 8976, time: 0.157, data: 0.000) loss: 0.143 
(epoch: 183, iters: 9056, time: 0.158, data: 0.005) loss: 0.166 
(epoch: 183, iters: 9136, time: 0.156, data: 0.016) loss: 0.388 
(epoch: 183, iters: 9216, time: 0.158, data: 0.000) loss: 0.260 
(epoch: 183, iters: 9296, time: 0.156, data: 0.000) loss: 0.157 
(epoch: 183, iters: 9376, time: 0.158, data: 0.032) loss: 0.308 
(epoch: 183, iters: 9456, time: 0.158, data: 0.000) loss: 0.064 
(epoch: 183, iters: 9536, time: 0.158, data: 0.013) loss: 0.082 
(epoch: 183, iters: 9616, time: 0.155, data: 0.000) loss: 0.414 
(epoch: 183, iters: 9696, time: 0.158, data: 0.025) loss: 0.323 
(epoch: 183, iters: 9776, time: 0.159, data: 0.000) loss: 0.441 
(epoch: 183, iters: 9856, time: 0.157, data: 0.000) loss: 0.600 
(epoch: 183, iters: 9936, time: 0.157, data: 0.000) loss: 0.102 
(epoch: 183, iters: 10016, time: 0.157, data: 0.005) loss: 0.171 
(epoch: 183, iters: 10096, time: 0.157, data: 0.008) loss: 0.160 
(epoch: 183, iters: 10176, time: 0.158, data: 0.000) loss: 0.223 
saving the model at the end of epoch 183, iters 1865136
End of epoch 183 / 200 	 Time Taken: 1618 sec
learning rate = 0.0000317
saving the latest model (epoch 184, total_steps 1865152)
(epoch: 184, iters: 64, time: 0.162, data: 0.003) loss: 0.215 
(epoch: 184, iters: 144, time: 0.160, data: 0.000) loss: 0.186 
(epoch: 184, iters: 224, time: 0.160, data: 0.008) loss: 0.248 
(epoch: 184, iters: 304, time: 0.159, data: 0.000) loss: 0.202 
(epoch: 184, iters: 384, time: 0.183, data: 0.008) loss: 0.446 
(epoch: 184, iters: 464, time: 0.171, data: 0.024) loss: 0.101 
(epoch: 184, iters: 544, time: 0.199, data: 0.000) loss: 0.406 
(epoch: 184, iters: 624, time: 0.173, data: 0.000) loss: 0.212 
(epoch: 184, iters: 704, time: 0.171, data: 0.017) loss: 0.259 
(epoch: 184, iters: 784, time: 0.226, data: 0.020) loss: 0.242 
(epoch: 184, iters: 864, time: 0.272, data: 0.022) loss: 0.245 
(epoch: 184, iters: 944, time: 0.276, data: 0.000) loss: 0.036 
(epoch: 184, iters: 1024, time: 0.172, data: 0.000) loss: 0.066 
(epoch: 184, iters: 1104, time: 0.172, data: 0.008) loss: 0.150 
(epoch: 184, iters: 1184, time: 0.174, data: 0.000) loss: 0.244 
(epoch: 184, iters: 1264, time: 0.203, data: 0.005) loss: 0.252 
(epoch: 184, iters: 1344, time: 0.165, data: 0.000) loss: 0.236 
(epoch: 184, iters: 1424, time: 0.159, data: 0.000) loss: 0.380 
(epoch: 184, iters: 1504, time: 0.159, data: 0.032) loss: 0.087 
(epoch: 184, iters: 1584, time: 0.160, data: 0.000) loss: 0.166 
(epoch: 184, iters: 1664, time: 0.160, data: 0.021) loss: 0.120 
(epoch: 184, iters: 1744, time: 0.160, data: 0.000) loss: 0.067 
(epoch: 184, iters: 1824, time: 0.158, data: 0.013) loss: 0.080 
(epoch: 184, iters: 1904, time: 0.159, data: 0.000) loss: 0.066 
(epoch: 184, iters: 1984, time: 0.161, data: 0.000) loss: 0.152 
(epoch: 184, iters: 2064, time: 0.159, data: 0.000) loss: 0.158 
(epoch: 184, iters: 2144, time: 0.158, data: 0.000) loss: 0.164 
(epoch: 184, iters: 2224, time: 0.172, data: 0.016) loss: 0.031 
(epoch: 184, iters: 2304, time: 0.161, data: 0.009) loss: 0.314 
(epoch: 184, iters: 2384, time: 0.161, data: 0.005) loss: 0.198 
(epoch: 184, iters: 2464, time: 0.159, data: 0.010) loss: 0.016 
(epoch: 184, iters: 2544, time: 0.163, data: 0.000) loss: 0.067 
(epoch: 184, iters: 2624, time: 0.159, data: 0.000) loss: 0.222 
(epoch: 184, iters: 2704, time: 0.158, data: 0.000) loss: 0.353 
(epoch: 184, iters: 2784, time: 0.185, data: 0.008) loss: 0.045 
(epoch: 184, iters: 2864, time: 0.202, data: 0.000) loss: 0.312 
(epoch: 184, iters: 2944, time: 0.171, data: 0.031) loss: 0.155 
(epoch: 184, iters: 3024, time: 0.169, data: 0.000) loss: 0.238 
(epoch: 184, iters: 3104, time: 0.173, data: 0.008) loss: 0.059 
(epoch: 184, iters: 3184, time: 0.249, data: 0.000) loss: 0.486 
(epoch: 184, iters: 3264, time: 0.172, data: 0.009) loss: 0.197 
(epoch: 184, iters: 3344, time: 0.171, data: 0.000) loss: 0.149 
(epoch: 184, iters: 3424, time: 0.173, data: 0.033) loss: 0.156 
(epoch: 184, iters: 3504, time: 0.172, data: 0.000) loss: 0.053 
(epoch: 184, iters: 3584, time: 0.172, data: 0.000) loss: 0.458 
(epoch: 184, iters: 3664, time: 0.173, data: 0.000) loss: 0.124 
(epoch: 184, iters: 3744, time: 0.175, data: 0.008) loss: 0.293 
(epoch: 184, iters: 3824, time: 0.159, data: 0.025) loss: 0.220 
(epoch: 184, iters: 3904, time: 0.160, data: 0.000) loss: 0.297 
(epoch: 184, iters: 3984, time: 0.160, data: 0.005) loss: 0.552 
saving the latest model (epoch 184, total_steps 1869152)
(epoch: 184, iters: 4064, time: 0.161, data: 0.005) loss: 0.169 
(epoch: 184, iters: 4144, time: 0.159, data: 0.000) loss: 0.231 
(epoch: 184, iters: 4224, time: 0.159, data: 0.013) loss: 0.170 
(epoch: 184, iters: 4304, time: 0.160, data: 0.008) loss: 0.773 
(epoch: 184, iters: 4384, time: 0.158, data: 0.000) loss: 0.285 
(epoch: 184, iters: 4464, time: 0.160, data: 0.008) loss: 0.619 
(epoch: 184, iters: 4544, time: 0.161, data: 0.000) loss: 0.252 
(epoch: 184, iters: 4624, time: 0.164, data: 0.009) loss: 0.241 
(epoch: 184, iters: 4704, time: 0.160, data: 0.000) loss: 0.306 
(epoch: 184, iters: 4784, time: 0.158, data: 0.000) loss: 0.308 
(epoch: 184, iters: 4864, time: 0.159, data: 0.000) loss: 0.069 
(epoch: 184, iters: 4944, time: 0.160, data: 0.021) loss: 0.384 
(epoch: 184, iters: 5024, time: 0.166, data: 0.000) loss: 0.311 
(epoch: 184, iters: 5104, time: 0.160, data: 0.009) loss: 0.158 
(epoch: 184, iters: 5184, time: 0.158, data: 0.000) loss: 0.084 
(epoch: 184, iters: 5264, time: 0.160, data: 0.017) loss: 0.485 
(epoch: 184, iters: 5344, time: 0.159, data: 0.000) loss: 0.380 
(epoch: 184, iters: 5424, time: 0.160, data: 0.014) loss: 0.144 
(epoch: 184, iters: 5504, time: 0.160, data: 0.000) loss: 0.190 
(epoch: 184, iters: 5584, time: 0.160, data: 0.013) loss: 0.114 
(epoch: 184, iters: 5664, time: 0.160, data: 0.000) loss: 0.163 
(epoch: 184, iters: 5744, time: 0.159, data: 0.000) loss: 0.176 
(epoch: 184, iters: 5824, time: 0.159, data: 0.015) loss: 0.394 
(epoch: 184, iters: 5904, time: 0.159, data: 0.000) loss: 0.138 
(epoch: 184, iters: 5984, time: 0.159, data: 0.032) loss: 0.320 
(epoch: 184, iters: 6064, time: 0.160, data: 0.000) loss: 0.117 
(epoch: 184, iters: 6144, time: 0.160, data: 0.000) loss: 0.575 
(epoch: 184, iters: 6224, time: 0.160, data: 0.000) loss: 0.134 
(epoch: 184, iters: 6304, time: 0.159, data: 0.014) loss: 0.196 
(epoch: 184, iters: 6384, time: 0.160, data: 0.031) loss: 0.196 
(epoch: 184, iters: 6464, time: 0.161, data: 0.000) loss: 0.488 
(epoch: 184, iters: 6544, time: 0.160, data: 0.010) loss: 0.143 
(epoch: 184, iters: 6624, time: 0.161, data: 0.000) loss: 0.754 
(epoch: 184, iters: 6704, time: 0.160, data: 0.000) loss: 0.254 
(epoch: 184, iters: 6784, time: 0.159, data: 0.005) loss: 0.421 
(epoch: 184, iters: 6864, time: 0.160, data: 0.000) loss: 0.456 
(epoch: 184, iters: 6944, time: 0.166, data: 0.008) loss: 0.182 
(epoch: 184, iters: 7024, time: 0.158, data: 0.000) loss: 0.130 
(epoch: 184, iters: 7104, time: 0.159, data: 0.016) loss: 0.614 
(epoch: 184, iters: 7184, time: 0.161, data: 0.015) loss: 0.262 
(epoch: 184, iters: 7264, time: 0.160, data: 0.000) loss: 0.387 
(epoch: 184, iters: 7344, time: 0.159, data: 0.016) loss: 0.425 
(epoch: 184, iters: 7424, time: 0.161, data: 0.015) loss: 0.239 
(epoch: 184, iters: 7504, time: 0.160, data: 0.019) loss: 0.218 
(epoch: 184, iters: 7584, time: 0.159, data: 0.000) loss: 0.412 
(epoch: 184, iters: 7664, time: 0.160, data: 0.020) loss: 0.334 
(epoch: 184, iters: 7744, time: 0.160, data: 0.000) loss: 0.198 
(epoch: 184, iters: 7824, time: 0.161, data: 0.034) loss: 0.213 
(epoch: 184, iters: 7904, time: 0.160, data: 0.000) loss: 0.527 
(epoch: 184, iters: 7984, time: 0.162, data: 0.031) loss: 0.240 
saving the latest model (epoch 184, total_steps 1873152)
(epoch: 184, iters: 8064, time: 0.159, data: 0.000) loss: 0.380 
(epoch: 184, iters: 8144, time: 0.159, data: 0.000) loss: 0.303 
(epoch: 184, iters: 8224, time: 0.158, data: 0.013) loss: 0.309 
(epoch: 184, iters: 8304, time: 0.161, data: 0.000) loss: 0.207 
(epoch: 184, iters: 8384, time: 0.160, data: 0.005) loss: 0.195 
(epoch: 184, iters: 8464, time: 0.159, data: 0.020) loss: 0.174 
(epoch: 184, iters: 8544, time: 0.160, data: 0.000) loss: 0.152 
(epoch: 184, iters: 8624, time: 0.160, data: 0.000) loss: 0.219 
(epoch: 184, iters: 8704, time: 0.159, data: 0.005) loss: 0.757 
(epoch: 184, iters: 8784, time: 0.159, data: 0.000) loss: 0.088 
(epoch: 184, iters: 8864, time: 0.159, data: 0.000) loss: 0.210 
(epoch: 184, iters: 8944, time: 0.160, data: 0.017) loss: 0.155 
(epoch: 184, iters: 9024, time: 0.160, data: 0.000) loss: 0.132 
(epoch: 184, iters: 9104, time: 0.160, data: 0.028) loss: 0.100 
(epoch: 184, iters: 9184, time: 0.161, data: 0.000) loss: 0.108 
(epoch: 184, iters: 9264, time: 0.161, data: 0.005) loss: 0.126 
(epoch: 184, iters: 9344, time: 0.160, data: 0.000) loss: 0.179 
(epoch: 184, iters: 9424, time: 0.160, data: 0.000) loss: 0.296 
(epoch: 184, iters: 9504, time: 0.159, data: 0.000) loss: 0.119 
(epoch: 184, iters: 9584, time: 0.161, data: 0.005) loss: 0.261 
(epoch: 184, iters: 9664, time: 0.163, data: 0.000) loss: 0.110 
(epoch: 184, iters: 9744, time: 0.159, data: 0.016) loss: 0.287 
(epoch: 184, iters: 9824, time: 0.159, data: 0.000) loss: 0.172 
(epoch: 184, iters: 9904, time: 0.159, data: 0.005) loss: 0.170 
(epoch: 184, iters: 9984, time: 0.160, data: 0.000) loss: 0.198 
(epoch: 184, iters: 10064, time: 0.158, data: 0.000) loss: 0.186 
(epoch: 184, iters: 10144, time: 0.159, data: 0.008) loss: 0.290 
saving the model at the end of epoch 184, iters 1875328
End of epoch 184 / 200 	 Time Taken: 1712 sec
learning rate = 0.0000297
saving the latest model (epoch 185, total_steps 1875344)
(epoch: 185, iters: 32, time: 0.166, data: 0.000) loss: 0.072 
(epoch: 185, iters: 112, time: 0.157, data: 0.000) loss: 0.162 
(epoch: 185, iters: 192, time: 0.156, data: 0.011) loss: 0.243 
(epoch: 185, iters: 272, time: 0.156, data: 0.016) loss: 0.055 
(epoch: 185, iters: 352, time: 0.155, data: 0.000) loss: 0.290 
(epoch: 185, iters: 432, time: 0.157, data: 0.008) loss: 0.261 
(epoch: 185, iters: 512, time: 0.154, data: 0.000) loss: 0.191 
(epoch: 185, iters: 592, time: 0.157, data: 0.015) loss: 0.050 
(epoch: 185, iters: 672, time: 0.158, data: 0.000) loss: 0.510 
(epoch: 185, iters: 752, time: 0.157, data: 0.000) loss: 0.291 
(epoch: 185, iters: 832, time: 0.155, data: 0.032) loss: 0.128 
(epoch: 185, iters: 912, time: 0.155, data: 0.000) loss: 0.081 
(epoch: 185, iters: 992, time: 0.154, data: 0.005) loss: 0.486 
(epoch: 185, iters: 1072, time: 0.155, data: 0.000) loss: 0.210 
(epoch: 185, iters: 1152, time: 0.155, data: 0.008) loss: 0.261 
(epoch: 185, iters: 1232, time: 0.155, data: 0.000) loss: 0.327 
(epoch: 185, iters: 1312, time: 0.157, data: 0.000) loss: 0.302 
(epoch: 185, iters: 1392, time: 0.154, data: 0.000) loss: 0.087 
(epoch: 185, iters: 1472, time: 0.157, data: 0.000) loss: 0.071 
(epoch: 185, iters: 1552, time: 0.154, data: 0.000) loss: 0.421 
(epoch: 185, iters: 1632, time: 0.156, data: 0.008) loss: 0.145 
(epoch: 185, iters: 1712, time: 0.156, data: 0.000) loss: 0.669 
(epoch: 185, iters: 1792, time: 0.157, data: 0.006) loss: 0.015 
(epoch: 185, iters: 1872, time: 0.155, data: 0.000) loss: 0.315 
(epoch: 185, iters: 1952, time: 0.156, data: 0.005) loss: 0.041 
(epoch: 185, iters: 2032, time: 0.156, data: 0.000) loss: 0.065 
(epoch: 185, iters: 2112, time: 0.157, data: 0.005) loss: 0.070 
(epoch: 185, iters: 2192, time: 0.155, data: 0.024) loss: 0.177 
(epoch: 185, iters: 2272, time: 0.156, data: 0.000) loss: 0.212 
(epoch: 185, iters: 2352, time: 0.154, data: 0.000) loss: 0.287 
(epoch: 185, iters: 2432, time: 0.158, data: 0.000) loss: 0.121 
(epoch: 185, iters: 2512, time: 0.157, data: 0.000) loss: 0.740 
(epoch: 185, iters: 2592, time: 0.157, data: 0.030) loss: 0.210 
(epoch: 185, iters: 2672, time: 0.157, data: 0.000) loss: 0.112 
(epoch: 185, iters: 2752, time: 0.155, data: 0.008) loss: 0.091 
(epoch: 185, iters: 2832, time: 0.154, data: 0.005) loss: 0.163 
(epoch: 185, iters: 2912, time: 0.155, data: 0.000) loss: 0.116 
(epoch: 185, iters: 2992, time: 0.156, data: 0.025) loss: 0.229 
(epoch: 185, iters: 3072, time: 0.154, data: 0.000) loss: 0.029 
(epoch: 185, iters: 3152, time: 0.156, data: 0.000) loss: 0.138 
(epoch: 185, iters: 3232, time: 0.155, data: 0.009) loss: 0.115 
(epoch: 185, iters: 3312, time: 0.155, data: 0.014) loss: 0.132 
(epoch: 185, iters: 3392, time: 0.154, data: 0.000) loss: 0.192 
(epoch: 185, iters: 3472, time: 0.155, data: 0.000) loss: 0.151 
(epoch: 185, iters: 3552, time: 0.154, data: 0.026) loss: 0.145 
(epoch: 185, iters: 3632, time: 0.156, data: 0.000) loss: 0.709 
(epoch: 185, iters: 3712, time: 0.155, data: 0.000) loss: 0.110 
(epoch: 185, iters: 3792, time: 0.154, data: 0.014) loss: 0.198 
(epoch: 185, iters: 3872, time: 0.154, data: 0.000) loss: 0.089 
(epoch: 185, iters: 3952, time: 0.155, data: 0.005) loss: 0.095 
saving the latest model (epoch 185, total_steps 1879344)
(epoch: 185, iters: 4032, time: 0.158, data: 0.000) loss: 0.104 
(epoch: 185, iters: 4112, time: 0.156, data: 0.005) loss: 0.316 
(epoch: 185, iters: 4192, time: 0.160, data: 0.000) loss: 0.153 
(epoch: 185, iters: 4272, time: 0.158, data: 0.000) loss: 0.092 
(epoch: 185, iters: 4352, time: 0.157, data: 0.000) loss: 0.350 
(epoch: 185, iters: 4432, time: 0.159, data: 0.019) loss: 0.134 
(epoch: 185, iters: 4512, time: 0.158, data: 0.000) loss: 0.133 
(epoch: 185, iters: 4592, time: 0.158, data: 0.009) loss: 0.209 
(epoch: 185, iters: 4672, time: 0.155, data: 0.000) loss: 0.043 
(epoch: 185, iters: 4752, time: 0.157, data: 0.000) loss: 0.091 
(epoch: 185, iters: 4832, time: 0.157, data: 0.000) loss: 0.105 
(epoch: 185, iters: 4912, time: 0.155, data: 0.000) loss: 0.236 
(epoch: 185, iters: 4992, time: 0.154, data: 0.000) loss: 0.083 
(epoch: 185, iters: 5072, time: 0.157, data: 0.000) loss: 0.103 
(epoch: 185, iters: 5152, time: 0.155, data: 0.000) loss: 0.108 
(epoch: 185, iters: 5232, time: 0.155, data: 0.021) loss: 0.095 
(epoch: 185, iters: 5312, time: 0.156, data: 0.019) loss: 0.214 
(epoch: 185, iters: 5392, time: 0.156, data: 0.020) loss: 0.079 
(epoch: 185, iters: 5472, time: 0.158, data: 0.000) loss: 0.177 
(epoch: 185, iters: 5552, time: 0.156, data: 0.000) loss: 0.243 
(epoch: 185, iters: 5632, time: 0.157, data: 0.026) loss: 0.113 
(epoch: 185, iters: 5712, time: 0.155, data: 0.000) loss: 0.103 
(epoch: 185, iters: 5792, time: 0.158, data: 0.014) loss: 0.116 
(epoch: 185, iters: 5872, time: 0.160, data: 0.005) loss: 0.360 
(epoch: 185, iters: 5952, time: 0.155, data: 0.000) loss: 0.331 
(epoch: 185, iters: 6032, time: 0.157, data: 0.005) loss: 0.151 
(epoch: 185, iters: 6112, time: 0.155, data: 0.000) loss: 0.464 
(epoch: 185, iters: 6192, time: 0.165, data: 0.011) loss: 0.259 
(epoch: 185, iters: 6272, time: 0.157, data: 0.005) loss: 0.191 
(epoch: 185, iters: 6352, time: 0.157, data: 0.005) loss: 0.772 
(epoch: 185, iters: 6432, time: 0.157, data: 0.000) loss: 0.269 
(epoch: 185, iters: 6512, time: 0.156, data: 0.029) loss: 0.170 
(epoch: 185, iters: 6592, time: 0.161, data: 0.000) loss: 0.195 
(epoch: 185, iters: 6672, time: 0.156, data: 0.000) loss: 0.338 
(epoch: 185, iters: 6752, time: 0.156, data: 0.008) loss: 0.260 
(epoch: 185, iters: 6832, time: 0.155, data: 0.009) loss: 0.129 
(epoch: 185, iters: 6912, time: 0.157, data: 0.000) loss: 0.276 
(epoch: 185, iters: 6992, time: 0.163, data: 0.000) loss: 0.306 
(epoch: 185, iters: 7072, time: 0.157, data: 0.000) loss: 0.186 
(epoch: 185, iters: 7152, time: 0.155, data: 0.010) loss: 0.354 
(epoch: 185, iters: 7232, time: 0.155, data: 0.008) loss: 0.147 
(epoch: 185, iters: 7312, time: 0.158, data: 0.006) loss: 0.261 
(epoch: 185, iters: 7392, time: 0.156, data: 0.013) loss: 0.365 
(epoch: 185, iters: 7472, time: 0.158, data: 0.000) loss: 0.175 
(epoch: 185, iters: 7552, time: 0.157, data: 0.005) loss: 0.244 
(epoch: 185, iters: 7632, time: 0.157, data: 0.000) loss: 0.131 
(epoch: 185, iters: 7712, time: 0.156, data: 0.006) loss: 0.250 
(epoch: 185, iters: 7792, time: 0.157, data: 0.000) loss: 0.407 
(epoch: 185, iters: 7872, time: 0.154, data: 0.011) loss: 0.239 
(epoch: 185, iters: 7952, time: 0.157, data: 0.005) loss: 0.355 
saving the latest model (epoch 185, total_steps 1883344)
(epoch: 185, iters: 8032, time: 0.157, data: 0.011) loss: 0.300 
(epoch: 185, iters: 8112, time: 0.156, data: 0.000) loss: 0.484 
(epoch: 185, iters: 8192, time: 0.156, data: 0.000) loss: 0.273 
(epoch: 185, iters: 8272, time: 0.157, data: 0.005) loss: 0.049 
(epoch: 185, iters: 8352, time: 0.154, data: 0.000) loss: 0.068 
(epoch: 185, iters: 8432, time: 0.158, data: 0.040) loss: 0.105 
(epoch: 185, iters: 8512, time: 0.158, data: 0.000) loss: 0.196 
(epoch: 185, iters: 8592, time: 0.156, data: 0.027) loss: 0.186 
(epoch: 185, iters: 8672, time: 0.158, data: 0.000) loss: 0.202 
(epoch: 185, iters: 8752, time: 0.156, data: 0.005) loss: 0.164 
(epoch: 185, iters: 8832, time: 0.157, data: 0.000) loss: 0.305 
(epoch: 185, iters: 8912, time: 0.157, data: 0.031) loss: 0.099 
(epoch: 185, iters: 8992, time: 0.155, data: 0.000) loss: 0.355 
(epoch: 185, iters: 9072, time: 0.157, data: 0.000) loss: 0.421 
(epoch: 185, iters: 9152, time: 0.157, data: 0.000) loss: 0.303 
(epoch: 185, iters: 9232, time: 0.159, data: 0.005) loss: 0.347 
(epoch: 185, iters: 9312, time: 0.157, data: 0.006) loss: 0.346 
(epoch: 185, iters: 9392, time: 0.159, data: 0.000) loss: 0.175 
(epoch: 185, iters: 9472, time: 0.158, data: 0.000) loss: 0.378 
(epoch: 185, iters: 9552, time: 0.157, data: 0.000) loss: 0.105 
(epoch: 185, iters: 9632, time: 0.158, data: 0.000) loss: 0.166 
(epoch: 185, iters: 9712, time: 0.158, data: 0.011) loss: 0.453 
(epoch: 185, iters: 9792, time: 0.157, data: 0.000) loss: 0.103 
(epoch: 185, iters: 9872, time: 0.159, data: 0.008) loss: 0.153 
(epoch: 185, iters: 9952, time: 0.155, data: 0.005) loss: 0.161 
(epoch: 185, iters: 10032, time: 0.157, data: 0.033) loss: 0.202 
(epoch: 185, iters: 10112, time: 0.157, data: 0.000) loss: 0.126 
(epoch: 185, iters: 10192, time: 0.094, data: 0.000) loss: 0.545 
saving the model at the end of epoch 185, iters 1885520
End of epoch 185 / 200 	 Time Taken: 1599 sec
learning rate = 0.0000277
saving the latest model (epoch 186, total_steps 1885536)
(epoch: 186, iters: 80, time: 0.164, data: 0.191) loss: 0.222 
(epoch: 186, iters: 160, time: 0.162, data: 0.000) loss: 0.232 
(epoch: 186, iters: 240, time: 0.157, data: 0.006) loss: 0.190 
(epoch: 186, iters: 320, time: 0.157, data: 0.018) loss: 0.121 
(epoch: 186, iters: 400, time: 0.159, data: 0.021) loss: 0.196 
(epoch: 186, iters: 480, time: 0.160, data: 0.011) loss: 0.359 
(epoch: 186, iters: 560, time: 0.159, data: 0.000) loss: 0.104 
(epoch: 186, iters: 640, time: 0.157, data: 0.000) loss: 0.352 
(epoch: 186, iters: 720, time: 0.162, data: 0.005) loss: 0.116 
(epoch: 186, iters: 800, time: 0.160, data: 0.000) loss: 0.343 
(epoch: 186, iters: 880, time: 0.158, data: 0.000) loss: 0.221 
(epoch: 186, iters: 960, time: 0.160, data: 0.000) loss: 0.849 
(epoch: 186, iters: 1040, time: 0.159, data: 0.006) loss: 0.100 
(epoch: 186, iters: 1120, time: 0.159, data: 0.000) loss: 0.360 
(epoch: 186, iters: 1200, time: 0.160, data: 0.000) loss: 0.095 
(epoch: 186, iters: 1280, time: 0.160, data: 0.000) loss: 0.198 
(epoch: 186, iters: 1360, time: 0.158, data: 0.000) loss: 0.391 
(epoch: 186, iters: 1440, time: 0.158, data: 0.009) loss: 0.253 
(epoch: 186, iters: 1520, time: 0.162, data: 0.000) loss: 0.095 
(epoch: 186, iters: 1600, time: 0.158, data: 0.015) loss: 0.091 
(epoch: 186, iters: 1680, time: 0.160, data: 0.000) loss: 0.247 
(epoch: 186, iters: 1760, time: 0.160, data: 0.000) loss: 0.280 
(epoch: 186, iters: 1840, time: 0.159, data: 0.017) loss: 0.147 
(epoch: 186, iters: 1920, time: 0.159, data: 0.000) loss: 0.113 
(epoch: 186, iters: 2000, time: 0.159, data: 0.015) loss: 0.255 
(epoch: 186, iters: 2080, time: 0.160, data: 0.000) loss: 0.079 
(epoch: 186, iters: 2160, time: 0.159, data: 0.014) loss: 0.108 
(epoch: 186, iters: 2240, time: 0.160, data: 0.010) loss: 0.194 
(epoch: 186, iters: 2320, time: 0.159, data: 0.000) loss: 0.055 
(epoch: 186, iters: 2400, time: 0.161, data: 0.012) loss: 0.252 
(epoch: 186, iters: 2480, time: 0.161, data: 0.000) loss: 0.355 
(epoch: 186, iters: 2560, time: 0.160, data: 0.000) loss: 0.520 
(epoch: 186, iters: 2640, time: 0.158, data: 0.000) loss: 0.181 
(epoch: 186, iters: 2720, time: 0.157, data: 0.000) loss: 0.385 
(epoch: 186, iters: 2800, time: 0.162, data: 0.016) loss: 0.225 
(epoch: 186, iters: 2880, time: 0.160, data: 0.000) loss: 0.165 
(epoch: 186, iters: 2960, time: 0.159, data: 0.029) loss: 0.345 
(epoch: 186, iters: 3040, time: 0.162, data: 0.025) loss: 0.325 
(epoch: 186, iters: 3120, time: 0.159, data: 0.000) loss: 0.111 
(epoch: 186, iters: 3200, time: 0.163, data: 0.000) loss: 0.152 
(epoch: 186, iters: 3280, time: 0.160, data: 0.005) loss: 0.064 
(epoch: 186, iters: 3360, time: 0.159, data: 0.000) loss: 0.123 
(epoch: 186, iters: 3440, time: 0.168, data: 0.019) loss: 0.235 
(epoch: 186, iters: 3520, time: 0.160, data: 0.000) loss: 0.072 
(epoch: 186, iters: 3600, time: 0.160, data: 0.005) loss: 0.278 
(epoch: 186, iters: 3680, time: 0.161, data: 0.005) loss: 0.167 
(epoch: 186, iters: 3760, time: 0.160, data: 0.006) loss: 0.796 
(epoch: 186, iters: 3840, time: 0.160, data: 0.000) loss: 0.729 
(epoch: 186, iters: 3920, time: 0.159, data: 0.010) loss: 0.111 
(epoch: 186, iters: 4000, time: 0.159, data: 0.000) loss: 0.171 
saving the latest model (epoch 186, total_steps 1889536)
(epoch: 186, iters: 4080, time: 0.161, data: 0.008) loss: 0.184 
(epoch: 186, iters: 4160, time: 0.161, data: 0.000) loss: 0.112 
(epoch: 186, iters: 4240, time: 0.159, data: 0.014) loss: 0.028 
(epoch: 186, iters: 4320, time: 0.158, data: 0.014) loss: 0.339 
(epoch: 186, iters: 4400, time: 0.159, data: 0.005) loss: 0.145 
(epoch: 186, iters: 4480, time: 0.159, data: 0.005) loss: 0.080 
(epoch: 186, iters: 4560, time: 0.159, data: 0.000) loss: 0.308 
(epoch: 186, iters: 4640, time: 0.157, data: 0.000) loss: 0.556 
(epoch: 186, iters: 4720, time: 0.156, data: 0.022) loss: 0.191 
(epoch: 186, iters: 4800, time: 0.159, data: 0.008) loss: 0.577 
(epoch: 186, iters: 4880, time: 0.159, data: 0.000) loss: 0.399 
(epoch: 186, iters: 4960, time: 0.161, data: 0.008) loss: 0.116 
(epoch: 186, iters: 5040, time: 0.160, data: 0.000) loss: 0.159 
(epoch: 186, iters: 5120, time: 0.160, data: 0.000) loss: 0.167 
(epoch: 186, iters: 5200, time: 0.159, data: 0.000) loss: 0.184 
(epoch: 186, iters: 5280, time: 0.159, data: 0.008) loss: 0.149 
(epoch: 186, iters: 5360, time: 0.162, data: 0.000) loss: 0.165 
(epoch: 186, iters: 5440, time: 0.161, data: 0.016) loss: 0.789 
(epoch: 186, iters: 5520, time: 0.160, data: 0.000) loss: 0.166 
(epoch: 186, iters: 5600, time: 0.160, data: 0.000) loss: 0.170 
(epoch: 186, iters: 5680, time: 0.158, data: 0.008) loss: 0.183 
(epoch: 186, iters: 5760, time: 0.168, data: 0.000) loss: 0.064 
(epoch: 186, iters: 5840, time: 0.161, data: 0.018) loss: 0.463 
(epoch: 186, iters: 5920, time: 0.158, data: 0.008) loss: 0.363 
(epoch: 186, iters: 6000, time: 0.158, data: 0.005) loss: 0.324 
(epoch: 186, iters: 6080, time: 0.158, data: 0.000) loss: 0.269 
(epoch: 186, iters: 6160, time: 0.159, data: 0.000) loss: 0.258 
(epoch: 186, iters: 6240, time: 0.160, data: 0.021) loss: 0.147 
(epoch: 186, iters: 6320, time: 0.159, data: 0.000) loss: 0.142 
(epoch: 186, iters: 6400, time: 0.160, data: 0.011) loss: 0.151 
(epoch: 186, iters: 6480, time: 0.161, data: 0.000) loss: 0.226 
(epoch: 186, iters: 6560, time: 0.159, data: 0.010) loss: 0.166 
(epoch: 186, iters: 6640, time: 0.157, data: 0.020) loss: 0.307 
(epoch: 186, iters: 6720, time: 0.160, data: 0.009) loss: 0.111 
(epoch: 186, iters: 6800, time: 0.158, data: 0.000) loss: 1.015 
(epoch: 186, iters: 6880, time: 0.161, data: 0.031) loss: 0.575 
(epoch: 186, iters: 6960, time: 0.161, data: 0.000) loss: 0.044 
(epoch: 186, iters: 7040, time: 0.160, data: 0.028) loss: 0.043 
(epoch: 186, iters: 7120, time: 0.162, data: 0.000) loss: 0.244 
(epoch: 186, iters: 7200, time: 0.165, data: 0.000) loss: 0.079 
(epoch: 186, iters: 7280, time: 0.176, data: 0.000) loss: 0.236 
(epoch: 186, iters: 7360, time: 0.170, data: 0.022) loss: 0.178 
(epoch: 186, iters: 7440, time: 0.175, data: 0.000) loss: 0.050 
(epoch: 186, iters: 7520, time: 0.237, data: 0.000) loss: 0.083 
(epoch: 186, iters: 7600, time: 0.170, data: 0.004) loss: 0.102 
(epoch: 186, iters: 7680, time: 0.171, data: 0.000) loss: 0.205 
(epoch: 186, iters: 7760, time: 0.273, data: 0.021) loss: 0.153 
(epoch: 186, iters: 7840, time: 0.169, data: 0.008) loss: 0.080 
(epoch: 186, iters: 7920, time: 0.169, data: 0.000) loss: 0.118 
(epoch: 186, iters: 8000, time: 0.250, data: 0.025) loss: 0.170 
saving the latest model (epoch 186, total_steps 1893536)
(epoch: 186, iters: 8080, time: 0.271, data: 0.000) loss: 0.251 
(epoch: 186, iters: 8160, time: 0.169, data: 0.004) loss: 0.151 
(epoch: 186, iters: 8240, time: 0.171, data: 0.000) loss: 0.581 
(epoch: 186, iters: 8320, time: 0.172, data: 0.024) loss: 0.468 
(epoch: 186, iters: 8400, time: 0.198, data: 0.008) loss: 0.127 
(epoch: 186, iters: 8480, time: 0.161, data: 0.036) loss: 0.086 
(epoch: 186, iters: 8560, time: 0.158, data: 0.000) loss: 0.307 
(epoch: 186, iters: 8640, time: 0.159, data: 0.000) loss: 0.297 
(epoch: 186, iters: 8720, time: 0.157, data: 0.000) loss: 0.195 
(epoch: 186, iters: 8800, time: 0.158, data: 0.023) loss: 0.166 
(epoch: 186, iters: 8880, time: 0.158, data: 0.013) loss: 0.212 
(epoch: 186, iters: 8960, time: 0.156, data: 0.000) loss: 0.014 
(epoch: 186, iters: 9040, time: 0.158, data: 0.000) loss: 0.070 
(epoch: 186, iters: 9120, time: 0.156, data: 0.021) loss: 0.565 
(epoch: 186, iters: 9200, time: 0.158, data: 0.000) loss: 0.512 
(epoch: 186, iters: 9280, time: 0.157, data: 0.000) loss: 0.350 
(epoch: 186, iters: 9360, time: 0.158, data: 0.008) loss: 0.180 
(epoch: 186, iters: 9440, time: 0.156, data: 0.000) loss: 0.398 
(epoch: 186, iters: 9520, time: 0.160, data: 0.000) loss: 0.218 
(epoch: 186, iters: 9600, time: 0.158, data: 0.000) loss: 0.078 
(epoch: 186, iters: 9680, time: 0.159, data: 0.000) loss: 0.085 
(epoch: 186, iters: 9760, time: 0.161, data: 0.000) loss: 0.155 
(epoch: 186, iters: 9840, time: 0.159, data: 0.015) loss: 0.303 
(epoch: 186, iters: 9920, time: 0.157, data: 0.000) loss: 0.168 
(epoch: 186, iters: 10000, time: 0.158, data: 0.017) loss: 0.131 
(epoch: 186, iters: 10080, time: 0.158, data: 0.006) loss: 0.114 
(epoch: 186, iters: 10160, time: 0.158, data: 0.000) loss: 0.256 
saving the model at the end of epoch 186, iters 1895712
End of epoch 186 / 200 	 Time Taken: 1665 sec
learning rate = 0.0000257
saving the latest model (epoch 187, total_steps 1895728)
(epoch: 187, iters: 48, time: 0.162, data: 0.005) loss: 0.265 
(epoch: 187, iters: 128, time: 0.158, data: 0.025) loss: 0.379 
(epoch: 187, iters: 208, time: 0.162, data: 0.000) loss: 0.508 
(epoch: 187, iters: 288, time: 0.159, data: 0.006) loss: 0.150 
(epoch: 187, iters: 368, time: 0.159, data: 0.000) loss: 0.317 
(epoch: 187, iters: 448, time: 0.158, data: 0.000) loss: 0.373 
(epoch: 187, iters: 528, time: 0.155, data: 0.026) loss: 0.381 
(epoch: 187, iters: 608, time: 0.160, data: 0.000) loss: 0.230 
(epoch: 187, iters: 688, time: 0.159, data: 0.000) loss: 0.286 
(epoch: 187, iters: 768, time: 0.157, data: 0.000) loss: 0.270 
(epoch: 187, iters: 848, time: 0.156, data: 0.005) loss: 0.088 
(epoch: 187, iters: 928, time: 0.162, data: 0.000) loss: 0.073 
(epoch: 187, iters: 1008, time: 0.156, data: 0.000) loss: 0.127 
(epoch: 187, iters: 1088, time: 0.156, data: 0.000) loss: 0.650 
(epoch: 187, iters: 1168, time: 0.157, data: 0.018) loss: 0.288 
(epoch: 187, iters: 1248, time: 0.183, data: 0.025) loss: 0.306 
(epoch: 187, iters: 1328, time: 0.296, data: 0.000) loss: 0.103 
(epoch: 187, iters: 1408, time: 0.189, data: 0.000) loss: 0.190 
(epoch: 187, iters: 1488, time: 0.163, data: 0.010) loss: 0.340 
(epoch: 187, iters: 1568, time: 0.162, data: 0.000) loss: 0.143 
(epoch: 187, iters: 1648, time: 0.163, data: 0.000) loss: 0.351 
(epoch: 187, iters: 1728, time: 0.163, data: 0.004) loss: 0.504 
(epoch: 187, iters: 1808, time: 0.162, data: 0.000) loss: 0.190 
(epoch: 187, iters: 1888, time: 0.162, data: 0.016) loss: 0.087 
(epoch: 187, iters: 1968, time: 0.162, data: 0.000) loss: 0.099 
(epoch: 187, iters: 2048, time: 0.163, data: 0.024) loss: 0.244 
(epoch: 187, iters: 2128, time: 0.163, data: 0.000) loss: 0.288 
(epoch: 187, iters: 2208, time: 0.162, data: 0.010) loss: 0.269 
(epoch: 187, iters: 2288, time: 0.161, data: 0.000) loss: 0.083 
(epoch: 187, iters: 2368, time: 0.161, data: 0.012) loss: 0.322 
(epoch: 187, iters: 2448, time: 0.162, data: 0.029) loss: 0.221 
(epoch: 187, iters: 2528, time: 0.163, data: 0.005) loss: 0.334 
(epoch: 187, iters: 2608, time: 0.163, data: 0.000) loss: 0.199 
(epoch: 187, iters: 2688, time: 0.164, data: 0.000) loss: 0.213 
(epoch: 187, iters: 2768, time: 0.163, data: 0.006) loss: 0.237 
(epoch: 187, iters: 2848, time: 0.162, data: 0.006) loss: 0.112 
(epoch: 187, iters: 2928, time: 0.162, data: 0.000) loss: 0.209 
(epoch: 187, iters: 3008, time: 0.162, data: 0.008) loss: 0.290 
(epoch: 187, iters: 3088, time: 0.163, data: 0.000) loss: 0.324 
(epoch: 187, iters: 3168, time: 0.173, data: 0.005) loss: 0.123 
(epoch: 187, iters: 3248, time: 0.165, data: 0.000) loss: 0.190 
(epoch: 187, iters: 3328, time: 0.162, data: 0.009) loss: 0.067 
(epoch: 187, iters: 3408, time: 0.169, data: 0.000) loss: 0.063 
(epoch: 187, iters: 3488, time: 0.284, data: 0.008) loss: 0.398 
(epoch: 187, iters: 3568, time: 0.204, data: 0.000) loss: 0.248 
(epoch: 187, iters: 3648, time: 0.199, data: 0.000) loss: 0.112 
(epoch: 187, iters: 3728, time: 0.170, data: 0.016) loss: 0.574 
(epoch: 187, iters: 3808, time: 0.172, data: 0.000) loss: 0.055 
(epoch: 187, iters: 3888, time: 0.234, data: 0.017) loss: 0.295 
(epoch: 187, iters: 3968, time: 0.204, data: 0.000) loss: 0.160 
saving the latest model (epoch 187, total_steps 1899728)
(epoch: 187, iters: 4048, time: 0.169, data: 0.015) loss: 0.286 
(epoch: 187, iters: 4128, time: 0.174, data: 0.000) loss: 0.150 
(epoch: 187, iters: 4208, time: 0.171, data: 0.000) loss: 0.379 
(epoch: 187, iters: 4288, time: 0.172, data: 0.016) loss: 0.176 
(epoch: 187, iters: 4368, time: 0.243, data: 0.025) loss: 0.120 
(epoch: 187, iters: 4448, time: 0.171, data: 0.013) loss: 0.302 
(epoch: 187, iters: 4528, time: 0.172, data: 0.035) loss: 0.241 
(epoch: 187, iters: 4608, time: 0.200, data: 0.000) loss: 0.038 
(epoch: 187, iters: 4688, time: 0.172, data: 0.017) loss: 0.134 
(epoch: 187, iters: 4768, time: 0.160, data: 0.000) loss: 0.076 
(epoch: 187, iters: 4848, time: 0.164, data: 0.000) loss: 0.326 
(epoch: 187, iters: 4928, time: 0.158, data: 0.005) loss: 0.393 
(epoch: 187, iters: 5008, time: 0.158, data: 0.000) loss: 0.179 
(epoch: 187, iters: 5088, time: 0.159, data: 0.013) loss: 0.212 
(epoch: 187, iters: 5168, time: 0.159, data: 0.000) loss: 0.158 
(epoch: 187, iters: 5248, time: 0.165, data: 0.014) loss: 0.147 
(epoch: 187, iters: 5328, time: 0.157, data: 0.006) loss: 0.101 
(epoch: 187, iters: 5408, time: 0.161, data: 0.000) loss: 0.507 
(epoch: 187, iters: 5488, time: 0.160, data: 0.005) loss: 0.036 
(epoch: 187, iters: 5568, time: 0.158, data: 0.000) loss: 0.073 
(epoch: 187, iters: 5648, time: 0.160, data: 0.000) loss: 0.321 
(epoch: 187, iters: 5728, time: 0.161, data: 0.005) loss: 0.146 
(epoch: 187, iters: 5808, time: 0.158, data: 0.009) loss: 0.083 
(epoch: 187, iters: 5888, time: 0.159, data: 0.005) loss: 0.196 
(epoch: 187, iters: 5968, time: 0.159, data: 0.000) loss: 0.375 
(epoch: 187, iters: 6048, time: 0.160, data: 0.008) loss: 0.399 
(epoch: 187, iters: 6128, time: 0.159, data: 0.000) loss: 0.382 
(epoch: 187, iters: 6208, time: 0.159, data: 0.021) loss: 0.208 
(epoch: 187, iters: 6288, time: 0.163, data: 0.021) loss: 0.126 
(epoch: 187, iters: 6368, time: 0.159, data: 0.000) loss: 0.243 
(epoch: 187, iters: 6448, time: 0.159, data: 0.005) loss: 0.191 
(epoch: 187, iters: 6528, time: 0.162, data: 0.000) loss: 0.403 
(epoch: 187, iters: 6608, time: 0.161, data: 0.000) loss: 0.107 
(epoch: 187, iters: 6688, time: 0.162, data: 0.033) loss: 1.232 
(epoch: 187, iters: 6768, time: 0.159, data: 0.000) loss: 0.300 
(epoch: 187, iters: 6848, time: 0.160, data: 0.019) loss: 0.080 
(epoch: 187, iters: 6928, time: 0.158, data: 0.000) loss: 0.150 
(epoch: 187, iters: 7008, time: 0.159, data: 0.000) loss: 0.375 
(epoch: 187, iters: 7088, time: 0.162, data: 0.005) loss: 0.208 
(epoch: 187, iters: 7168, time: 0.159, data: 0.016) loss: 0.126 
(epoch: 187, iters: 7248, time: 0.159, data: 0.029) loss: 0.049 
(epoch: 187, iters: 7328, time: 0.161, data: 0.000) loss: 0.071 
(epoch: 187, iters: 7408, time: 0.159, data: 0.016) loss: 0.445 
(epoch: 187, iters: 7488, time: 0.159, data: 0.000) loss: 0.463 
(epoch: 187, iters: 7568, time: 0.166, data: 0.015) loss: 0.164 
(epoch: 187, iters: 7648, time: 0.158, data: 0.016) loss: 0.194 
(epoch: 187, iters: 7728, time: 0.158, data: 0.000) loss: 0.273 
(epoch: 187, iters: 7808, time: 0.160, data: 0.000) loss: 0.141 
(epoch: 187, iters: 7888, time: 0.158, data: 0.000) loss: 0.198 
(epoch: 187, iters: 7968, time: 0.159, data: 0.020) loss: 0.152 
saving the latest model (epoch 187, total_steps 1903728)
(epoch: 187, iters: 8048, time: 0.159, data: 0.000) loss: 0.299 
(epoch: 187, iters: 8128, time: 0.158, data: 0.011) loss: 0.262 
(epoch: 187, iters: 8208, time: 0.160, data: 0.006) loss: 0.243 
(epoch: 187, iters: 8288, time: 0.160, data: 0.000) loss: 0.330 
(epoch: 187, iters: 8368, time: 0.159, data: 0.000) loss: 0.203 
(epoch: 187, iters: 8448, time: 0.160, data: 0.000) loss: 0.100 
(epoch: 187, iters: 8528, time: 0.161, data: 0.012) loss: 0.308 
(epoch: 187, iters: 8608, time: 0.160, data: 0.000) loss: 0.689 
(epoch: 187, iters: 8688, time: 0.160, data: 0.000) loss: 0.303 
(epoch: 187, iters: 8768, time: 0.158, data: 0.005) loss: 0.106 
(epoch: 187, iters: 8848, time: 0.160, data: 0.000) loss: 0.665 
(epoch: 187, iters: 8928, time: 0.159, data: 0.017) loss: 0.077 
(epoch: 187, iters: 9008, time: 0.159, data: 0.005) loss: 0.216 
(epoch: 187, iters: 9088, time: 0.176, data: 0.016) loss: 0.205 
(epoch: 187, iters: 9168, time: 0.204, data: 0.000) loss: 0.046 
(epoch: 187, iters: 9248, time: 0.175, data: 0.000) loss: 0.143 
(epoch: 187, iters: 9328, time: 0.160, data: 0.017) loss: 0.424 
(epoch: 187, iters: 9408, time: 0.159, data: 0.006) loss: 0.337 
(epoch: 187, iters: 9488, time: 0.166, data: 0.032) loss: 0.148 
(epoch: 187, iters: 9568, time: 0.161, data: 0.000) loss: 0.322 
(epoch: 187, iters: 9648, time: 0.161, data: 0.000) loss: 0.207 
(epoch: 187, iters: 9728, time: 0.161, data: 0.000) loss: 1.029 
(epoch: 187, iters: 9808, time: 0.161, data: 0.018) loss: 0.274 
(epoch: 187, iters: 9888, time: 0.158, data: 0.000) loss: 0.061 
(epoch: 187, iters: 9968, time: 0.157, data: 0.022) loss: 0.126 
(epoch: 187, iters: 10048, time: 0.159, data: 0.005) loss: 0.206 
(epoch: 187, iters: 10128, time: 0.201, data: 0.000) loss: 0.292 
saving the model at the end of epoch 187, iters 1905904
End of epoch 187 / 200 	 Time Taken: 1689 sec
learning rate = 0.0000238
(epoch: 188, iters: 16, time: 0.223, data: 0.016) loss: 1.175 
saving the latest model (epoch 188, total_steps 1905920)
(epoch: 188, iters: 96, time: 0.172, data: 0.000) loss: 0.268 
(epoch: 188, iters: 176, time: 0.159, data: 0.000) loss: 0.120 
(epoch: 188, iters: 256, time: 0.160, data: 0.000) loss: 0.204 
(epoch: 188, iters: 336, time: 0.159, data: 0.006) loss: 0.178 
(epoch: 188, iters: 416, time: 0.168, data: 0.012) loss: 0.280 
(epoch: 188, iters: 496, time: 0.163, data: 0.000) loss: 0.197 
(epoch: 188, iters: 576, time: 0.174, data: 0.017) loss: 0.175 
(epoch: 188, iters: 656, time: 0.174, data: 0.000) loss: 0.639 
(epoch: 188, iters: 736, time: 0.178, data: 0.027) loss: 0.238 
(epoch: 188, iters: 816, time: 0.175, data: 0.000) loss: 0.242 
(epoch: 188, iters: 896, time: 0.200, data: 0.009) loss: 0.294 
(epoch: 188, iters: 976, time: 0.169, data: 0.000) loss: 0.342 
(epoch: 188, iters: 1056, time: 0.171, data: 0.021) loss: 0.213 
(epoch: 188, iters: 1136, time: 0.200, data: 0.008) loss: 0.111 
(epoch: 188, iters: 1216, time: 0.170, data: 0.000) loss: 0.217 
(epoch: 188, iters: 1296, time: 0.169, data: 0.009) loss: 0.272 
(epoch: 188, iters: 1376, time: 0.169, data: 0.000) loss: 0.368 
(epoch: 188, iters: 1456, time: 0.166, data: 0.025) loss: 0.285 
(epoch: 188, iters: 1536, time: 0.172, data: 0.000) loss: 0.361 
(epoch: 188, iters: 1616, time: 0.173, data: 0.022) loss: 0.286 
(epoch: 188, iters: 1696, time: 0.168, data: 0.008) loss: 0.066 
(epoch: 188, iters: 1776, time: 0.173, data: 0.000) loss: 0.126 
(epoch: 188, iters: 1856, time: 0.173, data: 0.000) loss: 0.190 
(epoch: 188, iters: 1936, time: 0.168, data: 0.008) loss: 0.361 
(epoch: 188, iters: 2016, time: 0.172, data: 0.000) loss: 0.179 
(epoch: 188, iters: 2096, time: 0.171, data: 0.011) loss: 0.216 
(epoch: 188, iters: 2176, time: 0.174, data: 0.008) loss: 0.107 
(epoch: 188, iters: 2256, time: 0.170, data: 0.000) loss: 0.165 
(epoch: 188, iters: 2336, time: 0.171, data: 0.009) loss: 0.437 
(epoch: 188, iters: 2416, time: 0.170, data: 0.009) loss: 0.649 
(epoch: 188, iters: 2496, time: 0.166, data: 0.000) loss: 0.046 
(epoch: 188, iters: 2576, time: 0.196, data: 0.024) loss: 0.223 
(epoch: 188, iters: 2656, time: 0.196, data: 0.021) loss: 0.062 
(epoch: 188, iters: 2736, time: 0.197, data: 0.000) loss: 0.143 
(epoch: 188, iters: 2816, time: 0.197, data: 0.000) loss: 0.122 
(epoch: 188, iters: 2896, time: 0.167, data: 0.021) loss: 0.239 
(epoch: 188, iters: 2976, time: 0.166, data: 0.000) loss: 0.232 
(epoch: 188, iters: 3056, time: 0.168, data: 0.000) loss: 0.089 
(epoch: 188, iters: 3136, time: 0.168, data: 0.008) loss: 0.186 
(epoch: 188, iters: 3216, time: 0.170, data: 0.000) loss: 0.024 
(epoch: 188, iters: 3296, time: 0.198, data: 0.009) loss: 0.080 
(epoch: 188, iters: 3376, time: 0.167, data: 0.026) loss: 0.227 
(epoch: 188, iters: 3456, time: 0.172, data: 0.000) loss: 0.175 
(epoch: 188, iters: 3536, time: 0.195, data: 0.005) loss: 0.286 
(epoch: 188, iters: 3616, time: 0.173, data: 0.000) loss: 0.104 
(epoch: 188, iters: 3696, time: 0.169, data: 0.008) loss: 0.488 
(epoch: 188, iters: 3776, time: 0.168, data: 0.000) loss: 0.038 
(epoch: 188, iters: 3856, time: 0.169, data: 0.025) loss: 0.081 
(epoch: 188, iters: 3936, time: 0.195, data: 0.021) loss: 0.309 
(epoch: 188, iters: 4016, time: 0.171, data: 0.009) loss: 0.535 
saving the latest model (epoch 188, total_steps 1909920)
(epoch: 188, iters: 4096, time: 0.165, data: 0.008) loss: 0.087 
(epoch: 188, iters: 4176, time: 0.168, data: 0.009) loss: 0.444 
(epoch: 188, iters: 4256, time: 0.164, data: 0.000) loss: 0.153 
(epoch: 188, iters: 4336, time: 0.172, data: 0.000) loss: 0.145 
(epoch: 188, iters: 4416, time: 0.169, data: 0.000) loss: 0.283 
(epoch: 188, iters: 4496, time: 0.170, data: 0.008) loss: 0.274 
(epoch: 188, iters: 4576, time: 0.171, data: 0.000) loss: 0.421 
(epoch: 188, iters: 4656, time: 0.168, data: 0.000) loss: 0.343 
(epoch: 188, iters: 4736, time: 0.168, data: 0.008) loss: 0.295 
(epoch: 188, iters: 4816, time: 0.166, data: 0.000) loss: 0.197 
(epoch: 188, iters: 4896, time: 0.168, data: 0.009) loss: 0.342 
(epoch: 188, iters: 4976, time: 0.168, data: 0.000) loss: 0.052 
(epoch: 188, iters: 5056, time: 0.176, data: 0.009) loss: 0.236 
(epoch: 188, iters: 5136, time: 0.197, data: 0.008) loss: 0.044 
(epoch: 188, iters: 5216, time: 0.172, data: 0.000) loss: 0.131 
(epoch: 188, iters: 5296, time: 0.171, data: 0.039) loss: 0.160 
(epoch: 188, iters: 5376, time: 0.173, data: 0.000) loss: 0.375 
(epoch: 188, iters: 5456, time: 0.172, data: 0.000) loss: 0.175 
(epoch: 188, iters: 5536, time: 0.169, data: 0.008) loss: 0.167 
(epoch: 188, iters: 5616, time: 0.171, data: 0.000) loss: 0.103 
(epoch: 188, iters: 5696, time: 0.169, data: 0.000) loss: 0.349 
(epoch: 188, iters: 5776, time: 0.176, data: 0.017) loss: 0.105 
(epoch: 188, iters: 5856, time: 0.167, data: 0.009) loss: 0.362 
(epoch: 188, iters: 5936, time: 0.166, data: 0.000) loss: 0.220 
(epoch: 188, iters: 6016, time: 0.171, data: 0.009) loss: 0.124 
(epoch: 188, iters: 6096, time: 0.200, data: 0.000) loss: 0.279 
(epoch: 188, iters: 6176, time: 0.169, data: 0.000) loss: 0.319 
(epoch: 188, iters: 6256, time: 0.170, data: 0.000) loss: 0.124 
(epoch: 188, iters: 6336, time: 0.173, data: 0.008) loss: 0.108 
(epoch: 188, iters: 6416, time: 0.176, data: 0.000) loss: 0.150 
(epoch: 188, iters: 6496, time: 0.174, data: 0.000) loss: 0.274 
(epoch: 188, iters: 6576, time: 0.171, data: 0.008) loss: 0.586 
(epoch: 188, iters: 6656, time: 0.175, data: 0.000) loss: 0.107 
(epoch: 188, iters: 6736, time: 0.172, data: 0.000) loss: 0.205 
(epoch: 188, iters: 6816, time: 0.197, data: 0.000) loss: 0.139 
(epoch: 188, iters: 6896, time: 0.200, data: 0.000) loss: 0.161 
(epoch: 188, iters: 6976, time: 0.170, data: 0.000) loss: 0.119 
(epoch: 188, iters: 7056, time: 0.170, data: 0.009) loss: 0.104 
(epoch: 188, iters: 7136, time: 0.168, data: 0.009) loss: 0.229 
(epoch: 188, iters: 7216, time: 0.169, data: 0.020) loss: 0.202 
(epoch: 188, iters: 7296, time: 0.195, data: 0.000) loss: 0.309 
(epoch: 188, iters: 7376, time: 0.174, data: 0.000) loss: 0.140 
(epoch: 188, iters: 7456, time: 0.168, data: 0.024) loss: 0.555 
(epoch: 188, iters: 7536, time: 0.169, data: 0.009) loss: 0.198 
(epoch: 188, iters: 7616, time: 0.171, data: 0.000) loss: 0.069 
(epoch: 188, iters: 7696, time: 0.164, data: 0.008) loss: 0.106 
(epoch: 188, iters: 7776, time: 0.167, data: 0.000) loss: 0.206 
(epoch: 188, iters: 7856, time: 0.167, data: 0.000) loss: 0.445 
(epoch: 188, iters: 7936, time: 0.172, data: 0.035) loss: 0.659 
(epoch: 188, iters: 8016, time: 0.166, data: 0.000) loss: 0.504 
saving the latest model (epoch 188, total_steps 1913920)
(epoch: 188, iters: 8096, time: 0.168, data: 0.000) loss: 0.086 
(epoch: 188, iters: 8176, time: 0.165, data: 0.000) loss: 0.362 
(epoch: 188, iters: 8256, time: 0.167, data: 0.000) loss: 0.038 
(epoch: 188, iters: 8336, time: 0.169, data: 0.000) loss: 0.248 
(epoch: 188, iters: 8416, time: 0.169, data: 0.041) loss: 0.080 
(epoch: 188, iters: 8496, time: 0.199, data: 0.000) loss: 0.048 
(epoch: 188, iters: 8576, time: 0.196, data: 0.000) loss: 0.370 
(epoch: 188, iters: 8656, time: 0.168, data: 0.006) loss: 0.399 
(epoch: 188, iters: 8736, time: 0.170, data: 0.016) loss: 0.069 
(epoch: 188, iters: 8816, time: 0.167, data: 0.000) loss: 0.434 
(epoch: 188, iters: 8896, time: 0.170, data: 0.000) loss: 0.524 
(epoch: 188, iters: 8976, time: 0.200, data: 0.000) loss: 0.102 
(epoch: 188, iters: 9056, time: 0.173, data: 0.008) loss: 0.334 
(epoch: 188, iters: 9136, time: 0.172, data: 0.000) loss: 0.031 
(epoch: 188, iters: 9216, time: 0.200, data: 0.000) loss: 0.145 
(epoch: 188, iters: 9296, time: 0.203, data: 0.019) loss: 0.190 
(epoch: 188, iters: 9376, time: 0.173, data: 0.000) loss: 0.160 
(epoch: 188, iters: 9456, time: 0.168, data: 0.000) loss: 0.339 
(epoch: 188, iters: 9536, time: 0.171, data: 0.000) loss: 0.162 
(epoch: 188, iters: 9616, time: 0.169, data: 0.034) loss: 0.032 
(epoch: 188, iters: 9696, time: 0.172, data: 0.000) loss: 0.100 
(epoch: 188, iters: 9776, time: 0.167, data: 0.009) loss: 0.061 
(epoch: 188, iters: 9856, time: 0.167, data: 0.000) loss: 0.071 
(epoch: 188, iters: 9936, time: 0.178, data: 0.009) loss: 0.142 
(epoch: 188, iters: 10016, time: 0.173, data: 0.000) loss: 0.201 
(epoch: 188, iters: 10096, time: 0.168, data: 0.000) loss: 0.088 
(epoch: 188, iters: 10176, time: 0.168, data: 0.017) loss: 0.240 
saving the model at the end of epoch 188, iters 1916096
End of epoch 188 / 200 	 Time Taken: 1771 sec
learning rate = 0.0000218
saving the latest model (epoch 189, total_steps 1916112)
(epoch: 189, iters: 64, time: 0.176, data: 0.004) loss: 0.086 
(epoch: 189, iters: 144, time: 0.174, data: 0.019) loss: 0.082 
(epoch: 189, iters: 224, time: 0.178, data: 0.009) loss: 0.215 
(epoch: 189, iters: 304, time: 0.172, data: 0.000) loss: 0.039 
(epoch: 189, iters: 384, time: 0.176, data: 0.033) loss: 0.176 
(epoch: 189, iters: 464, time: 0.171, data: 0.000) loss: 0.287 
(epoch: 189, iters: 544, time: 0.175, data: 0.008) loss: 0.561 
(epoch: 189, iters: 624, time: 0.200, data: 0.000) loss: 0.207 
(epoch: 189, iters: 704, time: 0.169, data: 0.019) loss: 0.240 
(epoch: 189, iters: 784, time: 0.172, data: 0.021) loss: 0.188 
(epoch: 189, iters: 864, time: 0.201, data: 0.000) loss: 0.519 
(epoch: 189, iters: 944, time: 0.173, data: 0.022) loss: 0.201 
(epoch: 189, iters: 1024, time: 0.175, data: 0.000) loss: 0.102 
(epoch: 189, iters: 1104, time: 0.175, data: 0.022) loss: 0.293 
(epoch: 189, iters: 1184, time: 0.172, data: 0.009) loss: 0.075 
(epoch: 189, iters: 1264, time: 0.171, data: 0.009) loss: 0.347 
(epoch: 189, iters: 1344, time: 0.167, data: 0.021) loss: 0.204 
(epoch: 189, iters: 1424, time: 0.170, data: 0.025) loss: 0.199 
(epoch: 189, iters: 1504, time: 0.168, data: 0.008) loss: 0.700 
(epoch: 189, iters: 1584, time: 0.170, data: 0.009) loss: 0.182 
(epoch: 189, iters: 1664, time: 0.166, data: 0.021) loss: 0.278 
(epoch: 189, iters: 1744, time: 0.173, data: 0.021) loss: 0.222 
(epoch: 189, iters: 1824, time: 0.170, data: 0.025) loss: 0.245 
(epoch: 189, iters: 1904, time: 0.166, data: 0.000) loss: 0.320 
(epoch: 189, iters: 1984, time: 0.170, data: 0.008) loss: 0.389 
(epoch: 189, iters: 2064, time: 0.171, data: 0.000) loss: 0.190 
(epoch: 189, iters: 2144, time: 0.173, data: 0.000) loss: 0.458 
(epoch: 189, iters: 2224, time: 0.169, data: 0.000) loss: 0.124 
(epoch: 189, iters: 2304, time: 0.171, data: 0.000) loss: 0.277 
(epoch: 189, iters: 2384, time: 0.170, data: 0.029) loss: 0.264 
(epoch: 189, iters: 2464, time: 0.173, data: 0.016) loss: 0.198 
(epoch: 189, iters: 2544, time: 0.173, data: 0.009) loss: 0.216 
(epoch: 189, iters: 2624, time: 0.171, data: 0.000) loss: 0.189 
(epoch: 189, iters: 2704, time: 0.175, data: 0.009) loss: 0.273 
(epoch: 189, iters: 2784, time: 0.198, data: 0.000) loss: 0.087 
(epoch: 189, iters: 2864, time: 0.166, data: 0.000) loss: 0.347 
(epoch: 189, iters: 2944, time: 0.168, data: 0.033) loss: 0.294 
(epoch: 189, iters: 3024, time: 0.171, data: 0.000) loss: 0.204 
(epoch: 189, iters: 3104, time: 0.198, data: 0.009) loss: 0.059 
(epoch: 189, iters: 3184, time: 0.172, data: 0.000) loss: 0.092 
(epoch: 189, iters: 3264, time: 0.167, data: 0.000) loss: 0.170 
(epoch: 189, iters: 3344, time: 0.173, data: 0.008) loss: 0.463 
(epoch: 189, iters: 3424, time: 0.201, data: 0.000) loss: 0.241 
(epoch: 189, iters: 3504, time: 0.168, data: 0.009) loss: 0.409 
(epoch: 189, iters: 3584, time: 0.169, data: 0.008) loss: 0.505 
(epoch: 189, iters: 3664, time: 0.173, data: 0.000) loss: 0.130 
(epoch: 189, iters: 3744, time: 0.171, data: 0.009) loss: 0.418 
(epoch: 189, iters: 3824, time: 0.172, data: 0.000) loss: 0.126 
(epoch: 189, iters: 3904, time: 0.169, data: 0.009) loss: 0.065 
(epoch: 189, iters: 3984, time: 0.170, data: 0.000) loss: 0.118 
saving the latest model (epoch 189, total_steps 1920112)
(epoch: 189, iters: 4064, time: 0.169, data: 0.028) loss: 0.130 
(epoch: 189, iters: 4144, time: 0.171, data: 0.022) loss: 0.201 
(epoch: 189, iters: 4224, time: 0.198, data: 0.008) loss: 0.301 
(epoch: 189, iters: 4304, time: 0.170, data: 0.026) loss: 0.564 
(epoch: 189, iters: 4384, time: 0.170, data: 0.000) loss: 0.324 
(epoch: 189, iters: 4464, time: 0.173, data: 0.014) loss: 0.402 
(epoch: 189, iters: 4544, time: 0.194, data: 0.034) loss: 0.255 
(epoch: 189, iters: 4624, time: 0.170, data: 0.000) loss: 0.244 
(epoch: 189, iters: 4704, time: 0.172, data: 0.000) loss: 0.244 
(epoch: 189, iters: 4784, time: 0.172, data: 0.000) loss: 0.345 
(epoch: 189, iters: 4864, time: 0.201, data: 0.017) loss: 0.083 
(epoch: 189, iters: 4944, time: 0.174, data: 0.000) loss: 0.386 
(epoch: 189, iters: 5024, time: 0.168, data: 0.000) loss: 0.576 
(epoch: 189, iters: 5104, time: 0.174, data: 0.026) loss: 0.441 
(epoch: 189, iters: 5184, time: 0.168, data: 0.000) loss: 0.142 
(epoch: 189, iters: 5264, time: 0.172, data: 0.008) loss: 0.109 
(epoch: 189, iters: 5344, time: 0.201, data: 0.000) loss: 0.156 
(epoch: 189, iters: 5424, time: 0.173, data: 0.000) loss: 0.049 
(epoch: 189, iters: 5504, time: 0.169, data: 0.000) loss: 0.057 
(epoch: 189, iters: 5584, time: 0.172, data: 0.000) loss: 0.109 
(epoch: 189, iters: 5664, time: 0.200, data: 0.020) loss: 0.092 
(epoch: 189, iters: 5744, time: 0.172, data: 0.009) loss: 0.429 
(epoch: 189, iters: 5824, time: 0.200, data: 0.009) loss: 0.293 
(epoch: 189, iters: 5904, time: 0.173, data: 0.000) loss: 0.272 
(epoch: 189, iters: 5984, time: 0.173, data: 0.008) loss: 0.136 
(epoch: 189, iters: 6064, time: 0.168, data: 0.009) loss: 0.112 
(epoch: 189, iters: 6144, time: 0.169, data: 0.000) loss: 0.243 
(epoch: 189, iters: 6224, time: 0.167, data: 0.000) loss: 0.264 
(epoch: 189, iters: 6304, time: 0.168, data: 0.000) loss: 0.215 
(epoch: 189, iters: 6384, time: 0.167, data: 0.043) loss: 0.307 
(epoch: 189, iters: 6464, time: 0.170, data: 0.000) loss: 0.232 
(epoch: 189, iters: 6544, time: 0.199, data: 0.000) loss: 0.193 
(epoch: 189, iters: 6624, time: 0.200, data: 0.047) loss: 0.294 
(epoch: 189, iters: 6704, time: 0.172, data: 0.000) loss: 0.085 
(epoch: 189, iters: 6784, time: 0.173, data: 0.009) loss: 0.186 
(epoch: 189, iters: 6864, time: 0.198, data: 0.000) loss: 0.508 
(epoch: 189, iters: 6944, time: 0.166, data: 0.000) loss: 0.418 
(epoch: 189, iters: 7024, time: 0.198, data: 0.000) loss: 0.207 
(epoch: 189, iters: 7104, time: 0.165, data: 0.026) loss: 0.120 
(epoch: 189, iters: 7184, time: 0.168, data: 0.000) loss: 0.296 
(epoch: 189, iters: 7264, time: 0.169, data: 0.009) loss: 0.079 
(epoch: 189, iters: 7344, time: 0.169, data: 0.000) loss: 0.205 
(epoch: 189, iters: 7424, time: 0.167, data: 0.019) loss: 0.465 
(epoch: 189, iters: 7504, time: 0.170, data: 0.034) loss: 0.147 
(epoch: 189, iters: 7584, time: 0.173, data: 0.000) loss: 0.336 
(epoch: 189, iters: 7664, time: 0.173, data: 0.009) loss: 0.307 
(epoch: 189, iters: 7744, time: 0.166, data: 0.026) loss: 0.041 
(epoch: 189, iters: 7824, time: 0.169, data: 0.000) loss: 0.402 
(epoch: 189, iters: 7904, time: 0.168, data: 0.009) loss: 0.231 
(epoch: 189, iters: 7984, time: 0.167, data: 0.000) loss: 0.198 
saving the latest model (epoch 189, total_steps 1924112)
(epoch: 189, iters: 8064, time: 0.167, data: 0.026) loss: 0.087 
(epoch: 189, iters: 8144, time: 0.167, data: 0.000) loss: 0.272 
(epoch: 189, iters: 8224, time: 0.167, data: 0.009) loss: 0.184 
(epoch: 189, iters: 8304, time: 0.168, data: 0.000) loss: 0.222 
(epoch: 189, iters: 8384, time: 0.162, data: 0.025) loss: 0.180 
(epoch: 189, iters: 8464, time: 0.166, data: 0.000) loss: 0.534 
(epoch: 189, iters: 8544, time: 0.165, data: 0.009) loss: 0.157 
(epoch: 189, iters: 8624, time: 0.168, data: 0.000) loss: 0.106 
(epoch: 189, iters: 8704, time: 0.166, data: 0.000) loss: 0.051 
(epoch: 189, iters: 8784, time: 0.166, data: 0.024) loss: 0.329 
(epoch: 189, iters: 8864, time: 0.167, data: 0.005) loss: 0.085 
(epoch: 189, iters: 8944, time: 0.195, data: 0.007) loss: 0.190 
(epoch: 189, iters: 9024, time: 0.168, data: 0.000) loss: 0.193 
(epoch: 189, iters: 9104, time: 0.165, data: 0.009) loss: 0.082 
(epoch: 189, iters: 9184, time: 0.164, data: 0.021) loss: 0.220 
(epoch: 189, iters: 9264, time: 0.168, data: 0.000) loss: 0.245 
(epoch: 189, iters: 9344, time: 0.167, data: 0.000) loss: 0.103 
(epoch: 189, iters: 9424, time: 0.165, data: 0.009) loss: 0.373 
(epoch: 189, iters: 9504, time: 0.166, data: 0.000) loss: 0.306 
(epoch: 189, iters: 9584, time: 0.196, data: 0.005) loss: 0.153 
(epoch: 189, iters: 9664, time: 0.168, data: 0.000) loss: 0.250 
(epoch: 189, iters: 9744, time: 0.165, data: 0.008) loss: 0.172 
(epoch: 189, iters: 9824, time: 0.169, data: 0.000) loss: 0.101 
(epoch: 189, iters: 9904, time: 0.168, data: 0.000) loss: 0.053 
(epoch: 189, iters: 9984, time: 0.168, data: 0.034) loss: 0.353 
(epoch: 189, iters: 10064, time: 0.172, data: 0.000) loss: 0.143 
(epoch: 189, iters: 10144, time: 0.167, data: 0.000) loss: 0.132 
saving the model at the end of epoch 189, iters 1926288
End of epoch 189 / 200 	 Time Taken: 1771 sec
learning rate = 0.0000198
saving the latest model (epoch 190, total_steps 1926304)
(epoch: 190, iters: 32, time: 0.176, data: 0.005) loss: 0.190 
(epoch: 190, iters: 112, time: 0.173, data: 0.000) loss: 0.288 
(epoch: 190, iters: 192, time: 0.170, data: 0.000) loss: 0.190 
(epoch: 190, iters: 272, time: 0.170, data: 0.000) loss: 0.143 
(epoch: 190, iters: 352, time: 0.171, data: 0.008) loss: 0.497 
(epoch: 190, iters: 432, time: 0.173, data: 0.000) loss: 0.042 
(epoch: 190, iters: 512, time: 0.171, data: 0.043) loss: 0.102 
(epoch: 190, iters: 592, time: 0.202, data: 0.000) loss: 0.408 
(epoch: 190, iters: 672, time: 0.170, data: 0.010) loss: 0.375 
(epoch: 190, iters: 752, time: 0.170, data: 0.000) loss: 0.071 
(epoch: 190, iters: 832, time: 0.172, data: 0.000) loss: 0.374 
(epoch: 190, iters: 912, time: 0.174, data: 0.000) loss: 0.165 
(epoch: 190, iters: 992, time: 0.170, data: 0.000) loss: 0.106 
(epoch: 190, iters: 1072, time: 0.170, data: 0.034) loss: 0.192 
(epoch: 190, iters: 1152, time: 0.169, data: 0.000) loss: 0.215 
(epoch: 190, iters: 1232, time: 0.173, data: 0.000) loss: 0.059 
(epoch: 190, iters: 1312, time: 0.172, data: 0.000) loss: 0.198 
(epoch: 190, iters: 1392, time: 0.169, data: 0.032) loss: 0.129 
(epoch: 190, iters: 1472, time: 0.173, data: 0.000) loss: 0.144 
(epoch: 190, iters: 1552, time: 0.173, data: 0.009) loss: 0.191 
(epoch: 190, iters: 1632, time: 0.174, data: 0.000) loss: 0.049 
(epoch: 190, iters: 1712, time: 0.172, data: 0.009) loss: 0.064 
(epoch: 190, iters: 1792, time: 0.172, data: 0.008) loss: 0.204 
(epoch: 190, iters: 1872, time: 0.171, data: 0.021) loss: 0.240 
(epoch: 190, iters: 1952, time: 0.172, data: 0.000) loss: 0.265 
(epoch: 190, iters: 2032, time: 0.172, data: 0.000) loss: 0.384 
(epoch: 190, iters: 2112, time: 0.173, data: 0.000) loss: 0.242 
(epoch: 190, iters: 2192, time: 0.167, data: 0.000) loss: 0.047 
(epoch: 190, iters: 2272, time: 0.174, data: 0.000) loss: 0.189 
(epoch: 190, iters: 2352, time: 0.168, data: 0.000) loss: 0.020 
(epoch: 190, iters: 2432, time: 0.171, data: 0.000) loss: 0.900 
(epoch: 190, iters: 2512, time: 0.168, data: 0.000) loss: 0.542 
(epoch: 190, iters: 2592, time: 0.168, data: 0.008) loss: 0.037 
(epoch: 190, iters: 2672, time: 0.201, data: 0.026) loss: 0.306 
(epoch: 190, iters: 2752, time: 0.203, data: 0.000) loss: 0.106 
(epoch: 190, iters: 2832, time: 0.171, data: 0.033) loss: 0.376 
(epoch: 190, iters: 2912, time: 0.174, data: 0.000) loss: 0.160 
(epoch: 190, iters: 2992, time: 0.198, data: 0.000) loss: 0.112 
(epoch: 190, iters: 3072, time: 0.172, data: 0.000) loss: 0.318 
(epoch: 190, iters: 3152, time: 0.173, data: 0.017) loss: 0.194 
(epoch: 190, iters: 3232, time: 0.172, data: 0.000) loss: 0.150 
(epoch: 190, iters: 3312, time: 0.173, data: 0.000) loss: 0.173 
(epoch: 190, iters: 3392, time: 0.196, data: 0.014) loss: 0.231 
(epoch: 190, iters: 3472, time: 0.172, data: 0.000) loss: 0.061 
(epoch: 190, iters: 3552, time: 0.170, data: 0.000) loss: 0.052 
(epoch: 190, iters: 3632, time: 0.172, data: 0.022) loss: 0.165 
(epoch: 190, iters: 3712, time: 0.171, data: 0.008) loss: 0.341 
(epoch: 190, iters: 3792, time: 0.169, data: 0.017) loss: 0.457 
(epoch: 190, iters: 3872, time: 0.169, data: 0.000) loss: 0.148 
(epoch: 190, iters: 3952, time: 0.171, data: 0.000) loss: 0.135 
saving the latest model (epoch 190, total_steps 1930304)
(epoch: 190, iters: 4032, time: 0.171, data: 0.035) loss: 0.059 
(epoch: 190, iters: 4112, time: 0.171, data: 0.000) loss: 0.064 
(epoch: 190, iters: 4192, time: 0.173, data: 0.000) loss: 0.262 
(epoch: 190, iters: 4272, time: 0.172, data: 0.048) loss: 0.248 
(epoch: 190, iters: 4352, time: 0.170, data: 0.000) loss: 0.122 
(epoch: 190, iters: 4432, time: 0.200, data: 0.038) loss: 0.469 
(epoch: 190, iters: 4512, time: 0.171, data: 0.000) loss: 0.326 
(epoch: 190, iters: 4592, time: 0.170, data: 0.017) loss: 0.366 
(epoch: 190, iters: 4672, time: 0.174, data: 0.000) loss: 0.144 
(epoch: 190, iters: 4752, time: 0.172, data: 0.000) loss: 0.147 
(epoch: 190, iters: 4832, time: 0.173, data: 0.010) loss: 0.162 
(epoch: 190, iters: 4912, time: 0.170, data: 0.000) loss: 0.178 
(epoch: 190, iters: 4992, time: 0.166, data: 0.000) loss: 0.038 
(epoch: 190, iters: 5072, time: 0.174, data: 0.035) loss: 0.251 
(epoch: 190, iters: 5152, time: 0.172, data: 0.000) loss: 0.227 
(epoch: 190, iters: 5232, time: 0.169, data: 0.009) loss: 0.094 
(epoch: 190, iters: 5312, time: 0.173, data: 0.000) loss: 0.224 
(epoch: 190, iters: 5392, time: 0.171, data: 0.000) loss: 0.173 
(epoch: 190, iters: 5472, time: 0.169, data: 0.000) loss: 0.290 
(epoch: 190, iters: 5552, time: 0.167, data: 0.000) loss: 0.119 
(epoch: 190, iters: 5632, time: 0.169, data: 0.035) loss: 0.098 
(epoch: 190, iters: 5712, time: 0.167, data: 0.000) loss: 0.138 
(epoch: 190, iters: 5792, time: 0.171, data: 0.009) loss: 0.211 
(epoch: 190, iters: 5872, time: 0.167, data: 0.000) loss: 0.270 
(epoch: 190, iters: 5952, time: 0.172, data: 0.021) loss: 0.230 
(epoch: 190, iters: 6032, time: 0.170, data: 0.008) loss: 0.097 
(epoch: 190, iters: 6112, time: 0.168, data: 0.025) loss: 0.325 
(epoch: 190, iters: 6192, time: 0.169, data: 0.000) loss: 0.116 
(epoch: 190, iters: 6272, time: 0.173, data: 0.009) loss: 0.114 
(epoch: 190, iters: 6352, time: 0.169, data: 0.000) loss: 0.297 
(epoch: 190, iters: 6432, time: 0.170, data: 0.017) loss: 0.188 
(epoch: 190, iters: 6512, time: 0.171, data: 0.000) loss: 0.102 
(epoch: 190, iters: 6592, time: 0.171, data: 0.020) loss: 0.107 
(epoch: 190, iters: 6672, time: 0.165, data: 0.000) loss: 0.171 
(epoch: 190, iters: 6752, time: 0.169, data: 0.009) loss: 0.200 
(epoch: 190, iters: 6832, time: 0.169, data: 0.000) loss: 0.386 
(epoch: 190, iters: 6912, time: 0.202, data: 0.000) loss: 0.257 
(epoch: 190, iters: 6992, time: 0.173, data: 0.000) loss: 0.183 
(epoch: 190, iters: 7072, time: 0.169, data: 0.005) loss: 0.149 
(epoch: 190, iters: 7152, time: 0.167, data: 0.000) loss: 0.140 
(epoch: 190, iters: 7232, time: 0.169, data: 0.000) loss: 0.122 
(epoch: 190, iters: 7312, time: 0.200, data: 0.017) loss: 0.198 
(epoch: 190, iters: 7392, time: 0.175, data: 0.009) loss: 0.094 
(epoch: 190, iters: 7472, time: 0.169, data: 0.000) loss: 0.158 
(epoch: 190, iters: 7552, time: 0.165, data: 0.000) loss: 0.321 
(epoch: 190, iters: 7632, time: 0.166, data: 0.033) loss: 0.324 
(epoch: 190, iters: 7712, time: 0.168, data: 0.000) loss: 0.582 
(epoch: 190, iters: 7792, time: 0.169, data: 0.008) loss: 0.247 
(epoch: 190, iters: 7872, time: 0.167, data: 0.000) loss: 0.259 
(epoch: 190, iters: 7952, time: 0.170, data: 0.009) loss: 0.243 
saving the latest model (epoch 190, total_steps 1934304)
(epoch: 190, iters: 8032, time: 0.172, data: 0.000) loss: 0.501 
(epoch: 190, iters: 8112, time: 0.171, data: 0.000) loss: 0.048 
(epoch: 190, iters: 8192, time: 0.171, data: 0.000) loss: 0.384 
(epoch: 190, iters: 8272, time: 0.195, data: 0.009) loss: 0.460 
(epoch: 190, iters: 8352, time: 0.169, data: 0.009) loss: 0.324 
(epoch: 190, iters: 8432, time: 0.166, data: 0.000) loss: 0.317 
(epoch: 190, iters: 8512, time: 0.165, data: 0.009) loss: 0.182 
(epoch: 190, iters: 8592, time: 0.167, data: 0.000) loss: 0.046 
(epoch: 190, iters: 8672, time: 0.166, data: 0.000) loss: 0.381 
(epoch: 190, iters: 8752, time: 0.167, data: 0.000) loss: 0.299 
(epoch: 190, iters: 8832, time: 0.168, data: 0.026) loss: 0.169 
(epoch: 190, iters: 8912, time: 0.170, data: 0.000) loss: 0.232 
(epoch: 190, iters: 8992, time: 0.172, data: 0.008) loss: 0.281 
(epoch: 190, iters: 9072, time: 0.199, data: 0.000) loss: 0.137 
(epoch: 190, iters: 9152, time: 0.201, data: 0.017) loss: 0.138 
(epoch: 190, iters: 9232, time: 0.169, data: 0.009) loss: 0.014 
(epoch: 190, iters: 9312, time: 0.166, data: 0.000) loss: 0.173 
(epoch: 190, iters: 9392, time: 0.168, data: 0.009) loss: 0.444 
(epoch: 190, iters: 9472, time: 0.168, data: 0.000) loss: 0.191 
(epoch: 190, iters: 9552, time: 0.198, data: 0.008) loss: 0.293 
(epoch: 190, iters: 9632, time: 0.170, data: 0.000) loss: 0.459 
(epoch: 190, iters: 9712, time: 0.168, data: 0.000) loss: 0.487 
(epoch: 190, iters: 9792, time: 0.169, data: 0.000) loss: 0.096 
(epoch: 190, iters: 9872, time: 0.199, data: 0.033) loss: 0.357 
(epoch: 190, iters: 9952, time: 0.173, data: 0.000) loss: 0.183 
(epoch: 190, iters: 10032, time: 0.173, data: 0.000) loss: 0.055 
(epoch: 190, iters: 10112, time: 0.169, data: 0.020) loss: 0.071 
(epoch: 190, iters: 10192, time: 0.099, data: 0.000) loss: 0.249 
saving the model at the end of epoch 190, iters 1936480
End of epoch 190 / 200 	 Time Taken: 1765 sec
learning rate = 0.0000178
saving the latest model (epoch 191, total_steps 1936496)
(epoch: 191, iters: 80, time: 0.172, data: 0.174) loss: 0.340 
(epoch: 191, iters: 160, time: 0.171, data: 0.015) loss: 0.437 
(epoch: 191, iters: 240, time: 0.166, data: 0.037) loss: 0.292 
(epoch: 191, iters: 320, time: 0.163, data: 0.000) loss: 0.057 
(epoch: 191, iters: 400, time: 0.166, data: 0.000) loss: 0.187 
(epoch: 191, iters: 480, time: 0.164, data: 0.045) loss: 0.194 
(epoch: 191, iters: 560, time: 0.166, data: 0.000) loss: 0.406 
(epoch: 191, iters: 640, time: 0.167, data: 0.017) loss: 0.456 
(epoch: 191, iters: 720, time: 0.173, data: 0.000) loss: 0.176 
(epoch: 191, iters: 800, time: 0.172, data: 0.016) loss: 0.214 
(epoch: 191, iters: 880, time: 0.168, data: 0.000) loss: 0.423 
(epoch: 191, iters: 960, time: 0.170, data: 0.000) loss: 0.145 
(epoch: 191, iters: 1040, time: 0.170, data: 0.009) loss: 0.284 
(epoch: 191, iters: 1120, time: 0.171, data: 0.000) loss: 0.047 
(epoch: 191, iters: 1200, time: 0.171, data: 0.000) loss: 0.184 
(epoch: 191, iters: 1280, time: 0.170, data: 0.030) loss: 0.530 
(epoch: 191, iters: 1360, time: 0.167, data: 0.000) loss: 0.165 
(epoch: 191, iters: 1440, time: 0.168, data: 0.034) loss: 0.422 
(epoch: 191, iters: 1520, time: 0.169, data: 0.000) loss: 0.250 
(epoch: 191, iters: 1600, time: 0.170, data: 0.000) loss: 0.030 
(epoch: 191, iters: 1680, time: 0.199, data: 0.000) loss: 0.287 
(epoch: 191, iters: 1760, time: 0.200, data: 0.000) loss: 0.067 
(epoch: 191, iters: 1840, time: 0.171, data: 0.000) loss: 0.112 
(epoch: 191, iters: 1920, time: 0.168, data: 0.015) loss: 0.212 
(epoch: 191, iters: 2000, time: 0.173, data: 0.000) loss: 0.251 
(epoch: 191, iters: 2080, time: 0.169, data: 0.000) loss: 0.048 
(epoch: 191, iters: 2160, time: 0.168, data: 0.000) loss: 0.221 
(epoch: 191, iters: 2240, time: 0.169, data: 0.009) loss: 0.035 
(epoch: 191, iters: 2320, time: 0.199, data: 0.000) loss: 0.294 
(epoch: 191, iters: 2400, time: 0.197, data: 0.009) loss: 0.035 
(epoch: 191, iters: 2480, time: 0.173, data: 0.009) loss: 0.288 
(epoch: 191, iters: 2560, time: 0.170, data: 0.033) loss: 0.153 
(epoch: 191, iters: 2640, time: 0.172, data: 0.000) loss: 0.101 
(epoch: 191, iters: 2720, time: 0.168, data: 0.018) loss: 0.139 
(epoch: 191, iters: 2800, time: 0.173, data: 0.000) loss: 0.341 
(epoch: 191, iters: 2880, time: 0.168, data: 0.010) loss: 0.220 
(epoch: 191, iters: 2960, time: 0.168, data: 0.000) loss: 0.275 
(epoch: 191, iters: 3040, time: 0.173, data: 0.008) loss: 0.141 
(epoch: 191, iters: 3120, time: 0.203, data: 0.000) loss: 0.209 
(epoch: 191, iters: 3200, time: 0.175, data: 0.000) loss: 0.244 
(epoch: 191, iters: 3280, time: 0.176, data: 0.000) loss: 0.225 
(epoch: 191, iters: 3360, time: 0.171, data: 0.000) loss: 0.078 
(epoch: 191, iters: 3440, time: 0.174, data: 0.000) loss: 0.149 
(epoch: 191, iters: 3520, time: 0.171, data: 0.009) loss: 0.211 
(epoch: 191, iters: 3600, time: 0.170, data: 0.000) loss: 0.084 
(epoch: 191, iters: 3680, time: 0.169, data: 0.000) loss: 0.455 
(epoch: 191, iters: 3760, time: 0.169, data: 0.000) loss: 0.045 
(epoch: 191, iters: 3840, time: 0.172, data: 0.024) loss: 0.233 
(epoch: 191, iters: 3920, time: 0.169, data: 0.000) loss: 0.304 
(epoch: 191, iters: 4000, time: 0.174, data: 0.009) loss: 0.144 
saving the latest model (epoch 191, total_steps 1940496)
(epoch: 191, iters: 4080, time: 0.171, data: 0.000) loss: 0.438 
(epoch: 191, iters: 4160, time: 0.171, data: 0.009) loss: 0.731 
(epoch: 191, iters: 4240, time: 0.170, data: 0.021) loss: 0.342 
(epoch: 191, iters: 4320, time: 0.169, data: 0.009) loss: 0.251 
(epoch: 191, iters: 4400, time: 0.169, data: 0.000) loss: 0.260 
(epoch: 191, iters: 4480, time: 0.169, data: 0.008) loss: 0.145 
(epoch: 191, iters: 4560, time: 0.173, data: 0.000) loss: 0.102 
(epoch: 191, iters: 4640, time: 0.168, data: 0.008) loss: 0.468 
(epoch: 191, iters: 4720, time: 0.169, data: 0.000) loss: 0.145 
(epoch: 191, iters: 4800, time: 0.170, data: 0.017) loss: 0.238 
(epoch: 191, iters: 4880, time: 0.171, data: 0.000) loss: 0.173 
(epoch: 191, iters: 4960, time: 0.167, data: 0.016) loss: 0.123 
(epoch: 191, iters: 5040, time: 0.174, data: 0.009) loss: 0.195 
(epoch: 191, iters: 5120, time: 0.170, data: 0.034) loss: 0.120 
(epoch: 191, iters: 5200, time: 0.170, data: 0.000) loss: 0.487 
(epoch: 191, iters: 5280, time: 0.170, data: 0.000) loss: 0.091 
(epoch: 191, iters: 5360, time: 0.172, data: 0.000) loss: 0.036 
(epoch: 191, iters: 5440, time: 0.172, data: 0.008) loss: 0.194 
(epoch: 191, iters: 5520, time: 0.198, data: 0.000) loss: 0.084 
(epoch: 191, iters: 5600, time: 0.173, data: 0.000) loss: 0.262 
(epoch: 191, iters: 5680, time: 0.172, data: 0.029) loss: 0.218 
(epoch: 191, iters: 5760, time: 0.174, data: 0.000) loss: 0.071 
(epoch: 191, iters: 5840, time: 0.172, data: 0.000) loss: 0.397 
(epoch: 191, iters: 5920, time: 0.173, data: 0.000) loss: 0.076 
(epoch: 191, iters: 6000, time: 0.168, data: 0.000) loss: 0.415 
(epoch: 191, iters: 6080, time: 0.170, data: 0.022) loss: 0.380 
(epoch: 191, iters: 6160, time: 0.174, data: 0.000) loss: 0.133 
(epoch: 191, iters: 6240, time: 0.168, data: 0.000) loss: 0.266 
(epoch: 191, iters: 6320, time: 0.169, data: 0.000) loss: 0.176 
(epoch: 191, iters: 6400, time: 0.172, data: 0.000) loss: 0.284 
(epoch: 191, iters: 6480, time: 0.169, data: 0.000) loss: 0.519 
(epoch: 191, iters: 6560, time: 0.168, data: 0.022) loss: 0.329 
(epoch: 191, iters: 6640, time: 0.195, data: 0.009) loss: 0.171 
(epoch: 191, iters: 6720, time: 0.172, data: 0.000) loss: 0.505 
(epoch: 191, iters: 6800, time: 0.169, data: 0.000) loss: 0.342 
(epoch: 191, iters: 6880, time: 0.170, data: 0.000) loss: 0.144 
(epoch: 191, iters: 6960, time: 0.173, data: 0.029) loss: 0.453 
(epoch: 191, iters: 7040, time: 0.171, data: 0.037) loss: 0.262 
(epoch: 191, iters: 7120, time: 0.171, data: 0.000) loss: 0.133 
(epoch: 191, iters: 7200, time: 0.199, data: 0.021) loss: 0.371 
(epoch: 191, iters: 7280, time: 0.167, data: 0.005) loss: 0.188 
(epoch: 191, iters: 7360, time: 0.168, data: 0.000) loss: 0.193 
(epoch: 191, iters: 7440, time: 0.171, data: 0.008) loss: 0.176 
(epoch: 191, iters: 7520, time: 0.175, data: 0.000) loss: 0.499 
(epoch: 191, iters: 7600, time: 0.173, data: 0.009) loss: 0.050 
(epoch: 191, iters: 7680, time: 0.172, data: 0.000) loss: 0.412 
(epoch: 191, iters: 7760, time: 0.169, data: 0.009) loss: 0.064 
(epoch: 191, iters: 7840, time: 0.173, data: 0.025) loss: 0.106 
(epoch: 191, iters: 7920, time: 0.168, data: 0.000) loss: 0.388 
(epoch: 191, iters: 8000, time: 0.199, data: 0.000) loss: 0.066 
saving the latest model (epoch 191, total_steps 1944496)
(epoch: 191, iters: 8080, time: 0.172, data: 0.000) loss: 0.101 
(epoch: 191, iters: 8160, time: 0.167, data: 0.032) loss: 0.101 
(epoch: 191, iters: 8240, time: 0.171, data: 0.000) loss: 0.262 
(epoch: 191, iters: 8320, time: 0.174, data: 0.000) loss: 0.438 
(epoch: 191, iters: 8400, time: 0.171, data: 0.000) loss: 0.252 
(epoch: 191, iters: 8480, time: 0.198, data: 0.000) loss: 0.180 
(epoch: 191, iters: 8560, time: 0.198, data: 0.000) loss: 0.123 
(epoch: 191, iters: 8640, time: 0.171, data: 0.000) loss: 0.359 
(epoch: 191, iters: 8720, time: 0.197, data: 0.016) loss: 0.195 
(epoch: 191, iters: 8800, time: 0.171, data: 0.016) loss: 0.268 
(epoch: 191, iters: 8880, time: 0.172, data: 0.000) loss: 0.246 
(epoch: 191, iters: 8960, time: 0.173, data: 0.000) loss: 0.226 
(epoch: 191, iters: 9040, time: 0.170, data: 0.000) loss: 0.710 
(epoch: 191, iters: 9120, time: 0.173, data: 0.000) loss: 0.393 
(epoch: 191, iters: 9200, time: 0.169, data: 0.000) loss: 0.320 
(epoch: 191, iters: 9280, time: 0.202, data: 0.000) loss: 0.103 
(epoch: 191, iters: 9360, time: 0.197, data: 0.000) loss: 0.211 
(epoch: 191, iters: 9440, time: 0.173, data: 0.009) loss: 0.022 
(epoch: 191, iters: 9520, time: 0.170, data: 0.000) loss: 0.280 
(epoch: 191, iters: 9600, time: 0.169, data: 0.021) loss: 0.272 
(epoch: 191, iters: 9680, time: 0.169, data: 0.025) loss: 0.074 
(epoch: 191, iters: 9760, time: 0.169, data: 0.021) loss: 0.163 
(epoch: 191, iters: 9840, time: 0.169, data: 0.000) loss: 0.579 
(epoch: 191, iters: 9920, time: 0.170, data: 0.000) loss: 0.245 
(epoch: 191, iters: 10000, time: 0.171, data: 0.017) loss: 0.233 
(epoch: 191, iters: 10080, time: 0.172, data: 0.000) loss: 0.431 
(epoch: 191, iters: 10160, time: 0.171, data: 0.021) loss: 0.220 
saving the model at the end of epoch 191, iters 1946672
End of epoch 191 / 200 	 Time Taken: 1772 sec
learning rate = 0.0000158
saving the latest model (epoch 192, total_steps 1946688)
(epoch: 192, iters: 48, time: 0.174, data: 0.005) loss: 0.210 
(epoch: 192, iters: 128, time: 0.171, data: 0.012) loss: 0.094 
(epoch: 192, iters: 208, time: 0.168, data: 0.000) loss: 0.369 
(epoch: 192, iters: 288, time: 0.170, data: 0.027) loss: 0.114 
(epoch: 192, iters: 368, time: 0.174, data: 0.000) loss: 0.187 
(epoch: 192, iters: 448, time: 0.171, data: 0.000) loss: 0.050 
(epoch: 192, iters: 528, time: 0.171, data: 0.000) loss: 0.087 
(epoch: 192, iters: 608, time: 0.176, data: 0.008) loss: 0.038 
(epoch: 192, iters: 688, time: 0.173, data: 0.016) loss: 0.240 
(epoch: 192, iters: 768, time: 0.175, data: 0.000) loss: 0.040 
(epoch: 192, iters: 848, time: 0.170, data: 0.000) loss: 0.626 
(epoch: 192, iters: 928, time: 0.200, data: 0.034) loss: 0.384 
(epoch: 192, iters: 1008, time: 0.173, data: 0.000) loss: 0.368 
(epoch: 192, iters: 1088, time: 0.169, data: 0.009) loss: 0.184 
(epoch: 192, iters: 1168, time: 0.173, data: 0.000) loss: 0.360 
(epoch: 192, iters: 1248, time: 0.170, data: 0.020) loss: 0.145 
(epoch: 192, iters: 1328, time: 0.171, data: 0.008) loss: 0.292 
(epoch: 192, iters: 1408, time: 0.170, data: 0.000) loss: 0.138 
(epoch: 192, iters: 1488, time: 0.173, data: 0.043) loss: 0.169 
(epoch: 192, iters: 1568, time: 0.170, data: 0.000) loss: 0.357 
(epoch: 192, iters: 1648, time: 0.169, data: 0.033) loss: 0.169 
(epoch: 192, iters: 1728, time: 0.166, data: 0.000) loss: 0.389 
(epoch: 192, iters: 1808, time: 0.168, data: 0.000) loss: 0.243 
(epoch: 192, iters: 1888, time: 0.167, data: 0.021) loss: 0.025 
(epoch: 192, iters: 1968, time: 0.166, data: 0.025) loss: 0.169 
(epoch: 192, iters: 2048, time: 0.195, data: 0.000) loss: 0.059 
(epoch: 192, iters: 2128, time: 0.164, data: 0.009) loss: 0.156 
(epoch: 192, iters: 2208, time: 0.163, data: 0.026) loss: 0.188 
(epoch: 192, iters: 2288, time: 0.167, data: 0.000) loss: 0.071 
(epoch: 192, iters: 2368, time: 0.166, data: 0.000) loss: 0.047 
(epoch: 192, iters: 2448, time: 0.167, data: 0.000) loss: 0.283 
(epoch: 192, iters: 2528, time: 0.165, data: 0.009) loss: 0.163 
(epoch: 192, iters: 2608, time: 0.168, data: 0.000) loss: 0.109 
(epoch: 192, iters: 2688, time: 0.200, data: 0.000) loss: 0.156 
(epoch: 192, iters: 2768, time: 0.196, data: 0.000) loss: 0.159 
(epoch: 192, iters: 2848, time: 0.194, data: 0.000) loss: 0.155 
(epoch: 192, iters: 2928, time: 0.168, data: 0.009) loss: 0.229 
(epoch: 192, iters: 3008, time: 0.170, data: 0.000) loss: 0.232 
(epoch: 192, iters: 3088, time: 0.172, data: 0.008) loss: 0.170 
(epoch: 192, iters: 3168, time: 0.164, data: 0.000) loss: 0.136 
(epoch: 192, iters: 3248, time: 0.197, data: 0.006) loss: 0.425 
(epoch: 192, iters: 3328, time: 0.166, data: 0.000) loss: 0.405 
(epoch: 192, iters: 3408, time: 0.167, data: 0.000) loss: 0.386 
(epoch: 192, iters: 3488, time: 0.168, data: 0.017) loss: 0.254 
(epoch: 192, iters: 3568, time: 0.167, data: 0.022) loss: 0.154 
(epoch: 192, iters: 3648, time: 0.169, data: 0.008) loss: 0.564 
(epoch: 192, iters: 3728, time: 0.166, data: 0.000) loss: 0.104 
(epoch: 192, iters: 3808, time: 0.197, data: 0.017) loss: 0.256 
(epoch: 192, iters: 3888, time: 0.169, data: 0.000) loss: 0.096 
(epoch: 192, iters: 3968, time: 0.198, data: 0.009) loss: 0.301 
saving the latest model (epoch 192, total_steps 1950688)
(epoch: 192, iters: 4048, time: 0.169, data: 0.000) loss: 0.126 
(epoch: 192, iters: 4128, time: 0.168, data: 0.009) loss: 0.364 
(epoch: 192, iters: 4208, time: 0.172, data: 0.025) loss: 0.063 
(epoch: 192, iters: 4288, time: 0.170, data: 0.000) loss: 0.320 
(epoch: 192, iters: 4368, time: 0.165, data: 0.000) loss: 0.519 
(epoch: 192, iters: 4448, time: 0.166, data: 0.000) loss: 0.077 
(epoch: 192, iters: 4528, time: 0.193, data: 0.000) loss: 0.437 
(epoch: 192, iters: 4608, time: 0.163, data: 0.006) loss: 1.037 
(epoch: 192, iters: 4688, time: 0.169, data: 0.000) loss: 0.347 
(epoch: 192, iters: 4768, time: 0.166, data: 0.000) loss: 0.091 
(epoch: 192, iters: 4848, time: 0.193, data: 0.016) loss: 0.307 
(epoch: 192, iters: 4928, time: 0.197, data: 0.029) loss: 0.194 
(epoch: 192, iters: 5008, time: 0.167, data: 0.009) loss: 0.037 
(epoch: 192, iters: 5088, time: 0.170, data: 0.000) loss: 0.232 
(epoch: 192, iters: 5168, time: 0.195, data: 0.021) loss: 0.541 
(epoch: 192, iters: 5248, time: 0.194, data: 0.010) loss: 0.262 
(epoch: 192, iters: 5328, time: 0.165, data: 0.000) loss: 0.238 
(epoch: 192, iters: 5408, time: 0.169, data: 0.009) loss: 0.340 
(epoch: 192, iters: 5488, time: 0.169, data: 0.000) loss: 0.248 
(epoch: 192, iters: 5568, time: 0.163, data: 0.000) loss: 0.431 
(epoch: 192, iters: 5648, time: 0.168, data: 0.000) loss: 0.131 
(epoch: 192, iters: 5728, time: 0.168, data: 0.000) loss: 0.088 
(epoch: 192, iters: 5808, time: 0.172, data: 0.034) loss: 0.297 
(epoch: 192, iters: 5888, time: 0.170, data: 0.000) loss: 0.278 
(epoch: 192, iters: 5968, time: 0.170, data: 0.000) loss: 0.259 
(epoch: 192, iters: 6048, time: 0.171, data: 0.034) loss: 0.253 
(epoch: 192, iters: 6128, time: 0.171, data: 0.000) loss: 0.269 
(epoch: 192, iters: 6208, time: 0.165, data: 0.000) loss: 0.045 
(epoch: 192, iters: 6288, time: 0.168, data: 0.000) loss: 0.227 
(epoch: 192, iters: 6368, time: 0.168, data: 0.000) loss: 0.538 
(epoch: 192, iters: 6448, time: 0.168, data: 0.009) loss: 0.454 
(epoch: 192, iters: 6528, time: 0.167, data: 0.036) loss: 0.233 
(epoch: 192, iters: 6608, time: 0.169, data: 0.000) loss: 0.086 
(epoch: 192, iters: 6688, time: 0.169, data: 0.017) loss: 0.191 
(epoch: 192, iters: 6768, time: 0.170, data: 0.000) loss: 0.143 
(epoch: 192, iters: 6848, time: 0.169, data: 0.019) loss: 0.749 
(epoch: 192, iters: 6928, time: 0.168, data: 0.000) loss: 0.196 
(epoch: 192, iters: 7008, time: 0.170, data: 0.000) loss: 0.155 
(epoch: 192, iters: 7088, time: 0.168, data: 0.000) loss: 0.041 
(epoch: 192, iters: 7168, time: 0.168, data: 0.000) loss: 0.074 
(epoch: 192, iters: 7248, time: 0.173, data: 0.009) loss: 0.098 
(epoch: 192, iters: 7328, time: 0.169, data: 0.025) loss: 0.288 
(epoch: 192, iters: 7408, time: 0.168, data: 0.000) loss: 0.144 
(epoch: 192, iters: 7488, time: 0.168, data: 0.009) loss: 0.084 
(epoch: 192, iters: 7568, time: 0.167, data: 0.000) loss: 0.271 
(epoch: 192, iters: 7648, time: 0.171, data: 0.000) loss: 0.461 
(epoch: 192, iters: 7728, time: 0.171, data: 0.009) loss: 0.267 
(epoch: 192, iters: 7808, time: 0.174, data: 0.025) loss: 0.346 
(epoch: 192, iters: 7888, time: 0.167, data: 0.000) loss: 0.153 
(epoch: 192, iters: 7968, time: 0.171, data: 0.000) loss: 0.187 
saving the latest model (epoch 192, total_steps 1954688)
(epoch: 192, iters: 8048, time: 0.169, data: 0.000) loss: 0.150 
(epoch: 192, iters: 8128, time: 0.170, data: 0.034) loss: 0.124 
(epoch: 192, iters: 8208, time: 0.169, data: 0.000) loss: 0.047 
(epoch: 192, iters: 8288, time: 0.166, data: 0.008) loss: 0.177 
(epoch: 192, iters: 8368, time: 0.169, data: 0.025) loss: 0.078 
(epoch: 192, iters: 8448, time: 0.168, data: 0.000) loss: 0.207 
(epoch: 192, iters: 8528, time: 0.164, data: 0.008) loss: 0.230 
(epoch: 192, iters: 8608, time: 0.161, data: 0.000) loss: 0.139 
(epoch: 192, iters: 8688, time: 0.166, data: 0.042) loss: 0.144 
(epoch: 192, iters: 8768, time: 0.166, data: 0.000) loss: 0.196 
(epoch: 192, iters: 8848, time: 0.165, data: 0.009) loss: 0.182 
(epoch: 192, iters: 8928, time: 0.165, data: 0.000) loss: 0.067 
(epoch: 192, iters: 9008, time: 0.192, data: 0.009) loss: 0.349 
(epoch: 192, iters: 9088, time: 0.166, data: 0.000) loss: 0.114 
(epoch: 192, iters: 9168, time: 0.167, data: 0.009) loss: 0.349 
(epoch: 192, iters: 9248, time: 0.169, data: 0.000) loss: 0.160 
(epoch: 192, iters: 9328, time: 0.167, data: 0.000) loss: 0.136 
(epoch: 192, iters: 9408, time: 0.167, data: 0.000) loss: 0.296 
(epoch: 192, iters: 9488, time: 0.166, data: 0.000) loss: 0.428 
(epoch: 192, iters: 9568, time: 0.169, data: 0.000) loss: 0.287 
(epoch: 192, iters: 9648, time: 0.173, data: 0.009) loss: 0.098 
(epoch: 192, iters: 9728, time: 0.171, data: 0.008) loss: 0.255 
(epoch: 192, iters: 9808, time: 0.167, data: 0.000) loss: 0.054 
(epoch: 192, iters: 9888, time: 0.171, data: 0.035) loss: 0.659 
(epoch: 192, iters: 9968, time: 0.168, data: 0.000) loss: 0.271 
(epoch: 192, iters: 10048, time: 0.168, data: 0.009) loss: 0.190 
(epoch: 192, iters: 10128, time: 0.166, data: 0.000) loss: 0.096 
saving the model at the end of epoch 192, iters 1956864
End of epoch 192 / 200 	 Time Taken: 1756 sec
learning rate = 0.0000139
(epoch: 193, iters: 16, time: 0.197, data: 0.016) loss: 0.469 
saving the latest model (epoch 193, total_steps 1956880)
(epoch: 193, iters: 96, time: 0.176, data: 0.000) loss: 0.306 
(epoch: 193, iters: 176, time: 0.169, data: 0.022) loss: 0.019 
(epoch: 193, iters: 256, time: 0.167, data: 0.000) loss: 0.087 
(epoch: 193, iters: 336, time: 0.174, data: 0.011) loss: 0.116 
(epoch: 193, iters: 416, time: 0.173, data: 0.000) loss: 0.212 
(epoch: 193, iters: 496, time: 0.170, data: 0.009) loss: 0.156 
(epoch: 193, iters: 576, time: 0.167, data: 0.000) loss: 0.057 
(epoch: 193, iters: 656, time: 0.172, data: 0.009) loss: 0.123 
(epoch: 193, iters: 736, time: 0.172, data: 0.000) loss: 0.220 
(epoch: 193, iters: 816, time: 0.170, data: 0.019) loss: 0.248 
(epoch: 193, iters: 896, time: 0.200, data: 0.030) loss: 0.301 
(epoch: 193, iters: 976, time: 0.172, data: 0.000) loss: 0.122 
(epoch: 193, iters: 1056, time: 0.168, data: 0.000) loss: 0.421 
(epoch: 193, iters: 1136, time: 0.197, data: 0.000) loss: 0.197 
(epoch: 193, iters: 1216, time: 0.169, data: 0.009) loss: 0.052 
(epoch: 193, iters: 1296, time: 0.171, data: 0.020) loss: 0.515 
(epoch: 193, iters: 1376, time: 0.169, data: 0.000) loss: 0.295 
(epoch: 193, iters: 1456, time: 0.166, data: 0.034) loss: 0.022 
(epoch: 193, iters: 1536, time: 0.169, data: 0.000) loss: 0.475 
(epoch: 193, iters: 1616, time: 0.173, data: 0.000) loss: 0.090 
(epoch: 193, iters: 1696, time: 0.172, data: 0.034) loss: 0.127 
(epoch: 193, iters: 1776, time: 0.169, data: 0.000) loss: 0.430 
(epoch: 193, iters: 1856, time: 0.173, data: 0.009) loss: 0.107 
(epoch: 193, iters: 1936, time: 0.170, data: 0.000) loss: 0.193 
(epoch: 193, iters: 2016, time: 0.171, data: 0.009) loss: 0.151 
(epoch: 193, iters: 2096, time: 0.203, data: 0.000) loss: 0.154 
(epoch: 193, iters: 2176, time: 0.170, data: 0.021) loss: 0.221 
(epoch: 193, iters: 2256, time: 0.167, data: 0.009) loss: 0.120 
(epoch: 193, iters: 2336, time: 0.168, data: 0.025) loss: 0.391 
(epoch: 193, iters: 2416, time: 0.169, data: 0.000) loss: 0.279 
(epoch: 193, iters: 2496, time: 0.165, data: 0.000) loss: 0.098 
(epoch: 193, iters: 2576, time: 0.172, data: 0.034) loss: 0.192 
(epoch: 193, iters: 2656, time: 0.168, data: 0.000) loss: 0.209 
(epoch: 193, iters: 2736, time: 0.172, data: 0.000) loss: 0.241 
(epoch: 193, iters: 2816, time: 0.170, data: 0.000) loss: 0.053 
(epoch: 193, iters: 2896, time: 0.171, data: 0.033) loss: 0.184 
(epoch: 193, iters: 2976, time: 0.171, data: 0.000) loss: 0.308 
(epoch: 193, iters: 3056, time: 0.171, data: 0.008) loss: 0.174 
(epoch: 193, iters: 3136, time: 0.174, data: 0.000) loss: 0.116 
(epoch: 193, iters: 3216, time: 0.170, data: 0.000) loss: 0.075 
(epoch: 193, iters: 3296, time: 0.170, data: 0.000) loss: 0.318 
(epoch: 193, iters: 3376, time: 0.173, data: 0.021) loss: 0.413 
(epoch: 193, iters: 3456, time: 0.200, data: 0.006) loss: 0.425 
(epoch: 193, iters: 3536, time: 0.172, data: 0.026) loss: 0.321 
(epoch: 193, iters: 3616, time: 0.166, data: 0.000) loss: 0.200 
(epoch: 193, iters: 3696, time: 0.169, data: 0.000) loss: 0.268 
(epoch: 193, iters: 3776, time: 0.170, data: 0.009) loss: 0.296 
(epoch: 193, iters: 3856, time: 0.171, data: 0.000) loss: 0.182 
(epoch: 193, iters: 3936, time: 0.168, data: 0.000) loss: 0.302 
(epoch: 193, iters: 4016, time: 0.165, data: 0.034) loss: 0.163 
saving the latest model (epoch 193, total_steps 1960880)
(epoch: 193, iters: 4096, time: 0.168, data: 0.000) loss: 0.197 
(epoch: 193, iters: 4176, time: 0.172, data: 0.008) loss: 0.551 
(epoch: 193, iters: 4256, time: 0.172, data: 0.024) loss: 0.289 
(epoch: 193, iters: 4336, time: 0.199, data: 0.000) loss: 0.065 
(epoch: 193, iters: 4416, time: 0.172, data: 0.000) loss: 0.266 
(epoch: 193, iters: 4496, time: 0.173, data: 0.021) loss: 0.071 
(epoch: 193, iters: 4576, time: 0.199, data: 0.025) loss: 0.130 
(epoch: 193, iters: 4656, time: 0.167, data: 0.048) loss: 0.155 
(epoch: 193, iters: 4736, time: 0.171, data: 0.000) loss: 0.293 
(epoch: 193, iters: 4816, time: 0.174, data: 0.009) loss: 0.170 
(epoch: 193, iters: 4896, time: 0.168, data: 0.022) loss: 0.360 
(epoch: 193, iters: 4976, time: 0.170, data: 0.000) loss: 0.168 
(epoch: 193, iters: 5056, time: 0.173, data: 0.008) loss: 0.363 
(epoch: 193, iters: 5136, time: 0.174, data: 0.022) loss: 0.230 
(epoch: 193, iters: 5216, time: 0.169, data: 0.000) loss: 0.084 
(epoch: 193, iters: 5296, time: 0.169, data: 0.017) loss: 0.319 
(epoch: 193, iters: 5376, time: 0.168, data: 0.009) loss: 0.243 
(epoch: 193, iters: 5456, time: 0.171, data: 0.010) loss: 0.339 
(epoch: 193, iters: 5536, time: 0.169, data: 0.000) loss: 0.419 
(epoch: 193, iters: 5616, time: 0.170, data: 0.000) loss: 0.246 
(epoch: 193, iters: 5696, time: 0.174, data: 0.000) loss: 0.240 
(epoch: 193, iters: 5776, time: 0.199, data: 0.000) loss: 0.155 
(epoch: 193, iters: 5856, time: 0.171, data: 0.009) loss: 0.256 
(epoch: 193, iters: 5936, time: 0.168, data: 0.000) loss: 0.094 
(epoch: 193, iters: 6016, time: 0.165, data: 0.009) loss: 0.134 
(epoch: 193, iters: 6096, time: 0.171, data: 0.008) loss: 0.318 
(epoch: 193, iters: 6176, time: 0.170, data: 0.021) loss: 0.490 
(epoch: 193, iters: 6256, time: 0.201, data: 0.009) loss: 0.344 
(epoch: 193, iters: 6336, time: 0.173, data: 0.000) loss: 0.081 
(epoch: 193, iters: 6416, time: 0.166, data: 0.000) loss: 0.138 
(epoch: 193, iters: 6496, time: 0.172, data: 0.035) loss: 0.697 
(epoch: 193, iters: 6576, time: 0.171, data: 0.000) loss: 0.655 
(epoch: 193, iters: 6656, time: 0.199, data: 0.000) loss: 0.136 
(epoch: 193, iters: 6736, time: 0.174, data: 0.000) loss: 0.551 
(epoch: 193, iters: 6816, time: 0.197, data: 0.000) loss: 0.043 
(epoch: 193, iters: 6896, time: 0.168, data: 0.000) loss: 0.188 
(epoch: 193, iters: 6976, time: 0.202, data: 0.000) loss: 0.250 
(epoch: 193, iters: 7056, time: 0.201, data: 0.009) loss: 0.332 
(epoch: 193, iters: 7136, time: 0.200, data: 0.026) loss: 0.150 
(epoch: 193, iters: 7216, time: 0.171, data: 0.000) loss: 0.043 
(epoch: 193, iters: 7296, time: 0.201, data: 0.000) loss: 0.326 
(epoch: 193, iters: 7376, time: 0.174, data: 0.000) loss: 0.041 
(epoch: 193, iters: 7456, time: 0.169, data: 0.000) loss: 0.412 
(epoch: 193, iters: 7536, time: 0.198, data: 0.000) loss: 0.204 
(epoch: 193, iters: 7616, time: 0.169, data: 0.009) loss: 0.411 
(epoch: 193, iters: 7696, time: 0.171, data: 0.009) loss: 0.206 
(epoch: 193, iters: 7776, time: 0.173, data: 0.021) loss: 0.170 
(epoch: 193, iters: 7856, time: 0.172, data: 0.034) loss: 0.113 
(epoch: 193, iters: 7936, time: 0.167, data: 0.000) loss: 0.279 
(epoch: 193, iters: 8016, time: 0.170, data: 0.000) loss: 0.098 
saving the latest model (epoch 193, total_steps 1964880)
(epoch: 193, iters: 8096, time: 0.170, data: 0.000) loss: 0.129 
(epoch: 193, iters: 8176, time: 0.170, data: 0.000) loss: 0.232 
(epoch: 193, iters: 8256, time: 0.169, data: 0.000) loss: 0.268 
(epoch: 193, iters: 8336, time: 0.174, data: 0.008) loss: 0.116 
(epoch: 193, iters: 8416, time: 0.167, data: 0.000) loss: 0.116 
(epoch: 193, iters: 8496, time: 0.166, data: 0.043) loss: 0.046 
(epoch: 193, iters: 8576, time: 0.171, data: 0.000) loss: 0.224 
(epoch: 193, iters: 8656, time: 0.167, data: 0.000) loss: 0.309 
(epoch: 193, iters: 8736, time: 0.167, data: 0.017) loss: 0.070 
(epoch: 193, iters: 8816, time: 0.171, data: 0.000) loss: 0.179 
(epoch: 193, iters: 8896, time: 0.173, data: 0.045) loss: 0.118 
(epoch: 193, iters: 8976, time: 0.173, data: 0.000) loss: 0.143 
(epoch: 193, iters: 9056, time: 0.169, data: 0.034) loss: 0.464 
(epoch: 193, iters: 9136, time: 0.172, data: 0.000) loss: 0.224 
(epoch: 193, iters: 9216, time: 0.173, data: 0.000) loss: 0.343 
(epoch: 193, iters: 9296, time: 0.171, data: 0.017) loss: 0.279 
(epoch: 193, iters: 9376, time: 0.169, data: 0.000) loss: 0.160 
(epoch: 193, iters: 9456, time: 0.173, data: 0.000) loss: 0.128 
(epoch: 193, iters: 9536, time: 0.174, data: 0.008) loss: 0.341 
(epoch: 193, iters: 9616, time: 0.168, data: 0.000) loss: 0.347 
(epoch: 193, iters: 9696, time: 0.167, data: 0.000) loss: 0.114 
(epoch: 193, iters: 9776, time: 0.167, data: 0.009) loss: 0.445 
(epoch: 193, iters: 9856, time: 0.168, data: 0.000) loss: 0.229 
(epoch: 193, iters: 9936, time: 0.202, data: 0.021) loss: 0.673 
(epoch: 193, iters: 10016, time: 0.171, data: 0.009) loss: 0.126 
(epoch: 193, iters: 10096, time: 0.200, data: 0.026) loss: 0.302 
(epoch: 193, iters: 10176, time: 0.165, data: 0.000) loss: 0.347 
saving the model at the end of epoch 193, iters 1967056
End of epoch 193 / 200 	 Time Taken: 1780 sec
learning rate = 0.0000119
saving the latest model (epoch 194, total_steps 1967072)
(epoch: 194, iters: 64, time: 0.173, data: 0.000) loss: 0.195 
(epoch: 194, iters: 144, time: 0.169, data: 0.028) loss: 0.082 
(epoch: 194, iters: 224, time: 0.170, data: 0.000) loss: 0.243 
(epoch: 194, iters: 304, time: 0.170, data: 0.000) loss: 0.433 
(epoch: 194, iters: 384, time: 0.173, data: 0.000) loss: 0.057 
(epoch: 194, iters: 464, time: 0.199, data: 0.009) loss: 0.093 
(epoch: 194, iters: 544, time: 0.199, data: 0.000) loss: 0.133 
(epoch: 194, iters: 624, time: 0.170, data: 0.000) loss: 0.477 
(epoch: 194, iters: 704, time: 0.171, data: 0.017) loss: 0.367 
(epoch: 194, iters: 784, time: 0.175, data: 0.009) loss: 0.218 
(epoch: 194, iters: 864, time: 0.171, data: 0.008) loss: 0.231 
(epoch: 194, iters: 944, time: 0.169, data: 0.000) loss: 0.059 
(epoch: 194, iters: 1024, time: 0.169, data: 0.037) loss: 0.138 
(epoch: 194, iters: 1104, time: 0.173, data: 0.000) loss: 0.142 
(epoch: 194, iters: 1184, time: 0.172, data: 0.017) loss: 0.792 
(epoch: 194, iters: 1264, time: 0.167, data: 0.000) loss: 0.321 
(epoch: 194, iters: 1344, time: 0.169, data: 0.031) loss: 0.305 
(epoch: 194, iters: 1424, time: 0.169, data: 0.000) loss: 0.235 
(epoch: 194, iters: 1504, time: 0.203, data: 0.009) loss: 0.202 
(epoch: 194, iters: 1584, time: 0.173, data: 0.009) loss: 0.255 
(epoch: 194, iters: 1664, time: 0.172, data: 0.000) loss: 0.264 
(epoch: 194, iters: 1744, time: 0.202, data: 0.000) loss: 0.409 
(epoch: 194, iters: 1824, time: 0.175, data: 0.000) loss: 0.348 
(epoch: 194, iters: 1904, time: 0.175, data: 0.026) loss: 0.327 
(epoch: 194, iters: 1984, time: 0.172, data: 0.000) loss: 0.102 
(epoch: 194, iters: 2064, time: 0.169, data: 0.000) loss: 0.199 
(epoch: 194, iters: 2144, time: 0.170, data: 0.000) loss: 0.119 
(epoch: 194, iters: 2224, time: 0.168, data: 0.000) loss: 0.253 
(epoch: 194, iters: 2304, time: 0.175, data: 0.000) loss: 0.034 
(epoch: 194, iters: 2384, time: 0.171, data: 0.000) loss: 0.249 
(epoch: 194, iters: 2464, time: 0.171, data: 0.000) loss: 0.258 
(epoch: 194, iters: 2544, time: 0.170, data: 0.008) loss: 0.268 
(epoch: 194, iters: 2624, time: 0.174, data: 0.009) loss: 0.059 
(epoch: 194, iters: 2704, time: 0.168, data: 0.021) loss: 0.083 
(epoch: 194, iters: 2784, time: 0.201, data: 0.000) loss: 0.197 
(epoch: 194, iters: 2864, time: 0.200, data: 0.000) loss: 0.273 
(epoch: 194, iters: 2944, time: 0.171, data: 0.006) loss: 0.176 
(epoch: 194, iters: 3024, time: 0.173, data: 0.000) loss: 0.202 
(epoch: 194, iters: 3104, time: 0.172, data: 0.041) loss: 0.231 
(epoch: 194, iters: 3184, time: 0.167, data: 0.000) loss: 0.050 
(epoch: 194, iters: 3264, time: 0.170, data: 0.009) loss: 0.222 
(epoch: 194, iters: 3344, time: 0.172, data: 0.021) loss: 0.206 
(epoch: 194, iters: 3424, time: 0.174, data: 0.000) loss: 0.191 
(epoch: 194, iters: 3504, time: 0.172, data: 0.017) loss: 0.279 
(epoch: 194, iters: 3584, time: 0.174, data: 0.010) loss: 0.172 
(epoch: 194, iters: 3664, time: 0.201, data: 0.009) loss: 0.233 
(epoch: 194, iters: 3744, time: 0.173, data: 0.026) loss: 0.327 
(epoch: 194, iters: 3824, time: 0.175, data: 0.000) loss: 0.258 
(epoch: 194, iters: 3904, time: 0.173, data: 0.034) loss: 0.178 
(epoch: 194, iters: 3984, time: 0.172, data: 0.000) loss: 0.366 
saving the latest model (epoch 194, total_steps 1971072)
(epoch: 194, iters: 4064, time: 0.168, data: 0.000) loss: 0.124 
(epoch: 194, iters: 4144, time: 0.202, data: 0.000) loss: 0.106 
(epoch: 194, iters: 4224, time: 0.173, data: 0.000) loss: 0.278 
(epoch: 194, iters: 4304, time: 0.172, data: 0.000) loss: 0.028 
(epoch: 194, iters: 4384, time: 0.169, data: 0.000) loss: 0.263 
(epoch: 194, iters: 4464, time: 0.172, data: 0.000) loss: 0.282 
(epoch: 194, iters: 4544, time: 0.173, data: 0.000) loss: 0.034 
(epoch: 194, iters: 4624, time: 0.172, data: 0.000) loss: 0.172 
(epoch: 194, iters: 4704, time: 0.175, data: 0.006) loss: 0.164 
(epoch: 194, iters: 4784, time: 0.172, data: 0.000) loss: 0.447 
(epoch: 194, iters: 4864, time: 0.170, data: 0.044) loss: 0.282 
(epoch: 194, iters: 4944, time: 0.170, data: 0.000) loss: 0.171 
(epoch: 194, iters: 5024, time: 0.165, data: 0.000) loss: 0.030 
(epoch: 194, iters: 5104, time: 0.169, data: 0.000) loss: 0.170 
(epoch: 194, iters: 5184, time: 0.169, data: 0.042) loss: 0.227 
(epoch: 194, iters: 5264, time: 0.173, data: 0.000) loss: 0.037 
(epoch: 194, iters: 5344, time: 0.172, data: 0.000) loss: 0.049 
(epoch: 194, iters: 5424, time: 0.170, data: 0.000) loss: 0.348 
(epoch: 194, iters: 5504, time: 0.168, data: 0.022) loss: 0.497 
(epoch: 194, iters: 5584, time: 0.174, data: 0.009) loss: 0.100 
(epoch: 194, iters: 5664, time: 0.168, data: 0.000) loss: 0.495 
(epoch: 194, iters: 5744, time: 0.168, data: 0.008) loss: 0.043 
(epoch: 194, iters: 5824, time: 0.169, data: 0.000) loss: 0.138 
(epoch: 194, iters: 5904, time: 0.172, data: 0.000) loss: 0.298 
(epoch: 194, iters: 5984, time: 0.171, data: 0.000) loss: 0.077 
(epoch: 194, iters: 6064, time: 0.169, data: 0.000) loss: 0.101 
(epoch: 194, iters: 6144, time: 0.172, data: 0.000) loss: 0.189 
(epoch: 194, iters: 6224, time: 0.170, data: 0.000) loss: 0.499 
(epoch: 194, iters: 6304, time: 0.173, data: 0.000) loss: 0.366 
(epoch: 194, iters: 6384, time: 0.170, data: 0.000) loss: 0.074 
(epoch: 194, iters: 6464, time: 0.176, data: 0.034) loss: 0.185 
(epoch: 194, iters: 6544, time: 0.169, data: 0.000) loss: 0.262 
(epoch: 194, iters: 6624, time: 0.175, data: 0.000) loss: 0.200 
(epoch: 194, iters: 6704, time: 0.171, data: 0.000) loss: 0.245 
(epoch: 194, iters: 6784, time: 0.201, data: 0.000) loss: 0.205 
(epoch: 194, iters: 6864, time: 0.173, data: 0.034) loss: 0.165 
(epoch: 194, iters: 6944, time: 0.173, data: 0.000) loss: 0.127 
(epoch: 194, iters: 7024, time: 0.170, data: 0.000) loss: 0.240 
(epoch: 194, iters: 7104, time: 0.170, data: 0.017) loss: 0.283 
(epoch: 194, iters: 7184, time: 0.175, data: 0.009) loss: 0.029 
(epoch: 194, iters: 7264, time: 0.173, data: 0.000) loss: 0.106 
(epoch: 194, iters: 7344, time: 0.169, data: 0.020) loss: 0.377 
(epoch: 194, iters: 7424, time: 0.167, data: 0.009) loss: 0.086 
(epoch: 194, iters: 7504, time: 0.168, data: 0.009) loss: 0.380 
(epoch: 194, iters: 7584, time: 0.168, data: 0.000) loss: 0.227 
(epoch: 194, iters: 7664, time: 0.199, data: 0.009) loss: 0.175 
(epoch: 194, iters: 7744, time: 0.171, data: 0.009) loss: 0.272 
(epoch: 194, iters: 7824, time: 0.170, data: 0.022) loss: 0.224 
(epoch: 194, iters: 7904, time: 0.199, data: 0.000) loss: 0.367 
(epoch: 194, iters: 7984, time: 0.169, data: 0.000) loss: 0.164 
saving the latest model (epoch 194, total_steps 1975072)
(epoch: 194, iters: 8064, time: 0.172, data: 0.009) loss: 0.301 
(epoch: 194, iters: 8144, time: 0.172, data: 0.022) loss: 0.293 
(epoch: 194, iters: 8224, time: 0.172, data: 0.034) loss: 0.120 
(epoch: 194, iters: 8304, time: 0.174, data: 0.000) loss: 0.577 
(epoch: 194, iters: 8384, time: 0.201, data: 0.000) loss: 0.268 
(epoch: 194, iters: 8464, time: 0.176, data: 0.000) loss: 0.120 
(epoch: 194, iters: 8544, time: 0.202, data: 0.009) loss: 0.471 
(epoch: 194, iters: 8624, time: 0.177, data: 0.000) loss: 0.076 
(epoch: 194, iters: 8704, time: 0.170, data: 0.035) loss: 0.150 
(epoch: 194, iters: 8784, time: 0.170, data: 0.000) loss: 0.116 
(epoch: 194, iters: 8864, time: 0.170, data: 0.006) loss: 0.137 
(epoch: 194, iters: 8944, time: 0.171, data: 0.017) loss: 0.251 
(epoch: 194, iters: 9024, time: 0.168, data: 0.000) loss: 0.151 
(epoch: 194, iters: 9104, time: 0.165, data: 0.000) loss: 0.294 
(epoch: 194, iters: 9184, time: 0.171, data: 0.017) loss: 0.344 
(epoch: 194, iters: 9264, time: 0.169, data: 0.000) loss: 0.236 
(epoch: 194, iters: 9344, time: 0.174, data: 0.000) loss: 0.079 
(epoch: 194, iters: 9424, time: 0.171, data: 0.019) loss: 0.261 
(epoch: 194, iters: 9504, time: 0.173, data: 0.000) loss: 0.107 
(epoch: 194, iters: 9584, time: 0.170, data: 0.009) loss: 0.340 
(epoch: 194, iters: 9664, time: 0.168, data: 0.000) loss: 0.085 
(epoch: 194, iters: 9744, time: 0.173, data: 0.000) loss: 0.370 
(epoch: 194, iters: 9824, time: 0.173, data: 0.034) loss: 0.215 
(epoch: 194, iters: 9904, time: 0.171, data: 0.000) loss: 0.321 
(epoch: 194, iters: 9984, time: 0.169, data: 0.010) loss: 0.367 
(epoch: 194, iters: 10064, time: 0.171, data: 0.000) loss: 0.282 
(epoch: 194, iters: 10144, time: 0.166, data: 0.000) loss: 0.293 
saving the model at the end of epoch 194, iters 1977248
End of epoch 194 / 200 	 Time Taken: 1778 sec
learning rate = 0.0000099
saving the latest model (epoch 195, total_steps 1977264)
(epoch: 195, iters: 32, time: 0.181, data: 0.006) loss: 0.313 
(epoch: 195, iters: 112, time: 0.170, data: 0.022) loss: 0.315 
(epoch: 195, iters: 192, time: 0.173, data: 0.000) loss: 0.060 
(epoch: 195, iters: 272, time: 0.173, data: 0.000) loss: 0.069 
(epoch: 195, iters: 352, time: 0.176, data: 0.000) loss: 0.351 
(epoch: 195, iters: 432, time: 0.199, data: 0.009) loss: 0.232 
(epoch: 195, iters: 512, time: 0.171, data: 0.000) loss: 0.575 
(epoch: 195, iters: 592, time: 0.171, data: 0.009) loss: 0.345 
(epoch: 195, iters: 672, time: 0.169, data: 0.000) loss: 0.474 
(epoch: 195, iters: 752, time: 0.169, data: 0.009) loss: 0.129 
(epoch: 195, iters: 832, time: 0.172, data: 0.008) loss: 0.237 
(epoch: 195, iters: 912, time: 0.171, data: 0.021) loss: 0.063 
(epoch: 195, iters: 992, time: 0.171, data: 0.000) loss: 0.277 
(epoch: 195, iters: 1072, time: 0.172, data: 0.000) loss: 0.092 
(epoch: 195, iters: 1152, time: 0.170, data: 0.000) loss: 0.208 
(epoch: 195, iters: 1232, time: 0.173, data: 0.000) loss: 0.018 
(epoch: 195, iters: 1312, time: 0.170, data: 0.000) loss: 0.784 
(epoch: 195, iters: 1392, time: 0.172, data: 0.043) loss: 0.107 
(epoch: 195, iters: 1472, time: 0.174, data: 0.000) loss: 0.411 
(epoch: 195, iters: 1552, time: 0.171, data: 0.009) loss: 0.274 
(epoch: 195, iters: 1632, time: 0.172, data: 0.000) loss: 0.218 
(epoch: 195, iters: 1712, time: 0.172, data: 0.021) loss: 0.503 
(epoch: 195, iters: 1792, time: 0.175, data: 0.008) loss: 0.278 
(epoch: 195, iters: 1872, time: 0.203, data: 0.000) loss: 0.690 
(epoch: 195, iters: 1952, time: 0.202, data: 0.000) loss: 0.373 
(epoch: 195, iters: 2032, time: 0.171, data: 0.000) loss: 0.075 
(epoch: 195, iters: 2112, time: 0.169, data: 0.000) loss: 0.213 
(epoch: 195, iters: 2192, time: 0.170, data: 0.021) loss: 0.037 
(epoch: 195, iters: 2272, time: 0.170, data: 0.009) loss: 0.308 
(epoch: 195, iters: 2352, time: 0.168, data: 0.021) loss: 0.163 
(epoch: 195, iters: 2432, time: 0.170, data: 0.000) loss: 0.228 
(epoch: 195, iters: 2512, time: 0.169, data: 0.022) loss: 0.511 
(epoch: 195, iters: 2592, time: 0.168, data: 0.000) loss: 0.210 
(epoch: 195, iters: 2672, time: 0.175, data: 0.000) loss: 0.230 
(epoch: 195, iters: 2752, time: 0.203, data: 0.034) loss: 0.176 
(epoch: 195, iters: 2832, time: 0.173, data: 0.000) loss: 0.229 
(epoch: 195, iters: 2912, time: 0.174, data: 0.017) loss: 0.259 
(epoch: 195, iters: 2992, time: 0.174, data: 0.000) loss: 0.490 
(epoch: 195, iters: 3072, time: 0.170, data: 0.017) loss: 0.179 
(epoch: 195, iters: 3152, time: 0.173, data: 0.000) loss: 0.098 
(epoch: 195, iters: 3232, time: 0.170, data: 0.009) loss: 0.133 
(epoch: 195, iters: 3312, time: 0.201, data: 0.000) loss: 0.186 
(epoch: 195, iters: 3392, time: 0.173, data: 0.000) loss: 0.252 
(epoch: 195, iters: 3472, time: 0.172, data: 0.043) loss: 0.392 
(epoch: 195, iters: 3552, time: 0.173, data: 0.000) loss: 0.054 
(epoch: 195, iters: 3632, time: 0.172, data: 0.009) loss: 0.173 
(epoch: 195, iters: 3712, time: 0.169, data: 0.000) loss: 0.286 
(epoch: 195, iters: 3792, time: 0.169, data: 0.021) loss: 0.041 
(epoch: 195, iters: 3872, time: 0.169, data: 0.009) loss: 0.271 
(epoch: 195, iters: 3952, time: 0.198, data: 0.022) loss: 0.229 
saving the latest model (epoch 195, total_steps 1981264)
(epoch: 195, iters: 4032, time: 0.168, data: 0.000) loss: 0.114 
(epoch: 195, iters: 4112, time: 0.171, data: 0.000) loss: 0.275 
(epoch: 195, iters: 4192, time: 0.167, data: 0.010) loss: 0.149 
(epoch: 195, iters: 4272, time: 0.172, data: 0.000) loss: 0.327 
(epoch: 195, iters: 4352, time: 0.170, data: 0.000) loss: 0.239 
(epoch: 195, iters: 4432, time: 0.169, data: 0.021) loss: 0.043 
(epoch: 195, iters: 4512, time: 0.163, data: 0.000) loss: 0.200 
(epoch: 195, iters: 4592, time: 0.167, data: 0.000) loss: 0.209 
(epoch: 195, iters: 4672, time: 0.169, data: 0.021) loss: 0.080 
(epoch: 195, iters: 4752, time: 0.167, data: 0.000) loss: 0.437 
(epoch: 195, iters: 4832, time: 0.166, data: 0.000) loss: 0.202 
(epoch: 195, iters: 4912, time: 0.168, data: 0.021) loss: 0.094 
(epoch: 195, iters: 4992, time: 0.168, data: 0.009) loss: 0.209 
(epoch: 195, iters: 5072, time: 0.195, data: 0.000) loss: 0.506 
(epoch: 195, iters: 5152, time: 0.170, data: 0.022) loss: 0.053 
(epoch: 195, iters: 5232, time: 0.170, data: 0.035) loss: 0.122 
(epoch: 195, iters: 5312, time: 0.173, data: 0.000) loss: 0.472 
(epoch: 195, iters: 5392, time: 0.169, data: 0.000) loss: 0.024 
(epoch: 195, iters: 5472, time: 0.170, data: 0.042) loss: 0.267 
(epoch: 195, iters: 5552, time: 0.198, data: 0.000) loss: 0.201 
(epoch: 195, iters: 5632, time: 0.169, data: 0.008) loss: 0.049 
(epoch: 195, iters: 5712, time: 0.169, data: 0.000) loss: 0.211 
(epoch: 195, iters: 5792, time: 0.198, data: 0.009) loss: 0.345 
(epoch: 195, iters: 5872, time: 0.195, data: 0.000) loss: 0.186 
(epoch: 195, iters: 5952, time: 0.169, data: 0.006) loss: 0.126 
(epoch: 195, iters: 6032, time: 0.168, data: 0.000) loss: 0.052 
(epoch: 195, iters: 6112, time: 0.172, data: 0.000) loss: 0.267 
(epoch: 195, iters: 6192, time: 0.168, data: 0.025) loss: 0.262 
(epoch: 195, iters: 6272, time: 0.171, data: 0.021) loss: 0.160 
(epoch: 195, iters: 6352, time: 0.170, data: 0.000) loss: 0.282 
(epoch: 195, iters: 6432, time: 0.201, data: 0.008) loss: 0.275 
(epoch: 195, iters: 6512, time: 0.166, data: 0.000) loss: 0.139 
(epoch: 195, iters: 6592, time: 0.171, data: 0.000) loss: 0.041 
(epoch: 195, iters: 6672, time: 0.172, data: 0.000) loss: 0.097 
(epoch: 195, iters: 6752, time: 0.170, data: 0.000) loss: 0.129 
(epoch: 195, iters: 6832, time: 0.168, data: 0.000) loss: 0.490 
(epoch: 195, iters: 6912, time: 0.173, data: 0.000) loss: 0.167 
(epoch: 195, iters: 6992, time: 0.203, data: 0.000) loss: 0.669 
(epoch: 195, iters: 7072, time: 0.170, data: 0.005) loss: 0.273 
(epoch: 195, iters: 7152, time: 0.169, data: 0.000) loss: 0.570 
(epoch: 195, iters: 7232, time: 0.174, data: 0.000) loss: 0.198 
(epoch: 195, iters: 7312, time: 0.170, data: 0.009) loss: 0.234 
(epoch: 195, iters: 7392, time: 0.170, data: 0.030) loss: 0.121 
(epoch: 195, iters: 7472, time: 0.173, data: 0.000) loss: 0.114 
(epoch: 195, iters: 7552, time: 0.171, data: 0.000) loss: 0.321 
(epoch: 195, iters: 7632, time: 0.201, data: 0.000) loss: 0.038 
(epoch: 195, iters: 7712, time: 0.203, data: 0.000) loss: 0.148 
(epoch: 195, iters: 7792, time: 0.171, data: 0.025) loss: 0.344 
(epoch: 195, iters: 7872, time: 0.172, data: 0.008) loss: 0.041 
(epoch: 195, iters: 7952, time: 0.168, data: 0.000) loss: 0.114 
saving the latest model (epoch 195, total_steps 1985264)
(epoch: 195, iters: 8032, time: 0.176, data: 0.000) loss: 0.069 
(epoch: 195, iters: 8112, time: 0.171, data: 0.021) loss: 0.207 
(epoch: 195, iters: 8192, time: 0.171, data: 0.000) loss: 0.276 
(epoch: 195, iters: 8272, time: 0.168, data: 0.000) loss: 0.276 
(epoch: 195, iters: 8352, time: 0.172, data: 0.034) loss: 0.539 
(epoch: 195, iters: 8432, time: 0.169, data: 0.000) loss: 0.132 
(epoch: 195, iters: 8512, time: 0.201, data: 0.009) loss: 0.374 
(epoch: 195, iters: 8592, time: 0.199, data: 0.000) loss: 0.418 
(epoch: 195, iters: 8672, time: 0.174, data: 0.033) loss: 0.130 
(epoch: 195, iters: 8752, time: 0.171, data: 0.000) loss: 0.316 
(epoch: 195, iters: 8832, time: 0.175, data: 0.000) loss: 0.374 
(epoch: 195, iters: 8912, time: 0.175, data: 0.000) loss: 0.150 
(epoch: 195, iters: 8992, time: 0.174, data: 0.039) loss: 0.094 
(epoch: 195, iters: 9072, time: 0.175, data: 0.000) loss: 0.228 
(epoch: 195, iters: 9152, time: 0.177, data: 0.000) loss: 0.461 
(epoch: 195, iters: 9232, time: 0.176, data: 0.009) loss: 0.094 
(epoch: 195, iters: 9312, time: 0.174, data: 0.000) loss: 0.210 
(epoch: 195, iters: 9392, time: 0.176, data: 0.029) loss: 0.227 
(epoch: 195, iters: 9472, time: 0.174, data: 0.000) loss: 0.176 
(epoch: 195, iters: 9552, time: 0.175, data: 0.026) loss: 0.630 
(epoch: 195, iters: 9632, time: 0.200, data: 0.000) loss: 0.036 
(epoch: 195, iters: 9712, time: 0.171, data: 0.009) loss: 0.288 
(epoch: 195, iters: 9792, time: 0.172, data: 0.000) loss: 0.286 
(epoch: 195, iters: 9872, time: 0.169, data: 0.000) loss: 0.189 
(epoch: 195, iters: 9952, time: 0.197, data: 0.021) loss: 0.692 
(epoch: 195, iters: 10032, time: 0.172, data: 0.000) loss: 0.325 
(epoch: 195, iters: 10112, time: 0.172, data: 0.000) loss: 0.100 
(epoch: 195, iters: 10192, time: 0.101, data: 0.013) loss: 0.100 
saving the model at the end of epoch 195, iters 1987440
End of epoch 195 / 200 	 Time Taken: 1786 sec
learning rate = 0.0000079
saving the latest model (epoch 196, total_steps 1987456)
(epoch: 196, iters: 80, time: 0.174, data: 0.222) loss: 0.162 
(epoch: 196, iters: 160, time: 0.170, data: 0.014) loss: 0.096 
(epoch: 196, iters: 240, time: 0.168, data: 0.000) loss: 0.148 
(epoch: 196, iters: 320, time: 0.172, data: 0.009) loss: 0.104 
(epoch: 196, iters: 400, time: 0.165, data: 0.000) loss: 0.399 
(epoch: 196, iters: 480, time: 0.166, data: 0.008) loss: 0.112 
(epoch: 196, iters: 560, time: 0.171, data: 0.008) loss: 0.313 
(epoch: 196, iters: 640, time: 0.171, data: 0.000) loss: 0.340 
(epoch: 196, iters: 720, time: 0.170, data: 0.000) loss: 0.185 
(epoch: 196, iters: 800, time: 0.166, data: 0.033) loss: 0.374 
(epoch: 196, iters: 880, time: 0.169, data: 0.000) loss: 0.356 
(epoch: 196, iters: 960, time: 0.167, data: 0.009) loss: 0.122 
(epoch: 196, iters: 1040, time: 0.169, data: 0.000) loss: 0.166 
(epoch: 196, iters: 1120, time: 0.171, data: 0.008) loss: 0.187 
(epoch: 196, iters: 1200, time: 0.172, data: 0.000) loss: 0.192 
(epoch: 196, iters: 1280, time: 0.170, data: 0.000) loss: 0.058 
(epoch: 196, iters: 1360, time: 0.169, data: 0.008) loss: 0.119 
(epoch: 196, iters: 1440, time: 0.166, data: 0.009) loss: 0.172 
(epoch: 196, iters: 1520, time: 0.175, data: 0.009) loss: 0.759 
(epoch: 196, iters: 1600, time: 0.171, data: 0.009) loss: 0.381 
(epoch: 196, iters: 1680, time: 0.172, data: 0.009) loss: 0.066 
(epoch: 196, iters: 1760, time: 0.166, data: 0.009) loss: 0.153 
(epoch: 196, iters: 1840, time: 0.171, data: 0.009) loss: 0.157 
(epoch: 196, iters: 1920, time: 0.168, data: 0.025) loss: 0.158 
(epoch: 196, iters: 2000, time: 0.172, data: 0.000) loss: 0.301 
(epoch: 196, iters: 2080, time: 0.183, data: 0.000) loss: 0.298 
(epoch: 196, iters: 2160, time: 0.166, data: 0.017) loss: 0.186 
(epoch: 196, iters: 2240, time: 0.170, data: 0.022) loss: 0.075 
(epoch: 196, iters: 2320, time: 0.170, data: 0.000) loss: 0.346 
(epoch: 196, iters: 2400, time: 0.166, data: 0.000) loss: 0.599 
(epoch: 196, iters: 2480, time: 0.173, data: 0.009) loss: 0.161 
(epoch: 196, iters: 2560, time: 0.172, data: 0.000) loss: 0.389 
(epoch: 196, iters: 2640, time: 0.170, data: 0.000) loss: 0.433 
(epoch: 196, iters: 2720, time: 0.174, data: 0.014) loss: 0.163 
(epoch: 196, iters: 2800, time: 0.204, data: 0.009) loss: 0.141 
(epoch: 196, iters: 2880, time: 0.173, data: 0.009) loss: 0.294 
(epoch: 196, iters: 2960, time: 0.199, data: 0.000) loss: 0.131 
(epoch: 196, iters: 3040, time: 0.171, data: 0.008) loss: 0.083 
(epoch: 196, iters: 3120, time: 0.170, data: 0.000) loss: 0.445 
(epoch: 196, iters: 3200, time: 0.170, data: 0.042) loss: 0.227 
(epoch: 196, iters: 3280, time: 0.167, data: 0.000) loss: 0.079 
(epoch: 196, iters: 3360, time: 0.197, data: 0.000) loss: 0.065 
(epoch: 196, iters: 3440, time: 0.172, data: 0.009) loss: 0.352 
(epoch: 196, iters: 3520, time: 0.169, data: 0.000) loss: 0.274 
(epoch: 196, iters: 3600, time: 0.169, data: 0.000) loss: 0.175 
(epoch: 196, iters: 3680, time: 0.201, data: 0.000) loss: 0.105 
(epoch: 196, iters: 3760, time: 0.167, data: 0.000) loss: 0.195 
(epoch: 196, iters: 3840, time: 0.167, data: 0.000) loss: 0.303 
(epoch: 196, iters: 3920, time: 0.174, data: 0.012) loss: 0.280 
(epoch: 196, iters: 4000, time: 0.172, data: 0.000) loss: 0.441 
saving the latest model (epoch 196, total_steps 1991456)
(epoch: 196, iters: 4080, time: 0.167, data: 0.019) loss: 0.265 
(epoch: 196, iters: 4160, time: 0.173, data: 0.021) loss: 0.057 
(epoch: 196, iters: 4240, time: 0.174, data: 0.000) loss: 0.079 
(epoch: 196, iters: 4320, time: 0.172, data: 0.000) loss: 0.044 
(epoch: 196, iters: 4400, time: 0.202, data: 0.010) loss: 0.082 
(epoch: 196, iters: 4480, time: 0.170, data: 0.000) loss: 0.218 
(epoch: 196, iters: 4560, time: 0.176, data: 0.017) loss: 0.389 
(epoch: 196, iters: 4640, time: 0.176, data: 0.000) loss: 0.417 
(epoch: 196, iters: 4720, time: 0.171, data: 0.009) loss: 0.098 
(epoch: 196, iters: 4800, time: 0.175, data: 0.000) loss: 0.086 
(epoch: 196, iters: 4880, time: 0.174, data: 0.000) loss: 0.204 
(epoch: 196, iters: 4960, time: 0.176, data: 0.026) loss: 0.235 
(epoch: 196, iters: 5040, time: 0.178, data: 0.000) loss: 0.037 
(epoch: 196, iters: 5120, time: 0.199, data: 0.000) loss: 0.143 
(epoch: 196, iters: 5200, time: 0.171, data: 0.000) loss: 0.307 
(epoch: 196, iters: 5280, time: 0.171, data: 0.024) loss: 0.150 
(epoch: 196, iters: 5360, time: 0.173, data: 0.000) loss: 0.096 
(epoch: 196, iters: 5440, time: 0.169, data: 0.009) loss: 0.330 
(epoch: 196, iters: 5520, time: 0.169, data: 0.030) loss: 0.099 
(epoch: 196, iters: 5600, time: 0.171, data: 0.009) loss: 0.225 
(epoch: 196, iters: 5680, time: 0.174, data: 0.000) loss: 0.109 
(epoch: 196, iters: 5760, time: 0.173, data: 0.009) loss: 0.230 
(epoch: 196, iters: 5840, time: 0.169, data: 0.009) loss: 0.213 
(epoch: 196, iters: 5920, time: 0.172, data: 0.000) loss: 0.185 
(epoch: 196, iters: 6000, time: 0.175, data: 0.000) loss: 0.355 
(epoch: 196, iters: 6080, time: 0.171, data: 0.008) loss: 0.193 
(epoch: 196, iters: 6160, time: 0.175, data: 0.000) loss: 0.102 
(epoch: 196, iters: 6240, time: 0.202, data: 0.008) loss: 0.105 
(epoch: 196, iters: 6320, time: 0.176, data: 0.000) loss: 0.098 
(epoch: 196, iters: 6400, time: 0.203, data: 0.000) loss: 0.171 
(epoch: 196, iters: 6480, time: 0.174, data: 0.017) loss: 0.023 
(epoch: 196, iters: 6560, time: 0.171, data: 0.000) loss: 0.245 
(epoch: 196, iters: 6640, time: 0.172, data: 0.009) loss: 0.183 
(epoch: 196, iters: 6720, time: 0.170, data: 0.000) loss: 0.027 
(epoch: 196, iters: 6800, time: 0.171, data: 0.009) loss: 0.269 
(epoch: 196, iters: 6880, time: 0.170, data: 0.000) loss: 0.488 
(epoch: 196, iters: 6960, time: 0.174, data: 0.009) loss: 0.204 
(epoch: 196, iters: 7040, time: 0.181, data: 0.000) loss: 0.472 
(epoch: 196, iters: 7120, time: 0.173, data: 0.000) loss: 0.112 
(epoch: 196, iters: 7200, time: 0.174, data: 0.000) loss: 0.193 
(epoch: 196, iters: 7280, time: 0.174, data: 0.021) loss: 0.148 
(epoch: 196, iters: 7360, time: 0.176, data: 0.000) loss: 0.386 
(epoch: 196, iters: 7440, time: 0.174, data: 0.000) loss: 0.228 
(epoch: 196, iters: 7520, time: 0.175, data: 0.000) loss: 0.253 
(epoch: 196, iters: 7600, time: 0.175, data: 0.042) loss: 0.244 
(epoch: 196, iters: 7680, time: 0.174, data: 0.000) loss: 0.142 
(epoch: 196, iters: 7760, time: 0.174, data: 0.009) loss: 0.284 
(epoch: 196, iters: 7840, time: 0.173, data: 0.000) loss: 0.152 
(epoch: 196, iters: 7920, time: 0.170, data: 0.016) loss: 0.063 
(epoch: 196, iters: 8000, time: 0.169, data: 0.009) loss: 0.347 
saving the latest model (epoch 196, total_steps 1995456)
(epoch: 196, iters: 8080, time: 0.170, data: 0.009) loss: 0.568 
(epoch: 196, iters: 8160, time: 0.173, data: 0.000) loss: 0.142 
(epoch: 196, iters: 8240, time: 0.175, data: 0.008) loss: 0.357 
(epoch: 196, iters: 8320, time: 0.169, data: 0.000) loss: 0.133 
(epoch: 196, iters: 8400, time: 0.175, data: 0.000) loss: 0.046 
(epoch: 196, iters: 8480, time: 0.200, data: 0.000) loss: 0.241 
(epoch: 196, iters: 8560, time: 0.172, data: 0.009) loss: 0.062 
(epoch: 196, iters: 8640, time: 0.172, data: 0.000) loss: 0.183 
(epoch: 196, iters: 8720, time: 0.171, data: 0.021) loss: 0.157 
(epoch: 196, iters: 8800, time: 0.172, data: 0.009) loss: 0.513 
(epoch: 196, iters: 8880, time: 0.173, data: 0.000) loss: 0.181 
(epoch: 196, iters: 8960, time: 0.176, data: 0.008) loss: 0.132 
(epoch: 196, iters: 9040, time: 0.174, data: 0.000) loss: 0.268 
(epoch: 196, iters: 9120, time: 0.173, data: 0.000) loss: 0.158 
(epoch: 196, iters: 9200, time: 0.173, data: 0.009) loss: 0.149 
(epoch: 196, iters: 9280, time: 0.171, data: 0.000) loss: 0.143 
(epoch: 196, iters: 9360, time: 0.173, data: 0.044) loss: 0.209 
(epoch: 196, iters: 9440, time: 0.170, data: 0.000) loss: 0.129 
(epoch: 196, iters: 9520, time: 0.166, data: 0.000) loss: 0.093 
(epoch: 196, iters: 9600, time: 0.169, data: 0.000) loss: 0.326 
(epoch: 196, iters: 9680, time: 0.169, data: 0.009) loss: 0.085 
(epoch: 196, iters: 9760, time: 0.171, data: 0.000) loss: 0.150 
(epoch: 196, iters: 9840, time: 0.176, data: 0.009) loss: 0.147 
(epoch: 196, iters: 9920, time: 0.171, data: 0.000) loss: 0.435 
(epoch: 196, iters: 10000, time: 0.175, data: 0.000) loss: 0.162 
(epoch: 196, iters: 10080, time: 0.171, data: 0.000) loss: 0.132 
(epoch: 196, iters: 10160, time: 0.168, data: 0.000) loss: 0.200 
saving the model at the end of epoch 196, iters 1997632
End of epoch 196 / 200 	 Time Taken: 1784 sec
learning rate = 0.0000059
saving the latest model (epoch 197, total_steps 1997648)
(epoch: 197, iters: 48, time: 0.179, data: 0.008) loss: 0.224 
(epoch: 197, iters: 128, time: 0.197, data: 0.015) loss: 0.126 
(epoch: 197, iters: 208, time: 0.171, data: 0.009) loss: 0.454 
(epoch: 197, iters: 288, time: 0.173, data: 0.009) loss: 0.529 
(epoch: 197, iters: 368, time: 0.174, data: 0.026) loss: 0.312 
(epoch: 197, iters: 448, time: 0.172, data: 0.000) loss: 0.521 
(epoch: 197, iters: 528, time: 0.173, data: 0.008) loss: 0.255 
(epoch: 197, iters: 608, time: 0.169, data: 0.026) loss: 0.074 
(epoch: 197, iters: 688, time: 0.171, data: 0.000) loss: 0.274 
(epoch: 197, iters: 768, time: 0.173, data: 0.008) loss: 0.070 
(epoch: 197, iters: 848, time: 0.174, data: 0.000) loss: 0.163 
(epoch: 197, iters: 928, time: 0.168, data: 0.026) loss: 0.213 
(epoch: 197, iters: 1008, time: 0.200, data: 0.000) loss: 0.392 
(epoch: 197, iters: 1088, time: 0.169, data: 0.000) loss: 0.086 
(epoch: 197, iters: 1168, time: 0.168, data: 0.034) loss: 0.088 
(epoch: 197, iters: 1248, time: 0.168, data: 0.000) loss: 0.241 
(epoch: 197, iters: 1328, time: 0.170, data: 0.009) loss: 0.105 
(epoch: 197, iters: 1408, time: 0.170, data: 0.000) loss: 0.308 
(epoch: 197, iters: 1488, time: 0.170, data: 0.021) loss: 0.149 
(epoch: 197, iters: 1568, time: 0.168, data: 0.009) loss: 0.225 
(epoch: 197, iters: 1648, time: 0.170, data: 0.000) loss: 0.065 
(epoch: 197, iters: 1728, time: 0.170, data: 0.000) loss: 0.071 
(epoch: 197, iters: 1808, time: 0.168, data: 0.000) loss: 0.096 
(epoch: 197, iters: 1888, time: 0.169, data: 0.000) loss: 0.220 
(epoch: 197, iters: 1968, time: 0.174, data: 0.000) loss: 0.065 
(epoch: 197, iters: 2048, time: 0.201, data: 0.000) loss: 0.037 
(epoch: 197, iters: 2128, time: 0.172, data: 0.021) loss: 0.253 
(epoch: 197, iters: 2208, time: 0.170, data: 0.000) loss: 0.269 
(epoch: 197, iters: 2288, time: 0.173, data: 0.034) loss: 0.324 
(epoch: 197, iters: 2368, time: 0.171, data: 0.000) loss: 0.148 
(epoch: 197, iters: 2448, time: 0.171, data: 0.009) loss: 0.140 
(epoch: 197, iters: 2528, time: 0.175, data: 0.026) loss: 0.172 
(epoch: 197, iters: 2608, time: 0.172, data: 0.000) loss: 0.319 
(epoch: 197, iters: 2688, time: 0.170, data: 0.030) loss: 0.067 
(epoch: 197, iters: 2768, time: 0.171, data: 0.000) loss: 0.249 
(epoch: 197, iters: 2848, time: 0.169, data: 0.000) loss: 0.122 
(epoch: 197, iters: 2928, time: 0.199, data: 0.022) loss: 0.118 
(epoch: 197, iters: 3008, time: 0.174, data: 0.009) loss: 0.151 
(epoch: 197, iters: 3088, time: 0.173, data: 0.022) loss: 0.238 
(epoch: 197, iters: 3168, time: 0.197, data: 0.000) loss: 0.533 
(epoch: 197, iters: 3248, time: 0.170, data: 0.006) loss: 0.635 
(epoch: 197, iters: 3328, time: 0.175, data: 0.017) loss: 0.215 
(epoch: 197, iters: 3408, time: 0.172, data: 0.000) loss: 0.052 
(epoch: 197, iters: 3488, time: 0.173, data: 0.022) loss: 0.368 
(epoch: 197, iters: 3568, time: 0.172, data: 0.000) loss: 0.101 
(epoch: 197, iters: 3648, time: 0.169, data: 0.000) loss: 0.210 
(epoch: 197, iters: 3728, time: 0.169, data: 0.000) loss: 0.296 
(epoch: 197, iters: 3808, time: 0.171, data: 0.008) loss: 0.143 
(epoch: 197, iters: 3888, time: 0.172, data: 0.000) loss: 0.152 
(epoch: 197, iters: 3968, time: 0.171, data: 0.000) loss: 0.140 
saving the latest model (epoch 197, total_steps 2001648)
(epoch: 197, iters: 4048, time: 0.175, data: 0.034) loss: 0.099 
(epoch: 197, iters: 4128, time: 0.172, data: 0.000) loss: 0.129 
(epoch: 197, iters: 4208, time: 0.171, data: 0.000) loss: 0.305 
(epoch: 197, iters: 4288, time: 0.170, data: 0.000) loss: 0.168 
(epoch: 197, iters: 4368, time: 0.167, data: 0.000) loss: 0.501 
(epoch: 197, iters: 4448, time: 0.174, data: 0.000) loss: 0.160 
(epoch: 197, iters: 4528, time: 0.168, data: 0.034) loss: 0.201 
(epoch: 197, iters: 4608, time: 0.170, data: 0.000) loss: 0.057 
(epoch: 197, iters: 4688, time: 0.170, data: 0.009) loss: 0.078 
(epoch: 197, iters: 4768, time: 0.202, data: 0.009) loss: 0.230 
(epoch: 197, iters: 4848, time: 0.169, data: 0.034) loss: 0.248 
(epoch: 197, iters: 4928, time: 0.172, data: 0.000) loss: 0.180 
(epoch: 197, iters: 5008, time: 0.201, data: 0.018) loss: 0.385 
(epoch: 197, iters: 5088, time: 0.169, data: 0.000) loss: 0.315 
(epoch: 197, iters: 5168, time: 0.169, data: 0.035) loss: 0.082 
(epoch: 197, iters: 5248, time: 0.168, data: 0.000) loss: 0.166 
(epoch: 197, iters: 5328, time: 0.165, data: 0.009) loss: 0.143 
(epoch: 197, iters: 5408, time: 0.171, data: 0.031) loss: 0.103 
(epoch: 197, iters: 5488, time: 0.166, data: 0.000) loss: 0.348 
(epoch: 197, iters: 5568, time: 0.170, data: 0.000) loss: 0.027 
(epoch: 197, iters: 5648, time: 0.171, data: 0.000) loss: 0.195 
(epoch: 197, iters: 5728, time: 0.169, data: 0.030) loss: 0.080 
(epoch: 197, iters: 5808, time: 0.167, data: 0.037) loss: 0.648 
(epoch: 197, iters: 5888, time: 0.164, data: 0.022) loss: 0.211 
(epoch: 197, iters: 5968, time: 0.167, data: 0.009) loss: 0.155 
(epoch: 197, iters: 6048, time: 0.166, data: 0.026) loss: 0.251 
(epoch: 197, iters: 6128, time: 0.166, data: 0.000) loss: 0.640 
(epoch: 197, iters: 6208, time: 0.168, data: 0.009) loss: 0.185 
(epoch: 197, iters: 6288, time: 0.166, data: 0.000) loss: 0.165 
(epoch: 197, iters: 6368, time: 0.169, data: 0.000) loss: 0.286 
(epoch: 197, iters: 6448, time: 0.165, data: 0.009) loss: 0.074 
(epoch: 197, iters: 6528, time: 0.171, data: 0.015) loss: 0.243 
(epoch: 197, iters: 6608, time: 0.168, data: 0.021) loss: 0.153 
(epoch: 197, iters: 6688, time: 0.172, data: 0.009) loss: 0.133 
(epoch: 197, iters: 6768, time: 0.169, data: 0.025) loss: 0.375 
(epoch: 197, iters: 6848, time: 0.174, data: 0.000) loss: 0.468 
(epoch: 197, iters: 6928, time: 0.174, data: 0.000) loss: 0.212 
(epoch: 197, iters: 7008, time: 0.170, data: 0.000) loss: 0.181 
(epoch: 197, iters: 7088, time: 0.200, data: 0.000) loss: 0.231 
(epoch: 197, iters: 7168, time: 0.168, data: 0.034) loss: 0.154 
(epoch: 197, iters: 7248, time: 0.173, data: 0.000) loss: 0.132 
(epoch: 197, iters: 7328, time: 0.174, data: 0.030) loss: 0.138 
(epoch: 197, iters: 7408, time: 0.171, data: 0.024) loss: 0.064 
(epoch: 197, iters: 7488, time: 0.173, data: 0.016) loss: 0.051 
(epoch: 197, iters: 7568, time: 0.172, data: 0.000) loss: 0.297 
(epoch: 197, iters: 7648, time: 0.203, data: 0.000) loss: 0.373 
(epoch: 197, iters: 7728, time: 0.171, data: 0.000) loss: 0.053 
(epoch: 197, iters: 7808, time: 0.171, data: 0.024) loss: 0.061 
(epoch: 197, iters: 7888, time: 0.172, data: 0.000) loss: 0.037 
(epoch: 197, iters: 7968, time: 0.169, data: 0.005) loss: 0.081 
saving the latest model (epoch 197, total_steps 2005648)
(epoch: 197, iters: 8048, time: 0.173, data: 0.025) loss: 0.186 
(epoch: 197, iters: 8128, time: 0.174, data: 0.000) loss: 0.193 
(epoch: 197, iters: 8208, time: 0.175, data: 0.000) loss: 0.186 
(epoch: 197, iters: 8288, time: 0.204, data: 0.035) loss: 0.080 
(epoch: 197, iters: 8368, time: 0.173, data: 0.000) loss: 0.176 
(epoch: 197, iters: 8448, time: 0.182, data: 0.000) loss: 0.144 
(epoch: 197, iters: 8528, time: 0.170, data: 0.033) loss: 0.815 
(epoch: 197, iters: 8608, time: 0.172, data: 0.000) loss: 0.413 
(epoch: 197, iters: 8688, time: 0.171, data: 0.008) loss: 0.140 
(epoch: 197, iters: 8768, time: 0.174, data: 0.009) loss: 0.036 
(epoch: 197, iters: 8848, time: 0.203, data: 0.021) loss: 0.376 
(epoch: 197, iters: 8928, time: 0.174, data: 0.000) loss: 0.157 
(epoch: 197, iters: 9008, time: 0.170, data: 0.000) loss: 0.331 
(epoch: 197, iters: 9088, time: 0.171, data: 0.000) loss: 0.250 
(epoch: 197, iters: 9168, time: 0.171, data: 0.000) loss: 0.111 
(epoch: 197, iters: 9248, time: 0.176, data: 0.009) loss: 0.103 
(epoch: 197, iters: 9328, time: 0.203, data: 0.000) loss: 0.173 
(epoch: 197, iters: 9408, time: 0.175, data: 0.000) loss: 0.306 
(epoch: 197, iters: 9488, time: 0.203, data: 0.000) loss: 0.111 
(epoch: 197, iters: 9568, time: 0.175, data: 0.000) loss: 0.227 
(epoch: 197, iters: 9648, time: 0.175, data: 0.000) loss: 0.040 
(epoch: 197, iters: 9728, time: 0.169, data: 0.000) loss: 0.360 
(epoch: 197, iters: 9808, time: 0.172, data: 0.035) loss: 0.489 
(epoch: 197, iters: 9888, time: 0.175, data: 0.000) loss: 0.186 
(epoch: 197, iters: 9968, time: 0.174, data: 0.009) loss: 0.180 
(epoch: 197, iters: 10048, time: 0.176, data: 0.000) loss: 0.014 
(epoch: 197, iters: 10128, time: 0.174, data: 0.022) loss: 0.309 
saving the model at the end of epoch 197, iters 2007824
End of epoch 197 / 200 	 Time Taken: 1784 sec
learning rate = 0.0000040
(epoch: 198, iters: 16, time: 0.197, data: 0.009) loss: 0.167 
saving the latest model (epoch 198, total_steps 2007840)
(epoch: 198, iters: 96, time: 0.173, data: 0.000) loss: 0.104 
(epoch: 198, iters: 176, time: 0.171, data: 0.042) loss: 0.238 
(epoch: 198, iters: 256, time: 0.204, data: 0.000) loss: 0.308 
(epoch: 198, iters: 336, time: 0.170, data: 0.008) loss: 0.204 
(epoch: 198, iters: 416, time: 0.199, data: 0.026) loss: 0.184 
(epoch: 198, iters: 496, time: 0.202, data: 0.000) loss: 0.319 
(epoch: 198, iters: 576, time: 0.205, data: 0.000) loss: 0.089 
(epoch: 198, iters: 656, time: 0.170, data: 0.009) loss: 0.280 
(epoch: 198, iters: 736, time: 0.172, data: 0.000) loss: 0.198 
(epoch: 198, iters: 816, time: 0.173, data: 0.009) loss: 0.109 
(epoch: 198, iters: 896, time: 0.172, data: 0.000) loss: 0.056 
(epoch: 198, iters: 976, time: 0.173, data: 0.009) loss: 0.110 
(epoch: 198, iters: 1056, time: 0.168, data: 0.000) loss: 0.228 
(epoch: 198, iters: 1136, time: 0.174, data: 0.000) loss: 0.370 
(epoch: 198, iters: 1216, time: 0.169, data: 0.000) loss: 0.378 
(epoch: 198, iters: 1296, time: 0.172, data: 0.000) loss: 0.169 
(epoch: 198, iters: 1376, time: 0.173, data: 0.009) loss: 0.188 
(epoch: 198, iters: 1456, time: 0.173, data: 0.008) loss: 0.154 
(epoch: 198, iters: 1536, time: 0.174, data: 0.000) loss: 0.288 
(epoch: 198, iters: 1616, time: 0.176, data: 0.025) loss: 0.136 
(epoch: 198, iters: 1696, time: 0.171, data: 0.000) loss: 0.165 
(epoch: 198, iters: 1776, time: 0.172, data: 0.017) loss: 0.207 
(epoch: 198, iters: 1856, time: 0.172, data: 0.000) loss: 0.222 
(epoch: 198, iters: 1936, time: 0.176, data: 0.035) loss: 0.068 
(epoch: 198, iters: 2016, time: 0.175, data: 0.000) loss: 0.195 
(epoch: 198, iters: 2096, time: 0.170, data: 0.033) loss: 0.199 
(epoch: 198, iters: 2176, time: 0.172, data: 0.000) loss: 0.148 
(epoch: 198, iters: 2256, time: 0.177, data: 0.008) loss: 0.296 
(epoch: 198, iters: 2336, time: 0.176, data: 0.022) loss: 0.079 
(epoch: 198, iters: 2416, time: 0.177, data: 0.000) loss: 0.387 
(epoch: 198, iters: 2496, time: 0.175, data: 0.000) loss: 0.358 
(epoch: 198, iters: 2576, time: 0.199, data: 0.000) loss: 0.234 
(epoch: 198, iters: 2656, time: 0.204, data: 0.000) loss: 0.164 
(epoch: 198, iters: 2736, time: 0.199, data: 0.000) loss: 0.094 
(epoch: 198, iters: 2816, time: 0.199, data: 0.000) loss: 0.143 
(epoch: 198, iters: 2896, time: 0.173, data: 0.008) loss: 0.147 
(epoch: 198, iters: 2976, time: 0.201, data: 0.000) loss: 0.140 
(epoch: 198, iters: 3056, time: 0.171, data: 0.000) loss: 0.325 
(epoch: 198, iters: 3136, time: 0.170, data: 0.006) loss: 0.356 
(epoch: 198, iters: 3216, time: 0.171, data: 0.008) loss: 0.229 
(epoch: 198, iters: 3296, time: 0.175, data: 0.000) loss: 0.185 
(epoch: 198, iters: 3376, time: 0.173, data: 0.000) loss: 0.302 
(epoch: 198, iters: 3456, time: 0.173, data: 0.044) loss: 0.203 
(epoch: 198, iters: 3536, time: 0.172, data: 0.000) loss: 0.262 
(epoch: 198, iters: 3616, time: 0.174, data: 0.000) loss: 0.070 
(epoch: 198, iters: 3696, time: 0.171, data: 0.000) loss: 0.314 
(epoch: 198, iters: 3776, time: 0.172, data: 0.041) loss: 0.083 
(epoch: 198, iters: 3856, time: 0.173, data: 0.000) loss: 0.141 
(epoch: 198, iters: 3936, time: 0.175, data: 0.008) loss: 0.262 
(epoch: 198, iters: 4016, time: 0.170, data: 0.000) loss: 0.153 
saving the latest model (epoch 198, total_steps 2011840)
(epoch: 198, iters: 4096, time: 0.177, data: 0.009) loss: 0.319 
(epoch: 198, iters: 4176, time: 0.170, data: 0.000) loss: 0.246 
(epoch: 198, iters: 4256, time: 0.170, data: 0.000) loss: 0.151 
(epoch: 198, iters: 4336, time: 0.201, data: 0.009) loss: 0.036 
(epoch: 198, iters: 4416, time: 0.175, data: 0.000) loss: 0.303 
(epoch: 198, iters: 4496, time: 0.203, data: 0.009) loss: 0.220 
(epoch: 198, iters: 4576, time: 0.176, data: 0.000) loss: 0.202 
(epoch: 198, iters: 4656, time: 0.177, data: 0.000) loss: 0.081 
(epoch: 198, iters: 4736, time: 0.172, data: 0.033) loss: 0.205 
(epoch: 198, iters: 4816, time: 0.203, data: 0.000) loss: 0.195 
(epoch: 198, iters: 4896, time: 0.206, data: 0.000) loss: 0.275 
(epoch: 198, iters: 4976, time: 0.172, data: 0.000) loss: 0.292 
(epoch: 198, iters: 5056, time: 0.174, data: 0.008) loss: 0.192 
(epoch: 198, iters: 5136, time: 0.172, data: 0.025) loss: 0.033 
(epoch: 198, iters: 5216, time: 0.176, data: 0.000) loss: 0.434 
(epoch: 198, iters: 5296, time: 0.178, data: 0.008) loss: 0.181 
(epoch: 198, iters: 5376, time: 0.175, data: 0.000) loss: 0.534 
(epoch: 198, iters: 5456, time: 0.174, data: 0.000) loss: 0.434 
(epoch: 198, iters: 5536, time: 0.176, data: 0.009) loss: 0.212 
(epoch: 198, iters: 5616, time: 0.176, data: 0.000) loss: 0.150 
(epoch: 198, iters: 5696, time: 0.178, data: 0.021) loss: 0.404 
(epoch: 198, iters: 5776, time: 0.176, data: 0.009) loss: 0.053 
(epoch: 198, iters: 5856, time: 0.176, data: 0.008) loss: 0.790 
(epoch: 198, iters: 5936, time: 0.172, data: 0.000) loss: 0.172 
(epoch: 198, iters: 6016, time: 0.178, data: 0.021) loss: 0.093 
(epoch: 198, iters: 6096, time: 0.174, data: 0.000) loss: 0.138 
(epoch: 198, iters: 6176, time: 0.177, data: 0.000) loss: 0.025 
(epoch: 198, iters: 6256, time: 0.176, data: 0.010) loss: 0.356 
(epoch: 198, iters: 6336, time: 0.176, data: 0.000) loss: 0.257 
(epoch: 198, iters: 6416, time: 0.177, data: 0.021) loss: 0.420 
(epoch: 198, iters: 6496, time: 0.176, data: 0.008) loss: 0.185 
(epoch: 198, iters: 6576, time: 0.172, data: 0.006) loss: 0.090 
(epoch: 198, iters: 6656, time: 0.176, data: 0.000) loss: 0.261 
(epoch: 198, iters: 6736, time: 0.171, data: 0.010) loss: 0.132 
(epoch: 198, iters: 6816, time: 0.177, data: 0.000) loss: 0.028 
(epoch: 198, iters: 6896, time: 0.172, data: 0.000) loss: 0.228 
(epoch: 198, iters: 6976, time: 0.173, data: 0.000) loss: 0.396 
(epoch: 198, iters: 7056, time: 0.172, data: 0.008) loss: 0.144 
(epoch: 198, iters: 7136, time: 0.199, data: 0.000) loss: 0.290 
(epoch: 198, iters: 7216, time: 0.170, data: 0.000) loss: 0.234 
(epoch: 198, iters: 7296, time: 0.171, data: 0.008) loss: 0.234 
(epoch: 198, iters: 7376, time: 0.203, data: 0.021) loss: 0.158 
(epoch: 198, iters: 7456, time: 0.170, data: 0.009) loss: 0.045 
(epoch: 198, iters: 7536, time: 0.174, data: 0.000) loss: 0.334 
(epoch: 198, iters: 7616, time: 0.177, data: 0.009) loss: 0.061 
(epoch: 198, iters: 7696, time: 0.174, data: 0.000) loss: 0.424 
(epoch: 198, iters: 7776, time: 0.175, data: 0.009) loss: 0.478 
(epoch: 198, iters: 7856, time: 0.172, data: 0.039) loss: 0.261 
(epoch: 198, iters: 7936, time: 0.176, data: 0.000) loss: 0.233 
(epoch: 198, iters: 8016, time: 0.171, data: 0.043) loss: 0.122 
saving the latest model (epoch 198, total_steps 2015840)
(epoch: 198, iters: 8096, time: 0.199, data: 0.000) loss: 0.040 
(epoch: 198, iters: 8176, time: 0.173, data: 0.000) loss: 0.094 
(epoch: 198, iters: 8256, time: 0.172, data: 0.000) loss: 0.273 
(epoch: 198, iters: 8336, time: 0.174, data: 0.009) loss: 0.270 
(epoch: 198, iters: 8416, time: 0.205, data: 0.000) loss: 0.353 
(epoch: 198, iters: 8496, time: 0.173, data: 0.000) loss: 0.560 
(epoch: 198, iters: 8576, time: 0.176, data: 0.000) loss: 0.263 
(epoch: 198, iters: 8656, time: 0.173, data: 0.000) loss: 0.225 
(epoch: 198, iters: 8736, time: 0.176, data: 0.000) loss: 0.088 
(epoch: 198, iters: 8816, time: 0.204, data: 0.000) loss: 0.162 
(epoch: 198, iters: 8896, time: 0.177, data: 0.000) loss: 0.170 
(epoch: 198, iters: 8976, time: 0.205, data: 0.000) loss: 0.166 
(epoch: 198, iters: 9056, time: 0.173, data: 0.000) loss: 0.064 
(epoch: 198, iters: 9136, time: 0.176, data: 0.009) loss: 0.045 
(epoch: 198, iters: 9216, time: 0.176, data: 0.000) loss: 0.043 
(epoch: 198, iters: 9296, time: 0.203, data: 0.022) loss: 0.080 
(epoch: 198, iters: 9376, time: 0.178, data: 0.025) loss: 0.165 
(epoch: 198, iters: 9456, time: 0.174, data: 0.009) loss: 0.055 
(epoch: 198, iters: 9536, time: 0.173, data: 0.009) loss: 0.108 
(epoch: 198, iters: 9616, time: 0.176, data: 0.000) loss: 0.357 
(epoch: 198, iters: 9696, time: 0.174, data: 0.005) loss: 0.160 
(epoch: 198, iters: 9776, time: 0.176, data: 0.000) loss: 0.196 
(epoch: 198, iters: 9856, time: 0.177, data: 0.009) loss: 0.049 
(epoch: 198, iters: 9936, time: 0.171, data: 0.000) loss: 0.592 
(epoch: 198, iters: 10016, time: 0.171, data: 0.000) loss: 0.146 
(epoch: 198, iters: 10096, time: 0.177, data: 0.000) loss: 0.117 
(epoch: 198, iters: 10176, time: 0.171, data: 0.009) loss: 0.218 
saving the model at the end of epoch 198, iters 2018016
End of epoch 198 / 200 	 Time Taken: 1813 sec
learning rate = 0.0000020
saving the latest model (epoch 199, total_steps 2018032)
(epoch: 199, iters: 64, time: 0.205, data: 0.000) loss: 0.040 
(epoch: 199, iters: 144, time: 0.175, data: 0.049) loss: 0.284 
(epoch: 199, iters: 224, time: 0.172, data: 0.000) loss: 0.357 
(epoch: 199, iters: 304, time: 0.170, data: 0.009) loss: 0.023 
(epoch: 199, iters: 384, time: 0.168, data: 0.000) loss: 0.338 
(epoch: 199, iters: 464, time: 0.169, data: 0.009) loss: 0.484 
(epoch: 199, iters: 544, time: 0.168, data: 0.000) loss: 0.170 
(epoch: 199, iters: 624, time: 0.197, data: 0.000) loss: 0.153 
(epoch: 199, iters: 704, time: 0.172, data: 0.035) loss: 0.084 
(epoch: 199, iters: 784, time: 0.172, data: 0.000) loss: 0.074 
(epoch: 199, iters: 864, time: 0.170, data: 0.000) loss: 0.331 
(epoch: 199, iters: 944, time: 0.169, data: 0.000) loss: 0.275 
(epoch: 199, iters: 1024, time: 0.168, data: 0.000) loss: 0.113 
(epoch: 199, iters: 1104, time: 0.170, data: 0.008) loss: 0.067 
(epoch: 199, iters: 1184, time: 0.168, data: 0.000) loss: 0.071 
(epoch: 199, iters: 1264, time: 0.196, data: 0.000) loss: 0.190 
(epoch: 199, iters: 1344, time: 0.166, data: 0.000) loss: 0.207 
(epoch: 199, iters: 1424, time: 0.171, data: 0.009) loss: 0.194 
(epoch: 199, iters: 1504, time: 0.168, data: 0.031) loss: 0.021 
(epoch: 199, iters: 1584, time: 0.168, data: 0.000) loss: 0.079 
(epoch: 199, iters: 1664, time: 0.167, data: 0.017) loss: 0.347 
(epoch: 199, iters: 1744, time: 0.167, data: 0.000) loss: 0.247 
(epoch: 199, iters: 1824, time: 0.173, data: 0.000) loss: 0.236 
(epoch: 199, iters: 1904, time: 0.167, data: 0.000) loss: 0.333 
(epoch: 199, iters: 1984, time: 0.199, data: 0.021) loss: 0.224 
(epoch: 199, iters: 2064, time: 0.199, data: 0.021) loss: 0.182 
(epoch: 199, iters: 2144, time: 0.173, data: 0.000) loss: 0.039 
(epoch: 199, iters: 2224, time: 0.171, data: 0.005) loss: 0.150 
(epoch: 199, iters: 2304, time: 0.168, data: 0.000) loss: 0.226 
(epoch: 199, iters: 2384, time: 0.176, data: 0.000) loss: 0.147 
(epoch: 199, iters: 2464, time: 0.173, data: 0.008) loss: 0.280 
(epoch: 199, iters: 2544, time: 0.200, data: 0.000) loss: 0.030 
(epoch: 199, iters: 2624, time: 0.170, data: 0.009) loss: 0.126 
(epoch: 199, iters: 2704, time: 0.172, data: 0.000) loss: 0.077 
(epoch: 199, iters: 2784, time: 0.169, data: 0.000) loss: 0.246 
(epoch: 199, iters: 2864, time: 0.168, data: 0.033) loss: 0.258 
(epoch: 199, iters: 2944, time: 0.167, data: 0.000) loss: 0.205 
(epoch: 199, iters: 3024, time: 0.173, data: 0.009) loss: 0.216 
(epoch: 199, iters: 3104, time: 0.174, data: 0.025) loss: 0.114 
(epoch: 199, iters: 3184, time: 0.170, data: 0.000) loss: 0.357 
(epoch: 199, iters: 3264, time: 0.168, data: 0.000) loss: 0.666 
(epoch: 199, iters: 3344, time: 0.168, data: 0.000) loss: 0.750 
(epoch: 199, iters: 3424, time: 0.197, data: 0.000) loss: 0.436 
(epoch: 199, iters: 3504, time: 0.169, data: 0.024) loss: 0.108 
(epoch: 199, iters: 3584, time: 0.171, data: 0.021) loss: 0.049 
(epoch: 199, iters: 3664, time: 0.167, data: 0.000) loss: 0.194 
(epoch: 199, iters: 3744, time: 0.170, data: 0.008) loss: 0.156 
(epoch: 199, iters: 3824, time: 0.169, data: 0.000) loss: 0.252 
(epoch: 199, iters: 3904, time: 0.170, data: 0.005) loss: 0.260 
(epoch: 199, iters: 3984, time: 0.170, data: 0.000) loss: 0.103 
saving the latest model (epoch 199, total_steps 2022032)
(epoch: 199, iters: 4064, time: 0.172, data: 0.000) loss: 0.184 
(epoch: 199, iters: 4144, time: 0.176, data: 0.034) loss: 0.274 
(epoch: 199, iters: 4224, time: 0.169, data: 0.000) loss: 0.710 
(epoch: 199, iters: 4304, time: 0.171, data: 0.000) loss: 0.232 
(epoch: 199, iters: 4384, time: 0.166, data: 0.008) loss: 0.526 
(epoch: 199, iters: 4464, time: 0.167, data: 0.008) loss: 0.123 
(epoch: 199, iters: 4544, time: 0.167, data: 0.026) loss: 0.054 
(epoch: 199, iters: 4624, time: 0.169, data: 0.000) loss: 0.228 
(epoch: 199, iters: 4704, time: 0.170, data: 0.009) loss: 0.191 
(epoch: 199, iters: 4784, time: 0.169, data: 0.026) loss: 0.133 
(epoch: 199, iters: 4864, time: 0.200, data: 0.000) loss: 0.087 
(epoch: 199, iters: 4944, time: 0.172, data: 0.009) loss: 0.210 
(epoch: 199, iters: 5024, time: 0.169, data: 0.016) loss: 0.085 
(epoch: 199, iters: 5104, time: 0.166, data: 0.000) loss: 0.438 
(epoch: 199, iters: 5184, time: 0.172, data: 0.000) loss: 0.134 
(epoch: 199, iters: 5264, time: 0.168, data: 0.000) loss: 0.218 
(epoch: 199, iters: 5344, time: 0.167, data: 0.000) loss: 0.357 
(epoch: 199, iters: 5424, time: 0.169, data: 0.017) loss: 0.184 
(epoch: 199, iters: 5504, time: 0.172, data: 0.000) loss: 0.223 
(epoch: 199, iters: 5584, time: 0.171, data: 0.000) loss: 0.167 
(epoch: 199, iters: 5664, time: 0.173, data: 0.000) loss: 0.345 
(epoch: 199, iters: 5744, time: 0.169, data: 0.030) loss: 0.067 
(epoch: 199, iters: 5824, time: 0.168, data: 0.030) loss: 0.066 
(epoch: 199, iters: 5904, time: 0.166, data: 0.000) loss: 0.454 
(epoch: 199, iters: 5984, time: 0.172, data: 0.000) loss: 0.394 
(epoch: 199, iters: 6064, time: 0.174, data: 0.000) loss: 0.128 
(epoch: 199, iters: 6144, time: 0.169, data: 0.022) loss: 0.394 
(epoch: 199, iters: 6224, time: 0.173, data: 0.000) loss: 0.180 
(epoch: 199, iters: 6304, time: 0.201, data: 0.000) loss: 0.168 
(epoch: 199, iters: 6384, time: 0.176, data: 0.000) loss: 0.173 
(epoch: 199, iters: 6464, time: 0.202, data: 0.009) loss: 0.163 
(epoch: 199, iters: 6544, time: 0.170, data: 0.000) loss: 0.096 
(epoch: 199, iters: 6624, time: 0.172, data: 0.009) loss: 0.167 
(epoch: 199, iters: 6704, time: 0.174, data: 0.000) loss: 0.267 
(epoch: 199, iters: 6784, time: 0.174, data: 0.000) loss: 0.211 
(epoch: 199, iters: 6864, time: 0.171, data: 0.000) loss: 0.377 
(epoch: 199, iters: 6944, time: 0.173, data: 0.034) loss: 0.387 
(epoch: 199, iters: 7024, time: 0.173, data: 0.000) loss: 0.156 
(epoch: 199, iters: 7104, time: 0.202, data: 0.000) loss: 0.168 
(epoch: 199, iters: 7184, time: 0.201, data: 0.008) loss: 0.103 
(epoch: 199, iters: 7264, time: 0.201, data: 0.000) loss: 0.271 
(epoch: 199, iters: 7344, time: 0.172, data: 0.000) loss: 0.107 
(epoch: 199, iters: 7424, time: 0.174, data: 0.030) loss: 0.083 
(epoch: 199, iters: 7504, time: 0.170, data: 0.021) loss: 0.216 
(epoch: 199, iters: 7584, time: 0.170, data: 0.000) loss: 0.139 
(epoch: 199, iters: 7664, time: 0.199, data: 0.008) loss: 0.066 
(epoch: 199, iters: 7744, time: 0.171, data: 0.000) loss: 0.123 
(epoch: 199, iters: 7824, time: 0.172, data: 0.023) loss: 0.391 
(epoch: 199, iters: 7904, time: 0.171, data: 0.021) loss: 0.270 
(epoch: 199, iters: 7984, time: 0.169, data: 0.000) loss: 0.110 
saving the latest model (epoch 199, total_steps 2026032)
(epoch: 199, iters: 8064, time: 0.172, data: 0.042) loss: 0.091 
(epoch: 199, iters: 8144, time: 0.173, data: 0.000) loss: 0.397 
(epoch: 199, iters: 8224, time: 0.167, data: 0.009) loss: 0.219 
(epoch: 199, iters: 8304, time: 0.167, data: 0.000) loss: 0.084 
(epoch: 199, iters: 8384, time: 0.169, data: 0.009) loss: 0.113 
(epoch: 199, iters: 8464, time: 0.165, data: 0.000) loss: 0.244 
(epoch: 199, iters: 8544, time: 0.168, data: 0.000) loss: 0.327 
(epoch: 199, iters: 8624, time: 0.168, data: 0.017) loss: 0.227 
(epoch: 199, iters: 8704, time: 0.166, data: 0.000) loss: 0.166 
(epoch: 199, iters: 8784, time: 0.166, data: 0.034) loss: 0.179 
(epoch: 199, iters: 8864, time: 0.165, data: 0.000) loss: 0.026 
(epoch: 199, iters: 8944, time: 0.169, data: 0.000) loss: 0.243 
(epoch: 199, iters: 9024, time: 0.166, data: 0.000) loss: 0.069 
(epoch: 199, iters: 9104, time: 0.166, data: 0.034) loss: 0.083 
(epoch: 199, iters: 9184, time: 0.169, data: 0.000) loss: 0.065 
(epoch: 199, iters: 9264, time: 0.167, data: 0.000) loss: 0.149 
(epoch: 199, iters: 9344, time: 0.165, data: 0.009) loss: 0.225 
(epoch: 199, iters: 9424, time: 0.166, data: 0.021) loss: 0.250 
(epoch: 199, iters: 9504, time: 0.169, data: 0.000) loss: 0.116 
(epoch: 199, iters: 9584, time: 0.196, data: 0.000) loss: 0.184 
(epoch: 199, iters: 9664, time: 0.167, data: 0.036) loss: 0.072 
(epoch: 199, iters: 9744, time: 0.167, data: 0.000) loss: 0.057 
(epoch: 199, iters: 9824, time: 0.198, data: 0.041) loss: 0.323 
(epoch: 199, iters: 9904, time: 0.170, data: 0.000) loss: 0.151 
(epoch: 199, iters: 9984, time: 0.170, data: 0.035) loss: 0.359 
(epoch: 199, iters: 10064, time: 0.170, data: 0.000) loss: 0.078 
(epoch: 199, iters: 10144, time: 0.164, data: 0.034) loss: 0.089 
saving the model at the end of epoch 199, iters 2028208
End of epoch 199 / 200 	 Time Taken: 1768 sec
learning rate = 0.0000000
saving the latest model (epoch 200, total_steps 2028224)
(epoch: 200, iters: 32, time: 0.213, data: 0.000) loss: 0.131 
(epoch: 200, iters: 112, time: 0.174, data: 0.000) loss: 0.259 
(epoch: 200, iters: 192, time: 0.171, data: 0.011) loss: 0.293 
(epoch: 200, iters: 272, time: 0.175, data: 0.000) loss: 0.138 
(epoch: 200, iters: 352, time: 0.174, data: 0.009) loss: 0.094 
(epoch: 200, iters: 432, time: 0.167, data: 0.000) loss: 0.169 
(epoch: 200, iters: 512, time: 0.169, data: 0.000) loss: 0.209 
(epoch: 200, iters: 592, time: 0.174, data: 0.000) loss: 0.245 
(epoch: 200, iters: 672, time: 0.169, data: 0.000) loss: 0.261 
(epoch: 200, iters: 752, time: 0.170, data: 0.000) loss: 0.193 
(epoch: 200, iters: 832, time: 0.173, data: 0.000) loss: 0.191 
(epoch: 200, iters: 912, time: 0.169, data: 0.000) loss: 0.187 
(epoch: 200, iters: 992, time: 0.169, data: 0.000) loss: 0.433 
(epoch: 200, iters: 1072, time: 0.170, data: 0.033) loss: 0.219 
(epoch: 200, iters: 1152, time: 0.169, data: 0.000) loss: 0.197 
(epoch: 200, iters: 1232, time: 0.172, data: 0.009) loss: 0.178 
(epoch: 200, iters: 1312, time: 0.167, data: 0.000) loss: 0.126 
(epoch: 200, iters: 1392, time: 0.196, data: 0.008) loss: 0.291 
(epoch: 200, iters: 1472, time: 0.171, data: 0.000) loss: 0.437 
(epoch: 200, iters: 1552, time: 0.173, data: 0.005) loss: 0.432 
(epoch: 200, iters: 1632, time: 0.199, data: 0.000) loss: 0.176 
(epoch: 200, iters: 1712, time: 0.199, data: 0.030) loss: 0.054 
(epoch: 200, iters: 1792, time: 0.172, data: 0.000) loss: 0.244 
(epoch: 200, iters: 1872, time: 0.203, data: 0.024) loss: 0.103 
(epoch: 200, iters: 1952, time: 0.174, data: 0.021) loss: 0.565 
(epoch: 200, iters: 2032, time: 0.201, data: 0.000) loss: 0.158 
(epoch: 200, iters: 2112, time: 0.174, data: 0.026) loss: 0.187 
(epoch: 200, iters: 2192, time: 0.171, data: 0.000) loss: 0.275 
(epoch: 200, iters: 2272, time: 0.176, data: 0.008) loss: 0.377 
(epoch: 200, iters: 2352, time: 0.175, data: 0.000) loss: 0.263 
(epoch: 200, iters: 2432, time: 0.202, data: 0.009) loss: 0.091 
(epoch: 200, iters: 2512, time: 0.172, data: 0.009) loss: 0.195 
(epoch: 200, iters: 2592, time: 0.206, data: 0.000) loss: 0.079 
(epoch: 200, iters: 2672, time: 0.174, data: 0.000) loss: 0.112 
(epoch: 200, iters: 2752, time: 0.174, data: 0.033) loss: 0.280 
(epoch: 200, iters: 2832, time: 0.170, data: 0.000) loss: 0.142 
(epoch: 200, iters: 2912, time: 0.173, data: 0.000) loss: 0.056 
(epoch: 200, iters: 2992, time: 0.172, data: 0.034) loss: 0.231 
(epoch: 200, iters: 3072, time: 0.173, data: 0.000) loss: 0.022 
(epoch: 200, iters: 3152, time: 0.175, data: 0.009) loss: 0.101 
(epoch: 200, iters: 3232, time: 0.177, data: 0.030) loss: 0.071 
(epoch: 200, iters: 3312, time: 0.173, data: 0.000) loss: 0.085 
(epoch: 200, iters: 3392, time: 0.173, data: 0.009) loss: 0.314 
(epoch: 200, iters: 3472, time: 0.170, data: 0.000) loss: 0.402 
(epoch: 200, iters: 3552, time: 0.171, data: 0.009) loss: 0.156 
(epoch: 200, iters: 3632, time: 0.171, data: 0.000) loss: 0.370 
(epoch: 200, iters: 3712, time: 0.174, data: 0.000) loss: 0.082 
(epoch: 200, iters: 3792, time: 0.175, data: 0.018) loss: 0.274 
(epoch: 200, iters: 3872, time: 0.203, data: 0.000) loss: 0.121 
(epoch: 200, iters: 3952, time: 0.175, data: 0.009) loss: 0.381 
saving the latest model (epoch 200, total_steps 2032224)
(epoch: 200, iters: 4032, time: 0.205, data: 0.000) loss: 0.421 
(epoch: 200, iters: 4112, time: 0.172, data: 0.000) loss: 0.223 
(epoch: 200, iters: 4192, time: 0.171, data: 0.000) loss: 0.228 
(epoch: 200, iters: 4272, time: 0.174, data: 0.025) loss: 0.448 
(epoch: 200, iters: 4352, time: 0.172, data: 0.000) loss: 0.320 
(epoch: 200, iters: 4432, time: 0.172, data: 0.009) loss: 0.228 
(epoch: 200, iters: 4512, time: 0.169, data: 0.000) loss: 0.282 
(epoch: 200, iters: 4592, time: 0.168, data: 0.015) loss: 0.075 
(epoch: 200, iters: 4672, time: 0.174, data: 0.008) loss: 0.272 
(epoch: 200, iters: 4752, time: 0.171, data: 0.025) loss: 0.235 
(epoch: 200, iters: 4832, time: 0.171, data: 0.000) loss: 0.130 
(epoch: 200, iters: 4912, time: 0.172, data: 0.000) loss: 0.117 
(epoch: 200, iters: 4992, time: 0.202, data: 0.033) loss: 0.168 
(epoch: 200, iters: 5072, time: 0.171, data: 0.000) loss: 0.407 
(epoch: 200, iters: 5152, time: 0.169, data: 0.009) loss: 0.123 
(epoch: 200, iters: 5232, time: 0.168, data: 0.026) loss: 0.384 
(epoch: 200, iters: 5312, time: 0.171, data: 0.000) loss: 0.338 
(epoch: 200, iters: 5392, time: 0.198, data: 0.009) loss: 0.369 
(epoch: 200, iters: 5472, time: 0.173, data: 0.009) loss: 0.068 
(epoch: 200, iters: 5552, time: 0.172, data: 0.008) loss: 0.357 
(epoch: 200, iters: 5632, time: 0.173, data: 0.000) loss: 0.170 
(epoch: 200, iters: 5712, time: 0.173, data: 0.009) loss: 0.256 
(epoch: 200, iters: 5792, time: 0.175, data: 0.000) loss: 0.139 
(epoch: 200, iters: 5872, time: 0.173, data: 0.034) loss: 0.142 
(epoch: 200, iters: 5952, time: 0.169, data: 0.018) loss: 0.050 
(epoch: 200, iters: 6032, time: 0.168, data: 0.000) loss: 0.249 
(epoch: 200, iters: 6112, time: 0.174, data: 0.028) loss: 0.172 
(epoch: 200, iters: 6192, time: 0.204, data: 0.009) loss: 0.301 
(epoch: 200, iters: 6272, time: 0.173, data: 0.000) loss: 0.351 
(epoch: 200, iters: 6352, time: 0.174, data: 0.010) loss: 0.592 
(epoch: 200, iters: 6432, time: 0.175, data: 0.000) loss: 0.113 
(epoch: 200, iters: 6512, time: 0.171, data: 0.020) loss: 0.421 
(epoch: 200, iters: 6592, time: 0.173, data: 0.000) loss: 0.240 
(epoch: 200, iters: 6672, time: 0.171, data: 0.006) loss: 0.115 
(epoch: 200, iters: 6752, time: 0.171, data: 0.000) loss: 0.296 
(epoch: 200, iters: 6832, time: 0.176, data: 0.017) loss: 0.084 
(epoch: 200, iters: 6912, time: 0.206, data: 0.020) loss: 0.072 
(epoch: 200, iters: 6992, time: 0.176, data: 0.000) loss: 0.079 
(epoch: 200, iters: 7072, time: 0.175, data: 0.009) loss: 0.275 
(epoch: 200, iters: 7152, time: 0.172, data: 0.000) loss: 0.172 
(epoch: 200, iters: 7232, time: 0.170, data: 0.033) loss: 0.371 
(epoch: 200, iters: 7312, time: 0.174, data: 0.000) loss: 0.096 
(epoch: 200, iters: 7392, time: 0.173, data: 0.009) loss: 0.097 
(epoch: 200, iters: 7472, time: 0.171, data: 0.000) loss: 0.183 
(epoch: 200, iters: 7552, time: 0.169, data: 0.009) loss: 0.312 
(epoch: 200, iters: 7632, time: 0.175, data: 0.009) loss: 0.326 
(epoch: 200, iters: 7712, time: 0.174, data: 0.022) loss: 0.180 
(epoch: 200, iters: 7792, time: 0.173, data: 0.000) loss: 0.264 
(epoch: 200, iters: 7872, time: 0.172, data: 0.043) loss: 0.060 
(epoch: 200, iters: 7952, time: 0.205, data: 0.000) loss: 0.143 
saving the latest model (epoch 200, total_steps 2036224)
(epoch: 200, iters: 8032, time: 0.171, data: 0.000) loss: 0.175 
(epoch: 200, iters: 8112, time: 0.177, data: 0.025) loss: 0.670 
(epoch: 200, iters: 8192, time: 0.172, data: 0.000) loss: 0.728 
(epoch: 200, iters: 8272, time: 0.171, data: 0.008) loss: 0.367 
(epoch: 200, iters: 8352, time: 0.170, data: 0.000) loss: 0.554 
(epoch: 200, iters: 8432, time: 0.171, data: 0.000) loss: 0.120 
(epoch: 200, iters: 8512, time: 0.171, data: 0.034) loss: 0.157 
(epoch: 200, iters: 8592, time: 0.171, data: 0.000) loss: 0.330 
(epoch: 200, iters: 8672, time: 0.169, data: 0.009) loss: 0.423 
(epoch: 200, iters: 8752, time: 0.171, data: 0.000) loss: 0.081 
(epoch: 200, iters: 8832, time: 0.170, data: 0.021) loss: 0.195 
(epoch: 200, iters: 8912, time: 0.170, data: 0.009) loss: 0.267 
(epoch: 200, iters: 8992, time: 0.173, data: 0.000) loss: 0.139 
(epoch: 200, iters: 9072, time: 0.169, data: 0.017) loss: 0.107 
(epoch: 200, iters: 9152, time: 0.173, data: 0.000) loss: 0.052 
(epoch: 200, iters: 9232, time: 0.174, data: 0.000) loss: 0.286 
(epoch: 200, iters: 9312, time: 0.171, data: 0.000) loss: 0.207 
(epoch: 200, iters: 9392, time: 0.172, data: 0.008) loss: 0.122 
(epoch: 200, iters: 9472, time: 0.170, data: 0.009) loss: 0.062 
(epoch: 200, iters: 9552, time: 0.173, data: 0.035) loss: 0.173 
(epoch: 200, iters: 9632, time: 0.199, data: 0.000) loss: 0.222 
(epoch: 200, iters: 9712, time: 0.170, data: 0.017) loss: 0.290 
(epoch: 200, iters: 9792, time: 0.168, data: 0.000) loss: 0.207 
(epoch: 200, iters: 9872, time: 0.172, data: 0.042) loss: 0.130 
(epoch: 200, iters: 9952, time: 0.172, data: 0.000) loss: 0.129 
(epoch: 200, iters: 10032, time: 0.204, data: 0.000) loss: 0.330 
(epoch: 200, iters: 10112, time: 0.173, data: 0.005) loss: 0.074 
(epoch: 200, iters: 10192, time: 0.101, data: 0.010) loss: 0.038 
saving the model at the end of epoch 200, iters 2038400
End of epoch 200 / 200 	 Time Taken: 1795 sec
learning rate = -0.0000020
